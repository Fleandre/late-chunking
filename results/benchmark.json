[
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.85197,
                    "ndcg_at_3": 0.8951,
                    "ndcg_at_5": 0.90223,
                    "ndcg_at_10": 0.90788,
                    "ndcg_at_20": 0.91056,
                    "map_at_1": 0.85197,
                    "map_at_3": 0.88493,
                    "map_at_5": 0.88891,
                    "map_at_10": 0.89129,
                    "map_at_20": 0.89204,
                    "recall_at_1": 0.85197,
                    "recall_at_3": 0.92436,
                    "recall_at_5": 0.94155,
                    "recall_at_10": 0.95878,
                    "recall_at_20": 0.96931,
                    "precision_at_1": 0.85197,
                    "precision_at_3": 0.30812,
                    "precision_at_5": 0.18831,
                    "precision_at_10": 0.09588,
                    "precision_at_20": 0.04847,
                    "mrr_at_1": 0.8519653564290472,
                    "mrr_at_3": 0.8849285661410912,
                    "mrr_at_5": 0.8889081353171977,
                    "mrr_at_10": 0.8912944985529949,
                    "mrr_at_20": 0.8920366742705277,
                    "main_score": 0.90788,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 42.63316512107849,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.48653,
                    "ndcg_at_3": 0.55378,
                    "ndcg_at_5": 0.56973,
                    "ndcg_at_10": 0.58665,
                    "ndcg_at_20": 0.59835,
                    "map_at_1": 0.48647,
                    "map_at_3": 0.53744,
                    "map_at_5": 0.54628,
                    "map_at_10": 0.55331,
                    "map_at_20": 0.55652,
                    "recall_at_1": 0.48647,
                    "recall_at_3": 0.60079,
                    "recall_at_5": 0.63955,
                    "recall_at_10": 0.69159,
                    "recall_at_20": 0.73784,
                    "precision_at_1": 0.48653,
                    "precision_at_3": 0.20035,
                    "precision_at_5": 0.128,
                    "precision_at_10": 0.06922,
                    "precision_at_20": 0.03693,
                    "mrr_at_1": 0.48653077537969625,
                    "mrr_at_3": 0.5375699440447703,
                    "mrr_at_5": 0.5464588329336633,
                    "mrr_at_10": 0.5535047834748174,
                    "mrr_at_20": 0.5567241976368056,
                    "main_score": 0.58665,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 190.18594622612,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.23,
                    "ndcg_at_3": 0.18469,
                    "ndcg_at_5": 0.15854,
                    "ndcg_at_10": 0.18883,
                    "map_at_1": 0.04668,
                    "map_at_3": 0.08354,
                    "map_at_5": 0.09738,
                    "map_at_10": 0.11187,
                    "recall_at_1": 0.04668,
                    "recall_at_3": 0.10463,
                    "recall_at_5": 0.13913,
                    "recall_at_10": 0.1952,
                    "precision_at_1": 0.23,
                    "precision_at_3": 0.172,
                    "precision_at_5": 0.1372,
                    "precision_at_10": 0.0961,
                    "mrr_at_1": 0.23,
                    "mrr_at_3": 0.3000000000000001,
                    "mrr_at_5": 0.31755,
                    "mrr_at_10": 0.3315734126984127,
                    "main_score": 0.18883,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 406.36099100112915,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.341,
                    "ndcg_at_3": 0.42668,
                    "ndcg_at_5": 0.45289,
                    "ndcg_at_10": 0.4813,
                    "ndcg_at_20": 0.49939,
                    "map_at_1": 0.341,
                    "map_at_3": 0.4055,
                    "map_at_5": 0.4202,
                    "map_at_10": 0.43189,
                    "map_at_20": 0.43679,
                    "recall_at_1": 0.341,
                    "recall_at_3": 0.488,
                    "recall_at_5": 0.551,
                    "recall_at_10": 0.639,
                    "recall_at_20": 0.711,
                    "precision_at_1": 0.341,
                    "precision_at_3": 0.16267,
                    "precision_at_5": 0.1102,
                    "precision_at_10": 0.0639,
                    "precision_at_20": 0.03555,
                    "mrr_at_1": 0.34,
                    "mrr_at_3": 0.4049999999999997,
                    "mrr_at_5": 0.4196999999999995,
                    "mrr_at_10": 0.4314126984126982,
                    "mrr_at_20": 0.4363154683251043,
                    "main_score": 0.4813,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 219.01354098320007,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.17994,
                    "ndcg_at_3": 0.28387,
                    "ndcg_at_5": 0.33418,
                    "ndcg_at_10": 0.39561,
                    "ndcg_at_20": 0.43389,
                    "map_at_1": 0.17994,
                    "map_at_3": 0.25747,
                    "map_at_5": 0.28535,
                    "map_at_10": 0.31085,
                    "map_at_20": 0.32152,
                    "recall_at_1": 0.17994,
                    "recall_at_3": 0.3606,
                    "recall_at_5": 0.48293,
                    "recall_at_10": 0.67212,
                    "recall_at_20": 0.82219,
                    "precision_at_1": 0.17994,
                    "precision_at_3": 0.1202,
                    "precision_at_5": 0.09659,
                    "precision_at_10": 0.06721,
                    "precision_at_20": 0.04111,
                    "mrr_at_1": 0.17994310099573257,
                    "mrr_at_3": 0.2574679943100994,
                    "mrr_at_5": 0.28524182076813587,
                    "mrr_at_10": 0.3109146740725685,
                    "mrr_at_20": 0.32152551029343357,
                    "main_score": 0.39561,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 38.00299096107483,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.17852,
                    "ndcg_at_3": 0.28226,
                    "ndcg_at_5": 0.32927,
                    "ndcg_at_10": 0.39211,
                    "map_at_1": 0.17852,
                    "map_at_3": 0.25581,
                    "map_at_5": 0.2818,
                    "map_at_10": 0.3079,
                    "recall_at_1": 0.17852,
                    "recall_at_3": 0.35917,
                    "recall_at_5": 0.47368,
                    "recall_at_10": 0.66714,
                    "precision_at_1": 0.17852,
                    "precision_at_3": 0.11972,
                    "precision_at_5": 0.09474,
                    "precision_at_10": 0.06671,
                    "mrr_at_1": 0.17923186344238975,
                    "mrr_at_3": 0.25628259838786144,
                    "mrr_at_5": 0.2822427690848737,
                    "mrr_at_10": 0.30825910496963105,
                    "main_score": 0.39211,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 49.52971816062927,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.486,
                    "ndcg_at_3": 0.58882,
                    "ndcg_at_5": 0.61373,
                    "ndcg_at_10": 0.63951,
                    "ndcg_at_20": 0.65447,
                    "map_at_1": 0.486,
                    "map_at_3": 0.56383,
                    "map_at_5": 0.57753,
                    "map_at_10": 0.58831,
                    "map_at_20": 0.59244,
                    "recall_at_1": 0.486,
                    "recall_at_3": 0.661,
                    "recall_at_5": 0.722,
                    "recall_at_10": 0.801,
                    "recall_at_20": 0.86,
                    "precision_at_1": 0.486,
                    "precision_at_3": 0.22033,
                    "precision_at_5": 0.1444,
                    "precision_at_10": 0.0801,
                    "precision_at_20": 0.043,
                    "mrr_at_1": 0.486,
                    "mrr_at_3": 0.5638333333333332,
                    "mrr_at_5": 0.5775333333333331,
                    "mrr_at_10": 0.5883059523809525,
                    "mrr_at_20": 0.5924390182873543,
                    "main_score": 0.63951,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 50.91445541381836,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.415,
                    "ndcg_at_3": 0.5216,
                    "ndcg_at_5": 0.54725,
                    "ndcg_at_10": 0.56793,
                    "ndcg_at_20": 0.58913,
                    "map_at_1": 0.415,
                    "map_at_3": 0.49583,
                    "map_at_5": 0.51013,
                    "map_at_10": 0.51866,
                    "map_at_20": 0.52446,
                    "recall_at_1": 0.415,
                    "recall_at_3": 0.596,
                    "recall_at_5": 0.658,
                    "recall_at_10": 0.722,
                    "recall_at_20": 0.806,
                    "precision_at_1": 0.415,
                    "precision_at_3": 0.19867,
                    "precision_at_5": 0.1316,
                    "precision_at_10": 0.0722,
                    "precision_at_20": 0.0403,
                    "mrr_at_1": 0.414,
                    "mrr_at_3": 0.4953333333333328,
                    "mrr_at_5": 0.5096333333333326,
                    "mrr_at_10": 0.5181551587301583,
                    "mrr_at_20": 0.5239558302163946,
                    "main_score": 0.56793,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 73.30342102050781,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.30683,
                    "ndcg_at_3": 0.30966,
                    "ndcg_at_5": 0.32318,
                    "ndcg_at_10": 0.35029,
                    "ndcg_at_20": 0.37419,
                    "map_at_1": 0.19569,
                    "map_at_3": 0.26098,
                    "map_at_5": 0.27627,
                    "map_at_10": 0.29167,
                    "map_at_20": 0.29997,
                    "recall_at_1": 0.19569,
                    "recall_at_3": 0.3091,
                    "recall_at_5": 0.35713,
                    "recall_at_10": 0.43688,
                    "recall_at_20": 0.51812,
                    "precision_at_1": 0.30683,
                    "precision_at_3": 0.17754,
                    "precision_at_5": 0.12573,
                    "precision_at_10": 0.07899,
                    "precision_at_20": 0.04751,
                    "mrr_at_1": 0.30682670667666917,
                    "mrr_at_3": 0.35817287655247104,
                    "mrr_at_5": 0.36938818037842797,
                    "mrr_at_10": 0.38001246343331835,
                    "mrr_at_20": 0.38522362311148994,
                    "main_score": 0.35029,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 605.5062255859375,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.46,
                    "ndcg_at_3": 0.51753,
                    "ndcg_at_5": 0.52618,
                    "ndcg_at_10": 0.54264,
                    "ndcg_at_20": 0.55176,
                    "map_at_1": 0.46,
                    "map_at_3": 0.50383,
                    "map_at_5": 0.50863,
                    "map_at_10": 0.51559,
                    "map_at_20": 0.5181,
                    "recall_at_1": 0.46,
                    "recall_at_3": 0.557,
                    "recall_at_5": 0.578,
                    "recall_at_10": 0.628,
                    "recall_at_20": 0.664,
                    "precision_at_1": 0.46,
                    "precision_at_3": 0.18567,
                    "precision_at_5": 0.1156,
                    "precision_at_10": 0.0628,
                    "precision_at_20": 0.0332,
                    "mrr_at_1": 0.462,
                    "mrr_at_3": 0.5048333333333331,
                    "mrr_at_5": 0.509633333333333,
                    "mrr_at_10": 0.5165936507936508,
                    "mrr_at_20": 0.5191043015592939,
                    "main_score": 0.54264,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 214.05795168876648,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.48493,
                    "ndcg_at_3": 0.5477,
                    "ndcg_at_5": 0.56366,
                    "ndcg_at_10": 0.57969,
                    "ndcg_at_20": 0.59157,
                    "map_at_1": 0.48479,
                    "map_at_3": 0.53245,
                    "map_at_5": 0.54129,
                    "map_at_10": 0.54796,
                    "map_at_20": 0.55125,
                    "recall_at_1": 0.48479,
                    "recall_at_3": 0.59152,
                    "recall_at_5": 0.63034,
                    "recall_at_10": 0.67961,
                    "recall_at_20": 0.72628,
                    "precision_at_1": 0.48493,
                    "precision_at_3": 0.19728,
                    "precision_at_5": 0.12616,
                    "precision_at_10": 0.06803,
                    "precision_at_20": 0.03636,
                    "mrr_at_1": 0.48492713116390496,
                    "mrr_at_3": 0.5326345910694135,
                    "mrr_at_5": 0.5414926465695171,
                    "mrr_at_10": 0.5481642725633629,
                    "mrr_at_20": 0.5514781932349822,
                    "main_score": 0.57969,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 73.37784624099731,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.6914,
                    "ndcg_at_3": 0.75939,
                    "ndcg_at_5": 0.78024,
                    "ndcg_at_10": 0.79659,
                    "ndcg_at_20": 0.80322,
                    "map_at_1": 0.66836,
                    "map_at_3": 0.73971,
                    "map_at_5": 0.75211,
                    "map_at_10": 0.75921,
                    "map_at_20": 0.76119,
                    "recall_at_1": 0.66836,
                    "recall_at_3": 0.80782,
                    "recall_at_5": 0.85744,
                    "recall_at_10": 0.90666,
                    "recall_at_20": 0.93197,
                    "precision_at_1": 0.6914,
                    "precision_at_3": 0.28496,
                    "precision_at_5": 0.18206,
                    "precision_at_10": 0.09633,
                    "precision_at_20": 0.04957,
                    "mrr_at_1": 0.691404011461318,
                    "mrr_at_3": 0.7478510028653297,
                    "mrr_at_5": 0.7585530085959861,
                    "mrr_at_10": 0.7650929526538406,
                    "mrr_at_20": 0.7667901883244139,
                    "main_score": 0.79659,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 277.4924998283386,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1536,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.341,
                    "ndcg_at_3": 0.42668,
                    "ndcg_at_5": 0.45332,
                    "ndcg_at_10": 0.48169,
                    "ndcg_at_20": 0.49952,
                    "map_at_1": 0.341,
                    "map_at_3": 0.4055,
                    "map_at_5": 0.42045,
                    "map_at_10": 0.4321,
                    "map_at_20": 0.43693,
                    "recall_at_1": 0.341,
                    "recall_at_3": 0.488,
                    "recall_at_5": 0.552,
                    "recall_at_10": 0.64,
                    "recall_at_20": 0.711,
                    "precision_at_1": 0.341,
                    "precision_at_3": 0.16267,
                    "precision_at_5": 0.1104,
                    "precision_at_10": 0.064,
                    "precision_at_20": 0.03555,
                    "mrr_at_1": 0.341,
                    "mrr_at_3": 0.4054999999999997,
                    "mrr_at_5": 0.42044999999999955,
                    "mrr_at_10": 0.43209603174603156,
                    "mrr_at_20": 0.4369323172656374,
                    "main_score": 0.48169,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 224.03952479362488,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.221,
                    "ndcg_at_3": 0.1755,
                    "ndcg_at_5": 0.15082,
                    "ndcg_at_10": 0.17922,
                    "ndcg_at_20": 0.20429,
                    "map_at_1": 0.04488,
                    "map_at_3": 0.07829,
                    "map_at_5": 0.09157,
                    "map_at_10": 0.10564,
                    "map_at_20": 0.11439,
                    "recall_at_1": 0.04488,
                    "recall_at_3": 0.09913,
                    "recall_at_5": 0.13243,
                    "recall_at_10": 0.18418,
                    "recall_at_20": 0.24283,
                    "precision_at_1": 0.221,
                    "precision_at_3": 0.163,
                    "precision_at_5": 0.1304,
                    "precision_at_10": 0.0908,
                    "precision_at_20": 0.0599,
                    "mrr_at_1": 0.221,
                    "mrr_at_3": 0.28966666666666663,
                    "mrr_at_5": 0.30741666666666634,
                    "mrr_at_10": 0.3199626984126981,
                    "mrr_at_20": 0.326449051894098,
                    "main_score": 0.17922,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 117.79606103897095,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.18492,
                    "ndcg_at_3": 0.29829,
                    "ndcg_at_5": 0.35331,
                    "ndcg_at_10": 0.42198,
                    "ndcg_at_20": 0.45979,
                    "map_at_1": 0.18492,
                    "map_at_3": 0.27015,
                    "map_at_5": 0.30049,
                    "map_at_10": 0.32864,
                    "map_at_20": 0.33923,
                    "recall_at_1": 0.18492,
                    "recall_at_3": 0.3798,
                    "recall_at_5": 0.51422,
                    "recall_at_10": 0.7276,
                    "recall_at_20": 0.87553,
                    "precision_at_1": 0.18492,
                    "precision_at_3": 0.1266,
                    "precision_at_5": 0.10284,
                    "precision_at_10": 0.07276,
                    "precision_at_20": 0.04378,
                    "mrr_at_1": 0.18492176386913228,
                    "mrr_at_3": 0.2700331910858224,
                    "mrr_at_5": 0.3003674727358929,
                    "mrr_at_10": 0.32852316602316545,
                    "mrr_at_20": 0.339115953442985,
                    "main_score": 0.42198,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 76.10277009010315,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "6e346642246bfb4928c560ee08640dc84d074e8c",
        "task_name": "LEMBWikimQARetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.93667,
                    "ndcg_at_3": 0.96139,
                    "ndcg_at_5": 0.96555,
                    "ndcg_at_10": 0.96555,
                    "ndcg_at_20": 0.96636,
                    "map_at_1": 0.93667,
                    "map_at_3": 0.955,
                    "map_at_5": 0.95733,
                    "map_at_10": 0.95733,
                    "map_at_20": 0.95754,
                    "recall_at_1": 0.93667,
                    "recall_at_3": 0.98,
                    "recall_at_5": 0.99,
                    "recall_at_10": 0.99,
                    "recall_at_20": 0.99333,
                    "precision_at_1": 0.93667,
                    "precision_at_3": 0.32667,
                    "precision_at_5": 0.198,
                    "precision_at_10": 0.099,
                    "precision_at_20": 0.04967,
                    "mrr_at_1": 0.9366666666666666,
                    "mrr_at_3": 0.9549999999999998,
                    "mrr_at_5": 0.9573333333333333,
                    "mrr_at_10": 0.9573333333333333,
                    "mrr_at_20": 0.9575416666666666,
                    "main_score": 0.96555,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 44.35814142227173,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.556,
                    "ndcg_at_3": 0.665,
                    "ndcg_at_5": 0.6897,
                    "ndcg_at_10": 0.70625,
                    "ndcg_at_20": 0.71877,
                    "map_at_1": 0.556,
                    "map_at_3": 0.63867,
                    "map_at_5": 0.65237,
                    "map_at_10": 0.65923,
                    "map_at_20": 0.6626,
                    "recall_at_1": 0.556,
                    "recall_at_3": 0.741,
                    "recall_at_5": 0.801,
                    "recall_at_10": 0.852,
                    "recall_at_20": 0.902,
                    "precision_at_1": 0.556,
                    "precision_at_3": 0.247,
                    "precision_at_5": 0.1602,
                    "precision_at_10": 0.0852,
                    "precision_at_20": 0.0451,
                    "mrr_at_1": 0.556,
                    "mrr_at_3": 0.6386666666666667,
                    "mrr_at_5": 0.6523666666666668,
                    "mrr_at_10": 0.6592285714285714,
                    "mrr_at_20": 0.6626044653832577,
                    "main_score": 0.70625,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 37.313239097595215,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.26496,
                    "ndcg_at_3": 0.33139,
                    "ndcg_at_5": 0.35234,
                    "ndcg_at_10": 0.37381,
                    "ndcg_at_20": 0.39129,
                    "map_at_1": 0.26445,
                    "map_at_3": 0.31491,
                    "map_at_5": 0.32654,
                    "map_at_10": 0.33546,
                    "map_at_20": 0.3403,
                    "recall_at_1": 0.26445,
                    "recall_at_3": 0.37834,
                    "recall_at_5": 0.42913,
                    "recall_at_10": 0.49511,
                    "recall_at_20": 0.56376,
                    "precision_at_1": 0.26496,
                    "precision_at_3": 0.12653,
                    "precision_at_5": 0.08621,
                    "precision_at_10": 0.04984,
                    "precision_at_20": 0.02845,
                    "mrr_at_1": 0.26496079240610815,
                    "mrr_at_3": 0.3155116997461159,
                    "mrr_at_5": 0.32719143561074643,
                    "mrr_at_10": 0.33611155776859436,
                    "mrr_at_20": 0.3409140576778051,
                    "main_score": 0.37381,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 37.35997724533081,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.67249,
                    "ndcg_at_3": 0.74342,
                    "ndcg_at_5": 0.76278,
                    "ndcg_at_10": 0.77963,
                    "ndcg_at_20": 0.78816,
                    "map_at_1": 0.65054,
                    "map_at_3": 0.72269,
                    "map_at_5": 0.7341,
                    "map_at_10": 0.74156,
                    "map_at_20": 0.74406,
                    "recall_at_1": 0.65054,
                    "recall_at_3": 0.79454,
                    "recall_at_5": 0.8406,
                    "recall_at_10": 0.89113,
                    "recall_at_20": 0.92387,
                    "precision_at_1": 0.67249,
                    "precision_at_3": 0.27956,
                    "precision_at_5": 0.17817,
                    "precision_at_10": 0.09466,
                    "precision_at_20": 0.04915,
                    "mrr_at_1": 0.6724928366762177,
                    "mrr_at_3": 0.7313514804202483,
                    "mrr_at_5": 0.7413514804202456,
                    "mrr_at_10": 0.7478446354664099,
                    "mrr_at_20": 0.7500416546085089,
                    "main_score": 0.77963,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 86.54686164855957,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.48148,
                    "ndcg_at_3": 0.43116,
                    "ndcg_at_5": 0.44165,
                    "ndcg_at_10": 0.47275,
                    "ndcg_at_20": 0.50065,
                    "map_at_1": 0.2381,
                    "map_at_3": 0.33932,
                    "map_at_5": 0.36527,
                    "map_at_10": 0.39012,
                    "map_at_20": 0.40182,
                    "recall_at_1": 0.2381,
                    "recall_at_3": 0.38145,
                    "recall_at_5": 0.44739,
                    "recall_at_10": 0.54123,
                    "recall_at_20": 0.62826,
                    "precision_at_1": 0.48148,
                    "precision_at_3": 0.28961,
                    "precision_at_5": 0.2108,
                    "precision_at_10": 0.1341,
                    "precision_at_20": 0.07855,
                    "mrr_at_1": 0.48148148148148145,
                    "mrr_at_3": 0.5306069958847736,
                    "mrr_at_5": 0.5458847736625513,
                    "mrr_at_10": 0.5573106505976877,
                    "mrr_at_20": 0.5619812090588449,
                    "main_score": 0.47275,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 618.2335934638977,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.69336,
                    "ndcg_at_3": 0.77446,
                    "ndcg_at_5": 0.79327,
                    "ndcg_at_10": 0.80512,
                    "map_at_1": 0.69178,
                    "map_at_3": 0.75474,
                    "map_at_5": 0.76513,
                    "map_at_10": 0.7703,
                    "recall_at_1": 0.69178,
                    "recall_at_3": 0.83087,
                    "recall_at_5": 0.87619,
                    "recall_at_10": 0.91201,
                    "precision_at_1": 0.69336,
                    "precision_at_3": 0.27819,
                    "precision_at_5": 0.1764,
                    "precision_at_10": 0.0921,
                    "mrr_at_1": 0.6933614330874605,
                    "mrr_at_3": 0.7551808921671936,
                    "mrr_at_5": 0.765770987003864,
                    "mrr_at_10": 0.770437971465369,
                    "main_score": 0.80512,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2492.4693310260773,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.486,
                    "ndcg_at_3": 0.58882,
                    "ndcg_at_5": 0.61373,
                    "ndcg_at_10": 0.63951,
                    "ndcg_at_20": 0.65447,
                    "map_at_1": 0.486,
                    "map_at_3": 0.56383,
                    "map_at_5": 0.57753,
                    "map_at_10": 0.58831,
                    "map_at_20": 0.59244,
                    "recall_at_1": 0.486,
                    "recall_at_3": 0.661,
                    "recall_at_5": 0.722,
                    "recall_at_10": 0.801,
                    "recall_at_20": 0.86,
                    "precision_at_1": 0.486,
                    "precision_at_3": 0.22033,
                    "precision_at_5": 0.1444,
                    "precision_at_10": 0.0801,
                    "precision_at_20": 0.043,
                    "mrr_at_1": 0.486,
                    "mrr_at_3": 0.5638333333333332,
                    "mrr_at_5": 0.5775333333333331,
                    "mrr_at_10": 0.5883059523809525,
                    "mrr_at_20": 0.5924390182873543,
                    "main_score": 0.63951,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 50.970338582992554,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.33179,
                    "ndcg_at_3": 0.29435,
                    "ndcg_at_5": 0.30991,
                    "ndcg_at_10": 0.34132,
                    "ndcg_at_20": 0.36791,
                    "map_at_1": 0.1605,
                    "map_at_3": 0.22262,
                    "map_at_5": 0.24332,
                    "map_at_10": 0.26319,
                    "map_at_20": 0.27355,
                    "recall_at_1": 0.1605,
                    "recall_at_3": 0.26065,
                    "recall_at_5": 0.32229,
                    "recall_at_10": 0.41884,
                    "recall_at_20": 0.49963,
                    "precision_at_1": 0.33179,
                    "precision_at_3": 0.19753,
                    "precision_at_5": 0.15062,
                    "precision_at_10": 0.09815,
                    "precision_at_20": 0.06019,
                    "mrr_at_1": 0.3317901234567901,
                    "mrr_at_3": 0.3873456790123458,
                    "mrr_at_5": 0.40601851851851845,
                    "mrr_at_10": 0.41934401332549454,
                    "mrr_at_20": 0.4237111005715521,
                    "main_score": 0.34132,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 773.2870125770569,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.47318,
                    "ndcg_at_3": 0.56191,
                    "ndcg_at_5": 0.58484,
                    "ndcg_at_10": 0.60473,
                    "ndcg_at_20": 0.61804,
                    "map_at_1": 0.47312,
                    "map_at_3": 0.5404,
                    "map_at_5": 0.55315,
                    "map_at_10": 0.5614,
                    "map_at_20": 0.56507,
                    "recall_at_1": 0.47312,
                    "recall_at_3": 0.62399,
                    "recall_at_5": 0.67953,
                    "recall_at_10": 0.74079,
                    "recall_at_20": 0.79332,
                    "precision_at_1": 0.47318,
                    "precision_at_3": 0.20805,
                    "precision_at_5": 0.13595,
                    "precision_at_10": 0.0741,
                    "precision_at_20": 0.03968,
                    "mrr_at_1": 0.47318105992557424,
                    "mrr_at_3": 0.5404476239360209,
                    "mrr_at_5": 0.5532010565037154,
                    "mrr_at_10": 0.5614536549895329,
                    "mrr_at_20": 0.56512258487786,
                    "main_score": 0.60473,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 83.17398047447205,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.489,
                    "ndcg_at_3": 0.54109,
                    "ndcg_at_5": 0.55422,
                    "ndcg_at_10": 0.5675,
                    "ndcg_at_20": 0.57513,
                    "map_at_1": 0.489,
                    "map_at_3": 0.52833,
                    "map_at_5": 0.53558,
                    "map_at_10": 0.54089,
                    "map_at_20": 0.54301,
                    "recall_at_1": 0.489,
                    "recall_at_3": 0.578,
                    "recall_at_5": 0.61,
                    "recall_at_10": 0.652,
                    "recall_at_20": 0.682,
                    "precision_at_1": 0.489,
                    "precision_at_3": 0.19267,
                    "precision_at_5": 0.122,
                    "precision_at_10": 0.0652,
                    "precision_at_20": 0.0341,
                    "mrr_at_1": 0.49,
                    "mrr_at_3": 0.528833333333333,
                    "mrr_at_5": 0.536083333333333,
                    "mrr_at_10": 0.5413936507936508,
                    "mrr_at_20": 0.5435140310841546,
                    "main_score": 0.5675,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 202.95303654670715,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.87226,
                    "ndcg_at_3": 0.82962,
                    "ndcg_at_5": 0.81395,
                    "ndcg_at_10": 0.81254,
                    "ndcg_at_20": 0.83149,
                    "map_at_1": 0.2622,
                    "map_at_3": 0.51545,
                    "map_at_5": 0.63231,
                    "map_at_10": 0.73043,
                    "map_at_20": 0.75776,
                    "recall_at_1": 0.2622,
                    "recall_at_3": 0.53421,
                    "recall_at_5": 0.67006,
                    "recall_at_10": 0.80159,
                    "recall_at_20": 0.86381,
                    "precision_at_1": 0.87226,
                    "precision_at_3": 0.72668,
                    "precision_at_5": 0.60756,
                    "precision_at_10": 0.40417,
                    "precision_at_20": 0.22559,
                    "mrr_at_1": 0.872260213922497,
                    "mrr_at_3": 0.8977657957799974,
                    "mrr_at_5": 0.9010886083347955,
                    "mrr_at_10": 0.9030323778351143,
                    "mrr_at_20": 0.9037788602606673,
                    "main_score": 0.81254,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2511.1328971385956,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.31208,
                    "ndcg_at_3": 0.31368,
                    "ndcg_at_5": 0.33017,
                    "ndcg_at_10": 0.35911,
                    "ndcg_at_20": 0.38383,
                    "map_at_1": 0.20149,
                    "map_at_3": 0.26555,
                    "map_at_5": 0.28285,
                    "map_at_10": 0.29931,
                    "map_at_20": 0.30793,
                    "recall_at_1": 0.20149,
                    "recall_at_3": 0.31139,
                    "recall_at_5": 0.36535,
                    "recall_at_10": 0.44954,
                    "recall_at_20": 0.53365,
                    "precision_at_1": 0.31208,
                    "precision_at_3": 0.17879,
                    "precision_at_5": 0.12868,
                    "precision_at_10": 0.0814,
                    "precision_at_20": 0.04909,
                    "mrr_at_1": 0.31207801950487624,
                    "mrr_at_3": 0.36292406434942026,
                    "mrr_at_5": 0.3755147120113362,
                    "mrr_at_10": 0.38662889928831373,
                    "mrr_at_20": 0.3920168695453837,
                    "main_score": 0.35911,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 415.3475613594055,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.37024,
                    "ndcg_at_3": 0.44893,
                    "ndcg_at_5": 0.47005,
                    "ndcg_at_10": 0.49108,
                    "ndcg_at_20": 0.50607,
                    "map_at_1": 0.36966,
                    "map_at_3": 0.42944,
                    "map_at_5": 0.44119,
                    "map_at_10": 0.44995,
                    "map_at_20": 0.45407,
                    "recall_at_1": 0.36966,
                    "recall_at_3": 0.50457,
                    "recall_at_5": 0.55564,
                    "recall_at_10": 0.62017,
                    "recall_at_20": 0.6791,
                    "precision_at_1": 0.37024,
                    "precision_at_3": 0.16864,
                    "precision_at_5": 0.11156,
                    "precision_at_10": 0.06239,
                    "precision_at_20": 0.03423,
                    "mrr_at_1": 0.37024247428871704,
                    "mrr_at_3": 0.43014163100868597,
                    "mrr_at_5": 0.4419068888722131,
                    "mrr_at_10": 0.4506288852903285,
                    "mrr_at_20": 0.454727644070611,
                    "main_score": 0.49108,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 139.27937650680542,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.44553,
                    "ndcg_at_3": 0.52689,
                    "ndcg_at_5": 0.54898,
                    "ndcg_at_10": 0.57056,
                    "ndcg_at_20": 0.58496,
                    "map_at_1": 0.44541,
                    "map_at_3": 0.50697,
                    "map_at_5": 0.51922,
                    "map_at_10": 0.52821,
                    "map_at_20": 0.53219,
                    "recall_at_1": 0.44541,
                    "recall_at_3": 0.58438,
                    "recall_at_5": 0.63802,
                    "recall_at_10": 0.70435,
                    "recall_at_20": 0.76107,
                    "precision_at_1": 0.44553,
                    "precision_at_3": 0.19485,
                    "precision_at_5": 0.12767,
                    "precision_at_10": 0.07047,
                    "precision_at_20": 0.03808,
                    "mrr_at_1": 0.4455280379828051,
                    "mrr_at_3": 0.5070683091663568,
                    "mrr_at_5": 0.5193212926130464,
                    "mrr_at_10": 0.52830964500092,
                    "mrr_at_20": 0.5322951049052195,
                    "main_score": 0.57056,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 43.666592836380005,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.71596,
                    "ndcg_at_3": 0.77908,
                    "ndcg_at_5": 0.79125,
                    "ndcg_at_10": 0.80221,
                    "ndcg_at_20": 0.80952,
                    "map_at_1": 0.71559,
                    "map_at_3": 0.76406,
                    "map_at_5": 0.77083,
                    "map_at_10": 0.77541,
                    "map_at_20": 0.77742,
                    "recall_at_1": 0.71559,
                    "recall_at_3": 0.8221,
                    "recall_at_5": 0.85157,
                    "recall_at_10": 0.88521,
                    "recall_at_20": 0.91403,
                    "precision_at_1": 0.71596,
                    "precision_at_3": 0.27431,
                    "precision_at_5": 0.17052,
                    "precision_at_10": 0.08865,
                    "precision_at_20": 0.04578,
                    "mrr_at_1": 0.7159591333450767,
                    "mrr_at_3": 0.7642632063100525,
                    "mrr_at_5": 0.771011195271364,
                    "mrr_at_10": 0.7755748154858586,
                    "mrr_at_20": 0.7775816822404208,
                    "main_score": 0.80221,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 135.55582308769226,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.46061,
                    "ndcg_at_3": 0.52451,
                    "ndcg_at_5": 0.54096,
                    "ndcg_at_10": 0.55781,
                    "ndcg_at_20": 0.56973,
                    "map_at_1": 0.46047,
                    "map_at_3": 0.50901,
                    "map_at_5": 0.51817,
                    "map_at_10": 0.52515,
                    "map_at_20": 0.52842,
                    "recall_at_1": 0.46047,
                    "recall_at_3": 0.56899,
                    "recall_at_5": 0.60891,
                    "recall_at_10": 0.66082,
                    "recall_at_20": 0.70788,
                    "precision_at_1": 0.46061,
                    "precision_at_3": 0.18978,
                    "precision_at_5": 0.12187,
                    "precision_at_10": 0.06615,
                    "precision_at_20": 0.03544,
                    "mrr_at_1": 0.46061090037931723,
                    "mrr_at_3": 0.5092034338191302,
                    "mrr_at_5": 0.5183649431024236,
                    "mrr_at_10": 0.5253548850165018,
                    "mrr_at_20": 0.5286429092046397,
                    "main_score": 0.55781,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 92.77248883247375,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.74585,
                    "ndcg_at_3": 0.78343,
                    "ndcg_at_5": 0.79002,
                    "ndcg_at_10": 0.79567,
                    "map_at_1": 0.74585,
                    "map_at_3": 0.77456,
                    "map_at_5": 0.77821,
                    "map_at_10": 0.78057,
                    "recall_at_1": 0.74585,
                    "recall_at_3": 0.80895,
                    "recall_at_5": 0.82495,
                    "recall_at_10": 0.8423,
                    "precision_at_1": 0.74585,
                    "precision_at_3": 0.26965,
                    "precision_at_5": 0.16499,
                    "precision_at_10": 0.08423,
                    "mrr_at_1": 0.74585,
                    "mrr_at_3": 0.7745583333333366,
                    "mrr_at_5": 0.7782108333333386,
                    "mrr_at_10": 0.7805660317460361,
                    "main_score": 0.79567,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 767.2698931694031,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.66553,
                    "ndcg_at_3": 0.72968,
                    "ndcg_at_5": 0.74168,
                    "ndcg_at_10": 0.75329,
                    "ndcg_at_20": 0.76145,
                    "map_at_1": 0.66509,
                    "map_at_3": 0.7145,
                    "map_at_5": 0.72119,
                    "map_at_10": 0.726,
                    "map_at_20": 0.72827,
                    "recall_at_1": 0.66509,
                    "recall_at_3": 0.77317,
                    "recall_at_5": 0.80224,
                    "recall_at_10": 0.83798,
                    "recall_at_20": 0.87012,
                    "precision_at_1": 0.66553,
                    "precision_at_3": 0.25803,
                    "precision_at_5": 0.16068,
                    "precision_at_10": 0.08393,
                    "precision_at_20": 0.04359,
                    "mrr_at_1": 0.6655314151497358,
                    "mrr_at_3": 0.7146652965355194,
                    "mrr_at_5": 0.7213182618907804,
                    "mrr_at_10": 0.7261235541388203,
                    "mrr_at_20": 0.728370883350103,
                    "main_score": 0.75329,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 126.93000221252441,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.41975,
                    "ndcg_at_3": 0.38759,
                    "ndcg_at_5": 0.39112,
                    "ndcg_at_10": 0.41242,
                    "ndcg_at_20": 0.43837,
                    "map_at_1": 0.20737,
                    "map_at_3": 0.29874,
                    "map_at_5": 0.31812,
                    "map_at_10": 0.33536,
                    "map_at_20": 0.34575,
                    "recall_at_1": 0.20737,
                    "recall_at_3": 0.35411,
                    "recall_at_5": 0.40003,
                    "recall_at_10": 0.47168,
                    "recall_at_20": 0.5502,
                    "precision_at_1": 0.41975,
                    "precision_at_3": 0.26029,
                    "precision_at_5": 0.18488,
                    "precision_at_10": 0.11265,
                    "precision_at_20": 0.06767,
                    "mrr_at_1": 0.41975308641975306,
                    "mrr_at_3": 0.4858539094650204,
                    "mrr_at_5": 0.4948816872427981,
                    "mrr_at_10": 0.5036253184401329,
                    "mrr_at_20": 0.5079872364374208,
                    "main_score": 0.41242,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 327.7806978225708,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.66807,
                    "ndcg_at_3": 0.74899,
                    "ndcg_at_5": 0.77001,
                    "ndcg_at_10": 0.78456,
                    "ndcg_at_20": 0.79663,
                    "map_at_1": 0.66702,
                    "map_at_3": 0.72963,
                    "map_at_5": 0.74118,
                    "map_at_10": 0.74746,
                    "map_at_20": 0.7508,
                    "recall_at_1": 0.66702,
                    "recall_at_3": 0.80453,
                    "recall_at_5": 0.85564,
                    "recall_at_10": 0.89989,
                    "recall_at_20": 0.94731,
                    "precision_at_1": 0.66807,
                    "precision_at_3": 0.26976,
                    "precision_at_5": 0.1726,
                    "precision_at_10": 0.09094,
                    "precision_at_20": 0.04789,
                    "mrr_at_1": 0.6680716543730242,
                    "mrr_at_3": 0.7298911134527573,
                    "mrr_at_5": 0.7413768879522307,
                    "mrr_at_10": 0.7473731747704354,
                    "mrr_at_20": 0.7505933001641785,
                    "main_score": 0.78456,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 650.8493931293488,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.4984,
                    "ndcg_at_3": 0.58876,
                    "ndcg_at_5": 0.61217,
                    "ndcg_at_10": 0.63321,
                    "ndcg_at_20": 0.64644,
                    "map_at_1": 0.4983,
                    "map_at_3": 0.56683,
                    "map_at_5": 0.57987,
                    "map_at_10": 0.58862,
                    "map_at_20": 0.59227,
                    "recall_at_1": 0.4983,
                    "recall_at_3": 0.65195,
                    "recall_at_5": 0.70868,
                    "recall_at_10": 0.77336,
                    "recall_at_20": 0.82548,
                    "precision_at_1": 0.4984,
                    "precision_at_3": 0.21745,
                    "precision_at_5": 0.14185,
                    "precision_at_10": 0.0774,
                    "precision_at_20": 0.04132,
                    "mrr_at_1": 0.49839599640703197,
                    "mrr_at_3": 0.5669404166132073,
                    "mrr_at_5": 0.5799296377090687,
                    "mrr_at_10": 0.588693034958124,
                    "mrr_at_20": 0.5923395735882474,
                    "main_score": 0.63321,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 140.70287704467773,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.54868,
                    "ndcg_at_3": 0.60879,
                    "ndcg_at_5": 0.62348,
                    "ndcg_at_10": 0.63895,
                    "ndcg_at_20": 0.64963,
                    "map_at_1": 0.54855,
                    "map_at_3": 0.5942,
                    "map_at_5": 0.60235,
                    "map_at_10": 0.60874,
                    "map_at_20": 0.61168,
                    "recall_at_1": 0.54855,
                    "recall_at_3": 0.65066,
                    "recall_at_5": 0.68636,
                    "recall_at_10": 0.73407,
                    "recall_at_20": 0.7762,
                    "precision_at_1": 0.54868,
                    "precision_at_3": 0.21699,
                    "precision_at_5": 0.13735,
                    "precision_at_10": 0.07349,
                    "precision_at_20": 0.03887,
                    "mrr_at_1": 0.5486810551558753,
                    "mrr_at_3": 0.5943978150812746,
                    "mrr_at_5": 0.602567279509736,
                    "mrr_at_10": 0.6089876670092589,
                    "mrr_at_20": 0.6119316292314186,
                    "main_score": 0.63895,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 119.40685486793518,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.9018,
                    "ndcg_at_3": 0.93443,
                    "ndcg_at_5": 0.93913,
                    "ndcg_at_10": 0.94197,
                    "ndcg_at_20": 0.94382,
                    "map_at_1": 0.9018,
                    "map_at_3": 0.92677,
                    "map_at_5": 0.92937,
                    "map_at_10": 0.93056,
                    "map_at_20": 0.93108,
                    "recall_at_1": 0.9018,
                    "recall_at_3": 0.95647,
                    "recall_at_5": 0.96789,
                    "recall_at_10": 0.97659,
                    "recall_at_20": 0.98374,
                    "precision_at_1": 0.9018,
                    "precision_at_3": 0.31882,
                    "precision_at_5": 0.19358,
                    "precision_at_10": 0.09766,
                    "precision_at_20": 0.04919,
                    "mrr_at_1": 0.9017988007994671,
                    "mrr_at_3": 0.9267673402916559,
                    "mrr_at_5": 0.9293656081131103,
                    "mrr_at_10": 0.9305590629174915,
                    "mrr_at_20": 0.9310837719503099,
                    "main_score": 0.94197,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 78.76560091972351,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.88844,
                    "ndcg_at_3": 0.84822,
                    "ndcg_at_5": 0.83285,
                    "ndcg_at_10": 0.83082,
                    "map_at_1": 0.26859,
                    "map_at_3": 0.53161,
                    "map_at_5": 0.65269,
                    "map_at_10": 0.75349,
                    "recall_at_1": 0.26859,
                    "recall_at_3": 0.54865,
                    "recall_at_5": 0.68627,
                    "recall_at_10": 0.81813,
                    "precision_at_1": 0.88844,
                    "precision_at_3": 0.74281,
                    "precision_at_5": 0.62166,
                    "precision_at_10": 0.41281,
                    "mrr_at_1": 0.888435910924075,
                    "mrr_at_3": 0.910419954409959,
                    "mrr_at_5": 0.9131816587760841,
                    "mrr_at_10": 0.9149491774031507,
                    "main_score": 0.83082,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 4700.2262551784515,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.48973,
                    "ndcg_at_3": 0.5808,
                    "ndcg_at_5": 0.60407,
                    "ndcg_at_10": 0.62489,
                    "ndcg_at_20": 0.63871,
                    "map_at_1": 0.48964,
                    "map_at_3": 0.55868,
                    "map_at_5": 0.57161,
                    "map_at_10": 0.58023,
                    "map_at_20": 0.58408,
                    "recall_at_1": 0.48964,
                    "recall_at_3": 0.64456,
                    "recall_at_5": 0.70101,
                    "recall_at_10": 0.76521,
                    "recall_at_20": 0.81949,
                    "precision_at_1": 0.48973,
                    "precision_at_3": 0.21498,
                    "precision_at_5": 0.14031,
                    "precision_at_10": 0.07659,
                    "precision_at_20": 0.04102,
                    "mrr_at_1": 0.4897343770050045,
                    "mrr_at_3": 0.5587760383250007,
                    "mrr_at_5": 0.5716978912699576,
                    "mrr_at_10": 0.5803182139445575,
                    "mrr_at_20": 0.5841565237738093,
                    "main_score": 0.62489,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 139.73445010185242,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.486,
                    "ndcg_at_3": 0.58882,
                    "ndcg_at_5": 0.61373,
                    "ndcg_at_10": 0.63951,
                    "ndcg_at_20": 0.65447,
                    "map_at_1": 0.486,
                    "map_at_3": 0.56383,
                    "map_at_5": 0.57753,
                    "map_at_10": 0.58831,
                    "map_at_20": 0.59244,
                    "recall_at_1": 0.486,
                    "recall_at_3": 0.661,
                    "recall_at_5": 0.722,
                    "recall_at_10": 0.801,
                    "recall_at_20": 0.86,
                    "precision_at_1": 0.486,
                    "precision_at_3": 0.22033,
                    "precision_at_5": 0.1444,
                    "precision_at_10": 0.0801,
                    "precision_at_20": 0.043,
                    "mrr_at_1": 0.486,
                    "mrr_at_3": 0.5638333333333332,
                    "mrr_at_5": 0.5775333333333331,
                    "mrr_at_10": 0.5883059523809525,
                    "mrr_at_20": 0.5924390182873543,
                    "main_score": 0.63951,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 33.82744526863098,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.84881,
                    "ndcg_at_3": 0.80402,
                    "ndcg_at_5": 0.78887,
                    "ndcg_at_10": 0.7893,
                    "ndcg_at_20": 0.81028,
                    "map_at_1": 0.25058,
                    "map_at_3": 0.49193,
                    "map_at_5": 0.60495,
                    "map_at_10": 0.70171,
                    "map_at_20": 0.73009,
                    "recall_at_1": 0.25058,
                    "recall_at_3": 0.51341,
                    "recall_at_5": 0.6475,
                    "recall_at_10": 0.78225,
                    "recall_at_20": 0.84885,
                    "precision_at_1": 0.84881,
                    "precision_at_3": 0.70629,
                    "precision_at_5": 0.59212,
                    "precision_at_10": 0.39609,
                    "precision_at_20": 0.22283,
                    "mrr_at_1": 0.8488076450990707,
                    "mrr_at_3": 0.8791425565491845,
                    "mrr_at_5": 0.8833793617394373,
                    "mrr_at_10": 0.8856101390524086,
                    "mrr_at_20": 0.8863885008809416,
                    "main_score": 0.7893,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2254.1390266418457,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.61779,
                    "ndcg_at_3": 0.69268,
                    "ndcg_at_5": 0.70852,
                    "ndcg_at_10": 0.72222,
                    "ndcg_at_20": 0.73207,
                    "map_at_1": 0.61738,
                    "map_at_3": 0.6749,
                    "map_at_5": 0.68372,
                    "map_at_10": 0.68943,
                    "map_at_20": 0.69216,
                    "recall_at_1": 0.61738,
                    "recall_at_3": 0.7437,
                    "recall_at_5": 0.78203,
                    "recall_at_10": 0.82403,
                    "recall_at_20": 0.86276,
                    "precision_at_1": 0.61779,
                    "precision_at_3": 0.24819,
                    "precision_at_5": 0.1566,
                    "precision_at_10": 0.08252,
                    "precision_at_20": 0.04321,
                    "mrr_at_1": 0.6177852151958194,
                    "mrr_at_3": 0.6750680132307676,
                    "mrr_at_5": 0.6838901610788155,
                    "mrr_at_10": 0.6895912961704758,
                    "mrr_at_20": 0.6923173832637608,
                    "main_score": 0.72222,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 64.16294074058533,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.24,
                    "ndcg_at_3": 0.19258,
                    "ndcg_at_5": 0.16439,
                    "ndcg_at_10": 0.19889,
                    "map_at_1": 0.04883,
                    "map_at_3": 0.08639,
                    "map_at_5": 0.10078,
                    "map_at_10": 0.11789,
                    "recall_at_1": 0.04883,
                    "recall_at_3": 0.10893,
                    "recall_at_5": 0.14342,
                    "recall_at_10": 0.20695,
                    "precision_at_1": 0.24,
                    "precision_at_3": 0.179,
                    "precision_at_5": 0.1414,
                    "precision_at_10": 0.1021,
                    "mrr_at_1": 0.24,
                    "mrr_at_3": 0.31599999999999995,
                    "mrr_at_5": 0.3325999999999997,
                    "mrr_at_10": 0.34627182539682516,
                    "main_score": 0.19889,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 139.061017036438,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.439,
                    "ndcg_at_3": 0.53072,
                    "ndcg_at_5": 0.55284,
                    "ndcg_at_10": 0.58424,
                    "ndcg_at_20": 0.59902,
                    "map_at_1": 0.439,
                    "map_at_3": 0.50817,
                    "map_at_5": 0.52037,
                    "map_at_10": 0.53334,
                    "map_at_20": 0.53746,
                    "recall_at_1": 0.439,
                    "recall_at_3": 0.596,
                    "recall_at_5": 0.65,
                    "recall_at_10": 0.747,
                    "recall_at_20": 0.805,
                    "precision_at_1": 0.439,
                    "precision_at_3": 0.19867,
                    "precision_at_5": 0.13,
                    "precision_at_10": 0.0747,
                    "precision_at_20": 0.04025,
                    "mrr_at_1": 0.439,
                    "mrr_at_3": 0.5081666666666662,
                    "mrr_at_5": 0.5203666666666661,
                    "mrr_at_10": 0.533342857142857,
                    "mrr_at_20": 0.537459959175671,
                    "main_score": 0.58424,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 72.19503974914551,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.86674,
                    "ndcg_at_3": 0.82363,
                    "ndcg_at_5": 0.80828,
                    "ndcg_at_10": 0.80816,
                    "ndcg_at_20": 0.82769,
                    "map_at_1": 0.25845,
                    "map_at_3": 0.50903,
                    "map_at_5": 0.62561,
                    "map_at_10": 0.72497,
                    "map_at_20": 0.75298,
                    "recall_at_1": 0.25845,
                    "recall_at_3": 0.52817,
                    "recall_at_5": 0.6642,
                    "recall_at_10": 0.79858,
                    "recall_at_20": 0.86201,
                    "precision_at_1": 0.86674,
                    "precision_at_3": 0.72263,
                    "precision_at_5": 0.60537,
                    "precision_at_10": 0.4043,
                    "precision_at_20": 0.22623,
                    "mrr_at_1": 0.8667368051902508,
                    "mrr_at_3": 0.8935428721725395,
                    "mrr_at_5": 0.8971177450464674,
                    "mrr_at_10": 0.8991647044579726,
                    "mrr_at_20": 0.8998439239251178,
                    "main_score": 0.80816,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1907.2203838825226,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.53003,
                    "ndcg_at_3": 0.61183,
                    "ndcg_at_5": 0.63282,
                    "ndcg_at_10": 0.65825,
                    "ndcg_at_20": 0.66975,
                    "map_at_1": 0.5295,
                    "map_at_3": 0.59238,
                    "map_at_5": 0.60386,
                    "map_at_10": 0.6143,
                    "map_at_20": 0.61738,
                    "recall_at_1": 0.5295,
                    "recall_at_3": 0.66754,
                    "recall_at_5": 0.71918,
                    "recall_at_10": 0.79821,
                    "recall_at_20": 0.84405,
                    "precision_at_1": 0.53003,
                    "precision_at_3": 0.22339,
                    "precision_at_5": 0.14436,
                    "precision_at_10": 0.08019,
                    "precision_at_20": 0.04241,
                    "mrr_at_1": 0.530031612223393,
                    "mrr_at_3": 0.592553565156305,
                    "mrr_at_5": 0.604039339655778,
                    "mrr_at_10": 0.6143572181243415,
                    "mrr_at_20": 0.6174786566982441,
                    "main_score": 0.65825,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1373.6056776046753,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.3704,
                    "ndcg_at_3": 0.45079,
                    "ndcg_at_5": 0.47426,
                    "ndcg_at_10": 0.4981,
                    "ndcg_at_20": 0.51424,
                    "map_at_1": 0.37033,
                    "map_at_3": 0.43108,
                    "map_at_5": 0.44411,
                    "map_at_10": 0.45398,
                    "map_at_20": 0.45841,
                    "recall_at_1": 0.37033,
                    "recall_at_3": 0.50776,
                    "recall_at_5": 0.56471,
                    "recall_at_10": 0.63824,
                    "recall_at_20": 0.70205,
                    "precision_at_1": 0.3704,
                    "precision_at_3": 0.16931,
                    "precision_at_5": 0.11298,
                    "precision_at_10": 0.06386,
                    "precision_at_20": 0.03513,
                    "mrr_at_1": 0.3703965096881817,
                    "mrr_at_3": 0.43112408571796007,
                    "mrr_at_5": 0.4441501988964595,
                    "mrr_at_10": 0.4540273856880233,
                    "mrr_at_20": 0.45846010469980836,
                    "main_score": 0.4981,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 44.91579031944275,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.36308,
                    "ndcg_at_3": 0.44427,
                    "ndcg_at_5": 0.46833,
                    "ndcg_at_10": 0.49086,
                    "ndcg_at_20": 0.50693,
                    "map_at_1": 0.36305,
                    "map_at_3": 0.42433,
                    "map_at_5": 0.4377,
                    "map_at_10": 0.44702,
                    "map_at_20": 0.45144,
                    "recall_at_1": 0.36305,
                    "recall_at_3": 0.50192,
                    "recall_at_5": 0.56028,
                    "recall_at_10": 0.62977,
                    "recall_at_20": 0.69324,
                    "precision_at_1": 0.36308,
                    "precision_at_3": 0.16734,
                    "precision_at_5": 0.11209,
                    "precision_at_10": 0.063,
                    "precision_at_20": 0.03468,
                    "mrr_at_1": 0.3630822533042474,
                    "mrr_at_3": 0.4243712305915636,
                    "mrr_at_5": 0.437734184524586,
                    "mrr_at_10": 0.44706450793244584,
                    "mrr_at_20": 0.45148733250823864,
                    "main_score": 0.49086,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 42.99168372154236,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.8605,
                    "ndcg_at_3": 0.80886,
                    "ndcg_at_5": 0.79577,
                    "ndcg_at_10": 0.82292,
                    "ndcg_at_20": 0.84145,
                    "map_at_1": 0.24284,
                    "map_at_3": 0.50816,
                    "map_at_5": 0.6383,
                    "map_at_10": 0.73545,
                    "map_at_20": 0.758,
                    "recall_at_1": 0.24284,
                    "recall_at_3": 0.53603,
                    "recall_at_5": 0.69426,
                    "recall_at_10": 0.83909,
                    "recall_at_20": 0.89512,
                    "precision_at_1": 0.8605,
                    "precision_at_3": 0.725,
                    "precision_at_5": 0.61,
                    "precision_at_10": 0.39605,
                    "precision_at_20": 0.218,
                    "mrr_at_1": 0.8605,
                    "mrr_at_3": 0.8999166666666661,
                    "mrr_at_5": 0.9023166666666662,
                    "mrr_at_10": 0.9040063492063488,
                    "mrr_at_20": 0.9045206614055874,
                    "main_score": 0.82292,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 810.4863228797913,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "Touche2020Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.2551,
                    "ndcg_at_3": 0.27685,
                    "ndcg_at_5": 0.2811,
                    "ndcg_at_10": 0.27064,
                    "ndcg_at_20": 0.27543,
                    "map_at_1": 0.02395,
                    "map_at_3": 0.05508,
                    "map_at_5": 0.07698,
                    "map_at_10": 0.10883,
                    "map_at_20": 0.13184,
                    "recall_at_1": 0.02395,
                    "recall_at_3": 0.07065,
                    "recall_at_5": 0.11396,
                    "recall_at_10": 0.17725,
                    "recall_at_20": 0.2493,
                    "precision_at_1": 0.26531,
                    "precision_at_3": 0.29932,
                    "precision_at_5": 0.29796,
                    "precision_at_10": 0.24286,
                    "precision_at_20": 0.17551,
                    "mrr_at_1": 0.2653061224489796,
                    "mrr_at_3": 0.4285714285714285,
                    "mrr_at_5": 0.4683673469387755,
                    "mrr_at_10": 0.47295918367346934,
                    "mrr_at_20": 0.4775052328623756,
                    "main_score": 0.27064,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 3997.21173787117,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.31033,
                    "ndcg_at_3": 0.31227,
                    "ndcg_at_5": 0.32839,
                    "ndcg_at_10": 0.35717,
                    "ndcg_at_20": 0.3817,
                    "map_at_1": 0.19936,
                    "map_at_3": 0.26398,
                    "map_at_5": 0.28107,
                    "map_at_10": 0.29741,
                    "map_at_20": 0.30603,
                    "recall_at_1": 0.19936,
                    "recall_at_3": 0.31041,
                    "recall_at_5": 0.36346,
                    "recall_at_10": 0.44757,
                    "recall_at_20": 0.53064,
                    "precision_at_1": 0.31033,
                    "precision_at_3": 0.17829,
                    "precision_at_5": 0.12823,
                    "precision_at_10": 0.08095,
                    "precision_at_20": 0.04881,
                    "mrr_at_1": 0.3103275818954739,
                    "mrr_at_3": 0.36134033508377056,
                    "mrr_at_5": 0.37378094523630906,
                    "mrr_at_10": 0.3848649662415599,
                    "mrr_at_20": 0.3902916843157891,
                    "main_score": 0.35717,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 514.9339768886566,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.42879,
                    "ndcg_at_3": 0.36726,
                    "ndcg_at_5": 0.33869,
                    "ndcg_at_10": 0.30792,
                    "ndcg_at_20": 0.28281,
                    "map_at_1": 0.05604,
                    "map_at_3": 0.08265,
                    "map_at_5": 0.09692,
                    "map_at_10": 0.11136,
                    "map_at_20": 0.121,
                    "recall_at_1": 0.05604,
                    "recall_at_3": 0.09032,
                    "recall_at_5": 0.11484,
                    "recall_at_10": 0.1433,
                    "recall_at_20": 0.17352,
                    "precision_at_1": 0.43963,
                    "precision_at_3": 0.33746,
                    "precision_at_5": 0.28235,
                    "precision_at_10": 0.22198,
                    "precision_at_20": 0.1613,
                    "mrr_at_1": 0.43962848297213625,
                    "mrr_at_3": 0.49742002063983504,
                    "mrr_at_5": 0.5054695562435502,
                    "mrr_at_10": 0.5127905548184186,
                    "mrr_at_20": 0.517743680555914,
                    "main_score": 0.30792,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 23.800382614135742,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.72455,
                    "ndcg_at_3": 0.76228,
                    "ndcg_at_5": 0.76923,
                    "ndcg_at_10": 0.77507,
                    "ndcg_at_20": 0.77882,
                    "map_at_1": 0.72455,
                    "map_at_3": 0.75343,
                    "map_at_5": 0.7573,
                    "map_at_10": 0.75973,
                    "map_at_20": 0.76077,
                    "recall_at_1": 0.72455,
                    "recall_at_3": 0.78775,
                    "recall_at_5": 0.80455,
                    "recall_at_10": 0.8225,
                    "recall_at_20": 0.8372,
                    "precision_at_1": 0.72455,
                    "precision_at_3": 0.26258,
                    "precision_at_5": 0.16091,
                    "precision_at_10": 0.08225,
                    "precision_at_20": 0.04186,
                    "mrr_at_1": 0.72455,
                    "mrr_at_3": 0.753425000000004,
                    "mrr_at_5": 0.7572975000000058,
                    "mrr_at_10": 0.759730257936513,
                    "mrr_at_20": 0.7607711580524809,
                    "main_score": 0.77507,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 168.12212491035461,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.25533,
                    "ndcg_at_3": 0.39648,
                    "ndcg_at_5": 0.45395,
                    "ndcg_at_10": 0.50543,
                    "ndcg_at_20": 0.53163,
                    "map_at_1": 0.25533,
                    "map_at_3": 0.36083,
                    "map_at_5": 0.39259,
                    "map_at_10": 0.41421,
                    "map_at_20": 0.42156,
                    "recall_at_1": 0.25533,
                    "recall_at_3": 0.5,
                    "recall_at_5": 0.64011,
                    "recall_at_10": 0.7973,
                    "recall_at_20": 0.89972,
                    "precision_at_1": 0.25533,
                    "precision_at_3": 0.16667,
                    "precision_at_5": 0.12802,
                    "precision_at_10": 0.07973,
                    "precision_at_20": 0.04499,
                    "mrr_at_1": 0.2574679943100996,
                    "mrr_at_3": 0.36142721669037386,
                    "mrr_at_5": 0.39297060218112784,
                    "mrr_at_10": 0.41482591614170566,
                    "mrr_at_20": 0.4221788598815239,
                    "main_score": 0.50543,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 157.82298493385315,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.558,
                    "ndcg_at_3": 0.6651,
                    "ndcg_at_5": 0.68989,
                    "ndcg_at_10": 0.70649,
                    "ndcg_at_20": 0.71928,
                    "map_at_1": 0.558,
                    "map_at_3": 0.63917,
                    "map_at_5": 0.65297,
                    "map_at_10": 0.65987,
                    "map_at_20": 0.66334,
                    "recall_at_1": 0.558,
                    "recall_at_3": 0.74,
                    "recall_at_5": 0.8,
                    "recall_at_10": 0.851,
                    "recall_at_20": 0.902,
                    "precision_at_1": 0.558,
                    "precision_at_3": 0.24667,
                    "precision_at_5": 0.16,
                    "precision_at_10": 0.0851,
                    "precision_at_20": 0.0451,
                    "mrr_at_1": 0.558,
                    "mrr_at_3": 0.6391666666666668,
                    "mrr_at_5": 0.6529666666666669,
                    "mrr_at_10": 0.6598742063492063,
                    "mrr_at_20": 0.6633351415483381,
                    "main_score": 0.70649,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 42.64723825454712,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.463,
                    "ndcg_at_3": 0.55951,
                    "ndcg_at_5": 0.58055,
                    "ndcg_at_10": 0.60725,
                    "ndcg_at_20": 0.62412,
                    "map_at_1": 0.463,
                    "map_at_3": 0.53583,
                    "map_at_5": 0.54753,
                    "map_at_10": 0.55846,
                    "map_at_20": 0.56319,
                    "recall_at_1": 0.463,
                    "recall_at_3": 0.628,
                    "recall_at_5": 0.679,
                    "recall_at_10": 0.762,
                    "recall_at_20": 0.828,
                    "precision_at_1": 0.463,
                    "precision_at_3": 0.20933,
                    "precision_at_5": 0.1358,
                    "precision_at_10": 0.0762,
                    "precision_at_20": 0.0414,
                    "mrr_at_1": 0.463,
                    "mrr_at_3": 0.5358333333333328,
                    "mrr_at_5": 0.5475333333333328,
                    "mrr_at_10": 0.5584630952380948,
                    "mrr_at_20": 0.5631889455487747,
                    "main_score": 0.60725,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 169.33281874656677,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.88883,
                    "ndcg_at_3": 0.84807,
                    "ndcg_at_5": 0.83243,
                    "ndcg_at_10": 0.83032,
                    "ndcg_at_20": 0.84803,
                    "map_at_1": 0.26891,
                    "map_at_3": 0.53146,
                    "map_at_5": 0.65224,
                    "map_at_10": 0.75283,
                    "map_at_20": 0.77989,
                    "recall_at_1": 0.26891,
                    "recall_at_3": 0.54824,
                    "recall_at_5": 0.68562,
                    "recall_at_10": 0.81719,
                    "recall_at_20": 0.87692,
                    "precision_at_1": 0.88883,
                    "precision_at_3": 0.74261,
                    "precision_at_5": 0.62113,
                    "precision_at_10": 0.41242,
                    "precision_at_20": 0.22915,
                    "mrr_at_1": 0.8888304401192355,
                    "mrr_at_3": 0.9106318311999524,
                    "mrr_at_5": 0.9134527149453517,
                    "mrr_at_10": 0.9151296379794555,
                    "mrr_at_20": 0.9157742403409775,
                    "main_score": 0.83032,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 6220.039473772049,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "2e643e7363944af1c33a652d1c87320d0871c4e4",
        "task_name": "NarrativeQAChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.56275,
                    "ndcg_at_3": 0.63152,
                    "ndcg_at_5": 0.64878,
                    "ndcg_at_10": 0.66414,
                    "ndcg_at_20": 0.67538,
                    "map_at_1": 0.56275,
                    "map_at_3": 0.61509,
                    "map_at_5": 0.62468,
                    "map_at_10": 0.63102,
                    "map_at_20": 0.6341,
                    "recall_at_1": 0.56275,
                    "recall_at_3": 0.67889,
                    "recall_at_5": 0.72075,
                    "recall_at_10": 0.76821,
                    "recall_at_20": 0.81273,
                    "precision_at_1": 0.56275,
                    "precision_at_3": 0.2263,
                    "precision_at_5": 0.14415,
                    "precision_at_10": 0.07682,
                    "precision_at_20": 0.04064,
                    "mrr_at_1": 0.5627545704272047,
                    "mrr_at_3": 0.6150895140664933,
                    "mrr_at_5": 0.6246755707113708,
                    "mrr_at_10": 0.6310154174391148,
                    "mrr_at_20": 0.6340954186304291,
                    "main_score": 0.66414,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 720.4252903461456,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.492,
                    "ndcg_at_3": 0.54772,
                    "ndcg_at_5": 0.56158,
                    "ndcg_at_10": 0.57123,
                    "ndcg_at_20": 0.58373,
                    "map_at_1": 0.492,
                    "map_at_3": 0.53383,
                    "map_at_5": 0.54143,
                    "map_at_10": 0.54539,
                    "map_at_20": 0.54888,
                    "recall_at_1": 0.492,
                    "recall_at_3": 0.588,
                    "recall_at_5": 0.622,
                    "recall_at_10": 0.652,
                    "recall_at_20": 0.701,
                    "precision_at_1": 0.492,
                    "precision_at_3": 0.196,
                    "precision_at_5": 0.1244,
                    "precision_at_10": 0.0652,
                    "precision_at_20": 0.03505,
                    "mrr_at_1": 0.493,
                    "mrr_at_3": 0.5343333333333332,
                    "mrr_at_5": 0.5419333333333333,
                    "mrr_at_10": 0.5458900793650795,
                    "mrr_at_20": 0.549382323391263,
                    "main_score": 0.57123,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 246.37183809280396,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.66429,
                    "ndcg_at_3": 0.7397,
                    "ndcg_at_5": 0.75365,
                    "ndcg_at_10": 0.7654,
                    "ndcg_at_20": 0.77333,
                    "map_at_1": 0.66393,
                    "map_at_3": 0.72183,
                    "map_at_5": 0.72963,
                    "map_at_10": 0.73451,
                    "map_at_20": 0.73671,
                    "recall_at_1": 0.66393,
                    "recall_at_3": 0.79083,
                    "recall_at_5": 0.82452,
                    "recall_at_10": 0.86069,
                    "recall_at_20": 0.89189,
                    "precision_at_1": 0.66429,
                    "precision_at_3": 0.2639,
                    "precision_at_5": 0.16512,
                    "precision_at_10": 0.0862,
                    "precision_at_20": 0.04467,
                    "mrr_at_1": 0.6642886501086255,
                    "mrr_at_3": 0.7220754310766552,
                    "mrr_at_5": 0.7298171960933952,
                    "mrr_at_10": 0.7346790702854619,
                    "mrr_at_20": 0.7368659934519783,
                    "main_score": 0.7654,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 128.7403917312622,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "Touche2020Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.33673,
                    "ndcg_at_3": 0.31993,
                    "ndcg_at_5": 0.28785,
                    "ndcg_at_10": 0.26672,
                    "ndcg_at_20": 0.29005,
                    "map_at_1": 0.02762,
                    "map_at_3": 0.06737,
                    "map_at_5": 0.08299,
                    "map_at_10": 0.10842,
                    "map_at_20": 0.13907,
                    "recall_at_1": 0.02762,
                    "recall_at_3": 0.08135,
                    "recall_at_5": 0.10814,
                    "recall_at_10": 0.1683,
                    "recall_at_20": 0.26463,
                    "precision_at_1": 0.34694,
                    "precision_at_3": 0.33333,
                    "precision_at_5": 0.27755,
                    "precision_at_10": 0.22245,
                    "precision_at_20": 0.18469,
                    "mrr_at_1": 0.3469387755102041,
                    "mrr_at_3": 0.4829931972789115,
                    "mrr_at_5": 0.5074829931972789,
                    "mrr_at_10": 0.519954648526077,
                    "mrr_at_20": 0.5230104162877272,
                    "main_score": 0.26672,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 3988.152991294861,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.68939,
                    "ndcg_at_3": 0.75766,
                    "ndcg_at_5": 0.77082,
                    "ndcg_at_10": 0.78297,
                    "ndcg_at_20": 0.79096,
                    "map_at_1": 0.68902,
                    "map_at_3": 0.74142,
                    "map_at_5": 0.74876,
                    "map_at_10": 0.75382,
                    "map_at_20": 0.75603,
                    "recall_at_1": 0.68902,
                    "recall_at_3": 0.80415,
                    "recall_at_5": 0.83594,
                    "recall_at_10": 0.87332,
                    "recall_at_20": 0.90473,
                    "precision_at_1": 0.68939,
                    "precision_at_3": 0.26832,
                    "precision_at_5": 0.16738,
                    "precision_at_10": 0.08746,
                    "precision_at_20": 0.04531,
                    "mrr_at_1": 0.6893899359990605,
                    "mrr_at_3": 0.7416720490086628,
                    "mrr_at_5": 0.7489983950834729,
                    "mrr_at_10": 0.7540289858922045,
                    "mrr_at_20": 0.7562301579052206,
                    "main_score": 0.78297,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 138.28785157203674,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.7737,
                    "ndcg_at_3": 0.80713,
                    "ndcg_at_5": 0.81286,
                    "ndcg_at_10": 0.81748,
                    "ndcg_at_20": 0.82086,
                    "map_at_1": 0.7737,
                    "map_at_3": 0.79931,
                    "map_at_5": 0.80249,
                    "map_at_10": 0.80442,
                    "map_at_20": 0.80535,
                    "recall_at_1": 0.7737,
                    "recall_at_3": 0.8296,
                    "recall_at_5": 0.8435,
                    "recall_at_10": 0.8577,
                    "recall_at_20": 0.87105,
                    "precision_at_1": 0.7737,
                    "precision_at_3": 0.27653,
                    "precision_at_5": 0.1687,
                    "precision_at_10": 0.08577,
                    "precision_at_20": 0.04355,
                    "mrr_at_1": 0.7737,
                    "mrr_at_3": 0.7993083333333366,
                    "mrr_at_5": 0.8024858333333388,
                    "mrr_at_10": 0.8044171626984173,
                    "mrr_at_20": 0.8053458169189406,
                    "main_score": 0.81748,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 404.7881166934967,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.7715,
                    "ndcg_at_3": 0.80475,
                    "ndcg_at_5": 0.81114,
                    "ndcg_at_10": 0.81652,
                    "ndcg_at_20": 0.81945,
                    "map_at_1": 0.7715,
                    "map_at_3": 0.79698,
                    "map_at_5": 0.80054,
                    "map_at_10": 0.8028,
                    "map_at_20": 0.8036,
                    "recall_at_1": 0.7715,
                    "recall_at_3": 0.82705,
                    "recall_at_5": 0.8425,
                    "recall_at_10": 0.85895,
                    "recall_at_20": 0.8706,
                    "precision_at_1": 0.7715,
                    "precision_at_3": 0.27568,
                    "precision_at_5": 0.1685,
                    "precision_at_10": 0.08589,
                    "precision_at_20": 0.04353,
                    "mrr_at_1": 0.7715,
                    "mrr_at_3": 0.7969833333333366,
                    "mrr_at_5": 0.8005433333333384,
                    "mrr_at_10": 0.8027987698412742,
                    "mrr_at_20": 0.803601541138606,
                    "main_score": 0.81652,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 481.6441843509674,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.8805,
                    "ndcg_at_3": 0.83572,
                    "ndcg_at_5": 0.82375,
                    "ndcg_at_10": 0.84887,
                    "map_at_1": 0.25231,
                    "map_at_3": 0.53146,
                    "map_at_5": 0.66892,
                    "map_at_10": 0.76826,
                    "recall_at_1": 0.25231,
                    "recall_at_3": 0.55677,
                    "recall_at_5": 0.72081,
                    "recall_at_10": 0.86287,
                    "precision_at_1": 0.8805,
                    "precision_at_3": 0.74883,
                    "precision_at_5": 0.631,
                    "precision_at_10": 0.40745,
                    "mrr_at_1": 0.8805,
                    "mrr_at_3": 0.9149999999999998,
                    "mrr_at_5": 0.917325,
                    "mrr_at_10": 0.9186599206349206,
                    "main_score": 0.84887,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 684.0385332107544,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.238,
                    "ndcg_at_3": 0.19333,
                    "ndcg_at_5": 0.16502,
                    "ndcg_at_10": 0.199,
                    "ndcg_at_20": 0.22922,
                    "map_at_1": 0.04843,
                    "map_at_3": 0.08643,
                    "map_at_5": 0.10155,
                    "map_at_10": 0.11799,
                    "map_at_20": 0.12898,
                    "recall_at_1": 0.04843,
                    "recall_at_3": 0.11018,
                    "recall_at_5": 0.14467,
                    "recall_at_10": 0.20745,
                    "recall_at_20": 0.2784,
                    "precision_at_1": 0.238,
                    "precision_at_3": 0.181,
                    "precision_at_5": 0.1426,
                    "precision_at_10": 0.1023,
                    "precision_at_20": 0.06865,
                    "mrr_at_1": 0.238,
                    "mrr_at_3": 0.3165,
                    "mrr_at_5": 0.33029999999999976,
                    "mrr_at_10": 0.344915873015873,
                    "mrr_at_20": 0.35211101054947785,
                    "main_score": 0.199,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 373.4983036518097,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.32559,
                    "ndcg_at_3": 0.40357,
                    "ndcg_at_5": 0.42585,
                    "ndcg_at_10": 0.4477,
                    "ndcg_at_20": 0.46444,
                    "map_at_1": 0.32507,
                    "map_at_3": 0.38421,
                    "map_at_5": 0.39663,
                    "map_at_10": 0.40567,
                    "map_at_20": 0.4103,
                    "recall_at_1": 0.32507,
                    "recall_at_3": 0.45886,
                    "recall_at_5": 0.51273,
                    "recall_at_10": 0.57993,
                    "recall_at_20": 0.64568,
                    "precision_at_1": 0.32559,
                    "precision_at_3": 0.15344,
                    "precision_at_5": 0.10301,
                    "precision_at_10": 0.05837,
                    "precision_at_20": 0.03257,
                    "mrr_at_1": 0.3255918658312385,
                    "mrr_at_3": 0.3848910066409044,
                    "mrr_at_5": 0.39727047611901356,
                    "mrr_at_10": 0.4063173745592282,
                    "mrr_at_20": 0.4109042948898252,
                    "main_score": 0.4477,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 161.26917052268982,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.72695,
                    "ndcg_at_3": 0.76372,
                    "ndcg_at_5": 0.77044,
                    "ndcg_at_10": 0.77601,
                    "ndcg_at_20": 0.77916,
                    "map_at_1": 0.72695,
                    "map_at_3": 0.75507,
                    "map_at_5": 0.75882,
                    "map_at_10": 0.76114,
                    "map_at_20": 0.76202,
                    "recall_at_1": 0.72695,
                    "recall_at_3": 0.7886,
                    "recall_at_5": 0.80485,
                    "recall_at_10": 0.82195,
                    "recall_at_20": 0.8343,
                    "precision_at_1": 0.72695,
                    "precision_at_3": 0.26287,
                    "precision_at_5": 0.16097,
                    "precision_at_10": 0.08219,
                    "precision_at_20": 0.04171,
                    "mrr_at_1": 0.0,
                    "mrr_at_3": 0.24729999999999858,
                    "mrr_at_5": 0.26242499999998464,
                    "mrr_at_10": 0.26654942460315645,
                    "mrr_at_20": 0.26784335022302863,
                    "main_score": 0.77601,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 755.2587442398071,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.49257,
                    "ndcg_at_3": 0.56089,
                    "ndcg_at_5": 0.57801,
                    "ndcg_at_10": 0.59459,
                    "ndcg_at_20": 0.60755,
                    "map_at_1": 0.49251,
                    "map_at_3": 0.54428,
                    "map_at_5": 0.55377,
                    "map_at_10": 0.56064,
                    "map_at_20": 0.5642,
                    "recall_at_1": 0.49251,
                    "recall_at_3": 0.60873,
                    "recall_at_5": 0.65036,
                    "recall_at_10": 0.70136,
                    "recall_at_20": 0.75254,
                    "precision_at_1": 0.49257,
                    "precision_at_3": 0.20297,
                    "precision_at_5": 0.13012,
                    "precision_at_10": 0.0702,
                    "precision_at_20": 0.03768,
                    "mrr_at_1": 0.49256594724220626,
                    "mrr_at_3": 0.5443778310684853,
                    "mrr_at_5": 0.5538782307487454,
                    "mrr_at_10": 0.5607873383832722,
                    "mrr_at_20": 0.5643608449027976,
                    "main_score": 0.59459,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 98.27809381484985,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.3534,
                    "ndcg_at_3": 0.31779,
                    "ndcg_at_5": 0.32667,
                    "ndcg_at_10": 0.34851,
                    "ndcg_at_20": 0.3685,
                    "map_at_1": 0.17519,
                    "map_at_3": 0.2429,
                    "map_at_5": 0.26234,
                    "map_at_10": 0.27868,
                    "map_at_20": 0.28603,
                    "recall_at_1": 0.17519,
                    "recall_at_3": 0.2831,
                    "recall_at_5": 0.33271,
                    "recall_at_10": 0.40464,
                    "recall_at_20": 0.46571,
                    "precision_at_1": 0.3534,
                    "precision_at_3": 0.21193,
                    "precision_at_5": 0.15648,
                    "precision_at_10": 0.09691,
                    "precision_at_20": 0.05741,
                    "mrr_at_1": 0.3533950617283951,
                    "mrr_at_3": 0.407150205761317,
                    "mrr_at_5": 0.4190329218106996,
                    "mrr_at_10": 0.42960574661963546,
                    "mrr_at_20": 0.4334298139473864,
                    "main_score": 0.34851,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 120.70055508613586,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.39141,
                    "ndcg_at_3": 0.45407,
                    "ndcg_at_5": 0.47096,
                    "ndcg_at_10": 0.48733,
                    "ndcg_at_20": 0.4997,
                    "map_at_1": 0.39109,
                    "map_at_3": 0.43868,
                    "map_at_5": 0.44807,
                    "map_at_10": 0.45484,
                    "map_at_20": 0.45823,
                    "recall_at_1": 0.39109,
                    "recall_at_3": 0.49796,
                    "recall_at_5": 0.53911,
                    "recall_at_10": 0.58955,
                    "recall_at_20": 0.63844,
                    "precision_at_1": 0.39141,
                    "precision_at_3": 0.16617,
                    "precision_at_5": 0.10797,
                    "precision_at_10": 0.05908,
                    "precision_at_20": 0.03201,
                    "mrr_at_1": 0.3914068745003997,
                    "mrr_at_3": 0.4390820676791929,
                    "mrr_at_5": 0.44848454569678087,
                    "mrr_at_10": 0.45530041046528447,
                    "mrr_at_20": 0.45870361202567034,
                    "main_score": 0.48733,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 43.523091554641724,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.86467,
                    "ndcg_at_3": 0.90219,
                    "ndcg_at_5": 0.90896,
                    "ndcg_at_10": 0.91372,
                    "ndcg_at_20": 0.91651,
                    "map_at_1": 0.86467,
                    "map_at_3": 0.89332,
                    "map_at_5": 0.89708,
                    "map_at_10": 0.89906,
                    "map_at_20": 0.89984,
                    "recall_at_1": 0.86467,
                    "recall_at_3": 0.9277,
                    "recall_at_5": 0.94411,
                    "recall_at_10": 0.95876,
                    "recall_at_20": 0.96967,
                    "precision_at_1": 0.86467,
                    "precision_at_3": 0.30924,
                    "precision_at_5": 0.18883,
                    "precision_at_10": 0.09588,
                    "precision_at_20": 0.04849,
                    "mrr_at_1": 0.8646686854292839,
                    "mrr_at_3": 0.8933321458259118,
                    "mrr_at_5": 0.897097286545543,
                    "mrr_at_10": 0.8990740446220076,
                    "mrr_at_20": 0.899857232167421,
                    "main_score": 0.91372,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 43.232213258743286,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.35692,
                    "ndcg_at_3": 0.41158,
                    "ndcg_at_5": 0.42816,
                    "ndcg_at_10": 0.44409,
                    "ndcg_at_20": 0.45636,
                    "map_at_1": 0.35692,
                    "map_at_3": 0.39827,
                    "map_at_5": 0.40747,
                    "map_at_10": 0.41406,
                    "map_at_20": 0.41742,
                    "recall_at_1": 0.35692,
                    "recall_at_3": 0.45005,
                    "recall_at_5": 0.4903,
                    "recall_at_10": 0.53942,
                    "recall_at_20": 0.58805,
                    "precision_at_1": 0.35692,
                    "precision_at_3": 0.15002,
                    "precision_at_5": 0.09806,
                    "precision_at_10": 0.05395,
                    "precision_at_20": 0.02941,
                    "mrr_at_1": 0.35691754841285683,
                    "mrr_at_3": 0.39827643574898575,
                    "mrr_at_5": 0.4074718839422388,
                    "mrr_at_10": 0.4140814153571221,
                    "mrr_at_20": 0.41743950545869524,
                    "main_score": 0.44409,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 31.612406969070435,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.8455,
                    "ndcg_at_3": 0.80773,
                    "ndcg_at_5": 0.79745,
                    "ndcg_at_10": 0.82735,
                    "ndcg_at_20": 0.84759,
                    "map_at_1": 0.23921,
                    "map_at_3": 0.50695,
                    "map_at_5": 0.64009,
                    "map_at_10": 0.74066,
                    "map_at_20": 0.76498,
                    "recall_at_1": 0.23921,
                    "recall_at_3": 0.53797,
                    "recall_at_5": 0.70019,
                    "recall_at_10": 0.84995,
                    "recall_at_20": 0.91081,
                    "precision_at_1": 0.8455,
                    "precision_at_3": 0.72817,
                    "precision_at_5": 0.6148,
                    "precision_at_10": 0.4016,
                    "precision_at_20": 0.2217,
                    "mrr_at_1": 0.8455,
                    "mrr_at_3": 0.8904999999999993,
                    "mrr_at_5": 0.8933999999999993,
                    "mrr_at_10": 0.8949944444444435,
                    "mrr_at_20": 0.895549085971647,
                    "main_score": 0.82735,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 464.331645488739,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.66807,
                    "ndcg_at_3": 0.75492,
                    "ndcg_at_5": 0.77322,
                    "ndcg_at_10": 0.78684,
                    "map_at_1": 0.66702,
                    "map_at_3": 0.73446,
                    "map_at_5": 0.74464,
                    "map_at_10": 0.75043,
                    "recall_at_1": 0.66702,
                    "recall_at_3": 0.81296,
                    "recall_at_5": 0.85722,
                    "recall_at_10": 0.89884,
                    "precision_at_1": 0.66807,
                    "precision_at_3": 0.27257,
                    "precision_at_5": 0.17281,
                    "precision_at_10": 0.09083,
                    "mrr_at_1": 0.667017913593256,
                    "mrr_at_3": 0.7344573234984193,
                    "mrr_at_5": 0.7444678609062173,
                    "mrr_at_10": 0.749968220516166,
                    "main_score": 0.78684,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 593.5003879070282,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.89958,
                    "ndcg_at_3": 0.93209,
                    "ndcg_at_5": 0.93676,
                    "ndcg_at_10": 0.94019,
                    "ndcg_at_20": 0.94181,
                    "map_at_1": 0.89954,
                    "map_at_3": 0.92445,
                    "map_at_5": 0.92705,
                    "map_at_10": 0.92851,
                    "map_at_20": 0.92896,
                    "recall_at_1": 0.89954,
                    "recall_at_3": 0.954,
                    "recall_at_5": 0.96529,
                    "recall_at_10": 0.97571,
                    "recall_at_20": 0.98212,
                    "precision_at_1": 0.89958,
                    "precision_at_3": 0.31801,
                    "precision_at_5": 0.19307,
                    "precision_at_10": 0.09758,
                    "precision_at_20": 0.04911,
                    "mrr_at_1": 0.8995814036337727,
                    "mrr_at_3": 0.9244967937299602,
                    "mrr_at_5": 0.9270885286783053,
                    "mrr_at_10": 0.9285407336251226,
                    "mrr_at_20": 0.9289909360030336,
                    "main_score": 0.94019,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 98.83934736251831,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.557,
                    "ndcg_at_3": 0.66547,
                    "ndcg_at_5": 0.68936,
                    "ndcg_at_10": 0.70621,
                    "ndcg_at_20": 0.71901,
                    "map_at_1": 0.557,
                    "map_at_3": 0.639,
                    "map_at_5": 0.65225,
                    "map_at_10": 0.65923,
                    "map_at_20": 0.66269,
                    "recall_at_1": 0.557,
                    "recall_at_3": 0.742,
                    "recall_at_5": 0.8,
                    "recall_at_10": 0.852,
                    "recall_at_20": 0.903,
                    "precision_at_1": 0.557,
                    "precision_at_3": 0.24733,
                    "precision_at_5": 0.16,
                    "precision_at_10": 0.0852,
                    "precision_at_20": 0.04515,
                    "mrr_at_1": 0.557,
                    "mrr_at_3": 0.639,
                    "mrr_at_5": 0.6522500000000002,
                    "mrr_at_10": 0.6592257936507938,
                    "mrr_at_20": 0.6626894265607114,
                    "main_score": 0.70621,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 35.72272968292236,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.6914,
                    "ndcg_at_3": 0.75934,
                    "ndcg_at_5": 0.77989,
                    "ndcg_at_10": 0.79655,
                    "ndcg_at_20": 0.80327,
                    "map_at_1": 0.66829,
                    "map_at_3": 0.73963,
                    "map_at_5": 0.75189,
                    "map_at_10": 0.75914,
                    "map_at_20": 0.76114,
                    "recall_at_1": 0.66829,
                    "recall_at_3": 0.80782,
                    "recall_at_5": 0.85665,
                    "recall_at_10": 0.90669,
                    "recall_at_20": 0.9324,
                    "precision_at_1": 0.6914,
                    "precision_at_3": 0.28491,
                    "precision_at_5": 0.18189,
                    "precision_at_10": 0.09633,
                    "precision_at_20": 0.04959,
                    "mrr_at_1": 0.691404011461318,
                    "mrr_at_3": 0.7478271251193889,
                    "mrr_at_5": 0.7583715377268361,
                    "mrr_at_10": 0.7650418997589482,
                    "mrr_at_20": 0.7667760787934241,
                    "main_score": 0.79655,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 371.1788399219513,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.19,
                    "ndcg_at_3": 0.15672,
                    "ndcg_at_5": 0.13449,
                    "ndcg_at_10": 0.1634,
                    "map_at_1": 0.03858,
                    "map_at_3": 0.06863,
                    "map_at_5": 0.08044,
                    "map_at_10": 0.09443,
                    "recall_at_1": 0.03858,
                    "recall_at_3": 0.08928,
                    "recall_at_5": 0.11868,
                    "recall_at_10": 0.17192,
                    "precision_at_1": 0.19,
                    "precision_at_3": 0.147,
                    "precision_at_5": 0.1172,
                    "precision_at_10": 0.0848,
                    "mrr_at_1": 0.19,
                    "mrr_at_3": 0.25983333333333347,
                    "mrr_at_5": 0.27478333333333327,
                    "mrr_at_10": 0.288245238095238,
                    "main_score": 0.1634,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 211.47468852996826,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.38977,
                    "ndcg_at_3": 0.46973,
                    "ndcg_at_5": 0.49276,
                    "ndcg_at_10": 0.51596,
                    "ndcg_at_20": 0.53198,
                    "map_at_1": 0.38969,
                    "map_at_3": 0.45014,
                    "map_at_5": 0.46295,
                    "map_at_10": 0.47258,
                    "map_at_20": 0.477,
                    "recall_at_1": 0.38969,
                    "recall_at_3": 0.52629,
                    "recall_at_5": 0.58209,
                    "recall_at_10": 0.65349,
                    "recall_at_20": 0.71672,
                    "precision_at_1": 0.38977,
                    "precision_at_3": 0.17549,
                    "precision_at_5": 0.11646,
                    "precision_at_10": 0.06538,
                    "precision_at_20": 0.03586,
                    "mrr_at_1": 0.3897728730912357,
                    "mrr_at_3": 0.45021707515292386,
                    "mrr_at_5": 0.4630218358355935,
                    "mrr_at_10": 0.47266417613284695,
                    "mrr_at_20": 0.47707636008507115,
                    "main_score": 0.51596,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 46.00936198234558,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.71489,
                    "ndcg_at_3": 0.77399,
                    "ndcg_at_5": 0.78444,
                    "ndcg_at_10": 0.79465,
                    "ndcg_at_20": 0.80124,
                    "map_at_1": 0.71449,
                    "map_at_3": 0.76002,
                    "map_at_5": 0.76585,
                    "map_at_10": 0.77011,
                    "map_at_20": 0.77193,
                    "recall_at_1": 0.71449,
                    "recall_at_3": 0.81397,
                    "recall_at_5": 0.83924,
                    "recall_at_10": 0.87063,
                    "recall_at_20": 0.89661,
                    "precision_at_1": 0.71489,
                    "precision_at_3": 0.27165,
                    "precision_at_5": 0.16809,
                    "precision_at_10": 0.08721,
                    "precision_at_20": 0.04491,
                    "mrr_at_1": 0.7148854961832061,
                    "mrr_at_3": 0.7601830103738421,
                    "mrr_at_5": 0.7659786651007991,
                    "mrr_at_10": 0.7702050652909416,
                    "mrr_at_20": 0.7720242040282428,
                    "main_score": 0.79465,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 118.63883662223816,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.37361,
                    "ndcg_at_3": 0.43094,
                    "ndcg_at_5": 0.44687,
                    "ndcg_at_10": 0.46305,
                    "ndcg_at_20": 0.47503,
                    "map_at_1": 0.37359,
                    "map_at_3": 0.41692,
                    "map_at_5": 0.42575,
                    "map_at_10": 0.43248,
                    "map_at_20": 0.43577,
                    "recall_at_1": 0.37359,
                    "recall_at_3": 0.47145,
                    "recall_at_5": 0.51016,
                    "recall_at_10": 0.55986,
                    "recall_at_20": 0.60725,
                    "precision_at_1": 0.37361,
                    "precision_at_3": 0.15716,
                    "precision_at_5": 0.10204,
                    "precision_at_10": 0.056,
                    "precision_at_20": 0.03037,
                    "mrr_at_1": 0.37360750648832103,
                    "mrr_at_3": 0.41693618153989587,
                    "mrr_at_5": 0.4257702801623777,
                    "mrr_at_10": 0.43252263386222695,
                    "mrr_at_20": 0.43581610419692235,
                    "main_score": 0.46305,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 36.46196484565735,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.68739,
                    "ndcg_at_3": 0.75731,
                    "ndcg_at_5": 0.77759,
                    "ndcg_at_10": 0.79376,
                    "ndcg_at_20": 0.80091,
                    "map_at_1": 0.66435,
                    "map_at_3": 0.73713,
                    "map_at_5": 0.74918,
                    "map_at_10": 0.75625,
                    "map_at_20": 0.7584,
                    "recall_at_1": 0.66435,
                    "recall_at_3": 0.80708,
                    "recall_at_5": 0.85538,
                    "recall_at_10": 0.9038,
                    "recall_at_20": 0.93106,
                    "precision_at_1": 0.68739,
                    "precision_at_3": 0.28462,
                    "precision_at_5": 0.18158,
                    "precision_at_10": 0.09605,
                    "precision_at_20": 0.04952,
                    "mrr_at_1": 0.6873925501432665,
                    "mrr_at_3": 0.7453915950334293,
                    "mrr_at_5": 0.7557927411652319,
                    "mrr_at_10": 0.7622623595761123,
                    "mrr_at_20": 0.7641252324666385,
                    "main_score": 0.79376,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 233.24139881134033,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.232,
                    "ndcg_at_3": 0.18888,
                    "ndcg_at_5": 0.16229,
                    "ndcg_at_10": 0.19273,
                    "ndcg_at_20": 0.223,
                    "map_at_1": 0.04728,
                    "map_at_3": 0.08498,
                    "map_at_5": 0.09902,
                    "map_at_10": 0.11416,
                    "map_at_20": 0.12508,
                    "recall_at_1": 0.04728,
                    "recall_at_3": 0.10723,
                    "recall_at_5": 0.14258,
                    "recall_at_10": 0.19895,
                    "recall_at_20": 0.2698,
                    "precision_at_1": 0.232,
                    "precision_at_3": 0.17633,
                    "precision_at_5": 0.1406,
                    "precision_at_10": 0.0981,
                    "precision_at_20": 0.0665,
                    "mrr_at_1": 0.232,
                    "mrr_at_3": 0.30683333333333335,
                    "mrr_at_5": 0.32618333333333305,
                    "mrr_at_10": 0.3376388888888886,
                    "mrr_at_20": 0.34456984989554623,
                    "main_score": 0.19273,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 176.80295968055725,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.88734,
                    "ndcg_at_3": 0.84647,
                    "ndcg_at_5": 0.83151,
                    "ndcg_at_10": 0.82953,
                    "ndcg_at_20": 0.84707,
                    "map_at_1": 0.26831,
                    "map_at_3": 0.53003,
                    "map_at_5": 0.65118,
                    "map_at_10": 0.75177,
                    "map_at_20": 0.77864,
                    "recall_at_1": 0.26831,
                    "recall_at_3": 0.54709,
                    "recall_at_5": 0.68518,
                    "recall_at_10": 0.81699,
                    "recall_at_20": 0.87623,
                    "precision_at_1": 0.88734,
                    "precision_at_3": 0.74103,
                    "precision_at_5": 0.62068,
                    "precision_at_10": 0.41224,
                    "precision_at_20": 0.22897,
                    "mrr_at_1": 0.8873399964930738,
                    "mrr_at_3": 0.9095505289613643,
                    "mrr_at_5": 0.9124503185457954,
                    "mrr_at_10": 0.9142017289702736,
                    "mrr_at_20": 0.9148344477205997,
                    "main_score": 0.82953,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1592.6580457687378,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.76907,
                    "ndcg_at_3": 0.7206,
                    "ndcg_at_5": 0.70258,
                    "ndcg_at_10": 0.70315,
                    "ndcg_at_20": 0.72939,
                    "map_at_1": 0.21283,
                    "map_at_3": 0.41902,
                    "map_at_5": 0.51608,
                    "map_at_10": 0.60092,
                    "map_at_20": 0.62961,
                    "recall_at_1": 0.21283,
                    "recall_at_3": 0.44728,
                    "recall_at_5": 0.57062,
                    "recall_at_10": 0.70247,
                    "recall_at_20": 0.78279,
                    "precision_at_1": 0.76907,
                    "precision_at_3": 0.63814,
                    "precision_at_5": 0.53345,
                    "precision_at_10": 0.3583,
                    "precision_at_20": 0.20551,
                    "mrr_at_1": 0.7690689110994213,
                    "mrr_at_3": 0.813365772400494,
                    "mrr_at_5": 0.8196563212344438,
                    "mrr_at_10": 0.8232581222915306,
                    "mrr_at_20": 0.8247442355342227,
                    "main_score": 0.70315,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 3956.8806262016296,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.68599,
                    "ndcg_at_3": 0.7782,
                    "ndcg_at_5": 0.7931,
                    "ndcg_at_10": 0.81037,
                    "ndcg_at_20": 0.81945,
                    "map_at_1": 0.68361,
                    "map_at_3": 0.75588,
                    "map_at_5": 0.76426,
                    "map_at_10": 0.77186,
                    "map_at_20": 0.77445,
                    "recall_at_1": 0.68361,
                    "recall_at_3": 0.84062,
                    "recall_at_5": 0.87698,
                    "recall_at_10": 0.92835,
                    "recall_at_20": 0.96365,
                    "precision_at_1": 0.68599,
                    "precision_at_3": 0.28205,
                    "precision_at_5": 0.17661,
                    "precision_at_10": 0.09378,
                    "precision_at_20": 0.04868,
                    "mrr_at_1": 0.6880927291886196,
                    "mrr_at_3": 0.7583421145064981,
                    "mrr_at_5": 0.7662978573937481,
                    "mrr_at_10": 0.7734712395671302,
                    "mrr_at_20": 0.7759653370604448,
                    "main_score": 0.81037,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 317.19435119628906,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.48665,
                    "ndcg_at_3": 0.57426,
                    "ndcg_at_5": 0.59762,
                    "ndcg_at_10": 0.61811,
                    "ndcg_at_20": 0.6323,
                    "map_at_1": 0.48651,
                    "map_at_3": 0.55289,
                    "map_at_5": 0.56587,
                    "map_at_10": 0.5744,
                    "map_at_20": 0.57832,
                    "recall_at_1": 0.48651,
                    "recall_at_3": 0.63596,
                    "recall_at_5": 0.69258,
                    "recall_at_10": 0.75549,
                    "recall_at_20": 0.81142,
                    "precision_at_1": 0.48665,
                    "precision_at_3": 0.21209,
                    "precision_at_5": 0.13859,
                    "precision_at_10": 0.07561,
                    "precision_at_20": 0.04061,
                    "mrr_at_1": 0.48662261003464646,
                    "mrr_at_3": 0.5529267718893124,
                    "mrr_at_5": 0.5659208049959533,
                    "mrr_at_10": 0.5744549061123378,
                    "mrr_at_20": 0.5783769772489749,
                    "main_score": 0.61811,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 99.39511632919312,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.77205,
                    "ndcg_at_3": 0.80507,
                    "ndcg_at_5": 0.81153,
                    "ndcg_at_10": 0.81684,
                    "ndcg_at_20": 0.81964,
                    "map_at_1": 0.77205,
                    "map_at_3": 0.79737,
                    "map_at_5": 0.80096,
                    "map_at_10": 0.80316,
                    "map_at_20": 0.80393,
                    "recall_at_1": 0.77205,
                    "recall_at_3": 0.8272,
                    "recall_at_5": 0.84285,
                    "recall_at_10": 0.8592,
                    "recall_at_20": 0.87025,
                    "precision_at_1": 0.77205,
                    "precision_at_3": 0.27573,
                    "precision_at_5": 0.16857,
                    "precision_at_10": 0.08592,
                    "precision_at_20": 0.04351,
                    "mrr_at_1": 0.77205,
                    "mrr_at_3": 0.79736666666667,
                    "mrr_at_5": 0.8009566666666719,
                    "mrr_at_10": 0.8031621428571474,
                    "mrr_at_20": 0.8039314686408001,
                    "main_score": 0.81684,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 678.0722806453705,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.46433,
                    "ndcg_at_3": 0.55405,
                    "ndcg_at_5": 0.57731,
                    "ndcg_at_10": 0.59876,
                    "ndcg_at_20": 0.61241,
                    "map_at_1": 0.46418,
                    "map_at_3": 0.53225,
                    "map_at_5": 0.54519,
                    "map_at_10": 0.55409,
                    "map_at_20": 0.55787,
                    "recall_at_1": 0.46418,
                    "recall_at_3": 0.61693,
                    "recall_at_5": 0.67322,
                    "recall_at_10": 0.73933,
                    "recall_at_20": 0.79308,
                    "precision_at_1": 0.46433,
                    "precision_at_3": 0.20574,
                    "precision_at_5": 0.13471,
                    "precision_at_10": 0.07397,
                    "precision_at_20": 0.03968,
                    "mrr_at_1": 0.4643269600923906,
                    "mrr_at_3": 0.5323474057915338,
                    "mrr_at_5": 0.5452933187903841,
                    "mrr_at_10": 0.5541976264820625,
                    "mrr_at_20": 0.5579734285906359,
                    "main_score": 0.59876,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 94.59521865844727,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.8455,
                    "ndcg_at_3": 0.81047,
                    "ndcg_at_5": 0.80078,
                    "ndcg_at_10": 0.83069,
                    "map_at_1": 0.23912,
                    "map_at_3": 0.50838,
                    "map_at_5": 0.64339,
                    "map_at_10": 0.74488,
                    "recall_at_1": 0.23912,
                    "recall_at_3": 0.53932,
                    "recall_at_5": 0.70415,
                    "recall_at_10": 0.85338,
                    "precision_at_1": 0.8455,
                    "precision_at_3": 0.73133,
                    "precision_at_5": 0.6176,
                    "precision_at_10": 0.4039,
                    "mrr_at_1": 0.8455,
                    "mrr_at_3": 0.8910833333333327,
                    "mrr_at_5": 0.8938833333333327,
                    "mrr_at_10": 0.8954107142857135,
                    "main_score": 0.83069,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 558.5632729530334,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.51333,
                    "ndcg_at_3": 0.56486,
                    "ndcg_at_5": 0.58212,
                    "ndcg_at_10": 0.61224,
                    "ndcg_at_20": 0.63141,
                    "map_at_1": 0.48467,
                    "map_at_3": 0.54117,
                    "map_at_5": 0.55291,
                    "map_at_10": 0.56739,
                    "map_at_20": 0.57332,
                    "recall_at_1": 0.48467,
                    "recall_at_3": 0.60783,
                    "recall_at_5": 0.64928,
                    "recall_at_10": 0.73522,
                    "recall_at_20": 0.808,
                    "precision_at_1": 0.51333,
                    "precision_at_3": 0.22,
                    "precision_at_5": 0.144,
                    "precision_at_10": 0.08367,
                    "precision_at_20": 0.04617,
                    "mrr_at_1": 0.5133333333333333,
                    "mrr_at_3": 0.5616666666666666,
                    "mrr_at_5": 0.5721666666666667,
                    "mrr_at_10": 0.5827513227513228,
                    "mrr_at_20": 0.5873199088350018,
                    "main_score": 0.61224,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 30.771617889404297,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "e4e08e0b7dbe3c8700f0daef558ff32256715259",
        "task_name": "QuoraChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.8171,
                    "ndcg_at_3": 0.85704,
                    "ndcg_at_5": 0.87301,
                    "ndcg_at_10": 0.88563,
                    "ndcg_at_20": 0.89176,
                    "map_at_1": 0.70867,
                    "map_at_3": 0.81874,
                    "map_at_5": 0.83752,
                    "map_at_10": 0.84856,
                    "map_at_20": 0.85254,
                    "recall_at_1": 0.70867,
                    "recall_at_3": 0.87353,
                    "recall_at_5": 0.919,
                    "recall_at_10": 0.9561,
                    "recall_at_20": 0.97555,
                    "precision_at_1": 0.8171,
                    "precision_at_3": 0.37517,
                    "precision_at_5": 0.24696,
                    "precision_at_10": 0.13465,
                    "precision_at_20": 0.0713,
                    "mrr_at_1": 0.817,
                    "mrr_at_3": 0.8680333333333309,
                    "mrr_at_5": 0.87482833333333,
                    "mrr_at_10": 0.8777053174603144,
                    "mrr_at_20": 0.8783632185964158,
                    "main_score": 0.88563,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 399.44018387794495,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.237,
                    "ndcg_at_3": 0.19394,
                    "ndcg_at_5": 0.16557,
                    "ndcg_at_10": 0.1997,
                    "map_at_1": 0.04818,
                    "map_at_3": 0.08658,
                    "map_at_5": 0.10165,
                    "map_at_10": 0.11803,
                    "recall_at_1": 0.04818,
                    "recall_at_3": 0.11028,
                    "recall_at_5": 0.14517,
                    "recall_at_10": 0.20845,
                    "precision_at_1": 0.237,
                    "precision_at_3": 0.18133,
                    "precision_at_5": 0.1432,
                    "precision_at_10": 0.1028,
                    "mrr_at_1": 0.237,
                    "mrr_at_3": 0.3168333333333333,
                    "mrr_at_5": 0.3316833333333331,
                    "mrr_at_10": 0.34655833333333314,
                    "main_score": 0.1997,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 436.2748727798462,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.39204,
                    "ndcg_at_3": 0.4709,
                    "ndcg_at_5": 0.49156,
                    "ndcg_at_10": 0.51274,
                    "ndcg_at_20": 0.52775,
                    "map_at_1": 0.3915,
                    "map_at_3": 0.45139,
                    "map_at_5": 0.46289,
                    "map_at_10": 0.47167,
                    "map_at_20": 0.47585,
                    "recall_at_1": 0.3915,
                    "recall_at_3": 0.52659,
                    "recall_at_5": 0.57666,
                    "recall_at_10": 0.64174,
                    "recall_at_20": 0.70046,
                    "precision_at_1": 0.39204,
                    "precision_at_3": 0.17614,
                    "precision_at_5": 0.11583,
                    "precision_at_10": 0.06457,
                    "precision_at_20": 0.03534,
                    "mrr_at_1": 0.3920384196900912,
                    "mrr_at_3": 0.45201290661464444,
                    "mrr_at_5": 0.46345627133907036,
                    "mrr_at_10": 0.47226216828982914,
                    "mrr_at_20": 0.4763899231217652,
                    "main_score": 0.51274,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 134.86822724342346,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.556,
                    "ndcg_at_3": 0.6682,
                    "ndcg_at_5": 0.68997,
                    "ndcg_at_10": 0.70382,
                    "map_at_1": 0.556,
                    "map_at_3": 0.64183,
                    "map_at_5": 0.65388,
                    "map_at_10": 0.65975,
                    "recall_at_1": 0.556,
                    "recall_at_3": 0.744,
                    "recall_at_5": 0.797,
                    "recall_at_10": 0.839,
                    "precision_at_1": 0.556,
                    "precision_at_3": 0.248,
                    "precision_at_5": 0.1594,
                    "precision_at_10": 0.0839,
                    "mrr_at_1": 0.555,
                    "mrr_at_3": 0.6413333333333334,
                    "mrr_at_5": 0.6533833333333335,
                    "mrr_at_10": 0.6592507936507938,
                    "main_score": 0.70382,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 395.46708250045776,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.463,
                    "ndcg_at_3": 0.55951,
                    "ndcg_at_5": 0.58055,
                    "ndcg_at_10": 0.60725,
                    "ndcg_at_20": 0.62412,
                    "map_at_1": 0.463,
                    "map_at_3": 0.53583,
                    "map_at_5": 0.54753,
                    "map_at_10": 0.55846,
                    "map_at_20": 0.56319,
                    "recall_at_1": 0.463,
                    "recall_at_3": 0.628,
                    "recall_at_5": 0.679,
                    "recall_at_10": 0.762,
                    "recall_at_20": 0.828,
                    "precision_at_1": 0.463,
                    "precision_at_3": 0.20933,
                    "precision_at_5": 0.1358,
                    "precision_at_10": 0.0762,
                    "precision_at_20": 0.0414,
                    "mrr_at_1": 0.463,
                    "mrr_at_3": 0.5358333333333328,
                    "mrr_at_5": 0.5475333333333328,
                    "mrr_at_10": 0.5584630952380948,
                    "mrr_at_20": 0.5631889455487747,
                    "main_score": 0.60725,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 167.32360887527466,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.67249,
                    "ndcg_at_3": 0.74342,
                    "ndcg_at_5": 0.76278,
                    "ndcg_at_10": 0.77963,
                    "ndcg_at_20": 0.78816,
                    "map_at_1": 0.65054,
                    "map_at_3": 0.72269,
                    "map_at_5": 0.7341,
                    "map_at_10": 0.74156,
                    "map_at_20": 0.74406,
                    "recall_at_1": 0.65054,
                    "recall_at_3": 0.79454,
                    "recall_at_5": 0.8406,
                    "recall_at_10": 0.89113,
                    "recall_at_20": 0.92387,
                    "precision_at_1": 0.67249,
                    "precision_at_3": 0.27956,
                    "precision_at_5": 0.17817,
                    "precision_at_10": 0.09466,
                    "precision_at_20": 0.04915,
                    "mrr_at_1": 0.6724928366762177,
                    "mrr_at_3": 0.7313514804202483,
                    "mrr_at_5": 0.7413514804202456,
                    "mrr_at_10": 0.7478446354664099,
                    "mrr_at_20": 0.7500416546085089,
                    "main_score": 0.77963,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 181.16178178787231,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.396,
                    "ndcg_at_3": 0.49285,
                    "ndcg_at_5": 0.51988,
                    "ndcg_at_10": 0.55026,
                    "ndcg_at_20": 0.56607,
                    "map_at_1": 0.396,
                    "map_at_3": 0.46867,
                    "map_at_5": 0.48382,
                    "map_at_10": 0.49633,
                    "map_at_20": 0.50073,
                    "recall_at_1": 0.396,
                    "recall_at_3": 0.563,
                    "recall_at_5": 0.628,
                    "recall_at_10": 0.722,
                    "recall_at_20": 0.784,
                    "precision_at_1": 0.396,
                    "precision_at_3": 0.18767,
                    "precision_at_5": 0.1256,
                    "precision_at_10": 0.0722,
                    "precision_at_20": 0.0392,
                    "mrr_at_1": 0.396,
                    "mrr_at_3": 0.468666666666666,
                    "mrr_at_5": 0.4838166666666658,
                    "mrr_at_10": 0.49632857142857106,
                    "mrr_at_20": 0.5007310757611835,
                    "main_score": 0.55026,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 141.15970730781555,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "6e346642246bfb4928c560ee08640dc84d074e8c",
        "task_name": "LEMBWikimQARetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.94333,
                    "ndcg_at_3": 0.95972,
                    "ndcg_at_5": 0.96546,
                    "ndcg_at_10": 0.96658,
                    "ndcg_at_20": 0.96743,
                    "map_at_1": 0.94333,
                    "map_at_3": 0.95611,
                    "map_at_5": 0.95944,
                    "map_at_10": 0.95992,
                    "map_at_20": 0.96016,
                    "recall_at_1": 0.94333,
                    "recall_at_3": 0.97,
                    "recall_at_5": 0.98333,
                    "recall_at_10": 0.98667,
                    "recall_at_20": 0.99,
                    "precision_at_1": 0.94333,
                    "precision_at_3": 0.32333,
                    "precision_at_5": 0.19667,
                    "precision_at_10": 0.09867,
                    "precision_at_20": 0.0495,
                    "mrr_at_1": 0.9433333333333334,
                    "mrr_at_3": 0.9561111111111112,
                    "mrr_at_5": 0.9594444444444445,
                    "mrr_at_10": 0.959920634920635,
                    "mrr_at_20": 0.9601587301587301,
                    "main_score": 0.96658,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 42.27868366241455,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.39141,
                    "ndcg_at_3": 0.45407,
                    "ndcg_at_5": 0.47096,
                    "ndcg_at_10": 0.48733,
                    "ndcg_at_20": 0.4997,
                    "map_at_1": 0.39109,
                    "map_at_3": 0.43868,
                    "map_at_5": 0.44807,
                    "map_at_10": 0.45485,
                    "map_at_20": 0.45823,
                    "recall_at_1": 0.39109,
                    "recall_at_3": 0.49796,
                    "recall_at_5": 0.53911,
                    "recall_at_10": 0.58955,
                    "recall_at_20": 0.63844,
                    "precision_at_1": 0.39141,
                    "precision_at_3": 0.16617,
                    "precision_at_5": 0.10797,
                    "precision_at_10": 0.05908,
                    "precision_at_20": 0.03201,
                    "mrr_at_1": 0.3914068745003997,
                    "mrr_at_3": 0.4390820676791929,
                    "mrr_at_5": 0.4484865440980599,
                    "mrr_at_10": 0.4553024088665634,
                    "mrr_at_20": 0.4587053542216571,
                    "main_score": 0.48733,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 48.54063940048218,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.51695,
                    "ndcg_at_3": 0.58237,
                    "ndcg_at_5": 0.59889,
                    "ndcg_at_10": 0.6158,
                    "ndcg_at_20": 0.62811,
                    "map_at_1": 0.51682,
                    "map_at_3": 0.5665,
                    "map_at_5": 0.57567,
                    "map_at_10": 0.58267,
                    "map_at_20": 0.58605,
                    "recall_at_1": 0.51682,
                    "recall_at_3": 0.62799,
                    "recall_at_5": 0.66811,
                    "recall_at_10": 0.72019,
                    "recall_at_20": 0.76881,
                    "precision_at_1": 0.51695,
                    "precision_at_3": 0.20941,
                    "precision_at_5": 0.13368,
                    "precision_at_10": 0.07208,
                    "precision_at_20": 0.03849,
                    "mrr_at_1": 0.5169464428457234,
                    "mrr_at_3": 0.5666533439914792,
                    "mrr_at_5": 0.5758320010658244,
                    "mrr_at_10": 0.582881916688881,
                    "mrr_at_20": 0.5862721610220994,
                    "main_score": 0.6158,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 147.21525979042053,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.89575,
                    "ndcg_at_3": 0.92989,
                    "ndcg_at_5": 0.93448,
                    "ndcg_at_10": 0.93758,
                    "map_at_1": 0.89575,
                    "map_at_3": 0.92191,
                    "map_at_5": 0.92447,
                    "map_at_10": 0.92576,
                    "recall_at_1": 0.89575,
                    "recall_at_3": 0.95282,
                    "recall_at_5": 0.96388,
                    "recall_at_10": 0.97341,
                    "precision_at_1": 0.89575,
                    "precision_at_3": 0.31761,
                    "precision_at_5": 0.19279,
                    "precision_at_10": 0.09735,
                    "mrr_at_1": 0.8957516921980763,
                    "mrr_at_3": 0.9219213870086674,
                    "mrr_at_5": 0.9244864030400193,
                    "mrr_at_10": 0.9257747602365973,
                    "main_score": 0.93758,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 102.3998875617981,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.54852,
                    "ndcg_at_3": 0.6087,
                    "ndcg_at_5": 0.6234,
                    "ndcg_at_10": 0.63887,
                    "ndcg_at_20": 0.64956,
                    "map_at_1": 0.54842,
                    "map_at_3": 0.5941,
                    "map_at_5": 0.60225,
                    "map_at_10": 0.60865,
                    "map_at_20": 0.61159,
                    "recall_at_1": 0.54842,
                    "recall_at_3": 0.65062,
                    "recall_at_5": 0.68632,
                    "recall_at_10": 0.73407,
                    "recall_at_20": 0.77623,
                    "precision_at_1": 0.54852,
                    "precision_at_3": 0.21696,
                    "precision_at_5": 0.13735,
                    "precision_at_10": 0.07349,
                    "precision_at_20": 0.03887,
                    "mrr_at_1": 0.5485211830535571,
                    "mrr_at_3": 0.5942712496669393,
                    "mrr_at_5": 0.6024487077005166,
                    "mrr_at_10": 0.6088720452209752,
                    "mrr_at_20": 0.6118185938182705,
                    "main_score": 0.63887,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 122.52124643325806,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.492,
                    "ndcg_at_3": 0.54772,
                    "ndcg_at_5": 0.56158,
                    "ndcg_at_10": 0.57123,
                    "ndcg_at_20": 0.58373,
                    "map_at_1": 0.492,
                    "map_at_3": 0.53383,
                    "map_at_5": 0.54143,
                    "map_at_10": 0.54539,
                    "map_at_20": 0.54888,
                    "recall_at_1": 0.492,
                    "recall_at_3": 0.588,
                    "recall_at_5": 0.622,
                    "recall_at_10": 0.652,
                    "recall_at_20": 0.701,
                    "precision_at_1": 0.492,
                    "precision_at_3": 0.196,
                    "precision_at_5": 0.1244,
                    "precision_at_10": 0.0652,
                    "precision_at_20": 0.03505,
                    "mrr_at_1": 0.492,
                    "mrr_at_3": 0.5338333333333333,
                    "mrr_at_5": 0.5414333333333333,
                    "mrr_at_10": 0.5453900793650794,
                    "mrr_at_20": 0.548882323391263,
                    "main_score": 0.57123,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 351.776319026947,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.42105,
                    "ndcg_at_3": 0.39167,
                    "ndcg_at_5": 0.37414,
                    "ndcg_at_10": 0.35306,
                    "ndcg_at_20": 0.32777,
                    "map_at_1": 0.05095,
                    "map_at_3": 0.09057,
                    "map_at_5": 0.10704,
                    "map_at_10": 0.12907,
                    "map_at_20": 0.14359,
                    "recall_at_1": 0.05095,
                    "recall_at_3": 0.10266,
                    "recall_at_5": 0.12861,
                    "recall_at_10": 0.17513,
                    "recall_at_20": 0.21149,
                    "precision_at_1": 0.43653,
                    "precision_at_3": 0.37461,
                    "precision_at_5": 0.33127,
                    "precision_at_10": 0.26935,
                    "precision_at_20": 0.19706,
                    "mrr_at_1": 0.44272445820433437,
                    "mrr_at_3": 0.5175438596491229,
                    "mrr_at_5": 0.5285345717234261,
                    "mrr_at_10": 0.5368789621111602,
                    "mrr_at_20": 0.540395265294622,
                    "main_score": 0.35306,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 35.26216197013855,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "e4e08e0b7dbe3c8700f0daef558ff32256715259",
        "task_name": "QuoraChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.4692,
                    "ndcg_at_3": 0.55029,
                    "ndcg_at_5": 0.58253,
                    "ndcg_at_10": 0.61596,
                    "ndcg_at_20": 0.63813,
                    "map_at_1": 0.41221,
                    "map_at_3": 0.50985,
                    "map_at_5": 0.53296,
                    "map_at_10": 0.55043,
                    "map_at_20": 0.55867,
                    "recall_at_1": 0.41221,
                    "recall_at_3": 0.60182,
                    "recall_at_5": 0.67989,
                    "recall_at_10": 0.77564,
                    "recall_at_20": 0.85337,
                    "precision_at_1": 0.4692,
                    "precision_at_3": 0.2469,
                    "precision_at_5": 0.17392,
                    "precision_at_10": 0.10395,
                    "precision_at_20": 0.05967,
                    "mrr_at_1": 0.4693,
                    "mrr_at_3": 0.5526499999999981,
                    "mrr_at_5": 0.5696099999999948,
                    "mrr_at_10": 0.5816846428571408,
                    "mrr_at_20": 0.5863999029930301,
                    "main_score": 0.61596,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 1063.843726158142,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.24864,
                    "ndcg_at_3": 0.31061,
                    "ndcg_at_5": 0.3313,
                    "ndcg_at_10": 0.35295,
                    "ndcg_at_20": 0.37024,
                    "map_at_1": 0.24815,
                    "map_at_3": 0.29502,
                    "map_at_5": 0.30654,
                    "map_at_10": 0.31551,
                    "map_at_20": 0.32026,
                    "recall_at_1": 0.24815,
                    "recall_at_3": 0.35497,
                    "recall_at_5": 0.40502,
                    "recall_at_10": 0.47171,
                    "recall_at_20": 0.53999,
                    "precision_at_1": 0.24864,
                    "precision_at_3": 0.11879,
                    "precision_at_5": 0.08146,
                    "precision_at_10": 0.04755,
                    "precision_at_20": 0.02726,
                    "mrr_at_1": 0.24863992796308107,
                    "mrr_at_3": 0.2956765342237853,
                    "mrr_at_5": 0.3072249527882967,
                    "mrr_at_10": 0.3161710108573479,
                    "mrr_at_20": 0.32088385904527766,
                    "main_score": 0.35295,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 36.96477651596069,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "Touche2020Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.43878,
                    "ndcg_at_3": 0.32975,
                    "ndcg_at_5": 0.29271,
                    "ndcg_at_10": 0.27137,
                    "ndcg_at_20": 0.27617,
                    "map_at_1": 0.03354,
                    "map_at_3": 0.05938,
                    "map_at_5": 0.07598,
                    "map_at_10": 0.10605,
                    "map_at_20": 0.13038,
                    "recall_at_1": 0.03354,
                    "recall_at_3": 0.07287,
                    "recall_at_5": 0.10056,
                    "recall_at_10": 0.16877,
                    "recall_at_20": 0.24304,
                    "precision_at_1": 0.44898,
                    "precision_at_3": 0.32653,
                    "precision_at_5": 0.27347,
                    "precision_at_10": 0.23061,
                    "precision_at_20": 0.17041,
                    "mrr_at_1": 0.4489795918367347,
                    "mrr_at_3": 0.5510204081632653,
                    "mrr_at_5": 0.5663265306122449,
                    "mrr_at_10": 0.5777453838678328,
                    "mrr_at_20": 0.5808066083576288,
                    "main_score": 0.27137,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 11803.098767757416,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.463,
                    "ndcg_at_3": 0.55888,
                    "ndcg_at_5": 0.57958,
                    "ndcg_at_10": 0.6068,
                    "ndcg_at_20": 0.62443,
                    "map_at_1": 0.463,
                    "map_at_3": 0.53533,
                    "map_at_5": 0.54688,
                    "map_at_10": 0.55814,
                    "map_at_20": 0.56308,
                    "recall_at_1": 0.463,
                    "recall_at_3": 0.627,
                    "recall_at_5": 0.677,
                    "recall_at_10": 0.761,
                    "recall_at_20": 0.83,
                    "precision_at_1": 0.463,
                    "precision_at_3": 0.209,
                    "precision_at_5": 0.1354,
                    "precision_at_10": 0.0761,
                    "precision_at_20": 0.0415,
                    "mrr_at_1": 0.463,
                    "mrr_at_3": 0.5353333333333328,
                    "mrr_at_5": 0.5468833333333327,
                    "mrr_at_10": 0.5581408730158725,
                    "mrr_at_20": 0.5630801413842428,
                    "main_score": 0.6068,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 192.642014503479,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.48232,
                    "ndcg_at_3": 0.57326,
                    "ndcg_at_5": 0.59639,
                    "ndcg_at_10": 0.61791,
                    "ndcg_at_20": 0.63227,
                    "map_at_1": 0.48226,
                    "map_at_3": 0.55114,
                    "map_at_5": 0.564,
                    "map_at_10": 0.57293,
                    "map_at_20": 0.57693,
                    "recall_at_1": 0.48226,
                    "recall_at_3": 0.63697,
                    "recall_at_5": 0.69314,
                    "recall_at_10": 0.75939,
                    "recall_at_20": 0.81578,
                    "precision_at_1": 0.48232,
                    "precision_at_3": 0.21244,
                    "precision_at_5": 0.13875,
                    "precision_at_10": 0.07601,
                    "precision_at_20": 0.04083,
                    "mrr_at_1": 0.4823238804054921,
                    "mrr_at_3": 0.5512639548312678,
                    "mrr_at_5": 0.5640574874887873,
                    "mrr_at_10": 0.5729990818989084,
                    "mrr_at_20": 0.5769944117169996,
                    "main_score": 0.61791,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 135.2667739391327,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.2859,
                    "ndcg_at_3": 0.35975,
                    "ndcg_at_5": 0.38246,
                    "ndcg_at_10": 0.40648,
                    "ndcg_at_20": 0.42381,
                    "map_at_1": 0.28527,
                    "map_at_3": 0.34139,
                    "map_at_5": 0.35403,
                    "map_at_10": 0.36397,
                    "map_at_20": 0.36875,
                    "recall_at_1": 0.28527,
                    "recall_at_3": 0.41209,
                    "recall_at_5": 0.46706,
                    "recall_at_10": 0.54114,
                    "recall_at_20": 0.60929,
                    "precision_at_1": 0.2859,
                    "precision_at_3": 0.13788,
                    "precision_at_5": 0.09387,
                    "precision_at_10": 0.05444,
                    "precision_at_20": 0.03073,
                    "mrr_at_1": 0.28589652196750837,
                    "mrr_at_3": 0.34208156680298346,
                    "mrr_at_5": 0.35473492664990597,
                    "mrr_at_10": 0.3646539238264391,
                    "mrr_at_20": 0.36940927686844416,
                    "main_score": 0.40648,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 102.1621482372284,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.26207,
                    "ndcg_at_3": 0.33458,
                    "ndcg_at_5": 0.35687,
                    "ndcg_at_10": 0.379,
                    "ndcg_at_20": 0.39711,
                    "map_at_1": 0.26137,
                    "map_at_3": 0.31647,
                    "map_at_5": 0.32887,
                    "map_at_10": 0.33801,
                    "map_at_20": 0.34302,
                    "recall_at_1": 0.26137,
                    "recall_at_3": 0.38615,
                    "recall_at_5": 0.44017,
                    "recall_at_10": 0.50844,
                    "recall_at_20": 0.57957,
                    "precision_at_1": 0.26207,
                    "precision_at_3": 0.12927,
                    "precision_at_5": 0.08848,
                    "precision_at_10": 0.05119,
                    "precision_at_20": 0.02924,
                    "mrr_at_1": 0.2620718118035493,
                    "mrr_at_3": 0.31725009067146454,
                    "mrr_at_5": 0.3296051726509787,
                    "mrr_at_10": 0.3387747381247168,
                    "mrr_at_20": 0.34375716854662663,
                    "main_score": 0.379,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 115.97998976707458,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "Touche2020Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.29592,
                    "ndcg_at_3": 0.27167,
                    "ndcg_at_5": 0.27299,
                    "ndcg_at_10": 0.26588,
                    "map_at_1": 0.02814,
                    "map_at_3": 0.05544,
                    "map_at_5": 0.07457,
                    "map_at_10": 0.10582,
                    "recall_at_1": 0.02814,
                    "recall_at_3": 0.06928,
                    "recall_at_5": 0.10841,
                    "recall_at_10": 0.17228,
                    "precision_at_1": 0.30612,
                    "precision_at_3": 0.28571,
                    "precision_at_5": 0.28163,
                    "precision_at_10": 0.23469,
                    "mrr_at_1": 0.30612244897959184,
                    "mrr_at_3": 0.43537414965986393,
                    "mrr_at_5": 0.4721088435374149,
                    "mrr_at_10": 0.48165694849368307,
                    "main_score": 0.26588,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 2499.7108545303345,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.67249,
                    "ndcg_at_3": 0.74342,
                    "ndcg_at_5": 0.76278,
                    "ndcg_at_10": 0.77964,
                    "map_at_1": 0.65054,
                    "map_at_3": 0.72269,
                    "map_at_5": 0.7341,
                    "map_at_10": 0.74156,
                    "recall_at_1": 0.65054,
                    "recall_at_3": 0.79454,
                    "recall_at_5": 0.8406,
                    "recall_at_10": 0.89113,
                    "precision_at_1": 0.67249,
                    "precision_at_3": 0.27956,
                    "precision_at_5": 0.17817,
                    "precision_at_10": 0.09466,
                    "mrr_at_1": 0.6724928366762177,
                    "mrr_at_3": 0.7313514804202483,
                    "mrr_at_5": 0.7413514804202456,
                    "mrr_at_10": 0.7478480465729728,
                    "main_score": 0.77964,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 180.39047193527222,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.67249,
                    "ndcg_at_3": 0.74342,
                    "ndcg_at_5": 0.76279,
                    "ndcg_at_10": 0.77963,
                    "map_at_1": 0.65054,
                    "map_at_3": 0.72269,
                    "map_at_5": 0.7341,
                    "map_at_10": 0.74156,
                    "recall_at_1": 0.65054,
                    "recall_at_3": 0.79454,
                    "recall_at_5": 0.8406,
                    "recall_at_10": 0.89113,
                    "precision_at_1": 0.67249,
                    "precision_at_3": 0.27956,
                    "precision_at_5": 0.17817,
                    "precision_at_10": 0.09466,
                    "mrr_at_1": 0.6724928366762177,
                    "mrr_at_3": 0.7313514804202483,
                    "mrr_at_5": 0.7413514804202456,
                    "mrr_at_10": 0.7478386660299247,
                    "main_score": 0.77963,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 116.98779821395874,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "e4e08e0b7dbe3c8700f0daef558ff32256715259",
        "task_name": "QuoraChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.7823,
                    "ndcg_at_3": 0.82758,
                    "ndcg_at_5": 0.84523,
                    "ndcg_at_10": 0.86028,
                    "ndcg_at_20": 0.86805,
                    "map_at_1": 0.67829,
                    "map_at_3": 0.78754,
                    "map_at_5": 0.80693,
                    "map_at_10": 0.81862,
                    "map_at_20": 0.82315,
                    "recall_at_1": 0.67829,
                    "recall_at_3": 0.84924,
                    "recall_at_5": 0.89815,
                    "recall_at_10": 0.94209,
                    "recall_at_20": 0.96712,
                    "precision_at_1": 0.7823,
                    "precision_at_3": 0.3631,
                    "precision_at_5": 0.24008,
                    "precision_at_10": 0.13196,
                    "precision_at_20": 0.07036,
                    "mrr_at_1": 0.7824,
                    "mrr_at_3": 0.8391999999999962,
                    "mrr_at_5": 0.846729999999995,
                    "mrr_at_10": 0.8506050396825362,
                    "mrr_at_20": 0.8516045569579163,
                    "main_score": 0.86028,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 729.8062582015991,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.211,
                    "ndcg_at_3": 0.16483,
                    "ndcg_at_5": 0.14123,
                    "ndcg_at_10": 0.16942,
                    "ndcg_at_20": 0.19232,
                    "map_at_1": 0.04263,
                    "map_at_3": 0.07298,
                    "map_at_5": 0.08551,
                    "map_at_10": 0.09823,
                    "map_at_20": 0.10625,
                    "recall_at_1": 0.04263,
                    "recall_at_3": 0.09313,
                    "recall_at_5": 0.12363,
                    "recall_at_10": 0.17578,
                    "recall_at_20": 0.22973,
                    "precision_at_1": 0.211,
                    "precision_at_3": 0.153,
                    "precision_at_5": 0.122,
                    "precision_at_10": 0.0867,
                    "precision_at_20": 0.0567,
                    "mrr_at_1": 0.211,
                    "mrr_at_3": 0.27383333333333343,
                    "mrr_at_5": 0.28948333333333304,
                    "mrr_at_10": 0.30443412698412664,
                    "mrr_at_20": 0.3099911507910729,
                    "main_score": 0.16942,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 86.88353872299194,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.88008,
                    "ndcg_at_3": 0.91809,
                    "ndcg_at_5": 0.92443,
                    "ndcg_at_10": 0.9287,
                    "ndcg_at_20": 0.93075,
                    "map_at_1": 0.88008,
                    "map_at_3": 0.90922,
                    "map_at_5": 0.91275,
                    "map_at_10": 0.91454,
                    "map_at_20": 0.91511,
                    "recall_at_1": 0.88008,
                    "recall_at_3": 0.94355,
                    "recall_at_5": 0.95887,
                    "recall_at_10": 0.97197,
                    "recall_at_20": 0.98006,
                    "precision_at_1": 0.88008,
                    "precision_at_3": 0.31452,
                    "precision_at_5": 0.19177,
                    "precision_at_10": 0.0972,
                    "precision_at_20": 0.049,
                    "mrr_at_1": 0.8800799467021986,
                    "mrr_at_3": 0.9092234806425337,
                    "mrr_at_5": 0.9127544599896376,
                    "mrr_at_10": 0.9145401830878187,
                    "mrr_at_20": 0.91510932753854,
                    "main_score": 0.9287,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 154.0933792591095,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.50727,
                    "ndcg_at_3": 0.57309,
                    "ndcg_at_5": 0.5893,
                    "ndcg_at_10": 0.60592,
                    "ndcg_at_20": 0.61739,
                    "map_at_1": 0.50707,
                    "map_at_3": 0.55709,
                    "map_at_5": 0.56611,
                    "map_at_10": 0.57299,
                    "map_at_20": 0.57614,
                    "recall_at_1": 0.50707,
                    "recall_at_3": 0.61892,
                    "recall_at_5": 0.6582,
                    "recall_at_10": 0.70946,
                    "recall_at_20": 0.75471,
                    "precision_at_1": 0.50727,
                    "precision_at_3": 0.20646,
                    "precision_at_5": 0.13177,
                    "precision_at_10": 0.07103,
                    "precision_at_20": 0.03779,
                    "mrr_at_1": 0.5072741806554756,
                    "mrr_at_3": 0.5573874233946241,
                    "mrr_at_5": 0.5664501731947882,
                    "mrr_at_10": 0.5733427860885998,
                    "mrr_at_20": 0.5765033288384676,
                    "main_score": 0.60592,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 107.73848152160645,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.421,
                    "ndcg_at_3": 0.47709,
                    "ndcg_at_5": 0.49056,
                    "ndcg_at_10": 0.50129,
                    "ndcg_at_20": 0.51259,
                    "map_at_1": 0.421,
                    "map_at_3": 0.463,
                    "map_at_5": 0.4704,
                    "map_at_10": 0.47486,
                    "map_at_20": 0.47793,
                    "recall_at_1": 0.421,
                    "recall_at_3": 0.518,
                    "recall_at_5": 0.551,
                    "recall_at_10": 0.584,
                    "recall_at_20": 0.629,
                    "precision_at_1": 0.421,
                    "precision_at_3": 0.17267,
                    "precision_at_5": 0.1102,
                    "precision_at_10": 0.0584,
                    "precision_at_20": 0.03145,
                    "mrr_at_1": 0.422,
                    "mrr_at_3": 0.4634999999999996,
                    "mrr_at_5": 0.4708999999999996,
                    "mrr_at_10": 0.47535555555555525,
                    "mrr_at_20": 0.4784252467647586,
                    "main_score": 0.50129,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 890.1392858028412,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.341,
                    "ndcg_at_3": 0.42668,
                    "ndcg_at_5": 0.45289,
                    "ndcg_at_10": 0.48132,
                    "ndcg_at_20": 0.4994,
                    "map_at_1": 0.341,
                    "map_at_3": 0.4055,
                    "map_at_5": 0.4202,
                    "map_at_10": 0.43191,
                    "map_at_20": 0.43681,
                    "recall_at_1": 0.341,
                    "recall_at_3": 0.488,
                    "recall_at_5": 0.551,
                    "recall_at_10": 0.639,
                    "recall_at_20": 0.711,
                    "precision_at_1": 0.341,
                    "precision_at_3": 0.16267,
                    "precision_at_5": 0.1102,
                    "precision_at_10": 0.0639,
                    "precision_at_20": 0.03555,
                    "mrr_at_1": 0.34,
                    "mrr_at_3": 0.4049999999999997,
                    "mrr_at_5": 0.4196999999999995,
                    "mrr_at_10": 0.4314126984126982,
                    "mrr_at_20": 0.4363078925675285,
                    "main_score": 0.48132,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 325.8046987056732,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.5393,
                    "ndcg_at_3": 0.61976,
                    "ndcg_at_5": 0.63945,
                    "ndcg_at_10": 0.65753,
                    "ndcg_at_20": 0.66938,
                    "map_at_1": 0.53923,
                    "map_at_3": 0.60025,
                    "map_at_5": 0.6112,
                    "map_at_10": 0.61871,
                    "map_at_20": 0.622,
                    "recall_at_1": 0.53923,
                    "recall_at_3": 0.67604,
                    "recall_at_5": 0.72374,
                    "recall_at_10": 0.77934,
                    "recall_at_20": 0.82599,
                    "precision_at_1": 0.5393,
                    "precision_at_3": 0.22541,
                    "precision_at_5": 0.14481,
                    "precision_at_10": 0.07798,
                    "precision_at_20": 0.04133,
                    "mrr_at_1": 0.5392980880277172,
                    "mrr_at_3": 0.6002929979896524,
                    "mrr_at_5": 0.6112515505368158,
                    "mrr_at_10": 0.6187689679790048,
                    "mrr_at_20": 0.6220407765003307,
                    "main_score": 0.65753,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 105.87835121154785,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.88772,
                    "ndcg_at_3": 0.92195,
                    "ndcg_at_5": 0.92728,
                    "ndcg_at_10": 0.93062,
                    "ndcg_at_20": 0.93267,
                    "map_at_1": 0.88772,
                    "map_at_3": 0.914,
                    "map_at_5": 0.91699,
                    "map_at_10": 0.9184,
                    "map_at_20": 0.91897,
                    "recall_at_1": 0.88772,
                    "recall_at_3": 0.94479,
                    "recall_at_5": 0.95758,
                    "recall_at_10": 0.96775,
                    "recall_at_20": 0.97579,
                    "precision_at_1": 0.88772,
                    "precision_at_3": 0.31493,
                    "precision_at_5": 0.19152,
                    "precision_at_10": 0.09678,
                    "precision_at_20": 0.04879,
                    "mrr_at_1": 0.887719298245614,
                    "mrr_at_3": 0.9139980753571684,
                    "mrr_at_5": 0.9169894144644319,
                    "mrr_at_10": 0.9183973823447523,
                    "mrr_at_20": 0.9189683497169544,
                    "main_score": 0.93062,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 90.95888900756836,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.56211,
                    "ndcg_at_3": 0.61808,
                    "ndcg_at_5": 0.63493,
                    "ndcg_at_10": 0.64883,
                    "ndcg_at_20": 0.65961,
                    "map_at_1": 0.56199,
                    "map_at_3": 0.60439,
                    "map_at_5": 0.6138,
                    "map_at_10": 0.61957,
                    "map_at_20": 0.62252,
                    "recall_at_1": 0.56199,
                    "recall_at_3": 0.6573,
                    "recall_at_5": 0.69807,
                    "recall_at_10": 0.74084,
                    "recall_at_20": 0.78347,
                    "precision_at_1": 0.56211,
                    "precision_at_3": 0.21923,
                    "precision_at_5": 0.13972,
                    "precision_at_10": 0.07415,
                    "precision_at_20": 0.03922,
                    "mrr_at_1": 0.5621082052305849,
                    "mrr_at_3": 0.6046383176948233,
                    "mrr_at_5": 0.6140373993478526,
                    "mrr_at_10": 0.6198165999613497,
                    "mrr_at_20": 0.6227798592510475,
                    "main_score": 0.64883,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 100.42415595054626,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.32569,
                    "ndcg_at_3": 0.40827,
                    "ndcg_at_5": 0.43047,
                    "ndcg_at_10": 0.45144,
                    "ndcg_at_20": 0.46677,
                    "map_at_1": 0.32507,
                    "map_at_3": 0.38782,
                    "map_at_5": 0.40022,
                    "map_at_10": 0.4089,
                    "map_at_20": 0.41315,
                    "recall_at_1": 0.32507,
                    "recall_at_3": 0.46653,
                    "recall_at_5": 0.52021,
                    "recall_at_10": 0.58478,
                    "recall_at_20": 0.64494,
                    "precision_at_1": 0.32569,
                    "precision_at_3": 0.15603,
                    "precision_at_5": 0.1045,
                    "precision_at_10": 0.05884,
                    "precision_at_20": 0.03252,
                    "mrr_at_1": 0.32568876210494707,
                    "mrr_at_3": 0.3885906963941656,
                    "mrr_at_5": 0.40089270074819483,
                    "mrr_at_10": 0.4095971362796351,
                    "mrr_at_20": 0.41381875666134316,
                    "main_score": 0.45144,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 101.51357197761536,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.89394,
                    "ndcg_at_3": 0.93043,
                    "ndcg_at_5": 0.9349,
                    "ndcg_at_10": 0.93797,
                    "ndcg_at_20": 0.93964,
                    "map_at_1": 0.89394,
                    "map_at_3": 0.92197,
                    "map_at_5": 0.92446,
                    "map_at_10": 0.92574,
                    "map_at_20": 0.9262,
                    "recall_at_1": 0.89394,
                    "recall_at_3": 0.9547,
                    "recall_at_5": 0.96553,
                    "recall_at_10": 0.97495,
                    "recall_at_20": 0.98152,
                    "precision_at_1": 0.89394,
                    "precision_at_3": 0.31823,
                    "precision_at_5": 0.19311,
                    "precision_at_10": 0.0975,
                    "precision_at_20": 0.04908,
                    "mrr_at_1": 0.8939373750832779,
                    "mrr_at_3": 0.921970538159745,
                    "mrr_at_5": 0.9244577688948117,
                    "mrr_at_10": 0.9257422917349648,
                    "mrr_at_20": 0.9261984863633055,
                    "main_score": 0.93797,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 88.97584271430969,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.3768,
                    "ndcg_at_3": 0.43405,
                    "ndcg_at_5": 0.45038,
                    "ndcg_at_10": 0.4667,
                    "ndcg_at_20": 0.47863,
                    "map_at_1": 0.37676,
                    "map_at_3": 0.42012,
                    "map_at_5": 0.42919,
                    "map_at_10": 0.43598,
                    "map_at_20": 0.43924,
                    "recall_at_1": 0.37676,
                    "recall_at_3": 0.47423,
                    "recall_at_5": 0.51386,
                    "recall_at_10": 0.56404,
                    "recall_at_20": 0.61122,
                    "precision_at_1": 0.3768,
                    "precision_at_3": 0.15809,
                    "precision_at_5": 0.10278,
                    "precision_at_10": 0.05642,
                    "precision_at_20": 0.03057,
                    "mrr_at_1": 0.3768017568376922,
                    "mrr_at_3": 0.420163705330406,
                    "mrr_at_5": 0.42923537632262215,
                    "mrr_at_10": 0.43603106471843106,
                    "mrr_at_20": 0.4393065220710908,
                    "main_score": 0.4667,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 51.71006488800049,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.63095,
                    "ndcg_at_3": 0.70605,
                    "ndcg_at_5": 0.72741,
                    "ndcg_at_10": 0.7449,
                    "map_at_1": 0.6101,
                    "map_at_3": 0.68397,
                    "map_at_5": 0.69658,
                    "map_at_10": 0.7042,
                    "recall_at_1": 0.6101,
                    "recall_at_3": 0.76053,
                    "recall_at_5": 0.8114,
                    "recall_at_10": 0.86414,
                    "precision_at_1": 0.63095,
                    "precision_at_3": 0.26786,
                    "precision_at_5": 0.17201,
                    "precision_at_10": 0.09179,
                    "mrr_at_1": 0.6309455587392551,
                    "mrr_at_3": 0.6930515759312332,
                    "mrr_at_5": 0.7040759312320904,
                    "mrr_at_10": 0.7109124710055943,
                    "main_score": 0.7449,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 441.2955358028412,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "2e643e7363944af1c33a652d1c87320d0871c4e4",
        "task_name": "NarrativeQAChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.62338,
                    "ndcg_at_3": 0.69605,
                    "ndcg_at_5": 0.71138,
                    "ndcg_at_10": 0.72503,
                    "map_at_1": 0.62338,
                    "map_at_3": 0.67862,
                    "map_at_5": 0.68715,
                    "map_at_10": 0.69284,
                    "recall_at_1": 0.62338,
                    "recall_at_3": 0.74633,
                    "recall_at_5": 0.78346,
                    "recall_at_10": 0.82533,
                    "precision_at_1": 0.62338,
                    "precision_at_3": 0.24878,
                    "precision_at_5": 0.15669,
                    "precision_at_10": 0.08253,
                    "mrr_at_1": 0.6233778535568817,
                    "mrr_at_3": 0.6786176628461332,
                    "mrr_at_5": 0.6871475482302364,
                    "mrr_at_10": 0.6928418441987595,
                    "main_score": 0.72503,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 777.5265669822693,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.69855,
                    "ndcg_at_3": 0.76597,
                    "ndcg_at_5": 0.77817,
                    "ndcg_at_10": 0.78989,
                    "ndcg_at_20": 0.79764,
                    "map_at_1": 0.69812,
                    "map_at_3": 0.75003,
                    "map_at_5": 0.75684,
                    "map_at_10": 0.76172,
                    "map_at_20": 0.76387,
                    "recall_at_1": 0.69812,
                    "recall_at_3": 0.81153,
                    "recall_at_5": 0.841,
                    "recall_at_10": 0.87699,
                    "recall_at_20": 0.90752,
                    "precision_at_1": 0.69855,
                    "precision_at_3": 0.2708,
                    "precision_at_5": 0.1684,
                    "precision_at_10": 0.08783,
                    "precision_at_20": 0.04545,
                    "mrr_at_1": 0.6985497034818859,
                    "mrr_at_3": 0.7503131544438496,
                    "mrr_at_5": 0.7570978411915508,
                    "mrr_at_10": 0.7619643987201671,
                    "mrr_at_20": 0.7640996176770536,
                    "main_score": 0.78989,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 195.78234195709229,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.218,
                    "ndcg_at_3": 0.17416,
                    "ndcg_at_5": 0.15042,
                    "ndcg_at_10": 0.17857,
                    "ndcg_at_20": 0.20351,
                    "map_at_1": 0.04428,
                    "map_at_3": 0.07785,
                    "map_at_5": 0.09134,
                    "map_at_10": 0.10519,
                    "map_at_20": 0.1139,
                    "recall_at_1": 0.04428,
                    "recall_at_3": 0.09853,
                    "recall_at_5": 0.13263,
                    "recall_at_10": 0.18398,
                    "recall_at_20": 0.24238,
                    "precision_at_1": 0.218,
                    "precision_at_3": 0.162,
                    "precision_at_5": 0.1306,
                    "precision_at_10": 0.0907,
                    "precision_at_20": 0.0598,
                    "mrr_at_1": 0.218,
                    "mrr_at_3": 0.2865,
                    "mrr_at_5": 0.30549999999999966,
                    "mrr_at_10": 0.31806984126984095,
                    "mrr_at_20": 0.3244122014938961,
                    "main_score": 0.17857,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 112.67348217964172,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.32407,
                    "ndcg_at_3": 0.29827,
                    "ndcg_at_5": 0.31047,
                    "ndcg_at_10": 0.33285,
                    "ndcg_at_20": 0.35423,
                    "map_at_1": 0.16612,
                    "map_at_3": 0.22845,
                    "map_at_5": 0.24842,
                    "map_at_10": 0.26351,
                    "map_at_20": 0.27128,
                    "recall_at_1": 0.16612,
                    "recall_at_3": 0.26901,
                    "recall_at_5": 0.32444,
                    "recall_at_10": 0.3941,
                    "recall_at_20": 0.46079,
                    "precision_at_1": 0.32407,
                    "precision_at_3": 0.1965,
                    "precision_at_5": 0.14599,
                    "precision_at_10": 0.09244,
                    "precision_at_20": 0.05486,
                    "mrr_at_1": 0.32407407407407407,
                    "mrr_at_3": 0.38168724279835403,
                    "mrr_at_5": 0.39372427983539104,
                    "mrr_at_10": 0.40546982167352524,
                    "mrr_at_20": 0.4103150988126907,
                    "main_score": 0.33285,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 151.28186655044556,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.50715,
                    "ndcg_at_3": 0.59412,
                    "ndcg_at_5": 0.61641,
                    "ndcg_at_10": 0.63626,
                    "ndcg_at_20": 0.6483,
                    "map_at_1": 0.50707,
                    "map_at_3": 0.57301,
                    "map_at_5": 0.58541,
                    "map_at_10": 0.59368,
                    "map_at_20": 0.59702,
                    "recall_at_1": 0.50707,
                    "recall_at_3": 0.65504,
                    "recall_at_5": 0.70898,
                    "recall_at_10": 0.76996,
                    "recall_at_20": 0.81727,
                    "precision_at_1": 0.50715,
                    "precision_at_3": 0.21843,
                    "precision_at_5": 0.14185,
                    "precision_at_10": 0.07704,
                    "precision_at_20": 0.04089,
                    "mrr_at_1": 0.5071538560246375,
                    "mrr_at_3": 0.5730730570169876,
                    "mrr_at_5": 0.5854736087942299,
                    "mrr_at_10": 0.5937366460335913,
                    "mrr_at_20": 0.597074597319951,
                    "main_score": 0.63626,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 129.22700023651123,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.88767,
                    "ndcg_at_3": 0.92197,
                    "ndcg_at_5": 0.9273,
                    "ndcg_at_10": 0.93062,
                    "ndcg_at_20": 0.93268,
                    "map_at_1": 0.88767,
                    "map_at_3": 0.91401,
                    "map_at_5": 0.91699,
                    "map_at_10": 0.9184,
                    "map_at_20": 0.91897,
                    "recall_at_1": 0.88767,
                    "recall_at_3": 0.94484,
                    "recall_at_5": 0.95763,
                    "recall_at_10": 0.96775,
                    "recall_at_20": 0.97584,
                    "precision_at_1": 0.88767,
                    "precision_at_3": 0.31495,
                    "precision_at_5": 0.19153,
                    "precision_at_10": 0.09678,
                    "precision_at_20": 0.04879,
                    "mrr_at_1": 0.8876748834110593,
                    "mrr_at_3": 0.9140054778295944,
                    "mrr_at_5": 0.9169923754534022,
                    "mrr_at_10": 0.9183958137255954,
                    "mrr_at_20": 0.9189689951793766,
                    "main_score": 0.93062,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 88.46138119697571,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.34234,
                    "ndcg_at_3": 0.3462,
                    "ndcg_at_5": 0.36232,
                    "ndcg_at_10": 0.39116,
                    "map_at_1": 0.22069,
                    "map_at_3": 0.29341,
                    "map_at_5": 0.31202,
                    "map_at_10": 0.3291,
                    "recall_at_1": 0.22069,
                    "recall_at_3": 0.34607,
                    "recall_at_5": 0.39999,
                    "recall_at_10": 0.4844,
                    "precision_at_1": 0.34234,
                    "precision_at_3": 0.1973,
                    "precision_at_5": 0.14154,
                    "precision_at_10": 0.08807,
                    "mrr_at_1": 0.342335583895974,
                    "mrr_at_3": 0.3969742435608898,
                    "mrr_at_5": 0.4085271317829458,
                    "mrr_at_10": 0.41914982713932375,
                    "main_score": 0.39116,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 337.9114193916321,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "bb9466bac8153a0349341eb1b22e06409e78ef4e",
        "task_name": "TRECCOVIDChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.77,
                    "ndcg_at_3": 0.74112,
                    "ndcg_at_5": 0.71454,
                    "ndcg_at_10": 0.69013,
                    "ndcg_at_20": 0.67827,
                    "map_at_1": 0.00233,
                    "map_at_3": 0.00603,
                    "map_at_5": 0.00935,
                    "map_at_10": 0.01676,
                    "map_at_20": 0.03101,
                    "recall_at_1": 0.00233,
                    "recall_at_3": 0.00635,
                    "recall_at_5": 0.01013,
                    "recall_at_10": 0.01912,
                    "recall_at_20": 0.03714,
                    "precision_at_1": 0.84,
                    "precision_at_3": 0.8,
                    "precision_at_5": 0.772,
                    "precision_at_10": 0.738,
                    "precision_at_20": 0.735,
                    "mrr_at_1": 0.84,
                    "mrr_at_3": 0.9166666666666667,
                    "mrr_at_5": 0.9166666666666667,
                    "mrr_at_10": 0.9166666666666667,
                    "mrr_at_20": 0.9166666666666667,
                    "main_score": 0.69013,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 569.3991248607635,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.56211,
                    "ndcg_at_3": 0.61808,
                    "ndcg_at_5": 0.63493,
                    "ndcg_at_10": 0.64883,
                    "ndcg_at_20": 0.65961,
                    "map_at_1": 0.56199,
                    "map_at_3": 0.60439,
                    "map_at_5": 0.6138,
                    "map_at_10": 0.61957,
                    "map_at_20": 0.62252,
                    "recall_at_1": 0.56199,
                    "recall_at_3": 0.6573,
                    "recall_at_5": 0.69807,
                    "recall_at_10": 0.74084,
                    "recall_at_20": 0.78347,
                    "precision_at_1": 0.56211,
                    "precision_at_3": 0.21923,
                    "precision_at_5": 0.13972,
                    "precision_at_10": 0.07415,
                    "precision_at_20": 0.03922,
                    "mrr_at_1": 0.5621082052305849,
                    "mrr_at_3": 0.6046383176948233,
                    "mrr_at_5": 0.6140373993478526,
                    "mrr_at_10": 0.6198165999613497,
                    "mrr_at_20": 0.6227798592510475,
                    "main_score": 0.64883,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 100.54134583473206,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.26102,
                    "ndcg_at_3": 0.41023,
                    "ndcg_at_5": 0.4671,
                    "ndcg_at_10": 0.51568,
                    "ndcg_at_20": 0.54178,
                    "map_at_1": 0.26102,
                    "map_at_3": 0.37269,
                    "map_at_5": 0.40427,
                    "map_at_10": 0.42475,
                    "map_at_20": 0.43202,
                    "recall_at_1": 0.26102,
                    "recall_at_3": 0.5192,
                    "recall_at_5": 0.65718,
                    "recall_at_10": 0.80512,
                    "recall_at_20": 0.90754,
                    "precision_at_1": 0.26102,
                    "precision_at_3": 0.17307,
                    "precision_at_5": 0.13144,
                    "precision_at_10": 0.08051,
                    "precision_at_20": 0.04538,
                    "mrr_at_1": 0.2631578947368421,
                    "mrr_at_3": 0.37363679468942573,
                    "mrr_at_5": 0.4056069227121856,
                    "mrr_at_10": 0.4256655151391993,
                    "mrr_at_20": 0.43293881542924234,
                    "main_score": 0.51568,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 155.46878147125244,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.59727,
                    "ndcg_at_3": 0.67172,
                    "ndcg_at_5": 0.68651,
                    "ndcg_at_10": 0.69975,
                    "ndcg_at_20": 0.709,
                    "map_at_1": 0.59697,
                    "map_at_3": 0.65406,
                    "map_at_5": 0.66232,
                    "map_at_10": 0.6678,
                    "map_at_20": 0.67036,
                    "recall_at_1": 0.59697,
                    "recall_at_3": 0.72238,
                    "recall_at_5": 0.75812,
                    "recall_at_10": 0.79895,
                    "recall_at_20": 0.83533,
                    "precision_at_1": 0.59727,
                    "precision_at_3": 0.24106,
                    "precision_at_5": 0.15182,
                    "precision_at_10": 0.08002,
                    "precision_at_20": 0.04184,
                    "mrr_at_1": 0.597269524368761,
                    "mrr_at_3": 0.6541935799569332,
                    "mrr_at_5": 0.6624187707966329,
                    "mrr_at_10": 0.6678951243836744,
                    "mrr_at_20": 0.6704473689582742,
                    "main_score": 0.69975,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 53.14217495918274,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.90675,
                    "ndcg_at_3": 0.93728,
                    "ndcg_at_5": 0.94154,
                    "ndcg_at_10": 0.94467,
                    "ndcg_at_20": 0.9461,
                    "map_at_1": 0.90671,
                    "map_at_3": 0.93009,
                    "map_at_5": 0.93245,
                    "map_at_10": 0.93375,
                    "map_at_20": 0.93416,
                    "recall_at_1": 0.90671,
                    "recall_at_3": 0.95792,
                    "recall_at_5": 0.96825,
                    "recall_at_10": 0.97789,
                    "recall_at_20": 0.9835,
                    "precision_at_1": 0.90675,
                    "precision_at_3": 0.31932,
                    "precision_at_5": 0.19366,
                    "precision_at_10": 0.0978,
                    "precision_at_20": 0.04918,
                    "mrr_at_1": 0.9067509796936231,
                    "mrr_at_3": 0.930130032062699,
                    "mrr_at_5": 0.9324946562166017,
                    "mrr_at_10": 0.9337893397175993,
                    "mrr_at_20": 0.9341936045850086,
                    "main_score": 0.94467,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 110.31162810325623,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "2e643e7363944af1c33a652d1c87320d0871c4e4",
        "task_name": "NarrativeQAChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.64924,
                    "ndcg_at_3": 0.71546,
                    "ndcg_at_5": 0.72776,
                    "ndcg_at_10": 0.74114,
                    "ndcg_at_20": 0.74889,
                    "map_at_1": 0.64924,
                    "map_at_3": 0.69965,
                    "map_at_5": 0.7065,
                    "map_at_10": 0.71204,
                    "map_at_20": 0.71417,
                    "recall_at_1": 0.64924,
                    "recall_at_3": 0.76101,
                    "recall_at_5": 0.79075,
                    "recall_at_10": 0.83205,
                    "recall_at_20": 0.86265,
                    "precision_at_1": 0.64924,
                    "precision_at_3": 0.25367,
                    "precision_at_5": 0.15815,
                    "precision_at_10": 0.08321,
                    "precision_at_20": 0.04313,
                    "mrr_at_1": 0.6492374727668845,
                    "mrr_at_3": 0.6996463641817399,
                    "mrr_at_5": 0.7065043730857831,
                    "mrr_at_10": 0.7120401944996974,
                    "mrr_at_20": 0.714171043387832,
                    "main_score": 0.74114,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 1663.0409932136536,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.492,
                    "ndcg_at_3": 0.54772,
                    "ndcg_at_5": 0.56158,
                    "ndcg_at_10": 0.57123,
                    "ndcg_at_20": 0.58373,
                    "map_at_1": 0.492,
                    "map_at_3": 0.53383,
                    "map_at_5": 0.54143,
                    "map_at_10": 0.54539,
                    "map_at_20": 0.54888,
                    "recall_at_1": 0.492,
                    "recall_at_3": 0.588,
                    "recall_at_5": 0.622,
                    "recall_at_10": 0.652,
                    "recall_at_20": 0.701,
                    "precision_at_1": 0.492,
                    "precision_at_3": 0.196,
                    "precision_at_5": 0.1244,
                    "precision_at_10": 0.0652,
                    "precision_at_20": 0.03505,
                    "mrr_at_1": 0.495,
                    "mrr_at_3": 0.5353333333333332,
                    "mrr_at_5": 0.5429333333333333,
                    "mrr_at_10": 0.5468900793650795,
                    "mrr_at_20": 0.550382323391263,
                    "main_score": 0.57123,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 123.83551549911499,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.53875,
                    "ndcg_at_3": 0.62457,
                    "ndcg_at_5": 0.64597,
                    "ndcg_at_10": 0.66479,
                    "ndcg_at_20": 0.67702,
                    "map_at_1": 0.53864,
                    "map_at_3": 0.60374,
                    "map_at_5": 0.61561,
                    "map_at_10": 0.62343,
                    "map_at_20": 0.62682,
                    "recall_at_1": 0.53864,
                    "recall_at_3": 0.68465,
                    "recall_at_5": 0.7366,
                    "recall_at_10": 0.79447,
                    "recall_at_20": 0.84266,
                    "precision_at_1": 0.53875,
                    "precision_at_3": 0.22834,
                    "precision_at_5": 0.1474,
                    "precision_at_10": 0.0795,
                    "precision_at_20": 0.04217,
                    "mrr_at_1": 0.5387206467342487,
                    "mrr_at_3": 0.6037897258223217,
                    "mrr_at_5": 0.6156609564138849,
                    "mrr_at_10": 0.6234941206903305,
                    "mrr_at_20": 0.62687699233514,
                    "main_score": 0.66479,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 85.55856800079346,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.29432,
                    "ndcg_at_3": 0.29527,
                    "ndcg_at_5": 0.31332,
                    "ndcg_at_10": 0.33779,
                    "ndcg_at_20": 0.36121,
                    "map_at_1": 0.18652,
                    "map_at_3": 0.24768,
                    "map_at_5": 0.2656,
                    "map_at_10": 0.27973,
                    "map_at_20": 0.28775,
                    "recall_at_1": 0.18652,
                    "recall_at_3": 0.29482,
                    "recall_at_5": 0.35096,
                    "recall_at_10": 0.42345,
                    "recall_at_20": 0.50344,
                    "precision_at_1": 0.29432,
                    "precision_at_3": 0.16863,
                    "precision_at_5": 0.12368,
                    "precision_at_10": 0.07677,
                    "precision_at_20": 0.04614,
                    "mrr_at_1": 0.2943235808952238,
                    "mrr_at_3": 0.3447945319663246,
                    "mrr_at_5": 0.35794782028840566,
                    "mrr_at_10": 0.3673949241278571,
                    "mrr_at_20": 0.37271051852854187,
                    "main_score": 0.33779,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 611.3871111869812,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.22,
                    "ndcg_at_3": 0.17545,
                    "ndcg_at_5": 0.15116,
                    "ndcg_at_10": 0.17909,
                    "map_at_1": 0.04468,
                    "map_at_3": 0.07852,
                    "map_at_5": 0.09193,
                    "map_at_10": 0.10574,
                    "recall_at_1": 0.04468,
                    "recall_at_3": 0.09913,
                    "recall_at_5": 0.13303,
                    "recall_at_10": 0.18393,
                    "precision_at_1": 0.22,
                    "precision_at_3": 0.163,
                    "precision_at_5": 0.131,
                    "precision_at_10": 0.0907,
                    "mrr_at_1": 0.22,
                    "mrr_at_3": 0.2884999999999999,
                    "mrr_at_5": 0.30709999999999965,
                    "mrr_at_10": 0.31942857142857106,
                    "main_score": 0.17909,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 82.39537477493286,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.26252,
                    "ndcg_at_3": 0.3346,
                    "ndcg_at_5": 0.3571,
                    "ndcg_at_10": 0.37937,
                    "ndcg_at_20": 0.39735,
                    "map_at_1": 0.26177,
                    "map_at_3": 0.31658,
                    "map_at_5": 0.3291,
                    "map_at_10": 0.33829,
                    "map_at_20": 0.34325,
                    "recall_at_1": 0.26177,
                    "recall_at_3": 0.38589,
                    "recall_at_5": 0.44045,
                    "recall_at_10": 0.50915,
                    "recall_at_20": 0.57987,
                    "precision_at_1": 0.26252,
                    "precision_at_3": 0.12918,
                    "precision_at_5": 0.08853,
                    "precision_at_10": 0.05126,
                    "precision_at_20": 0.02926,
                    "mrr_at_1": 0.2625220425468052,
                    "mrr_at_3": 0.3173876611763485,
                    "mrr_at_5": 0.32985342488024644,
                    "mrr_at_10": 0.3390784949905872,
                    "mrr_at_20": 0.344015022887873,
                    "main_score": 0.37937,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 103.71160864830017,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.76395,
                    "ndcg_at_3": 0.79919,
                    "ndcg_at_5": 0.80543,
                    "ndcg_at_10": 0.81087,
                    "map_at_1": 0.76395,
                    "map_at_3": 0.79088,
                    "map_at_5": 0.79434,
                    "map_at_10": 0.79661,
                    "recall_at_1": 0.76395,
                    "recall_at_3": 0.8231,
                    "recall_at_5": 0.83825,
                    "recall_at_10": 0.8549,
                    "precision_at_1": 0.76395,
                    "precision_at_3": 0.27437,
                    "precision_at_5": 0.16765,
                    "precision_at_10": 0.08549,
                    "mrr_at_1": 0.764,
                    "mrr_at_3": 0.7909000000000036,
                    "mrr_at_5": 0.7943625000000054,
                    "mrr_at_10": 0.7966381547619094,
                    "main_score": 0.81087,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 326.2516989707947,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.90283,
                    "ndcg_at_3": 0.93466,
                    "ndcg_at_5": 0.93877,
                    "ndcg_at_10": 0.94221,
                    "ndcg_at_20": 0.94372,
                    "map_at_1": 0.90279,
                    "map_at_3": 0.92719,
                    "map_at_5": 0.92949,
                    "map_at_10": 0.93093,
                    "map_at_20": 0.93135,
                    "recall_at_1": 0.90279,
                    "recall_at_3": 0.95609,
                    "recall_at_5": 0.966,
                    "recall_at_10": 0.97651,
                    "recall_at_20": 0.98248,
                    "precision_at_1": 0.90283,
                    "precision_at_3": 0.31871,
                    "precision_at_5": 0.19321,
                    "precision_at_10": 0.09766,
                    "precision_at_20": 0.04913,
                    "mrr_at_1": 0.9028322052012825,
                    "mrr_at_3": 0.9272354827217657,
                    "mrr_at_5": 0.9295244032775204,
                    "mrr_at_10": 0.9309701758924682,
                    "mrr_at_20": 0.931381275441033,
                    "main_score": 0.94221,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 123.92132925987244,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.8475,
                    "ndcg_at_3": 0.81286,
                    "ndcg_at_5": 0.80175,
                    "ndcg_at_10": 0.8317,
                    "ndcg_at_20": 0.85112,
                    "map_at_1": 0.23909,
                    "map_at_3": 0.51045,
                    "map_at_5": 0.6445,
                    "map_at_10": 0.74629,
                    "map_at_20": 0.76995,
                    "recall_at_1": 0.23909,
                    "recall_at_3": 0.54168,
                    "recall_at_5": 0.70453,
                    "recall_at_10": 0.85374,
                    "recall_at_20": 0.91365,
                    "precision_at_1": 0.8475,
                    "precision_at_3": 0.73333,
                    "precision_at_5": 0.6179,
                    "precision_at_10": 0.4043,
                    "precision_at_20": 0.22258,
                    "mrr_at_1": 0.8475,
                    "mrr_at_3": 0.8927499999999993,
                    "mrr_at_5": 0.8956249999999993,
                    "mrr_at_10": 0.8970128968253961,
                    "mrr_at_20": 0.8976625559081435,
                    "main_score": 0.8317,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 614.472204208374,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.89517,
                    "ndcg_at_3": 0.92934,
                    "ndcg_at_5": 0.93396,
                    "ndcg_at_10": 0.93708,
                    "ndcg_at_20": 0.93873,
                    "map_at_1": 0.89517,
                    "map_at_3": 0.92135,
                    "map_at_5": 0.92393,
                    "map_at_10": 0.92523,
                    "map_at_20": 0.92569,
                    "recall_at_1": 0.89517,
                    "recall_at_3": 0.95228,
                    "recall_at_5": 0.96344,
                    "recall_at_10": 0.97297,
                    "recall_at_20": 0.97947,
                    "precision_at_1": 0.89517,
                    "precision_at_3": 0.31744,
                    "precision_at_5": 0.1927,
                    "precision_at_10": 0.0973,
                    "precision_at_20": 0.04898,
                    "mrr_at_1": 0.8951727823298896,
                    "mrr_at_3": 0.9213573209832544,
                    "mrr_at_5": 0.9239446027787671,
                    "mrr_at_10": 0.9252475210782566,
                    "mrr_at_20": 0.9257074485231013,
                    "main_score": 0.93708,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 77.20284652709961,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.799,
                    "ndcg_at_3": 0.75589,
                    "ndcg_at_5": 0.74628,
                    "ndcg_at_10": 0.77838,
                    "map_at_1": 0.22261,
                    "map_at_3": 0.46272,
                    "map_at_5": 0.58453,
                    "map_at_10": 0.67985,
                    "recall_at_1": 0.22261,
                    "recall_at_3": 0.49653,
                    "recall_at_5": 0.65257,
                    "recall_at_10": 0.80312,
                    "precision_at_1": 0.799,
                    "precision_at_3": 0.68083,
                    "precision_at_5": 0.5758,
                    "precision_at_10": 0.3807,
                    "mrr_at_1": 0.799,
                    "mrr_at_3": 0.8582499999999994,
                    "mrr_at_5": 0.8626999999999998,
                    "mrr_at_10": 0.8645176587301584,
                    "main_score": 0.77838,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1261.0685827732086,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.32554,
                    "ndcg_at_3": 0.40833,
                    "ndcg_at_5": 0.43035,
                    "ndcg_at_10": 0.4515,
                    "ndcg_at_20": 0.46682,
                    "map_at_1": 0.32494,
                    "map_at_3": 0.38786,
                    "map_at_5": 0.40016,
                    "map_at_10": 0.40892,
                    "map_at_20": 0.41316,
                    "recall_at_1": 0.32494,
                    "recall_at_3": 0.46665,
                    "recall_at_5": 0.51991,
                    "recall_at_10": 0.58501,
                    "recall_at_20": 0.64511,
                    "precision_at_1": 0.32554,
                    "precision_at_3": 0.15607,
                    "precision_at_5": 0.10444,
                    "precision_at_10": 0.05886,
                    "precision_at_20": 0.03252,
                    "mrr_at_1": 0.3255386232264845,
                    "mrr_at_3": 0.3886157195405761,
                    "mrr_at_5": 0.40082388709556627,
                    "mrr_at_10": 0.4096076370642897,
                    "mrr_at_20": 0.41381590235087895,
                    "main_score": 0.4515,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 78.82844638824463,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "e4e08e0b7dbe3c8700f0daef558ff32256715259",
        "task_name": "QuoraChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.8157,
                    "ndcg_at_3": 0.85581,
                    "ndcg_at_5": 0.87211,
                    "ndcg_at_10": 0.88479,
                    "ndcg_at_20": 0.89127,
                    "map_at_1": 0.70842,
                    "map_at_3": 0.81768,
                    "map_at_5": 0.83671,
                    "map_at_10": 0.84757,
                    "map_at_20": 0.85179,
                    "recall_at_1": 0.70842,
                    "recall_at_3": 0.8723,
                    "recall_at_5": 0.91808,
                    "recall_at_10": 0.95528,
                    "recall_at_20": 0.97576,
                    "precision_at_1": 0.8157,
                    "precision_at_3": 0.37393,
                    "precision_at_5": 0.2466,
                    "precision_at_10": 0.13443,
                    "precision_at_20": 0.07139,
                    "mrr_at_1": 0.8155,
                    "mrr_at_3": 0.8669499999999974,
                    "mrr_at_5": 0.8736399999999971,
                    "mrr_at_10": 0.8768247619047599,
                    "mrr_at_20": 0.8774952041899425,
                    "main_score": 0.88479,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 166.24741339683533,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.86467,
                    "ndcg_at_3": 0.90219,
                    "ndcg_at_5": 0.90894,
                    "ndcg_at_10": 0.91372,
                    "ndcg_at_20": 0.91651,
                    "map_at_1": 0.86467,
                    "map_at_3": 0.89332,
                    "map_at_5": 0.89707,
                    "map_at_10": 0.89905,
                    "map_at_20": 0.89984,
                    "recall_at_1": 0.86467,
                    "recall_at_3": 0.9277,
                    "recall_at_5": 0.94407,
                    "recall_at_10": 0.95876,
                    "recall_at_20": 0.96967,
                    "precision_at_1": 0.86467,
                    "precision_at_3": 0.30924,
                    "precision_at_5": 0.18882,
                    "precision_at_10": 0.09588,
                    "precision_at_20": 0.04849,
                    "mrr_at_1": 0.8646686854292839,
                    "mrr_at_3": 0.8933321458259118,
                    "mrr_at_5": 0.8970861536634623,
                    "mrr_at_10": 0.8990703336613141,
                    "mrr_at_20": 0.8998531838466645,
                    "main_score": 0.91372,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 31.756469249725342,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.34722,
                    "ndcg_at_3": 0.31501,
                    "ndcg_at_5": 0.32809,
                    "ndcg_at_10": 0.34939,
                    "map_at_1": 0.17117,
                    "map_at_3": 0.23875,
                    "map_at_5": 0.26112,
                    "map_at_10": 0.27773,
                    "recall_at_1": 0.17117,
                    "recall_at_3": 0.27804,
                    "recall_at_5": 0.33953,
                    "recall_at_10": 0.41023,
                    "precision_at_1": 0.34722,
                    "precision_at_3": 0.21245,
                    "precision_at_5": 0.15988,
                    "precision_at_10": 0.09877,
                    "mrr_at_1": 0.3472222222222222,
                    "mrr_at_3": 0.40252057613168746,
                    "mrr_at_5": 0.4174897119341564,
                    "mrr_at_10": 0.42711272780717224,
                    "main_score": 0.34939,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 131.6872615814209,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.27857,
                    "ndcg_at_3": 0.28171,
                    "ndcg_at_5": 0.29694,
                    "ndcg_at_10": 0.32131,
                    "ndcg_at_20": 0.34467,
                    "map_at_1": 0.17513,
                    "map_at_3": 0.23482,
                    "map_at_5": 0.2503,
                    "map_at_10": 0.26437,
                    "map_at_20": 0.27239,
                    "recall_at_1": 0.17513,
                    "recall_at_3": 0.28215,
                    "recall_at_5": 0.33235,
                    "recall_at_10": 0.40472,
                    "recall_at_20": 0.48374,
                    "precision_at_1": 0.27857,
                    "precision_at_3": 0.16196,
                    "precision_at_5": 0.11698,
                    "precision_at_10": 0.07329,
                    "precision_at_20": 0.04447,
                    "mrr_at_1": 0.27856964241060267,
                    "mrr_at_3": 0.3290822705676415,
                    "mrr_at_5": 0.3417729432358091,
                    "mrr_at_10": 0.351007990092761,
                    "mrr_at_20": 0.3564648341030319,
                    "main_score": 0.32131,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1315.685854434967,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.37365,
                    "ndcg_at_3": 0.43095,
                    "ndcg_at_5": 0.44688,
                    "ndcg_at_10": 0.46306,
                    "ndcg_at_20": 0.47505,
                    "map_at_1": 0.37363,
                    "map_at_3": 0.41694,
                    "map_at_5": 0.42577,
                    "map_at_10": 0.4325,
                    "map_at_20": 0.43579,
                    "recall_at_1": 0.37363,
                    "recall_at_3": 0.47145,
                    "recall_at_5": 0.51016,
                    "recall_at_10": 0.55986,
                    "recall_at_20": 0.60725,
                    "precision_at_1": 0.37365,
                    "precision_at_3": 0.15716,
                    "precision_at_5": 0.10204,
                    "precision_at_10": 0.056,
                    "precision_at_20": 0.03037,
                    "mrr_at_1": 0.3736474346176882,
                    "mrr_at_3": 0.41695614560457944,
                    "mrr_at_5": 0.4257902442270613,
                    "mrr_at_10": 0.4325425979269105,
                    "mrr_at_20": 0.4358360682616059,
                    "main_score": 0.46306,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 40.21932077407837,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "2e643e7363944af1c33a652d1c87320d0871c4e4",
        "task_name": "NarrativeQAChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.66411,
                    "ndcg_at_3": 0.731,
                    "ndcg_at_5": 0.74328,
                    "ndcg_at_10": 0.75472,
                    "map_at_1": 0.66411,
                    "map_at_3": 0.71505,
                    "map_at_5": 0.72194,
                    "map_at_10": 0.72673,
                    "recall_at_1": 0.66411,
                    "recall_at_3": 0.77693,
                    "recall_at_5": 0.80648,
                    "recall_at_10": 0.84143,
                    "precision_at_1": 0.66411,
                    "precision_at_3": 0.25898,
                    "precision_at_5": 0.1613,
                    "precision_at_10": 0.08414,
                    "mrr_at_1": 0.6641091219096334,
                    "mrr_at_3": 0.715054781977199,
                    "mrr_at_5": 0.7219364718512149,
                    "mrr_at_10": 0.7267329959358909,
                    "main_score": 0.75472,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 873.2299950122833,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.848,
                    "ndcg_at_3": 0.81207,
                    "ndcg_at_5": 0.80212,
                    "ndcg_at_10": 0.83183,
                    "map_at_1": 0.23888,
                    "map_at_3": 0.50944,
                    "map_at_5": 0.64453,
                    "map_at_10": 0.74635,
                    "recall_at_1": 0.23888,
                    "recall_at_3": 0.5408,
                    "recall_at_5": 0.70498,
                    "recall_at_10": 0.8541,
                    "precision_at_1": 0.848,
                    "precision_at_3": 0.73217,
                    "precision_at_5": 0.6187,
                    "precision_at_10": 0.4044,
                    "mrr_at_1": 0.848,
                    "mrr_at_3": 0.8932499999999992,
                    "mrr_at_5": 0.8959749999999993,
                    "mrr_at_10": 0.8972696428571421,
                    "main_score": 0.83183,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2461.3568279743195,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.66877,
                    "ndcg_at_3": 0.73626,
                    "ndcg_at_5": 0.75619,
                    "ndcg_at_10": 0.77259,
                    "map_at_1": 0.64633,
                    "map_at_3": 0.71606,
                    "map_at_5": 0.72791,
                    "map_at_10": 0.73513,
                    "recall_at_1": 0.64633,
                    "recall_at_3": 0.78506,
                    "recall_at_5": 0.83247,
                    "recall_at_10": 0.88179,
                    "precision_at_1": 0.66877,
                    "precision_at_3": 0.27674,
                    "precision_at_5": 0.17668,
                    "precision_at_10": 0.09378,
                    "mrr_at_1": 0.6687679083094555,
                    "mrr_at_3": 0.7254536771728753,
                    "mrr_at_5": 0.7355969436485179,
                    "mrr_at_10": 0.7418811115659254,
                    "main_score": 0.77259,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 205.23829126358032,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.63023,
                    "ndcg_at_3": 0.70502,
                    "ndcg_at_5": 0.72693,
                    "ndcg_at_10": 0.7443,
                    "ndcg_at_20": 0.75314,
                    "map_at_1": 0.60948,
                    "map_at_3": 0.68309,
                    "map_at_5": 0.69596,
                    "map_at_10": 0.70353,
                    "map_at_20": 0.70612,
                    "recall_at_1": 0.60948,
                    "recall_at_3": 0.7591,
                    "recall_at_5": 0.81145,
                    "recall_at_10": 0.86385,
                    "recall_at_20": 0.89789,
                    "precision_at_1": 0.63023,
                    "precision_at_3": 0.26748,
                    "precision_at_5": 0.17201,
                    "precision_at_10": 0.09175,
                    "precision_at_20": 0.04776,
                    "mrr_at_1": 0.6302292263610315,
                    "mrr_at_3": 0.6920725883476612,
                    "mrr_at_5": 0.7034407831900655,
                    "mrr_at_10": 0.7102086460181012,
                    "mrr_at_20": 0.7124921585597922,
                    "main_score": 0.7443,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 387.6157944202423,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.89394,
                    "ndcg_at_3": 0.92711,
                    "ndcg_at_5": 0.93166,
                    "ndcg_at_10": 0.93522,
                    "ndcg_at_20": 0.93691,
                    "map_at_1": 0.89394,
                    "map_at_3": 0.91942,
                    "map_at_5": 0.92195,
                    "map_at_10": 0.92345,
                    "map_at_20": 0.92391,
                    "recall_at_1": 0.89394,
                    "recall_at_3": 0.94915,
                    "recall_at_5": 0.9602,
                    "recall_at_10": 0.97109,
                    "recall_at_20": 0.9777,
                    "precision_at_1": 0.89394,
                    "precision_at_3": 0.31638,
                    "precision_at_5": 0.19204,
                    "precision_at_10": 0.09711,
                    "precision_at_20": 0.04889,
                    "mrr_at_1": 0.8939373750832779,
                    "mrr_at_3": 0.9194240876452721,
                    "mrr_at_5": 0.9219512917314383,
                    "mrr_at_10": 0.923445956663812,
                    "mrr_at_20": 0.9239144974203397,
                    "main_score": 0.93522,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 82.94184398651123,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.17781,
                    "ndcg_at_3": 0.28265,
                    "ndcg_at_5": 0.33361,
                    "ndcg_at_10": 0.39505,
                    "ndcg_at_20": 0.43333,
                    "map_at_1": 0.17781,
                    "map_at_3": 0.25628,
                    "map_at_5": 0.28455,
                    "map_at_10": 0.31007,
                    "map_at_20": 0.32074,
                    "recall_at_1": 0.17781,
                    "recall_at_3": 0.35917,
                    "recall_at_5": 0.48293,
                    "recall_at_10": 0.67212,
                    "recall_at_20": 0.82219,
                    "precision_at_1": 0.17781,
                    "precision_at_3": 0.11972,
                    "precision_at_5": 0.09659,
                    "precision_at_10": 0.06721,
                    "precision_at_20": 0.04111,
                    "mrr_at_1": 0.1806543385490754,
                    "mrr_at_3": 0.257705073494547,
                    "mrr_at_5": 0.2854077761972493,
                    "mrr_at_10": 0.3114720923931449,
                    "mrr_at_20": 0.32208198675935296,
                    "main_score": 0.39505,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 24.85482954978943,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.41641,
                    "ndcg_at_3": 0.37834,
                    "ndcg_at_5": 0.35206,
                    "ndcg_at_10": 0.31456,
                    "ndcg_at_20": 0.29175,
                    "map_at_1": 0.05244,
                    "map_at_3": 0.08956,
                    "map_at_5": 0.10241,
                    "map_at_10": 0.11726,
                    "map_at_20": 0.12864,
                    "recall_at_1": 0.05244,
                    "recall_at_3": 0.1008,
                    "recall_at_5": 0.11991,
                    "recall_at_10": 0.14745,
                    "recall_at_20": 0.17995,
                    "precision_at_1": 0.43344,
                    "precision_at_3": 0.35707,
                    "precision_at_5": 0.30341,
                    "precision_at_10": 0.22879,
                    "precision_at_20": 0.16873,
                    "mrr_at_1": 0.43653250773993807,
                    "mrr_at_3": 0.5098039215686276,
                    "mrr_at_5": 0.5180082559339527,
                    "mrr_at_10": 0.5248648582239914,
                    "mrr_at_20": 0.528174032980942,
                    "main_score": 0.31456,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 61.03584098815918,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.7377,
                    "ndcg_at_3": 0.77416,
                    "ndcg_at_5": 0.78054,
                    "ndcg_at_10": 0.78643,
                    "map_at_1": 0.7377,
                    "map_at_3": 0.76559,
                    "map_at_5": 0.76914,
                    "map_at_10": 0.77158,
                    "recall_at_1": 0.7377,
                    "recall_at_3": 0.7988,
                    "recall_at_5": 0.81425,
                    "recall_at_10": 0.8324,
                    "precision_at_1": 0.7377,
                    "precision_at_3": 0.26627,
                    "precision_at_5": 0.16285,
                    "precision_at_10": 0.08324,
                    "mrr_at_1": 0.7377,
                    "mrr_at_3": 0.7655916666666702,
                    "mrr_at_5": 0.769139166666672,
                    "mrr_at_10": 0.771578948412703,
                    "main_score": 0.78643,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 480.92096281051636,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.879,
                    "ndcg_at_3": 0.83457,
                    "ndcg_at_5": 0.82134,
                    "ndcg_at_10": 0.84585,
                    "ndcg_at_20": 0.86248,
                    "map_at_1": 0.25164,
                    "map_at_3": 0.52958,
                    "map_at_5": 0.66552,
                    "map_at_10": 0.76402,
                    "map_at_20": 0.78598,
                    "recall_at_1": 0.25164,
                    "recall_at_3": 0.55604,
                    "recall_at_5": 0.71859,
                    "recall_at_10": 0.86012,
                    "recall_at_20": 0.91282,
                    "precision_at_1": 0.879,
                    "precision_at_3": 0.74867,
                    "precision_at_5": 0.629,
                    "precision_at_10": 0.40625,
                    "precision_at_20": 0.22215,
                    "mrr_at_1": 0.879,
                    "mrr_at_3": 0.9126666666666664,
                    "mrr_at_5": 0.9152416666666665,
                    "mrr_at_10": 0.916781349206349,
                    "mrr_at_20": 0.9171826721158955,
                    "main_score": 0.84585,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 273.5301134586334,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.49458,
                    "ndcg_at_3": 0.58295,
                    "ndcg_at_5": 0.60539,
                    "ndcg_at_10": 0.62566,
                    "ndcg_at_20": 0.63812,
                    "map_at_1": 0.49449,
                    "map_at_3": 0.56161,
                    "map_at_5": 0.5741,
                    "map_at_10": 0.58254,
                    "map_at_20": 0.586,
                    "recall_at_1": 0.49449,
                    "recall_at_3": 0.64446,
                    "recall_at_5": 0.69878,
                    "recall_at_10": 0.76109,
                    "recall_at_20": 0.80999,
                    "precision_at_1": 0.49458,
                    "precision_at_3": 0.2149,
                    "precision_at_5": 0.13981,
                    "precision_at_10": 0.07615,
                    "precision_at_20": 0.04053,
                    "mrr_at_1": 0.494578467855768,
                    "mrr_at_3": 0.5616739381496288,
                    "mrr_at_5": 0.5741627101244845,
                    "mrr_at_10": 0.5825996544518085,
                    "mrr_at_20": 0.5860576107101007,
                    "main_score": 0.62566,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 89.60544347763062,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.59727,
                    "ndcg_at_3": 0.67172,
                    "ndcg_at_5": 0.68651,
                    "ndcg_at_10": 0.69975,
                    "ndcg_at_20": 0.709,
                    "map_at_1": 0.59697,
                    "map_at_3": 0.65406,
                    "map_at_5": 0.66232,
                    "map_at_10": 0.6678,
                    "map_at_20": 0.67036,
                    "recall_at_1": 0.59697,
                    "recall_at_3": 0.72238,
                    "recall_at_5": 0.75812,
                    "recall_at_10": 0.79895,
                    "recall_at_20": 0.83533,
                    "precision_at_1": 0.59727,
                    "precision_at_3": 0.24106,
                    "precision_at_5": 0.15182,
                    "precision_at_10": 0.08002,
                    "precision_at_20": 0.04184,
                    "mrr_at_1": 0.597269524368761,
                    "mrr_at_3": 0.6541935799569332,
                    "mrr_at_5": 0.6624187707966329,
                    "mrr_at_10": 0.6678951243836744,
                    "mrr_at_20": 0.6704473689582742,
                    "main_score": 0.69975,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 52.87007522583008,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "e4e08e0b7dbe3c8700f0daef558ff32256715259",
        "task_name": "QuoraChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.8174,
                    "ndcg_at_3": 0.85713,
                    "ndcg_at_5": 0.87311,
                    "ndcg_at_10": 0.88572,
                    "ndcg_at_20": 0.89185,
                    "map_at_1": 0.70892,
                    "map_at_3": 0.81884,
                    "map_at_5": 0.83764,
                    "map_at_10": 0.84868,
                    "map_at_20": 0.85266,
                    "recall_at_1": 0.70892,
                    "recall_at_3": 0.87352,
                    "recall_at_5": 0.919,
                    "recall_at_10": 0.9561,
                    "recall_at_20": 0.97555,
                    "precision_at_1": 0.8174,
                    "precision_at_3": 0.37517,
                    "precision_at_5": 0.24696,
                    "precision_at_10": 0.13465,
                    "precision_at_20": 0.0713,
                    "mrr_at_1": 0.8174,
                    "mrr_at_3": 0.8682166666666642,
                    "mrr_at_5": 0.8750716666666635,
                    "mrr_at_10": 0.8779486507936479,
                    "mrr_at_20": 0.8786065519297492,
                    "main_score": 0.88572,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 307.7062315940857,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.6738,
                    "ndcg_at_3": 0.74817,
                    "ndcg_at_5": 0.76151,
                    "ndcg_at_10": 0.77314,
                    "ndcg_at_20": 0.78079,
                    "map_at_1": 0.6734,
                    "map_at_3": 0.73054,
                    "map_at_5": 0.738,
                    "map_at_10": 0.74282,
                    "map_at_20": 0.74494,
                    "recall_at_1": 0.6734,
                    "recall_at_3": 0.79859,
                    "recall_at_5": 0.83087,
                    "recall_at_10": 0.86666,
                    "recall_at_20": 0.89679,
                    "precision_at_1": 0.6738,
                    "precision_at_3": 0.26648,
                    "precision_at_5": 0.1664,
                    "precision_at_10": 0.0868,
                    "precision_at_20": 0.04492,
                    "mrr_at_1": 0.6738007163407903,
                    "mrr_at_3": 0.7307997181609913,
                    "mrr_at_5": 0.7381921202513028,
                    "mrr_at_10": 0.7430013942828783,
                    "mrr_at_20": 0.7451155328300437,
                    "main_score": 0.77314,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 132.422456741333,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "6e346642246bfb4928c560ee08640dc84d074e8c",
        "task_name": "LEMBWikimQARetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.98333,
                    "ndcg_at_3": 0.99298,
                    "ndcg_at_5": 0.99298,
                    "ndcg_at_10": 0.99298,
                    "ndcg_at_20": 0.99298,
                    "map_at_1": 0.98333,
                    "map_at_3": 0.99056,
                    "map_at_5": 0.99056,
                    "map_at_10": 0.99056,
                    "map_at_20": 0.99056,
                    "recall_at_1": 0.98333,
                    "recall_at_3": 1.0,
                    "recall_at_5": 1.0,
                    "recall_at_10": 1.0,
                    "recall_at_20": 1.0,
                    "precision_at_1": 0.98333,
                    "precision_at_3": 0.33333,
                    "precision_at_5": 0.2,
                    "precision_at_10": 0.1,
                    "precision_at_20": 0.05,
                    "mrr_at_1": 0.9833333333333333,
                    "mrr_at_3": 0.9905555555555554,
                    "mrr_at_5": 0.9905555555555554,
                    "mrr_at_10": 0.9905555555555554,
                    "mrr_at_20": 0.9905555555555554,
                    "main_score": 0.99298,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 35.42308473587036,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.46112,
                    "ndcg_at_3": 0.55076,
                    "ndcg_at_5": 0.57404,
                    "ndcg_at_10": 0.59457,
                    "ndcg_at_20": 0.6085,
                    "map_at_1": 0.46104,
                    "map_at_3": 0.52893,
                    "map_at_5": 0.54188,
                    "map_at_10": 0.55042,
                    "map_at_20": 0.55429,
                    "recall_at_1": 0.46104,
                    "recall_at_3": 0.61377,
                    "recall_at_5": 0.67019,
                    "recall_at_10": 0.73327,
                    "recall_at_20": 0.78807,
                    "precision_at_1": 0.46112,
                    "precision_at_3": 0.20465,
                    "precision_at_5": 0.13408,
                    "precision_at_10": 0.07335,
                    "precision_at_20": 0.03942,
                    "mrr_at_1": 0.4611189529064545,
                    "mrr_at_3": 0.5289950382822306,
                    "mrr_at_5": 0.5419345352667103,
                    "mrr_at_10": 0.5504813920307134,
                    "mrr_at_20": 0.5543432028299144,
                    "main_score": 0.59457,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 73.17182898521423,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.48302,
                    "ndcg_at_3": 0.43592,
                    "ndcg_at_5": 0.44698,
                    "ndcg_at_10": 0.47562,
                    "ndcg_at_20": 0.50234,
                    "map_at_1": 0.239,
                    "map_at_3": 0.34384,
                    "map_at_5": 0.36957,
                    "map_at_10": 0.39323,
                    "map_at_20": 0.40452,
                    "recall_at_1": 0.239,
                    "recall_at_3": 0.38851,
                    "recall_at_5": 0.45543,
                    "recall_at_10": 0.54373,
                    "recall_at_20": 0.62706,
                    "precision_at_1": 0.48302,
                    "precision_at_3": 0.29321,
                    "precision_at_5": 0.21358,
                    "precision_at_10": 0.13457,
                    "precision_at_20": 0.07824,
                    "mrr_at_1": 0.48302469135802467,
                    "mrr_at_3": 0.5344650205761315,
                    "mrr_at_5": 0.5503600823045265,
                    "mrr_at_10": 0.560357265334117,
                    "mrr_at_20": 0.5648108281348088,
                    "main_score": 0.47562,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 626.9657852649689,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.46142,
                    "ndcg_at_3": 0.4202,
                    "ndcg_at_5": 0.42927,
                    "ndcg_at_10": 0.46228,
                    "ndcg_at_20": 0.48936,
                    "map_at_1": 0.22916,
                    "map_at_3": 0.33002,
                    "map_at_5": 0.35474,
                    "map_at_10": 0.37942,
                    "map_at_20": 0.39055,
                    "recall_at_1": 0.22916,
                    "recall_at_3": 0.37349,
                    "recall_at_5": 0.43523,
                    "recall_at_10": 0.5357,
                    "recall_at_20": 0.61952,
                    "precision_at_1": 0.46142,
                    "precision_at_3": 0.28395,
                    "precision_at_5": 0.20556,
                    "precision_at_10": 0.13148,
                    "precision_at_20": 0.07716,
                    "mrr_at_1": 0.46141975308641975,
                    "mrr_at_3": 0.5159465020576132,
                    "mrr_at_5": 0.5307613168724278,
                    "mrr_at_10": 0.5430316725455612,
                    "mrr_at_20": 0.5479616493643334,
                    "main_score": 0.46228,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 217.040185213089,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.88857,
                    "ndcg_at_3": 0.84798,
                    "ndcg_at_5": 0.83241,
                    "ndcg_at_10": 0.83065,
                    "ndcg_at_20": 0.84808,
                    "map_at_1": 0.26874,
                    "map_at_3": 0.53138,
                    "map_at_5": 0.65228,
                    "map_at_10": 0.75307,
                    "map_at_20": 0.77996,
                    "recall_at_1": 0.26874,
                    "recall_at_3": 0.54822,
                    "recall_at_5": 0.68569,
                    "recall_at_10": 0.8181,
                    "recall_at_20": 0.87708,
                    "precision_at_1": 0.88857,
                    "precision_at_3": 0.7425,
                    "precision_at_5": 0.62111,
                    "precision_at_10": 0.41265,
                    "precision_at_20": 0.22916,
                    "mrr_at_1": 0.8885674206557952,
                    "mrr_at_3": 0.9104126483137521,
                    "mrr_at_5": 0.9132620258343572,
                    "mrr_at_10": 0.9150401730918578,
                    "mrr_at_20": 0.915629598993904,
                    "main_score": 0.83065,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 6015.414859056473,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "bb9466bac8153a0349341eb1b22e06409e78ef4e",
        "task_name": "TRECCOVIDChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.84,
                    "ndcg_at_3": 0.80754,
                    "ndcg_at_5": 0.79144,
                    "ndcg_at_10": 0.75891,
                    "map_at_1": 0.0024,
                    "map_at_3": 0.00653,
                    "map_at_5": 0.01064,
                    "map_at_10": 0.01944,
                    "recall_at_1": 0.0024,
                    "recall_at_3": 0.00684,
                    "recall_at_5": 0.01145,
                    "recall_at_10": 0.0214,
                    "precision_at_1": 0.88,
                    "precision_at_3": 0.86667,
                    "precision_at_5": 0.848,
                    "precision_at_10": 0.8,
                    "mrr_at_1": 0.88,
                    "mrr_at_3": 0.93,
                    "mrr_at_5": 0.93,
                    "mrr_at_10": 0.93,
                    "main_score": 0.75891,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 875.6650054454803,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.684,
                    "ndcg_at_3": 0.74493,
                    "ndcg_at_5": 0.75618,
                    "ndcg_at_10": 0.767,
                    "ndcg_at_20": 0.7747,
                    "map_at_1": 0.68354,
                    "map_at_3": 0.73044,
                    "map_at_5": 0.7367,
                    "map_at_10": 0.7412,
                    "map_at_20": 0.74331,
                    "recall_at_1": 0.68354,
                    "recall_at_3": 0.78644,
                    "recall_at_5": 0.81372,
                    "recall_at_10": 0.84704,
                    "recall_at_20": 0.87753,
                    "precision_at_1": 0.684,
                    "precision_at_3": 0.26249,
                    "precision_at_5": 0.16298,
                    "precision_at_10": 0.08484,
                    "precision_at_20": 0.04396,
                    "mrr_at_1": 0.6839988256018791,
                    "mrr_at_3": 0.7306028577020871,
                    "mrr_at_5": 0.7368403797220572,
                    "mrr_at_10": 0.7413185065570562,
                    "mrr_at_20": 0.7434264156450737,
                    "main_score": 0.767,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 118.13388180732727,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.36223,
                    "ndcg_at_3": 0.31208,
                    "ndcg_at_5": 0.29632,
                    "ndcg_at_10": 0.27435,
                    "ndcg_at_20": 0.25306,
                    "map_at_1": 0.047,
                    "map_at_3": 0.07633,
                    "map_at_5": 0.08722,
                    "map_at_10": 0.10349,
                    "map_at_20": 0.11291,
                    "recall_at_1": 0.047,
                    "recall_at_3": 0.0851,
                    "recall_at_5": 0.10287,
                    "recall_at_10": 0.13611,
                    "recall_at_20": 0.16268,
                    "precision_at_1": 0.37771,
                    "precision_at_3": 0.28999,
                    "precision_at_5": 0.25449,
                    "precision_at_10": 0.20031,
                    "precision_at_20": 0.14334,
                    "mrr_at_1": 0.37770897832817335,
                    "mrr_at_3": 0.4422084623323014,
                    "mrr_at_5": 0.4564499484004128,
                    "mrr_at_10": 0.46570593149540523,
                    "mrr_at_20": 0.4689039255370285,
                    "main_score": 0.27435,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 1630.8568518161774,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.865,
                    "ndcg_at_3": 0.81858,
                    "ndcg_at_5": 0.81385,
                    "ndcg_at_10": 0.84069,
                    "ndcg_at_20": 0.85765,
                    "map_at_1": 0.2438,
                    "map_at_3": 0.51401,
                    "map_at_5": 0.65644,
                    "map_at_10": 0.75686,
                    "map_at_20": 0.77871,
                    "recall_at_1": 0.2438,
                    "recall_at_3": 0.54277,
                    "recall_at_5": 0.71753,
                    "recall_at_10": 0.86404,
                    "recall_at_20": 0.91645,
                    "precision_at_1": 0.865,
                    "precision_at_3": 0.73617,
                    "precision_at_5": 0.6293,
                    "precision_at_10": 0.40755,
                    "precision_at_20": 0.22283,
                    "mrr_at_1": 0.865,
                    "mrr_at_3": 0.9030833333333328,
                    "mrr_at_5": 0.9060333333333329,
                    "mrr_at_10": 0.9076892857142853,
                    "mrr_at_20": 0.9080924491659008,
                    "main_score": 0.84069,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 977.2377920150757,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.36728,
                    "ndcg_at_3": 0.44574,
                    "ndcg_at_5": 0.46673,
                    "ndcg_at_10": 0.48775,
                    "ndcg_at_20": 0.50264,
                    "map_at_1": 0.36669,
                    "map_at_3": 0.42631,
                    "map_at_5": 0.43798,
                    "map_at_10": 0.44674,
                    "map_at_20": 0.45086,
                    "recall_at_1": 0.36669,
                    "recall_at_3": 0.50121,
                    "recall_at_5": 0.55206,
                    "recall_at_10": 0.61647,
                    "recall_at_20": 0.67487,
                    "precision_at_1": 0.36728,
                    "precision_at_3": 0.16754,
                    "precision_at_5": 0.11084,
                    "precision_at_10": 0.06201,
                    "precision_at_20": 0.03402,
                    "mrr_at_1": 0.36727723143908114,
                    "mrr_at_3": 0.4270074819207797,
                    "mrr_at_5": 0.4386845331932101,
                    "mrr_at_10": 0.44739674377371136,
                    "mrr_at_20": 0.4515003504385654,
                    "main_score": 0.48775,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 136.02353167533875,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.88901,
                    "ndcg_at_3": 0.92303,
                    "ndcg_at_5": 0.92833,
                    "ndcg_at_10": 0.93168,
                    "ndcg_at_20": 0.93358,
                    "map_at_1": 0.88901,
                    "map_at_3": 0.91512,
                    "map_at_5": 0.91809,
                    "map_at_10": 0.91948,
                    "map_at_20": 0.92001,
                    "recall_at_1": 0.88901,
                    "recall_at_3": 0.94573,
                    "recall_at_5": 0.95852,
                    "recall_at_10": 0.96878,
                    "recall_at_20": 0.97628,
                    "precision_at_1": 0.88901,
                    "precision_at_3": 0.31524,
                    "precision_at_5": 0.1917,
                    "precision_at_10": 0.09688,
                    "precision_at_20": 0.04881,
                    "mrr_at_1": 0.8890073284477016,
                    "mrr_at_3": 0.9151232511658883,
                    "mrr_at_5": 0.9180857206306912,
                    "mrr_at_10": 0.9194837656729741,
                    "mrr_at_20": 0.9200078372361978,
                    "main_score": 0.93168,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 81.10605192184448,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.67756,
                    "ndcg_at_3": 0.75455,
                    "ndcg_at_5": 0.7765,
                    "ndcg_at_10": 0.79262,
                    "map_at_1": 0.67597,
                    "map_at_3": 0.73595,
                    "map_at_5": 0.74821,
                    "map_at_10": 0.7552,
                    "recall_at_1": 0.67597,
                    "recall_at_3": 0.80769,
                    "recall_at_5": 0.85985,
                    "recall_at_10": 0.90885,
                    "precision_at_1": 0.67756,
                    "precision_at_3": 0.27046,
                    "precision_at_5": 0.17323,
                    "precision_at_10": 0.09178,
                    "mrr_at_1": 0.6775553213909379,
                    "mrr_at_3": 0.7363891815946609,
                    "mrr_at_5": 0.748981383912891,
                    "mrr_at_10": 0.7553828591499828,
                    "main_score": 0.79262,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1508.8549971580505,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.46795,
                    "ndcg_at_3": 0.55697,
                    "ndcg_at_5": 0.57994,
                    "ndcg_at_10": 0.60075,
                    "ndcg_at_20": 0.61462,
                    "map_at_1": 0.46788,
                    "map_at_3": 0.53531,
                    "map_at_5": 0.54807,
                    "map_at_10": 0.55672,
                    "map_at_20": 0.56056,
                    "recall_at_1": 0.46788,
                    "recall_at_3": 0.61945,
                    "recall_at_5": 0.6752,
                    "recall_at_10": 0.73923,
                    "recall_at_20": 0.79374,
                    "precision_at_1": 0.46795,
                    "precision_at_3": 0.20653,
                    "precision_at_5": 0.13508,
                    "precision_at_10": 0.07396,
                    "precision_at_20": 0.03971,
                    "mrr_at_1": 0.4679520082124984,
                    "mrr_at_3": 0.5353736259035997,
                    "mrr_at_5": 0.5481447025108178,
                    "mrr_at_10": 0.5567883341582641,
                    "mrr_at_20": 0.5606345571974779,
                    "main_score": 0.60075,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 75.67484998703003,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.84419,
                    "ndcg_at_3": 0.88733,
                    "ndcg_at_5": 0.89498,
                    "ndcg_at_10": 0.90099,
                    "ndcg_at_20": 0.90417,
                    "map_at_1": 0.84419,
                    "map_at_3": 0.87716,
                    "map_at_5": 0.88143,
                    "map_at_10": 0.88394,
                    "map_at_20": 0.88482,
                    "recall_at_1": 0.84419,
                    "recall_at_3": 0.91659,
                    "recall_at_5": 0.93507,
                    "recall_at_10": 0.95345,
                    "recall_at_20": 0.96602,
                    "precision_at_1": 0.84419,
                    "precision_at_3": 0.30553,
                    "precision_at_5": 0.18701,
                    "precision_at_10": 0.09535,
                    "precision_at_20": 0.0483,
                    "mrr_at_1": 0.8441927603819676,
                    "mrr_at_3": 0.8771633725664366,
                    "mrr_at_5": 0.8814271966836945,
                    "mrr_at_10": 0.8839412173189679,
                    "mrr_at_20": 0.8848222676105924,
                    "main_score": 0.90099,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 44.8105034828186,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.51667,
                    "ndcg_at_3": 0.55871,
                    "ndcg_at_5": 0.58513,
                    "ndcg_at_10": 0.61264,
                    "map_at_1": 0.488,
                    "map_at_3": 0.53678,
                    "map_at_5": 0.5542,
                    "map_at_10": 0.56744,
                    "recall_at_1": 0.488,
                    "recall_at_3": 0.592,
                    "recall_at_5": 0.65817,
                    "recall_at_10": 0.73661,
                    "precision_at_1": 0.51667,
                    "precision_at_3": 0.21556,
                    "precision_at_5": 0.14667,
                    "precision_at_10": 0.08367,
                    "mrr_at_1": 0.5166666666666667,
                    "mrr_at_3": 0.56,
                    "mrr_at_5": 0.5734999999999999,
                    "mrr_at_10": 0.5836878306878305,
                    "main_score": 0.61264,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 795.0106041431427,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.44667,
                    "ndcg_at_3": 0.51596,
                    "ndcg_at_5": 0.55357,
                    "ndcg_at_10": 0.57891,
                    "ndcg_at_20": 0.59334,
                    "map_at_1": 0.42567,
                    "map_at_3": 0.48968,
                    "map_at_5": 0.51283,
                    "map_at_10": 0.52482,
                    "map_at_20": 0.52932,
                    "recall_at_1": 0.42567,
                    "recall_at_3": 0.56561,
                    "recall_at_5": 0.6575,
                    "recall_at_10": 0.73028,
                    "recall_at_20": 0.78389,
                    "precision_at_1": 0.44667,
                    "precision_at_3": 0.20444,
                    "precision_at_5": 0.14467,
                    "precision_at_10": 0.082,
                    "precision_at_20": 0.04417,
                    "mrr_at_1": 0.44666666666666666,
                    "mrr_at_3": 0.5111111111111112,
                    "mrr_at_5": 0.5309444444444446,
                    "mrr_at_10": 0.5401600529100531,
                    "mrr_at_20": 0.5441220519676404,
                    "main_score": 0.57891,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 101.26725244522095,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "Touche2020Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.43878,
                    "ndcg_at_3": 0.31955,
                    "ndcg_at_5": 0.28261,
                    "ndcg_at_10": 0.26357,
                    "map_at_1": 0.03282,
                    "map_at_3": 0.05648,
                    "map_at_5": 0.07219,
                    "map_at_10": 0.10072,
                    "recall_at_1": 0.03282,
                    "recall_at_3": 0.06907,
                    "recall_at_5": 0.09683,
                    "recall_at_10": 0.16432,
                    "precision_at_1": 0.44898,
                    "precision_at_3": 0.31293,
                    "precision_at_5": 0.26122,
                    "precision_at_10": 0.22245,
                    "mrr_at_1": 0.4489795918367347,
                    "mrr_at_3": 0.5510204081632653,
                    "mrr_at_5": 0.5653061224489796,
                    "mrr_at_10": 0.5769274376417234,
                    "main_score": 0.26357,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 13658.39564037323,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.8823,
                    "ndcg_at_3": 0.84121,
                    "ndcg_at_5": 0.82609,
                    "ndcg_at_10": 0.82421,
                    "map_at_1": 0.26598,
                    "map_at_3": 0.52538,
                    "map_at_5": 0.64522,
                    "map_at_10": 0.74491,
                    "recall_at_1": 0.26598,
                    "recall_at_3": 0.5433,
                    "recall_at_5": 0.68109,
                    "recall_at_10": 0.81271,
                    "precision_at_1": 0.8823,
                    "precision_at_3": 0.73705,
                    "precision_at_5": 0.61696,
                    "precision_at_10": 0.40993,
                    "mrr_at_1": 0.8822987901104682,
                    "mrr_at_3": 0.9053495236425259,
                    "mrr_at_5": 0.9085671284119475,
                    "mrr_at_10": 0.9103703425376242,
                    "main_score": 0.82421,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1258.4867675304413,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.22,
                    "ndcg_at_3": 0.17516,
                    "ndcg_at_5": 0.15109,
                    "ndcg_at_10": 0.17904,
                    "map_at_1": 0.04468,
                    "map_at_3": 0.07842,
                    "map_at_5": 0.09188,
                    "map_at_10": 0.10568,
                    "recall_at_1": 0.04468,
                    "recall_at_3": 0.09893,
                    "recall_at_5": 0.13303,
                    "recall_at_10": 0.18393,
                    "precision_at_1": 0.22,
                    "precision_at_3": 0.16267,
                    "precision_at_5": 0.131,
                    "precision_at_10": 0.0907,
                    "mrr_at_1": 0.22,
                    "mrr_at_3": 0.2879999999999999,
                    "mrr_at_5": 0.3068499999999996,
                    "mrr_at_10": 0.3193273809523805,
                    "main_score": 0.17904,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 118.44957756996155,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.556,
                    "ndcg_at_3": 0.66957,
                    "ndcg_at_5": 0.69005,
                    "ndcg_at_10": 0.70448,
                    "ndcg_at_20": 0.71687,
                    "map_at_1": 0.556,
                    "map_at_3": 0.64267,
                    "map_at_5": 0.65397,
                    "map_at_10": 0.66003,
                    "map_at_20": 0.66344,
                    "recall_at_1": 0.556,
                    "recall_at_3": 0.747,
                    "recall_at_5": 0.797,
                    "recall_at_10": 0.841,
                    "recall_at_20": 0.89,
                    "precision_at_1": 0.556,
                    "precision_at_3": 0.249,
                    "precision_at_5": 0.1594,
                    "precision_at_10": 0.0841,
                    "precision_at_20": 0.0445,
                    "mrr_at_1": 0.556,
                    "mrr_at_3": 0.6426666666666667,
                    "mrr_at_5": 0.6539666666666668,
                    "mrr_at_10": 0.6600345238095238,
                    "mrr_at_20": 0.6634399166150325,
                    "main_score": 0.70448,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 343.73264813423157,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.34877,
                    "ndcg_at_3": 0.31583,
                    "ndcg_at_5": 0.32742,
                    "ndcg_at_10": 0.34931,
                    "map_at_1": 0.17222,
                    "map_at_3": 0.23985,
                    "map_at_5": 0.26205,
                    "map_at_10": 0.27858,
                    "recall_at_1": 0.17222,
                    "recall_at_3": 0.27916,
                    "recall_at_5": 0.33743,
                    "recall_at_10": 0.40877,
                    "precision_at_1": 0.34877,
                    "precision_at_3": 0.21245,
                    "precision_at_5": 0.15864,
                    "precision_at_10": 0.09892,
                    "mrr_at_1": 0.3487654320987654,
                    "mrr_at_3": 0.40200617283950635,
                    "mrr_at_5": 0.4157407407407408,
                    "mrr_at_10": 0.4265640309621791,
                    "main_score": 0.34931,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 319.38058614730835,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.557,
                    "ndcg_at_3": 0.66547,
                    "ndcg_at_5": 0.68936,
                    "ndcg_at_10": 0.70621,
                    "ndcg_at_20": 0.71901,
                    "map_at_1": 0.557,
                    "map_at_3": 0.639,
                    "map_at_5": 0.65225,
                    "map_at_10": 0.65923,
                    "map_at_20": 0.66269,
                    "recall_at_1": 0.557,
                    "recall_at_3": 0.742,
                    "recall_at_5": 0.8,
                    "recall_at_10": 0.852,
                    "recall_at_20": 0.903,
                    "precision_at_1": 0.557,
                    "precision_at_3": 0.24733,
                    "precision_at_5": 0.16,
                    "precision_at_10": 0.0852,
                    "precision_at_20": 0.04515,
                    "mrr_at_1": 0.557,
                    "mrr_at_3": 0.639,
                    "mrr_at_5": 0.6522500000000002,
                    "mrr_at_10": 0.6592257936507938,
                    "mrr_at_20": 0.6626894265607114,
                    "main_score": 0.70621,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 114.12581825256348,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.55716,
                    "ndcg_at_3": 0.61833,
                    "ndcg_at_5": 0.63443,
                    "ndcg_at_10": 0.64908,
                    "ndcg_at_20": 0.66087,
                    "map_at_1": 0.55704,
                    "map_at_3": 0.6035,
                    "map_at_5": 0.61243,
                    "map_at_10": 0.6185,
                    "map_at_20": 0.62174,
                    "recall_at_1": 0.55704,
                    "recall_at_3": 0.66091,
                    "recall_at_5": 0.70002,
                    "recall_at_10": 0.7452,
                    "recall_at_20": 0.79177,
                    "precision_at_1": 0.55716,
                    "precision_at_3": 0.22039,
                    "precision_at_5": 0.14008,
                    "precision_at_10": 0.07457,
                    "precision_at_20": 0.03963,
                    "mrr_at_1": 0.5571571171890597,
                    "mrr_at_3": 0.6036733879017834,
                    "mrr_at_5": 0.6126312637253059,
                    "mrr_at_10": 0.6186996422312956,
                    "mrr_at_20": 0.6219560748885555,
                    "main_score": 0.64908,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 84.68556880950928,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.40594,
                    "ndcg_at_3": 0.48063,
                    "ndcg_at_5": 0.501,
                    "ndcg_at_10": 0.51983,
                    "ndcg_at_20": 0.53405,
                    "map_at_1": 0.40536,
                    "map_at_3": 0.46234,
                    "map_at_5": 0.47367,
                    "map_at_10": 0.48151,
                    "map_at_20": 0.48546,
                    "recall_at_1": 0.40536,
                    "recall_at_3": 0.53269,
                    "recall_at_5": 0.58201,
                    "recall_at_10": 0.63976,
                    "recall_at_20": 0.69546,
                    "precision_at_1": 0.40594,
                    "precision_at_3": 0.17808,
                    "precision_at_5": 0.1169,
                    "precision_at_10": 0.06435,
                    "precision_at_20": 0.03506,
                    "mrr_at_1": 0.40593799264319497,
                    "mrr_at_3": 0.46303455696519874,
                    "mrr_at_5": 0.47437379576108907,
                    "mrr_at_10": 0.4821770554429607,
                    "mrr_at_20": 0.4860816760430762,
                    "main_score": 0.51983,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 76.91002869606018,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.89078,
                    "ndcg_at_3": 0.92504,
                    "ndcg_at_5": 0.93048,
                    "ndcg_at_10": 0.93346,
                    "ndcg_at_20": 0.93525,
                    "map_at_1": 0.89078,
                    "map_at_3": 0.91706,
                    "map_at_5": 0.9201,
                    "map_at_10": 0.92135,
                    "map_at_20": 0.92184,
                    "recall_at_1": 0.89078,
                    "recall_at_3": 0.94795,
                    "recall_at_5": 0.96109,
                    "recall_at_10": 0.9702,
                    "recall_at_20": 0.97726,
                    "precision_at_1": 0.89078,
                    "precision_at_3": 0.31598,
                    "precision_at_5": 0.19222,
                    "precision_at_10": 0.09702,
                    "precision_at_20": 0.04886,
                    "mrr_at_1": 0.8907839218298912,
                    "mrr_at_3": 0.9170626989414462,
                    "mrr_at_5": 0.9200962321415365,
                    "mrr_at_10": 0.9213453817384547,
                    "mrr_at_20": 0.9218421758512335,
                    "main_score": 0.93346,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 69.53317880630493,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.8839,
                    "ndcg_at_3": 0.92115,
                    "ndcg_at_5": 0.9272,
                    "ndcg_at_10": 0.93123,
                    "ndcg_at_20": 0.93321,
                    "map_at_1": 0.8839,
                    "map_at_3": 0.91245,
                    "map_at_5": 0.91582,
                    "map_at_10": 0.91749,
                    "map_at_20": 0.91805,
                    "recall_at_1": 0.8839,
                    "recall_at_3": 0.94612,
                    "recall_at_5": 0.96078,
                    "recall_at_10": 0.97317,
                    "recall_at_20": 0.98095,
                    "precision_at_1": 0.8839,
                    "precision_at_3": 0.31537,
                    "precision_at_5": 0.19216,
                    "precision_at_10": 0.09732,
                    "precision_at_20": 0.04905,
                    "mrr_at_1": 0.8838996224739063,
                    "mrr_at_3": 0.9124509586201778,
                    "mrr_at_5": 0.9158153823377014,
                    "mrr_at_10": 0.9174932760875467,
                    "mrr_at_20": 0.918048074284154,
                    "main_score": 0.93123,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 107.13245844841003,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.31283,
                    "ndcg_at_3": 0.31362,
                    "ndcg_at_5": 0.33043,
                    "ndcg_at_10": 0.35899,
                    "map_at_1": 0.20155,
                    "map_at_3": 0.26536,
                    "map_at_5": 0.28295,
                    "map_at_10": 0.2993,
                    "recall_at_1": 0.20155,
                    "recall_at_3": 0.31095,
                    "recall_at_5": 0.36551,
                    "recall_at_10": 0.44873,
                    "precision_at_1": 0.31283,
                    "precision_at_3": 0.17871,
                    "precision_at_5": 0.12898,
                    "precision_at_10": 0.0814,
                    "mrr_at_1": 0.31282820705176295,
                    "mrr_at_3": 0.3631741268650491,
                    "mrr_at_5": 0.37597732766524966,
                    "mrr_at_10": 0.3868881903015432,
                    "main_score": 0.35899,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1457.9369797706604,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.86467,
                    "ndcg_at_3": 0.90219,
                    "ndcg_at_5": 0.90894,
                    "ndcg_at_10": 0.91372,
                    "ndcg_at_20": 0.91651,
                    "map_at_1": 0.86467,
                    "map_at_3": 0.89332,
                    "map_at_5": 0.89707,
                    "map_at_10": 0.89905,
                    "map_at_20": 0.89984,
                    "recall_at_1": 0.86467,
                    "recall_at_3": 0.9277,
                    "recall_at_5": 0.94407,
                    "recall_at_10": 0.95876,
                    "recall_at_20": 0.96967,
                    "precision_at_1": 0.86467,
                    "precision_at_3": 0.30924,
                    "precision_at_5": 0.18882,
                    "precision_at_10": 0.09588,
                    "precision_at_20": 0.04849,
                    "mrr_at_1": 0.8646686854292839,
                    "mrr_at_3": 0.8933321458259118,
                    "mrr_at_5": 0.8970861536634623,
                    "mrr_at_10": 0.8990703336613141,
                    "mrr_at_20": 0.8998535212067276,
                    "main_score": 0.91372,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 32.75661301612854,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.88,
                    "ndcg_at_3": 0.83611,
                    "ndcg_at_5": 0.82338,
                    "ndcg_at_10": 0.8469,
                    "ndcg_at_20": 0.86383,
                    "map_at_1": 0.25208,
                    "map_at_3": 0.53106,
                    "map_at_5": 0.66795,
                    "map_at_10": 0.76596,
                    "map_at_20": 0.78792,
                    "recall_at_1": 0.25208,
                    "recall_at_3": 0.55701,
                    "recall_at_5": 0.72105,
                    "recall_at_10": 0.86048,
                    "recall_at_20": 0.91407,
                    "precision_at_1": 0.88,
                    "precision_at_3": 0.75017,
                    "precision_at_5": 0.6308,
                    "precision_at_10": 0.4065,
                    "precision_at_20": 0.22235,
                    "mrr_at_1": 0.88,
                    "mrr_at_3": 0.9132499999999998,
                    "mrr_at_5": 0.9161499999999999,
                    "mrr_at_10": 0.9172890873015872,
                    "mrr_at_20": 0.9178056493944651,
                    "main_score": 0.8469,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 677.6922478675842,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.156,
                    "ndcg_at_3": 0.12758,
                    "ndcg_at_5": 0.11226,
                    "ndcg_at_10": 0.13861,
                    "ndcg_at_20": 0.16361,
                    "map_at_1": 0.03188,
                    "map_at_3": 0.0554,
                    "map_at_5": 0.06615,
                    "map_at_10": 0.07835,
                    "map_at_20": 0.08672,
                    "recall_at_1": 0.03188,
                    "recall_at_3": 0.07333,
                    "recall_at_5": 0.10068,
                    "recall_at_10": 0.1491,
                    "recall_at_20": 0.2076,
                    "precision_at_1": 0.156,
                    "precision_at_3": 0.12033,
                    "precision_at_5": 0.0994,
                    "precision_at_10": 0.0735,
                    "precision_at_20": 0.05125,
                    "mrr_at_1": 0.156,
                    "mrr_at_3": 0.2136666666666669,
                    "mrr_at_5": 0.22951666666666676,
                    "mrr_at_10": 0.24200317460317464,
                    "mrr_at_20": 0.2502888884893918,
                    "main_score": 0.13861,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 262.3152244091034,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.66553,
                    "ndcg_at_3": 0.72968,
                    "ndcg_at_5": 0.7417,
                    "ndcg_at_10": 0.75328,
                    "ndcg_at_20": 0.76145,
                    "map_at_1": 0.66509,
                    "map_at_3": 0.7145,
                    "map_at_5": 0.72119,
                    "map_at_10": 0.726,
                    "map_at_20": 0.72827,
                    "recall_at_1": 0.66509,
                    "recall_at_3": 0.77317,
                    "recall_at_5": 0.80227,
                    "recall_at_10": 0.83795,
                    "recall_at_20": 0.87012,
                    "precision_at_1": 0.66553,
                    "precision_at_3": 0.25803,
                    "precision_at_5": 0.16068,
                    "precision_at_10": 0.08393,
                    "precision_at_20": 0.04359,
                    "mrr_at_1": 0.6655314151497358,
                    "mrr_at_3": 0.7146652965355194,
                    "mrr_at_5": 0.7213241338813853,
                    "mrr_at_10": 0.7261210725237434,
                    "mrr_at_20": 0.728371255701068,
                    "main_score": 0.75328,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 126.4323627948761,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.49,
                    "ndcg_at_3": 0.54259,
                    "ndcg_at_5": 0.5537,
                    "ndcg_at_10": 0.56587,
                    "ndcg_at_20": 0.57542,
                    "map_at_1": 0.49,
                    "map_at_3": 0.52967,
                    "map_at_5": 0.53582,
                    "map_at_10": 0.54078,
                    "map_at_20": 0.54351,
                    "recall_at_1": 0.49,
                    "recall_at_3": 0.58,
                    "recall_at_5": 0.607,
                    "recall_at_10": 0.645,
                    "recall_at_20": 0.682,
                    "precision_at_1": 0.49,
                    "precision_at_3": 0.19333,
                    "precision_at_5": 0.1214,
                    "precision_at_10": 0.0645,
                    "precision_at_20": 0.0341,
                    "mrr_at_1": 0.49,
                    "mrr_at_3": 0.5296666666666663,
                    "mrr_at_5": 0.5358166666666663,
                    "mrr_at_10": 0.5407849206349206,
                    "mrr_at_20": 0.5435099017769293,
                    "main_score": 0.56587,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 387.6296648979187,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.4733,
                    "ndcg_at_3": 0.54036,
                    "ndcg_at_5": 0.55692,
                    "ndcg_at_10": 0.57328,
                    "ndcg_at_20": 0.58609,
                    "map_at_1": 0.47323,
                    "map_at_3": 0.52408,
                    "map_at_5": 0.53326,
                    "map_at_10": 0.54003,
                    "map_at_20": 0.54355,
                    "recall_at_1": 0.47323,
                    "recall_at_3": 0.58702,
                    "recall_at_5": 0.62733,
                    "recall_at_10": 0.6778,
                    "recall_at_20": 0.72837,
                    "precision_at_1": 0.4733,
                    "precision_at_3": 0.19583,
                    "precision_at_5": 0.12559,
                    "precision_at_10": 0.06787,
                    "precision_at_20": 0.03648,
                    "mrr_at_1": 0.47330135891286973,
                    "mrr_at_3": 0.5243072208899596,
                    "mrr_at_5": 0.5335218491873257,
                    "mrr_at_10": 0.5403151922906205,
                    "mrr_at_20": 0.5438402750651157,
                    "main_score": 0.57328,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 70.80690503120422,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "e4e08e0b7dbe3c8700f0daef558ff32256715259",
        "task_name": "QuoraChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.7826,
                    "ndcg_at_3": 0.82767,
                    "ndcg_at_5": 0.84529,
                    "ndcg_at_10": 0.86037,
                    "ndcg_at_20": 0.86813,
                    "map_at_1": 0.67849,
                    "map_at_3": 0.78768,
                    "map_at_5": 0.80702,
                    "map_at_10": 0.81873,
                    "map_at_20": 0.82326,
                    "recall_at_1": 0.67849,
                    "recall_at_3": 0.84922,
                    "recall_at_5": 0.89812,
                    "recall_at_10": 0.9421,
                    "recall_at_20": 0.96712,
                    "precision_at_1": 0.7826,
                    "precision_at_3": 0.36313,
                    "precision_at_5": 0.24006,
                    "precision_at_10": 0.13197,
                    "precision_at_20": 0.07036,
                    "mrr_at_1": 0.7823,
                    "mrr_at_3": 0.839116666666663,
                    "mrr_at_5": 0.8466266666666618,
                    "mrr_at_10": 0.8505005952380917,
                    "mrr_at_20": 0.8515001125134717,
                    "main_score": 0.86037,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 599.3509521484375,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.44118,
                    "ndcg_at_3": 0.40954,
                    "ndcg_at_5": 0.39318,
                    "ndcg_at_10": 0.36663,
                    "ndcg_at_20": 0.34426,
                    "map_at_1": 0.04844,
                    "map_at_3": 0.09096,
                    "map_at_5": 0.10993,
                    "map_at_10": 0.13275,
                    "map_at_20": 0.14993,
                    "recall_at_1": 0.04844,
                    "recall_at_3": 0.10439,
                    "recall_at_5": 0.13737,
                    "recall_at_10": 0.1798,
                    "recall_at_20": 0.2205,
                    "precision_at_1": 0.4613,
                    "precision_at_3": 0.39628,
                    "precision_at_5": 0.35108,
                    "precision_at_10": 0.28483,
                    "precision_at_20": 0.21517,
                    "mrr_at_1": 0.4613003095975232,
                    "mrr_at_3": 0.5335397316821465,
                    "mrr_at_5": 0.5466976264189887,
                    "mrr_at_10": 0.5528367487345814,
                    "mrr_at_20": 0.55637223082085,
                    "main_score": 0.36663,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 46.91260766983032,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.33746,
                    "ndcg_at_3": 0.29364,
                    "ndcg_at_5": 0.28052,
                    "ndcg_at_10": 0.26124,
                    "ndcg_at_20": 0.24659,
                    "map_at_1": 0.04526,
                    "map_at_3": 0.06906,
                    "map_at_5": 0.08163,
                    "map_at_10": 0.09503,
                    "map_at_20": 0.1043,
                    "recall_at_1": 0.04526,
                    "recall_at_3": 0.07865,
                    "recall_at_5": 0.10211,
                    "recall_at_10": 0.13188,
                    "recall_at_20": 0.16333,
                    "precision_at_1": 0.34675,
                    "precision_at_3": 0.27038,
                    "precision_at_5": 0.23839,
                    "precision_at_10": 0.19195,
                    "precision_at_20": 0.14381,
                    "mrr_at_1": 0.3498452012383901,
                    "mrr_at_3": 0.414344685242518,
                    "mrr_at_5": 0.4290505675954593,
                    "mrr_at_10": 0.43658165020394113,
                    "mrr_at_20": 0.44242989204145733,
                    "main_score": 0.26124,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 16.084781646728516,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.218,
                    "ndcg_at_3": 0.17338,
                    "ndcg_at_5": 0.14981,
                    "ndcg_at_10": 0.17691,
                    "ndcg_at_20": 0.20118,
                    "map_at_1": 0.04423,
                    "map_at_3": 0.07731,
                    "map_at_5": 0.09077,
                    "map_at_10": 0.10435,
                    "map_at_20": 0.11273,
                    "recall_at_1": 0.04423,
                    "recall_at_3": 0.09803,
                    "recall_at_5": 0.13223,
                    "recall_at_10": 0.18158,
                    "recall_at_20": 0.23843,
                    "precision_at_1": 0.218,
                    "precision_at_3": 0.16133,
                    "precision_at_5": 0.1302,
                    "precision_at_10": 0.0895,
                    "precision_at_20": 0.0588,
                    "mrr_at_1": 0.218,
                    "mrr_at_3": 0.2854999999999999,
                    "mrr_at_5": 0.3039499999999997,
                    "mrr_at_10": 0.31620277777777756,
                    "mrr_at_20": 0.3228888259358458,
                    "main_score": 0.17691,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 71.60052394866943,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.46,
                    "ndcg_at_3": 0.51753,
                    "ndcg_at_5": 0.52618,
                    "ndcg_at_10": 0.54264,
                    "ndcg_at_20": 0.55176,
                    "map_at_1": 0.46,
                    "map_at_3": 0.50383,
                    "map_at_5": 0.50863,
                    "map_at_10": 0.51559,
                    "map_at_20": 0.5181,
                    "recall_at_1": 0.46,
                    "recall_at_3": 0.557,
                    "recall_at_5": 0.578,
                    "recall_at_10": 0.628,
                    "recall_at_20": 0.664,
                    "precision_at_1": 0.46,
                    "precision_at_3": 0.18567,
                    "precision_at_5": 0.1156,
                    "precision_at_10": 0.0628,
                    "precision_at_20": 0.0332,
                    "mrr_at_1": 0.462,
                    "mrr_at_3": 0.5048333333333331,
                    "mrr_at_5": 0.509633333333333,
                    "mrr_at_10": 0.5165936507936508,
                    "mrr_at_20": 0.5191043015592939,
                    "main_score": 0.54264,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 213.95936560630798,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.32108,
                    "ndcg_at_3": 0.32689,
                    "ndcg_at_5": 0.34303,
                    "ndcg_at_10": 0.37063,
                    "ndcg_at_20": 0.39801,
                    "map_at_1": 0.20435,
                    "map_at_3": 0.27548,
                    "map_at_5": 0.29339,
                    "map_at_10": 0.30939,
                    "map_at_20": 0.31919,
                    "recall_at_1": 0.20435,
                    "recall_at_3": 0.32847,
                    "recall_at_5": 0.38189,
                    "recall_at_10": 0.46268,
                    "recall_at_20": 0.5562,
                    "precision_at_1": 0.32108,
                    "precision_at_3": 0.18805,
                    "precision_at_5": 0.13533,
                    "precision_at_10": 0.08425,
                    "precision_at_20": 0.05113,
                    "mrr_at_1": 0.3210802700675169,
                    "mrr_at_3": 0.3755938984746182,
                    "mrr_at_5": 0.38764691172793203,
                    "mrr_at_10": 0.39822167843548145,
                    "mrr_at_20": 0.40406083183934083,
                    "main_score": 0.37063,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 362.35180282592773,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.4258,
                    "ndcg_at_3": 0.50595,
                    "ndcg_at_5": 0.52917,
                    "ndcg_at_10": 0.55149,
                    "ndcg_at_20": 0.56669,
                    "map_at_1": 0.4257,
                    "map_at_3": 0.4863,
                    "map_at_5": 0.49917,
                    "map_at_10": 0.50843,
                    "map_at_20": 0.51262,
                    "recall_at_1": 0.4257,
                    "recall_at_3": 0.56269,
                    "recall_at_5": 0.61911,
                    "recall_at_10": 0.68788,
                    "recall_at_20": 0.74783,
                    "precision_at_1": 0.4258,
                    "precision_at_3": 0.18761,
                    "precision_at_5": 0.12387,
                    "precision_at_10": 0.06882,
                    "precision_at_20": 0.03742,
                    "mrr_at_1": 0.4257987937892981,
                    "mrr_at_3": 0.48638200949571125,
                    "mrr_at_5": 0.4992637623508454,
                    "mrr_at_10": 0.508518404795529,
                    "mrr_at_20": 0.5127154028277724,
                    "main_score": 0.55149,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 47.28121900558472,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.16643,
                    "ndcg_at_3": 0.27051,
                    "ndcg_at_5": 0.32149,
                    "ndcg_at_10": 0.38088,
                    "ndcg_at_20": 0.42133,
                    "map_at_1": 0.16643,
                    "map_at_3": 0.24372,
                    "map_at_5": 0.27167,
                    "map_at_10": 0.29622,
                    "map_at_20": 0.3076,
                    "recall_at_1": 0.16643,
                    "recall_at_3": 0.34851,
                    "recall_at_5": 0.47368,
                    "recall_at_10": 0.65718,
                    "recall_at_20": 0.81508,
                    "precision_at_1": 0.16643,
                    "precision_at_3": 0.11617,
                    "precision_at_5": 0.09474,
                    "precision_at_10": 0.06572,
                    "precision_at_20": 0.04075,
                    "mrr_at_1": 0.16856330014224752,
                    "mrr_at_3": 0.24454717875770499,
                    "mrr_at_5": 0.27249881460407704,
                    "mrr_at_10": 0.2971256971256967,
                    "mrr_at_20": 0.30847339686247044,
                    "main_score": 0.38088,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 23.452430963516235,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.49246,
                    "ndcg_at_3": 0.58078,
                    "ndcg_at_5": 0.60301,
                    "ndcg_at_10": 0.62364,
                    "ndcg_at_20": 0.63642,
                    "map_at_1": 0.49236,
                    "map_at_3": 0.55939,
                    "map_at_5": 0.57175,
                    "map_at_10": 0.58034,
                    "map_at_20": 0.58388,
                    "recall_at_1": 0.49236,
                    "recall_at_3": 0.64248,
                    "recall_at_5": 0.69634,
                    "recall_at_10": 0.75968,
                    "recall_at_20": 0.80995,
                    "precision_at_1": 0.49246,
                    "precision_at_3": 0.21424,
                    "precision_at_5": 0.13932,
                    "precision_at_10": 0.07601,
                    "precision_at_20": 0.04053,
                    "mrr_at_1": 0.49246118311305015,
                    "mrr_at_3": 0.5594604131913343,
                    "mrr_at_5": 0.5718112408571944,
                    "mrr_at_10": 0.5804123154886782,
                    "mrr_at_20": 0.5839479511742537,
                    "main_score": 0.62364,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 86.0221905708313,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.221,
                    "ndcg_at_3": 0.17503,
                    "ndcg_at_5": 0.15099,
                    "ndcg_at_10": 0.17914,
                    "ndcg_at_20": 0.20381,
                    "map_at_1": 0.04488,
                    "map_at_3": 0.07835,
                    "map_at_5": 0.0918,
                    "map_at_10": 0.10569,
                    "map_at_20": 0.11437,
                    "recall_at_1": 0.04488,
                    "recall_at_3": 0.09873,
                    "recall_at_5": 0.13283,
                    "recall_at_10": 0.18418,
                    "recall_at_20": 0.24198,
                    "precision_at_1": 0.221,
                    "precision_at_3": 0.16233,
                    "precision_at_5": 0.1308,
                    "precision_at_10": 0.0908,
                    "precision_at_20": 0.0597,
                    "mrr_at_1": 0.221,
                    "mrr_at_3": 0.28833333333333333,
                    "mrr_at_5": 0.30713333333333304,
                    "mrr_at_10": 0.31956428571428536,
                    "mrr_at_20": 0.3257077434519381,
                    "main_score": 0.17914,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 119.70084476470947,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "e4e08e0b7dbe3c8700f0daef558ff32256715259",
        "task_name": "QuoraChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.4705,
                    "ndcg_at_3": 0.55074,
                    "ndcg_at_5": 0.58327,
                    "ndcg_at_10": 0.61606,
                    "ndcg_at_20": 0.63842,
                    "map_at_1": 0.41322,
                    "map_at_3": 0.51037,
                    "map_at_5": 0.53363,
                    "map_at_10": 0.55079,
                    "map_at_20": 0.55909,
                    "recall_at_1": 0.41322,
                    "recall_at_3": 0.60184,
                    "recall_at_5": 0.68065,
                    "recall_at_10": 0.77479,
                    "recall_at_20": 0.85321,
                    "precision_at_1": 0.4705,
                    "precision_at_3": 0.247,
                    "precision_at_5": 0.17418,
                    "precision_at_10": 0.10385,
                    "precision_at_20": 0.05964,
                    "mrr_at_1": 0.4705,
                    "mrr_at_3": 0.5532833333333312,
                    "mrr_at_5": 0.5704533333333277,
                    "mrr_at_10": 0.582205753968251,
                    "mrr_at_20": 0.5870146840818234,
                    "main_score": 0.61606,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 779.5216317176819,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "bb9466bac8153a0349341eb1b22e06409e78ef4e",
        "task_name": "TRECCOVIDChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.89,
                    "ndcg_at_3": 0.85039,
                    "ndcg_at_5": 0.82357,
                    "ndcg_at_10": 0.77251,
                    "ndcg_at_20": 0.72544,
                    "map_at_1": 0.00251,
                    "map_at_3": 0.00702,
                    "map_at_5": 0.011,
                    "map_at_10": 0.01952,
                    "map_at_20": 0.03365,
                    "recall_at_1": 0.00251,
                    "recall_at_3": 0.00724,
                    "recall_at_5": 0.01155,
                    "recall_at_10": 0.02106,
                    "recall_at_20": 0.03822,
                    "precision_at_1": 0.94,
                    "precision_at_3": 0.91333,
                    "precision_at_5": 0.868,
                    "precision_at_10": 0.804,
                    "precision_at_20": 0.753,
                    "mrr_at_1": 0.94,
                    "mrr_at_3": 0.9566666666666666,
                    "mrr_at_5": 0.9616666666666666,
                    "mrr_at_10": 0.9616666666666666,
                    "mrr_at_20": 0.9616666666666666,
                    "main_score": 0.77251,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 2392.7719914913177,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.40594,
                    "ndcg_at_3": 0.48063,
                    "ndcg_at_5": 0.501,
                    "ndcg_at_10": 0.51983,
                    "ndcg_at_20": 0.53405,
                    "map_at_1": 0.40536,
                    "map_at_3": 0.46234,
                    "map_at_5": 0.47367,
                    "map_at_10": 0.48151,
                    "map_at_20": 0.48546,
                    "recall_at_1": 0.40536,
                    "recall_at_3": 0.53269,
                    "recall_at_5": 0.58201,
                    "recall_at_10": 0.63976,
                    "recall_at_20": 0.69546,
                    "precision_at_1": 0.40594,
                    "precision_at_3": 0.17808,
                    "precision_at_5": 0.1169,
                    "precision_at_10": 0.06435,
                    "precision_at_20": 0.03506,
                    "mrr_at_1": 0.40593799264319497,
                    "mrr_at_3": 0.46303455696519874,
                    "mrr_at_5": 0.47437379576108907,
                    "mrr_at_10": 0.4821770554429607,
                    "mrr_at_20": 0.4860816760430762,
                    "main_score": 0.51983,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 76.05930638313293,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "2e643e7363944af1c33a652d1c87320d0871c4e4",
        "task_name": "NarrativeQAChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.5997,
                    "ndcg_at_3": 0.67636,
                    "ndcg_at_5": 0.69281,
                    "ndcg_at_10": 0.70725,
                    "ndcg_at_20": 0.71751,
                    "map_at_1": 0.5997,
                    "map_at_3": 0.65778,
                    "map_at_5": 0.66694,
                    "map_at_10": 0.67291,
                    "map_at_20": 0.67573,
                    "recall_at_1": 0.5997,
                    "recall_at_3": 0.73004,
                    "recall_at_5": 0.76982,
                    "recall_at_10": 0.81444,
                    "recall_at_20": 0.85498,
                    "precision_at_1": 0.5997,
                    "precision_at_3": 0.24335,
                    "precision_at_5": 0.15396,
                    "precision_at_10": 0.08144,
                    "precision_at_20": 0.04275,
                    "mrr_at_1": 0.5996968835843516,
                    "mrr_at_3": 0.6577784092703064,
                    "mrr_at_5": 0.6669429446496737,
                    "mrr_at_10": 0.6729096469505642,
                    "mrr_at_20": 0.6757257971429753,
                    "main_score": 0.70725,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 753.3759415149689,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "bb9466bac8153a0349341eb1b22e06409e78ef4e",
        "task_name": "TRECCOVIDChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.87,
                    "ndcg_at_3": 0.84458,
                    "ndcg_at_5": 0.82477,
                    "ndcg_at_10": 0.77742,
                    "map_at_1": 0.00249,
                    "map_at_3": 0.00682,
                    "map_at_5": 0.0109,
                    "map_at_10": 0.0197,
                    "recall_at_1": 0.00249,
                    "recall_at_3": 0.00707,
                    "recall_at_5": 0.01156,
                    "recall_at_10": 0.02147,
                    "precision_at_1": 0.92,
                    "precision_at_3": 0.89333,
                    "precision_at_5": 0.876,
                    "precision_at_10": 0.82,
                    "mrr_at_1": 0.92,
                    "mrr_at_3": 0.94,
                    "mrr_at_5": 0.945,
                    "mrr_at_10": 0.9483333333333335,
                    "main_score": 0.77742,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 2388.794912815094,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "e4e08e0b7dbe3c8700f0daef558ff32256715259",
        "task_name": "QuoraChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.8152,
                    "ndcg_at_3": 0.85565,
                    "ndcg_at_5": 0.87191,
                    "ndcg_at_10": 0.88459,
                    "ndcg_at_20": 0.89107,
                    "map_at_1": 0.70794,
                    "map_at_3": 0.81744,
                    "map_at_5": 0.83645,
                    "map_at_10": 0.84731,
                    "map_at_20": 0.85153,
                    "recall_at_1": 0.70794,
                    "recall_at_3": 0.87231,
                    "recall_at_5": 0.91808,
                    "recall_at_10": 0.95528,
                    "recall_at_20": 0.97576,
                    "precision_at_1": 0.8152,
                    "precision_at_3": 0.37397,
                    "precision_at_5": 0.2466,
                    "precision_at_10": 0.13443,
                    "precision_at_20": 0.07139,
                    "mrr_at_1": 0.8152,
                    "mrr_at_3": 0.8667999999999975,
                    "mrr_at_5": 0.873479999999997,
                    "mrr_at_10": 0.8766671428571408,
                    "mrr_at_20": 0.8773375851423236,
                    "main_score": 0.88459,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 302.43118500709534,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.57333,
                    "ndcg_at_3": 0.66251,
                    "ndcg_at_5": 0.68271,
                    "ndcg_at_10": 0.70531,
                    "ndcg_at_20": 0.71955,
                    "map_at_1": 0.54383,
                    "map_at_3": 0.63057,
                    "map_at_5": 0.64502,
                    "map_at_10": 0.65614,
                    "map_at_20": 0.66024,
                    "recall_at_1": 0.54383,
                    "recall_at_3": 0.72672,
                    "recall_at_5": 0.7765,
                    "recall_at_10": 0.84178,
                    "recall_at_20": 0.89689,
                    "precision_at_1": 0.57333,
                    "precision_at_3": 0.26222,
                    "precision_at_5": 0.172,
                    "precision_at_10": 0.09467,
                    "precision_at_20": 0.0505,
                    "mrr_at_1": 0.5733333333333334,
                    "mrr_at_3": 0.6511111111111111,
                    "mrr_at_5": 0.6611111111111111,
                    "mrr_at_10": 0.6690489417989417,
                    "mrr_at_20": 0.6726495596480117,
                    "main_score": 0.70531,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 37.464356899261475,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.87777,
                    "ndcg_at_3": 0.9162,
                    "ndcg_at_5": 0.92287,
                    "ndcg_at_10": 0.9271,
                    "ndcg_at_20": 0.92922,
                    "map_at_1": 0.87777,
                    "map_at_3": 0.90724,
                    "map_at_5": 0.91094,
                    "map_at_10": 0.91271,
                    "map_at_20": 0.9133,
                    "recall_at_1": 0.87777,
                    "recall_at_3": 0.94195,
                    "recall_at_5": 0.95816,
                    "recall_at_10": 0.97109,
                    "recall_at_20": 0.97939,
                    "precision_at_1": 0.87777,
                    "precision_at_3": 0.31398,
                    "precision_at_5": 0.19163,
                    "precision_at_10": 0.09711,
                    "precision_at_20": 0.04897,
                    "mrr_at_1": 0.877770375305352,
                    "mrr_at_3": 0.907239618032422,
                    "mrr_at_5": 0.9109371530091069,
                    "mrr_at_10": 0.9127087937847451,
                    "mrr_at_20": 0.913298741050526,
                    "main_score": 0.9271,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 103.82445240020752,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.48302,
                    "ndcg_at_3": 0.44003,
                    "ndcg_at_5": 0.44783,
                    "ndcg_at_10": 0.47632,
                    "ndcg_at_20": 0.50609,
                    "map_at_1": 0.23879,
                    "map_at_3": 0.34541,
                    "map_at_5": 0.37095,
                    "map_at_10": 0.39446,
                    "map_at_20": 0.40683,
                    "recall_at_1": 0.23879,
                    "recall_at_3": 0.39336,
                    "recall_at_5": 0.45534,
                    "recall_at_10": 0.54288,
                    "recall_at_20": 0.63558,
                    "precision_at_1": 0.48302,
                    "precision_at_3": 0.29784,
                    "precision_at_5": 0.21358,
                    "precision_at_10": 0.1338,
                    "precision_at_20": 0.07924,
                    "mrr_at_1": 0.48302469135802467,
                    "mrr_at_3": 0.5370370370370371,
                    "mrr_at_5": 0.5507716049382716,
                    "mrr_at_10": 0.5616077552420146,
                    "mrr_at_20": 0.5665195846186772,
                    "main_score": 0.47632,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 623.6336822509766,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.66491,
                    "ndcg_at_3": 0.76302,
                    "ndcg_at_5": 0.77882,
                    "ndcg_at_10": 0.79352,
                    "ndcg_at_20": 0.80314,
                    "map_at_1": 0.66359,
                    "map_at_3": 0.73955,
                    "map_at_5": 0.74845,
                    "map_at_10": 0.75485,
                    "map_at_20": 0.75758,
                    "recall_at_1": 0.66359,
                    "recall_at_3": 0.82903,
                    "recall_at_5": 0.86749,
                    "recall_at_10": 0.91201,
                    "recall_at_20": 0.94942,
                    "precision_at_1": 0.66491,
                    "precision_at_3": 0.27819,
                    "precision_at_5": 0.17513,
                    "precision_at_10": 0.0922,
                    "precision_at_20": 0.048,
                    "mrr_at_1": 0.6649104320337197,
                    "mrr_at_3": 0.7400772743238501,
                    "mrr_at_5": 0.7488760098349145,
                    "mrr_at_10": 0.7548049743255224,
                    "mrr_at_20": 0.7574881554537917,
                    "main_score": 0.79352,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 570.3745727539062,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.6914,
                    "ndcg_at_3": 0.75983,
                    "ndcg_at_5": 0.77998,
                    "ndcg_at_10": 0.79659,
                    "ndcg_at_20": 0.80342,
                    "map_at_1": 0.66836,
                    "map_at_3": 0.74008,
                    "map_at_5": 0.7521,
                    "map_at_10": 0.75935,
                    "map_at_20": 0.76138,
                    "recall_at_1": 0.66836,
                    "recall_at_3": 0.80846,
                    "recall_at_5": 0.85636,
                    "recall_at_10": 0.90616,
                    "recall_at_20": 0.93226,
                    "precision_at_1": 0.6914,
                    "precision_at_3": 0.28515,
                    "precision_at_5": 0.18183,
                    "precision_at_10": 0.09629,
                    "precision_at_20": 0.04958,
                    "mrr_at_1": 0.691404011461318,
                    "mrr_at_3": 0.7481852913085006,
                    "mrr_at_5": 0.7585219675262631,
                    "mrr_at_10": 0.7651996634374854,
                    "mrr_at_20": 0.7669630318076167,
                    "main_score": 0.79659,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 256.6061954498291,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.879,
                    "ndcg_at_3": 0.83496,
                    "ndcg_at_5": 0.82195,
                    "ndcg_at_10": 0.84573,
                    "map_at_1": 0.25164,
                    "map_at_3": 0.52976,
                    "map_at_5": 0.66608,
                    "map_at_10": 0.76407,
                    "recall_at_1": 0.25164,
                    "recall_at_3": 0.55617,
                    "recall_at_5": 0.71956,
                    "recall_at_10": 0.85962,
                    "precision_at_1": 0.879,
                    "precision_at_3": 0.74933,
                    "precision_at_5": 0.6298,
                    "precision_at_10": 0.40615,
                    "mrr_at_1": 0.879,
                    "mrr_at_3": 0.9126666666666663,
                    "mrr_at_5": 0.9152666666666665,
                    "mrr_at_10": 0.9166819444444441,
                    "main_score": 0.84573,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 669.1356353759766,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.155,
                    "ndcg_at_3": 0.13061,
                    "ndcg_at_5": 0.1149,
                    "ndcg_at_10": 0.14171,
                    "map_at_1": 0.03163,
                    "map_at_3": 0.0566,
                    "map_at_5": 0.06765,
                    "map_at_10": 0.0802,
                    "recall_at_1": 0.03163,
                    "recall_at_3": 0.07533,
                    "recall_at_5": 0.10353,
                    "recall_at_10": 0.1528,
                    "precision_at_1": 0.155,
                    "precision_at_3": 0.12367,
                    "precision_at_5": 0.1022,
                    "precision_at_10": 0.0754,
                    "mrr_at_1": 0.155,
                    "mrr_at_3": 0.21816666666666681,
                    "mrr_at_5": 0.23331666666666673,
                    "mrr_at_10": 0.2465055555555555,
                    "main_score": 0.14171,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 265.49326753616333,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "Touche2020Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.42857,
                    "ndcg_at_3": 0.33818,
                    "ndcg_at_5": 0.30204,
                    "ndcg_at_10": 0.27571,
                    "map_at_1": 0.03229,
                    "map_at_3": 0.06427,
                    "map_at_5": 0.08357,
                    "map_at_10": 0.1104,
                    "recall_at_1": 0.03229,
                    "recall_at_3": 0.0764,
                    "recall_at_5": 0.11065,
                    "recall_at_10": 0.17079,
                    "precision_at_1": 0.44898,
                    "precision_at_3": 0.34014,
                    "precision_at_5": 0.2898,
                    "precision_at_10": 0.23061,
                    "mrr_at_1": 0.4489795918367347,
                    "mrr_at_3": 0.5374149659863945,
                    "mrr_at_5": 0.5517006802721088,
                    "mrr_at_10": 0.5681567865241335,
                    "main_score": 0.27571,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 3882.2480227947235,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.46027,
                    "ndcg_at_3": 0.52388,
                    "ndcg_at_5": 0.53978,
                    "ndcg_at_10": 0.55628,
                    "ndcg_at_20": 0.56858,
                    "map_at_1": 0.46021,
                    "map_at_3": 0.50838,
                    "map_at_5": 0.51719,
                    "map_at_10": 0.524,
                    "map_at_20": 0.52736,
                    "recall_at_1": 0.46021,
                    "recall_at_3": 0.56846,
                    "recall_at_5": 0.60714,
                    "recall_at_10": 0.65809,
                    "recall_at_20": 0.70673,
                    "precision_at_1": 0.46027,
                    "precision_at_3": 0.18957,
                    "precision_at_5": 0.12149,
                    "precision_at_10": 0.06588,
                    "precision_at_20": 0.03539,
                    "mrr_at_1": 0.4601918465227818,
                    "mrr_at_3": 0.5084732214228672,
                    "mrr_at_5": 0.517294164668274,
                    "mrr_at_10": 0.5241460165201256,
                    "mrr_at_20": 0.5275308671305143,
                    "main_score": 0.55628,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 47.3893141746521,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.58896,
                    "ndcg_at_3": 0.6649,
                    "ndcg_at_5": 0.68055,
                    "ndcg_at_10": 0.69506,
                    "ndcg_at_20": 0.70539,
                    "map_at_1": 0.5886,
                    "map_at_3": 0.64674,
                    "map_at_5": 0.65548,
                    "map_at_10": 0.66152,
                    "map_at_20": 0.66437,
                    "recall_at_1": 0.5886,
                    "recall_at_3": 0.71697,
                    "recall_at_5": 0.75478,
                    "recall_at_10": 0.79939,
                    "recall_at_20": 0.84014,
                    "precision_at_1": 0.58896,
                    "precision_at_3": 0.23927,
                    "precision_at_5": 0.15116,
                    "precision_at_10": 0.08007,
                    "precision_at_20": 0.04208,
                    "mrr_at_1": 0.5889554342082085,
                    "mrr_at_3": 0.6469477227800228,
                    "mrr_at_5": 0.6556729884720017,
                    "mrr_at_10": 0.6616797986491498,
                    "mrr_at_20": 0.6645270383521414,
                    "main_score": 0.69506,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 59.99535131454468,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.7501,
                    "ndcg_at_3": 0.78479,
                    "ndcg_at_5": 0.79142,
                    "ndcg_at_10": 0.7971,
                    "ndcg_at_20": 0.80099,
                    "map_at_1": 0.7501,
                    "map_at_3": 0.77659,
                    "map_at_5": 0.78027,
                    "map_at_10": 0.78261,
                    "map_at_20": 0.78368,
                    "recall_at_1": 0.7501,
                    "recall_at_3": 0.8084,
                    "recall_at_5": 0.82445,
                    "recall_at_10": 0.84205,
                    "recall_at_20": 0.85745,
                    "precision_at_1": 0.7501,
                    "precision_at_3": 0.26947,
                    "precision_at_5": 0.16489,
                    "precision_at_10": 0.0842,
                    "precision_at_20": 0.04287,
                    "mrr_at_1": 0.7501,
                    "mrr_at_3": 0.7765916666666701,
                    "mrr_at_5": 0.7802716666666717,
                    "mrr_at_10": 0.782611071428576,
                    "mrr_at_20": 0.7836807989903187,
                    "main_score": 0.7971,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 542.6128680706024,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "Touche2020Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.15306,
                    "ndcg_at_3": 0.17917,
                    "ndcg_at_5": 0.17363,
                    "ndcg_at_10": 0.16331,
                    "ndcg_at_20": 0.17528,
                    "map_at_1": 0.01815,
                    "map_at_3": 0.04137,
                    "map_at_5": 0.05324,
                    "map_at_10": 0.06846,
                    "map_at_20": 0.0836,
                    "recall_at_1": 0.01815,
                    "recall_at_3": 0.05118,
                    "recall_at_5": 0.07497,
                    "recall_at_10": 0.1138,
                    "recall_at_20": 0.17313,
                    "precision_at_1": 0.18367,
                    "precision_at_3": 0.20408,
                    "precision_at_5": 0.19184,
                    "precision_at_10": 0.1449,
                    "precision_at_20": 0.11531,
                    "mrr_at_1": 0.1836734693877551,
                    "mrr_at_3": 0.28911564625850344,
                    "mrr_at_5": 0.31360544217687075,
                    "mrr_at_10": 0.3219873663751215,
                    "mrr_at_20": 0.3325745378684975,
                    "main_score": 0.16331,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 9393.829140901566,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.6914,
                    "ndcg_at_3": 0.75934,
                    "ndcg_at_5": 0.77989,
                    "ndcg_at_10": 0.79655,
                    "ndcg_at_20": 0.80327,
                    "map_at_1": 0.66829,
                    "map_at_3": 0.73963,
                    "map_at_5": 0.75189,
                    "map_at_10": 0.75914,
                    "map_at_20": 0.76114,
                    "recall_at_1": 0.66829,
                    "recall_at_3": 0.80782,
                    "recall_at_5": 0.85665,
                    "recall_at_10": 0.90669,
                    "recall_at_20": 0.9324,
                    "precision_at_1": 0.6914,
                    "precision_at_3": 0.28491,
                    "precision_at_5": 0.18189,
                    "precision_at_10": 0.09633,
                    "precision_at_20": 0.04959,
                    "mrr_at_1": 0.691404011461318,
                    "mrr_at_3": 0.7478271251193889,
                    "mrr_at_5": 0.7583715377268361,
                    "mrr_at_10": 0.7650418997589482,
                    "mrr_at_20": 0.7667760787934241,
                    "main_score": 0.79655,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 367.7912743091583,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.61,
                    "ndcg_at_3": 0.6886,
                    "ndcg_at_5": 0.70826,
                    "ndcg_at_10": 0.73279,
                    "map_at_1": 0.58789,
                    "map_at_3": 0.66302,
                    "map_at_5": 0.67619,
                    "map_at_10": 0.68865,
                    "recall_at_1": 0.58789,
                    "recall_at_3": 0.74089,
                    "recall_at_5": 0.78817,
                    "recall_at_10": 0.85756,
                    "precision_at_1": 0.61,
                    "precision_at_3": 0.26667,
                    "precision_at_5": 0.17467,
                    "precision_at_10": 0.09667,
                    "mrr_at_1": 0.61,
                    "mrr_at_3": 0.6772222222222222,
                    "mrr_at_5": 0.6878888888888889,
                    "mrr_at_10": 0.6963769841269841,
                    "main_score": 0.73279,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 85.17573499679565,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.39141,
                    "ndcg_at_3": 0.45407,
                    "ndcg_at_5": 0.47096,
                    "ndcg_at_10": 0.48733,
                    "ndcg_at_20": 0.4997,
                    "map_at_1": 0.39109,
                    "map_at_3": 0.43868,
                    "map_at_5": 0.44807,
                    "map_at_10": 0.45485,
                    "map_at_20": 0.45823,
                    "recall_at_1": 0.39109,
                    "recall_at_3": 0.49796,
                    "recall_at_5": 0.53911,
                    "recall_at_10": 0.58955,
                    "recall_at_20": 0.63844,
                    "precision_at_1": 0.39141,
                    "precision_at_3": 0.16617,
                    "precision_at_5": 0.10797,
                    "precision_at_10": 0.05908,
                    "precision_at_20": 0.03201,
                    "mrr_at_1": 0.3914068745003997,
                    "mrr_at_3": 0.4390820676791929,
                    "mrr_at_5": 0.4484865440980599,
                    "mrr_at_10": 0.4553024088665634,
                    "mrr_at_20": 0.4587053542216571,
                    "main_score": 0.48733,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 48.8012318611145,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.36308,
                    "ndcg_at_3": 0.44427,
                    "ndcg_at_5": 0.46833,
                    "ndcg_at_10": 0.49086,
                    "ndcg_at_20": 0.50693,
                    "map_at_1": 0.36305,
                    "map_at_3": 0.42433,
                    "map_at_5": 0.4377,
                    "map_at_10": 0.44702,
                    "map_at_20": 0.45144,
                    "recall_at_1": 0.36305,
                    "recall_at_3": 0.50192,
                    "recall_at_5": 0.56028,
                    "recall_at_10": 0.62977,
                    "recall_at_20": 0.69324,
                    "precision_at_1": 0.36308,
                    "precision_at_3": 0.16734,
                    "precision_at_5": 0.11209,
                    "precision_at_10": 0.063,
                    "precision_at_20": 0.03468,
                    "mrr_at_1": 0.3630822533042474,
                    "mrr_at_3": 0.4243712305915636,
                    "mrr_at_5": 0.437734184524586,
                    "mrr_at_10": 0.44706450793244584,
                    "mrr_at_20": 0.45148733250823864,
                    "main_score": 0.49086,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 53.30297350883484,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.24864,
                    "ndcg_at_3": 0.31061,
                    "ndcg_at_5": 0.3313,
                    "ndcg_at_10": 0.35295,
                    "ndcg_at_20": 0.37024,
                    "map_at_1": 0.24815,
                    "map_at_3": 0.29502,
                    "map_at_5": 0.30654,
                    "map_at_10": 0.31551,
                    "map_at_20": 0.32026,
                    "recall_at_1": 0.24815,
                    "recall_at_3": 0.35497,
                    "recall_at_5": 0.40502,
                    "recall_at_10": 0.47171,
                    "recall_at_20": 0.53999,
                    "precision_at_1": 0.24864,
                    "precision_at_3": 0.11879,
                    "precision_at_5": 0.08146,
                    "precision_at_10": 0.04755,
                    "precision_at_20": 0.02726,
                    "mrr_at_1": 0.24863992796308107,
                    "mrr_at_3": 0.2956765342237853,
                    "mrr_at_5": 0.3072249527882967,
                    "mrr_at_10": 0.31617011754238117,
                    "mrr_at_20": 0.3208829657303109,
                    "main_score": 0.35295,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 63.48255014419556,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.86583,
                    "ndcg_at_3": 0.9042,
                    "ndcg_at_5": 0.91087,
                    "ndcg_at_10": 0.91575,
                    "map_at_1": 0.86583,
                    "map_at_3": 0.89525,
                    "map_at_5": 0.89897,
                    "map_at_10": 0.90099,
                    "recall_at_1": 0.86583,
                    "recall_at_3": 0.92989,
                    "recall_at_5": 0.94603,
                    "recall_at_10": 0.96108,
                    "precision_at_1": 0.86583,
                    "precision_at_3": 0.30997,
                    "precision_at_5": 0.18921,
                    "precision_at_10": 0.09611,
                    "mrr_at_1": 0.8658265051656573,
                    "mrr_at_3": 0.8952544234651462,
                    "mrr_at_5": 0.898970579503623,
                    "mrr_at_10": 0.900990048970545,
                    "main_score": 0.91575,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 41.633241415023804,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.8195,
                    "ndcg_at_3": 0.77144,
                    "ndcg_at_5": 0.76693,
                    "ndcg_at_10": 0.79937,
                    "ndcg_at_20": 0.82015,
                    "map_at_1": 0.22727,
                    "map_at_3": 0.47761,
                    "map_at_5": 0.60746,
                    "map_at_10": 0.70627,
                    "map_at_20": 0.72986,
                    "recall_at_1": 0.22727,
                    "recall_at_3": 0.51019,
                    "recall_at_5": 0.67528,
                    "recall_at_10": 0.8267,
                    "recall_at_20": 0.88777,
                    "precision_at_1": 0.8195,
                    "precision_at_3": 0.69333,
                    "precision_at_5": 0.5935,
                    "precision_at_10": 0.3911,
                    "precision_at_20": 0.2163,
                    "mrr_at_1": 0.8195,
                    "mrr_at_3": 0.8693333333333327,
                    "mrr_at_5": 0.8738583333333327,
                    "mrr_at_10": 0.8758160714285708,
                    "mrr_at_20": 0.8763591891660962,
                    "main_score": 0.79937,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 789.9928405284882,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.85,
                    "ndcg_at_3": 0.81202,
                    "ndcg_at_5": 0.80237,
                    "ndcg_at_10": 0.8316,
                    "ndcg_at_20": 0.85103,
                    "map_at_1": 0.23909,
                    "map_at_3": 0.50894,
                    "map_at_5": 0.64459,
                    "map_at_10": 0.74571,
                    "map_at_20": 0.76957,
                    "recall_at_1": 0.23909,
                    "recall_at_3": 0.5404,
                    "recall_at_5": 0.70511,
                    "recall_at_10": 0.85398,
                    "recall_at_20": 0.91287,
                    "precision_at_1": 0.85,
                    "precision_at_3": 0.73183,
                    "precision_at_5": 0.6191,
                    "precision_at_10": 0.40375,
                    "precision_at_20": 0.22253,
                    "mrr_at_1": 0.85,
                    "mrr_at_3": 0.8943333333333325,
                    "mrr_at_5": 0.8968083333333327,
                    "mrr_at_10": 0.8983968253968246,
                    "mrr_at_20": 0.8989379076182665,
                    "main_score": 0.8316,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2709.705117225647,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.3808,
                    "ndcg_at_3": 0.35378,
                    "ndcg_at_5": 0.32363,
                    "ndcg_at_10": 0.29308,
                    "ndcg_at_20": 0.27376,
                    "map_at_1": 0.04715,
                    "map_at_3": 0.08183,
                    "map_at_5": 0.09156,
                    "map_at_10": 0.10694,
                    "map_at_20": 0.11805,
                    "recall_at_1": 0.04715,
                    "recall_at_3": 0.09234,
                    "recall_at_5": 0.10667,
                    "recall_at_10": 0.13773,
                    "recall_at_20": 0.17448,
                    "precision_at_1": 0.39938,
                    "precision_at_3": 0.33849,
                    "precision_at_5": 0.27864,
                    "precision_at_10": 0.21393,
                    "precision_at_20": 0.15882,
                    "mrr_at_1": 0.4024767801857585,
                    "mrr_at_3": 0.47110423116615074,
                    "mrr_at_5": 0.4816305469556244,
                    "mrr_at_10": 0.4891702294953069,
                    "mrr_at_20": 0.4921530752276519,
                    "main_score": 0.29308,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 69.0573558807373,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.89495,
                    "ndcg_at_3": 0.92921,
                    "ndcg_at_5": 0.93389,
                    "ndcg_at_10": 0.93702,
                    "ndcg_at_20": 0.9386,
                    "map_at_1": 0.89495,
                    "map_at_3": 0.92122,
                    "map_at_5": 0.92383,
                    "map_at_10": 0.92514,
                    "map_at_20": 0.92558,
                    "recall_at_1": 0.89495,
                    "recall_at_3": 0.95215,
                    "recall_at_5": 0.96344,
                    "recall_at_10": 0.97301,
                    "recall_at_20": 0.9792,
                    "precision_at_1": 0.89495,
                    "precision_at_3": 0.31739,
                    "precision_at_5": 0.1927,
                    "precision_at_10": 0.09731,
                    "precision_at_20": 0.04896,
                    "mrr_at_1": 0.8949501246882793,
                    "mrr_at_3": 0.9212311483196755,
                    "mrr_at_5": 0.9238451490321814,
                    "mrr_at_10": 0.9251581752817503,
                    "mrr_at_20": 0.9255986595364633,
                    "main_score": 0.93702,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 66.1805260181427,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.28961,
                    "ndcg_at_3": 0.36248,
                    "ndcg_at_5": 0.3851,
                    "ndcg_at_10": 0.40793,
                    "ndcg_at_20": 0.42499,
                    "map_at_1": 0.28884,
                    "map_at_3": 0.34426,
                    "map_at_5": 0.35687,
                    "map_at_10": 0.36635,
                    "map_at_20": 0.37106,
                    "recall_at_1": 0.28884,
                    "recall_at_3": 0.41424,
                    "recall_at_5": 0.46901,
                    "recall_at_10": 0.53919,
                    "recall_at_20": 0.6064,
                    "precision_at_1": 0.28961,
                    "precision_at_3": 0.13872,
                    "precision_at_5": 0.09432,
                    "precision_at_10": 0.0543,
                    "precision_at_20": 0.03061,
                    "mrr_at_1": 0.2896109255993697,
                    "mrr_at_3": 0.3451018647056598,
                    "mrr_at_5": 0.3576858139796634,
                    "mrr_at_10": 0.36716232247598524,
                    "mrr_at_20": 0.37181326698251566,
                    "main_score": 0.40793,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 120.13767600059509,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.24349,
                    "ndcg_at_3": 0.30448,
                    "ndcg_at_5": 0.32386,
                    "ndcg_at_10": 0.34472,
                    "ndcg_at_20": 0.36126,
                    "map_at_1": 0.24304,
                    "map_at_3": 0.2892,
                    "map_at_5": 0.29998,
                    "map_at_10": 0.3086,
                    "map_at_20": 0.31317,
                    "recall_at_1": 0.24304,
                    "recall_at_3": 0.34806,
                    "recall_at_5": 0.39508,
                    "recall_at_10": 0.4593,
                    "recall_at_20": 0.52443,
                    "precision_at_1": 0.24349,
                    "precision_at_3": 0.11638,
                    "precision_at_5": 0.07936,
                    "precision_at_10": 0.04624,
                    "precision_at_20": 0.02647,
                    "mrr_at_1": 0.24348772614668568,
                    "mrr_at_3": 0.28976803543277063,
                    "mrr_at_5": 0.3005423766984386,
                    "mrr_at_10": 0.30917726873548135,
                    "mrr_at_20": 0.3136819742536568,
                    "main_score": 0.34472,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 45.435654640197754,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.34034,
                    "ndcg_at_3": 0.34354,
                    "ndcg_at_5": 0.36077,
                    "ndcg_at_10": 0.3891,
                    "ndcg_at_20": 0.41634,
                    "map_at_1": 0.21896,
                    "map_at_3": 0.29091,
                    "map_at_5": 0.31019,
                    "map_at_10": 0.32698,
                    "map_at_20": 0.33674,
                    "recall_at_1": 0.21896,
                    "recall_at_3": 0.34316,
                    "recall_at_5": 0.3993,
                    "recall_at_10": 0.48249,
                    "recall_at_20": 0.57489,
                    "precision_at_1": 0.34034,
                    "precision_at_3": 0.19572,
                    "precision_at_5": 0.14124,
                    "precision_at_10": 0.0877,
                    "precision_at_20": 0.0529,
                    "mrr_at_1": 0.34033508377094274,
                    "mrr_at_3": 0.3947236809202296,
                    "mrr_at_5": 0.40675168792198063,
                    "mrr_at_10": 0.41715657088875324,
                    "mrr_at_20": 0.42307231718421434,
                    "main_score": 0.3891,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 439.5478835105896,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.89517,
                    "ndcg_at_3": 0.92934,
                    "ndcg_at_5": 0.93396,
                    "ndcg_at_10": 0.93708,
                    "ndcg_at_20": 0.93873,
                    "map_at_1": 0.89517,
                    "map_at_3": 0.92135,
                    "map_at_5": 0.92393,
                    "map_at_10": 0.92523,
                    "map_at_20": 0.92569,
                    "recall_at_1": 0.89517,
                    "recall_at_3": 0.95228,
                    "recall_at_5": 0.96344,
                    "recall_at_10": 0.97297,
                    "recall_at_20": 0.97947,
                    "precision_at_1": 0.89517,
                    "precision_at_3": 0.31744,
                    "precision_at_5": 0.1927,
                    "precision_at_10": 0.0973,
                    "precision_at_20": 0.04898,
                    "mrr_at_1": 0.8951727823298896,
                    "mrr_at_3": 0.9213573209832544,
                    "mrr_at_5": 0.9239446027787671,
                    "mrr_at_10": 0.9252475210782566,
                    "mrr_at_20": 0.9257077339816162,
                    "main_score": 0.93708,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 78.04351854324341,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.34877,
                    "ndcg_at_3": 0.30941,
                    "ndcg_at_5": 0.32097,
                    "ndcg_at_10": 0.35342,
                    "ndcg_at_20": 0.38066,
                    "map_at_1": 0.16835,
                    "map_at_3": 0.23256,
                    "map_at_5": 0.25263,
                    "map_at_10": 0.27463,
                    "map_at_20": 0.28506,
                    "recall_at_1": 0.16835,
                    "recall_at_3": 0.27479,
                    "recall_at_5": 0.33006,
                    "recall_at_10": 0.42729,
                    "recall_at_20": 0.51047,
                    "precision_at_1": 0.34877,
                    "precision_at_3": 0.2073,
                    "precision_at_5": 0.15432,
                    "precision_at_10": 0.10139,
                    "precision_at_20": 0.06188,
                    "mrr_at_1": 0.3487654320987654,
                    "mrr_at_3": 0.410493827160494,
                    "mrr_at_5": 0.42283950617283944,
                    "mrr_at_10": 0.43581349206349185,
                    "mrr_at_20": 0.4410288451446288,
                    "main_score": 0.35342,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 780.8392379283905,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.86525,
                    "ndcg_at_3": 0.82295,
                    "ndcg_at_5": 0.8073,
                    "ndcg_at_10": 0.80721,
                    "ndcg_at_20": 0.82695,
                    "map_at_1": 0.25784,
                    "map_at_3": 0.50811,
                    "map_at_5": 0.62451,
                    "map_at_10": 0.72397,
                    "map_at_20": 0.75202,
                    "recall_at_1": 0.25784,
                    "recall_at_3": 0.52757,
                    "recall_at_5": 0.66334,
                    "recall_at_10": 0.79772,
                    "recall_at_20": 0.86202,
                    "precision_at_1": 0.86525,
                    "precision_at_3": 0.72243,
                    "precision_at_5": 0.60501,
                    "precision_at_10": 0.40432,
                    "precision_at_20": 0.22628,
                    "mrr_at_1": 0.8652463615640891,
                    "mrr_at_3": 0.8923227541060246,
                    "mrr_at_5": 0.8958713250336089,
                    "mrr_at_10": 0.8978618535496509,
                    "mrr_at_20": 0.8986152717692967,
                    "main_score": 0.80721,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2271.615082502365,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.4733,
                    "ndcg_at_3": 0.54026,
                    "ndcg_at_5": 0.55672,
                    "ndcg_at_10": 0.57315,
                    "ndcg_at_20": 0.58601,
                    "map_at_1": 0.47323,
                    "map_at_3": 0.52398,
                    "map_at_5": 0.53311,
                    "map_at_10": 0.53991,
                    "map_at_20": 0.54343,
                    "recall_at_1": 0.47323,
                    "recall_at_3": 0.58694,
                    "recall_at_5": 0.627,
                    "recall_at_10": 0.67764,
                    "recall_at_20": 0.72848,
                    "precision_at_1": 0.4733,
                    "precision_at_3": 0.1958,
                    "precision_at_5": 0.12552,
                    "precision_at_10": 0.06785,
                    "precision_at_20": 0.03648,
                    "mrr_at_1": 0.47330135891286973,
                    "mrr_at_3": 0.5242006394884141,
                    "mrr_at_5": 0.5333573141486899,
                    "mrr_at_10": 0.540188848920872,
                    "mrr_at_20": 0.5437183844230251,
                    "main_score": 0.57315,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 79.37800335884094,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.45694,
                    "ndcg_at_3": 0.52101,
                    "ndcg_at_5": 0.53749,
                    "ndcg_at_10": 0.55434,
                    "ndcg_at_20": 0.56642,
                    "map_at_1": 0.45676,
                    "map_at_3": 0.50549,
                    "map_at_5": 0.51466,
                    "map_at_10": 0.52166,
                    "map_at_20": 0.52498,
                    "recall_at_1": 0.45676,
                    "recall_at_3": 0.56555,
                    "recall_at_5": 0.60553,
                    "recall_at_10": 0.65735,
                    "recall_at_20": 0.70498,
                    "precision_at_1": 0.45694,
                    "precision_at_3": 0.18862,
                    "precision_at_5": 0.12121,
                    "precision_at_10": 0.06581,
                    "precision_at_20": 0.0353,
                    "mrr_at_1": 0.45693751247754044,
                    "mrr_at_3": 0.5056897584348218,
                    "mrr_at_5": 0.5148572569375199,
                    "mrr_at_10": 0.521876289345851,
                    "mrr_at_20": 0.5252176415631017,
                    "main_score": 0.55434,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 90.84023022651672,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.556,
                    "ndcg_at_3": 0.6687,
                    "ndcg_at_5": 0.69004,
                    "ndcg_at_10": 0.70393,
                    "map_at_1": 0.556,
                    "map_at_3": 0.64217,
                    "map_at_5": 0.65397,
                    "map_at_10": 0.65987,
                    "recall_at_1": 0.556,
                    "recall_at_3": 0.745,
                    "recall_at_5": 0.797,
                    "recall_at_10": 0.839,
                    "precision_at_1": 0.556,
                    "precision_at_3": 0.24833,
                    "precision_at_5": 0.1594,
                    "precision_at_10": 0.0839,
                    "mrr_at_1": 0.556,
                    "mrr_at_3": 0.6421666666666668,
                    "mrr_at_5": 0.6539666666666667,
                    "mrr_at_10": 0.6598698412698414,
                    "main_score": 0.70393,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 174.36455702781677,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "2e643e7363944af1c33a652d1c87320d0871c4e4",
        "task_name": "NarrativeQAChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.66828,
                    "ndcg_at_3": 0.73383,
                    "ndcg_at_5": 0.7482,
                    "ndcg_at_10": 0.75956,
                    "ndcg_at_20": 0.76717,
                    "map_at_1": 0.66828,
                    "map_at_3": 0.71818,
                    "map_at_5": 0.72618,
                    "map_at_10": 0.73087,
                    "map_at_20": 0.73296,
                    "recall_at_1": 0.66828,
                    "recall_at_3": 0.77891,
                    "recall_at_5": 0.81368,
                    "recall_at_10": 0.84882,
                    "recall_at_20": 0.87894,
                    "precision_at_1": 0.66828,
                    "precision_at_3": 0.25964,
                    "precision_at_5": 0.16274,
                    "precision_at_10": 0.08488,
                    "precision_at_20": 0.04395,
                    "mrr_at_1": 0.6682769726247987,
                    "mrr_at_3": 0.7181806700135736,
                    "mrr_at_5": 0.7261848378642871,
                    "mrr_at_10": 0.7308719032433125,
                    "mrr_at_20": 0.7329589236089026,
                    "main_score": 0.75956,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 2085.6420505046844,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.89664,
                    "ndcg_at_3": 0.9302,
                    "ndcg_at_5": 0.93478,
                    "ndcg_at_10": 0.93786,
                    "map_at_1": 0.89664,
                    "map_at_3": 0.92235,
                    "map_at_5": 0.92489,
                    "map_at_10": 0.92618,
                    "recall_at_1": 0.89664,
                    "recall_at_3": 0.95273,
                    "recall_at_5": 0.96384,
                    "recall_at_10": 0.97328,
                    "precision_at_1": 0.89664,
                    "precision_at_3": 0.31758,
                    "precision_at_5": 0.19278,
                    "precision_at_10": 0.09733,
                    "mrr_at_1": 0.8966423227645173,
                    "mrr_at_3": 0.922359280370501,
                    "mrr_at_5": 0.9249064837905242,
                    "mrr_at_10": 0.9261920842734442,
                    "main_score": 0.93786,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 83.27353954315186,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.19915,
                    "ndcg_at_3": 0.31566,
                    "ndcg_at_5": 0.36551,
                    "ndcg_at_10": 0.43593,
                    "map_at_1": 0.19915,
                    "map_at_3": 0.2858,
                    "map_at_5": 0.31332,
                    "map_at_10": 0.34267,
                    "recall_at_1": 0.19915,
                    "recall_at_3": 0.40256,
                    "recall_at_5": 0.52418,
                    "recall_at_10": 0.7404,
                    "precision_at_1": 0.19915,
                    "precision_at_3": 0.13419,
                    "precision_at_5": 0.10484,
                    "precision_at_10": 0.07404,
                    "mrr_at_1": 0.2019914651493599,
                    "mrr_at_3": 0.28710289236604974,
                    "mrr_at_5": 0.31452110004741485,
                    "mrr_at_10": 0.34401205716995154,
                    "main_score": 0.43593,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 56.644696950912476,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.36728,
                    "ndcg_at_3": 0.44574,
                    "ndcg_at_5": 0.46673,
                    "ndcg_at_10": 0.48775,
                    "ndcg_at_20": 0.50264,
                    "map_at_1": 0.36669,
                    "map_at_3": 0.42631,
                    "map_at_5": 0.43798,
                    "map_at_10": 0.44674,
                    "map_at_20": 0.45086,
                    "recall_at_1": 0.36669,
                    "recall_at_3": 0.50121,
                    "recall_at_5": 0.55206,
                    "recall_at_10": 0.61647,
                    "recall_at_20": 0.67487,
                    "precision_at_1": 0.36728,
                    "precision_at_3": 0.16754,
                    "precision_at_5": 0.11084,
                    "precision_at_10": 0.06201,
                    "precision_at_20": 0.03402,
                    "mrr_at_1": 0.36727723143908114,
                    "mrr_at_3": 0.4270074819207797,
                    "mrr_at_5": 0.4386845331932101,
                    "mrr_at_10": 0.44739674377371136,
                    "mrr_at_20": 0.4515003504385654,
                    "main_score": 0.48775,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 136.00702095031738,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "e4e08e0b7dbe3c8700f0daef558ff32256715259",
        "task_name": "QuoraChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.8158,
                    "ndcg_at_3": 0.85579,
                    "ndcg_at_5": 0.87212,
                    "ndcg_at_10": 0.88478,
                    "ndcg_at_20": 0.89126,
                    "map_at_1": 0.70839,
                    "map_at_3": 0.81765,
                    "map_at_5": 0.83669,
                    "map_at_10": 0.84755,
                    "map_at_20": 0.85176,
                    "recall_at_1": 0.70839,
                    "recall_at_3": 0.87229,
                    "recall_at_5": 0.91815,
                    "recall_at_10": 0.95528,
                    "recall_at_20": 0.97576,
                    "precision_at_1": 0.8158,
                    "precision_at_3": 0.3739,
                    "precision_at_5": 0.2466,
                    "precision_at_10": 0.13443,
                    "precision_at_20": 0.07139,
                    "mrr_at_1": 0.8153,
                    "mrr_at_3": 0.8668333333333309,
                    "mrr_at_5": 0.8735383333333302,
                    "mrr_at_10": 0.8767088095238074,
                    "mrr_at_20": 0.87737925180899,
                    "main_score": 0.88478,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 194.49078822135925,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "e4e08e0b7dbe3c8700f0daef558ff32256715259",
        "task_name": "QuoraChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.7826,
                    "ndcg_at_3": 0.82767,
                    "ndcg_at_5": 0.84529,
                    "ndcg_at_10": 0.86037,
                    "ndcg_at_20": 0.86813,
                    "map_at_1": 0.67849,
                    "map_at_3": 0.78768,
                    "map_at_5": 0.80702,
                    "map_at_10": 0.81873,
                    "map_at_20": 0.82326,
                    "recall_at_1": 0.67849,
                    "recall_at_3": 0.84922,
                    "recall_at_5": 0.89812,
                    "recall_at_10": 0.9421,
                    "recall_at_20": 0.96712,
                    "precision_at_1": 0.7826,
                    "precision_at_3": 0.36313,
                    "precision_at_5": 0.24006,
                    "precision_at_10": 0.13197,
                    "precision_at_20": 0.07036,
                    "mrr_at_1": 0.7825,
                    "mrr_at_3": 0.8391999999999962,
                    "mrr_at_5": 0.846729999999995,
                    "mrr_at_10": 0.8506039285714251,
                    "mrr_at_20": 0.8516034458468049,
                    "main_score": 0.86037,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 621.2573220729828,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.56,
                    "ndcg_at_3": 0.67041,
                    "ndcg_at_5": 0.69309,
                    "ndcg_at_10": 0.70698,
                    "ndcg_at_20": 0.71839,
                    "map_at_1": 0.56,
                    "map_at_3": 0.64417,
                    "map_at_5": 0.65677,
                    "map_at_10": 0.66268,
                    "map_at_20": 0.66583,
                    "recall_at_1": 0.56,
                    "recall_at_3": 0.746,
                    "recall_at_5": 0.801,
                    "recall_at_10": 0.843,
                    "recall_at_20": 0.888,
                    "precision_at_1": 0.56,
                    "precision_at_3": 0.24867,
                    "precision_at_5": 0.1602,
                    "precision_at_10": 0.0843,
                    "precision_at_20": 0.0444,
                    "mrr_at_1": 0.56,
                    "mrr_at_3": 0.6441666666666668,
                    "mrr_at_5": 0.6567666666666668,
                    "mrr_at_10": 0.662677777777778,
                    "mrr_at_20": 0.665827948844241,
                    "main_score": 0.70698,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 157.092360496521,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.69155,
                    "ndcg_at_3": 0.76007,
                    "ndcg_at_5": 0.77997,
                    "ndcg_at_10": 0.79664,
                    "ndcg_at_20": 0.80341,
                    "map_at_1": 0.66858,
                    "map_at_3": 0.74024,
                    "map_at_5": 0.75212,
                    "map_at_10": 0.75938,
                    "map_at_20": 0.76141,
                    "recall_at_1": 0.66858,
                    "recall_at_3": 0.80889,
                    "recall_at_5": 0.85622,
                    "recall_at_10": 0.90623,
                    "recall_at_20": 0.93212,
                    "precision_at_1": 0.69155,
                    "precision_at_3": 0.28534,
                    "precision_at_5": 0.18178,
                    "precision_at_10": 0.09629,
                    "precision_at_20": 0.04958,
                    "mrr_at_1": 0.6915472779369628,
                    "mrr_at_3": 0.7484001910219675,
                    "mrr_at_5": 0.7585721107927387,
                    "mrr_at_10": 0.7652679992722968,
                    "mrr_at_20": 0.7670108767165141,
                    "main_score": 0.79664,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 679.787519454956,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.8625,
                    "ndcg_at_3": 0.81663,
                    "ndcg_at_5": 0.81224,
                    "ndcg_at_10": 0.83879,
                    "map_at_1": 0.24328,
                    "map_at_3": 0.51264,
                    "map_at_5": 0.65482,
                    "map_at_10": 0.75493,
                    "recall_at_1": 0.24328,
                    "recall_at_3": 0.54174,
                    "recall_at_5": 0.71626,
                    "recall_at_10": 0.86144,
                    "precision_at_1": 0.8625,
                    "precision_at_3": 0.7345,
                    "precision_at_5": 0.6283,
                    "precision_at_10": 0.4067,
                    "mrr_at_1": 0.8625,
                    "mrr_at_3": 0.901583333333333,
                    "mrr_at_5": 0.9044833333333329,
                    "mrr_at_10": 0.9060426587301583,
                    "main_score": 0.83879,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 885.3971171379089,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.67249,
                    "ndcg_at_3": 0.74342,
                    "ndcg_at_5": 0.76278,
                    "ndcg_at_10": 0.77963,
                    "ndcg_at_20": 0.78816,
                    "map_at_1": 0.65054,
                    "map_at_3": 0.72269,
                    "map_at_5": 0.7341,
                    "map_at_10": 0.74156,
                    "map_at_20": 0.74406,
                    "recall_at_1": 0.65054,
                    "recall_at_3": 0.79454,
                    "recall_at_5": 0.8406,
                    "recall_at_10": 0.89113,
                    "recall_at_20": 0.92387,
                    "precision_at_1": 0.67249,
                    "precision_at_3": 0.27956,
                    "precision_at_5": 0.17817,
                    "precision_at_10": 0.09466,
                    "precision_at_20": 0.04915,
                    "mrr_at_1": 0.6724928366762177,
                    "mrr_at_3": 0.7313514804202483,
                    "mrr_at_5": 0.7413514804202456,
                    "mrr_at_10": 0.7478446354664099,
                    "mrr_at_20": 0.7500416546085089,
                    "main_score": 0.77963,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 181.11002826690674,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.28521,
                    "ndcg_at_3": 0.43921,
                    "ndcg_at_5": 0.49382,
                    "ndcg_at_10": 0.53956,
                    "ndcg_at_20": 0.56558,
                    "map_at_1": 0.28521,
                    "map_at_3": 0.40126,
                    "map_at_5": 0.4318,
                    "map_at_10": 0.45092,
                    "map_at_20": 0.45823,
                    "recall_at_1": 0.28521,
                    "recall_at_3": 0.54908,
                    "recall_at_5": 0.68065,
                    "recall_at_10": 0.82077,
                    "recall_at_20": 0.92248,
                    "precision_at_1": 0.28521,
                    "precision_at_3": 0.18303,
                    "precision_at_5": 0.13613,
                    "precision_at_10": 0.08208,
                    "precision_at_20": 0.04612,
                    "mrr_at_1": 0.2972972972972973,
                    "mrr_at_3": 0.4067093409198675,
                    "mrr_at_5": 0.4361190137505933,
                    "mrr_at_10": 0.4554299600352236,
                    "mrr_at_20": 0.46266640807540327,
                    "main_score": 0.53956,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 92.13975882530212,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.37415,
                    "ndcg_at_3": 0.46015,
                    "ndcg_at_5": 0.4823,
                    "ndcg_at_10": 0.50282,
                    "ndcg_at_20": 0.5171,
                    "map_at_1": 0.37337,
                    "map_at_3": 0.43891,
                    "map_at_5": 0.45127,
                    "map_at_10": 0.45984,
                    "map_at_20": 0.46378,
                    "recall_at_1": 0.37337,
                    "recall_at_3": 0.52052,
                    "recall_at_5": 0.57412,
                    "recall_at_10": 0.63705,
                    "recall_at_20": 0.6931,
                    "precision_at_1": 0.37415,
                    "precision_at_3": 0.17414,
                    "precision_at_5": 0.11535,
                    "precision_at_10": 0.06409,
                    "precision_at_20": 0.03494,
                    "mrr_at_1": 0.3741460851287441,
                    "mrr_at_3": 0.43978805394990783,
                    "mrr_at_5": 0.4520806746240353,
                    "mrr_at_10": 0.46059484487437374,
                    "mrr_at_20": 0.4645299757400808,
                    "main_score": 0.50282,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 95.2762622833252,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.34259,
                    "ndcg_at_3": 0.34619,
                    "ndcg_at_5": 0.36237,
                    "ndcg_at_10": 0.39136,
                    "ndcg_at_20": 0.41866,
                    "map_at_1": 0.22072,
                    "map_at_3": 0.29344,
                    "map_at_5": 0.31207,
                    "map_at_10": 0.32917,
                    "map_at_20": 0.339,
                    "recall_at_1": 0.22072,
                    "recall_at_3": 0.34589,
                    "recall_at_5": 0.39997,
                    "recall_at_10": 0.48488,
                    "recall_at_20": 0.57751,
                    "precision_at_1": 0.34259,
                    "precision_at_3": 0.19713,
                    "precision_at_5": 0.14144,
                    "precision_at_10": 0.08807,
                    "precision_at_20": 0.0531,
                    "mrr_at_1": 0.3425856464116029,
                    "mrr_at_3": 0.3970992748187042,
                    "mrr_at_5": 0.40881470367591904,
                    "mrr_at_10": 0.41947619841468214,
                    "mrr_at_20": 0.42530245672872286,
                    "main_score": 0.39136,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 717.1196811199188,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.30341,
                    "ndcg_at_3": 0.28213,
                    "ndcg_at_5": 0.26107,
                    "ndcg_at_10": 0.24009,
                    "map_at_1": 0.04125,
                    "map_at_3": 0.0639,
                    "map_at_5": 0.07408,
                    "map_at_10": 0.08801,
                    "recall_at_1": 0.04125,
                    "recall_at_3": 0.07216,
                    "recall_at_5": 0.08962,
                    "recall_at_10": 0.12653,
                    "precision_at_1": 0.31269,
                    "precision_at_3": 0.26832,
                    "precision_at_5": 0.22477,
                    "precision_at_10": 0.17307,
                    "mrr_at_1": 0.3126934984520124,
                    "mrr_at_3": 0.3890608875128998,
                    "mrr_at_5": 0.40098039215686276,
                    "mrr_at_10": 0.40984077841663,
                    "main_score": 0.24009,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 19.375033855438232,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.54526,
                    "ndcg_at_3": 0.60604,
                    "ndcg_at_5": 0.62214,
                    "ndcg_at_10": 0.63778,
                    "ndcg_at_20": 0.64922,
                    "map_at_1": 0.54513,
                    "map_at_3": 0.5913,
                    "map_at_5": 0.60025,
                    "map_at_10": 0.60672,
                    "map_at_20": 0.60986,
                    "recall_at_1": 0.54513,
                    "recall_at_3": 0.64831,
                    "recall_at_5": 0.68741,
                    "recall_at_10": 0.73569,
                    "recall_at_20": 0.78087,
                    "precision_at_1": 0.54526,
                    "precision_at_3": 0.21621,
                    "precision_at_5": 0.13757,
                    "precision_at_10": 0.07363,
                    "precision_at_20": 0.03909,
                    "mrr_at_1": 0.5452585346376523,
                    "mrr_at_3": 0.5915019631330336,
                    "mrr_at_5": 0.6004518533306825,
                    "mrr_at_10": 0.6069329017292786,
                    "mrr_at_20": 0.6100928566267173,
                    "main_score": 0.63778,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 117.96674227714539,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.69125,
                    "ndcg_at_3": 0.77709,
                    "ndcg_at_5": 0.79392,
                    "ndcg_at_10": 0.81199,
                    "ndcg_at_20": 0.81803,
                    "map_at_1": 0.68862,
                    "map_at_3": 0.7565,
                    "map_at_5": 0.76599,
                    "map_at_10": 0.77379,
                    "map_at_20": 0.77553,
                    "recall_at_1": 0.68862,
                    "recall_at_3": 0.83562,
                    "recall_at_5": 0.87566,
                    "recall_at_10": 0.93045,
                    "recall_at_20": 0.95364,
                    "precision_at_1": 0.69125,
                    "precision_at_3": 0.2803,
                    "precision_at_5": 0.17661,
                    "precision_at_10": 0.09399,
                    "precision_at_20": 0.04816,
                    "mrr_at_1": 0.6912539515279241,
                    "mrr_at_3": 0.7572883737267301,
                    "mrr_at_5": 0.7666666666666669,
                    "mrr_at_10": 0.774058323715858,
                    "mrr_at_20": 0.7757985086395799,
                    "main_score": 0.81199,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 393.2765882015228,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "2e643e7363944af1c33a652d1c87320d0871c4e4",
        "task_name": "NarrativeQAChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.61097,
                    "ndcg_at_3": 0.68448,
                    "ndcg_at_5": 0.70025,
                    "ndcg_at_10": 0.71417,
                    "ndcg_at_20": 0.72439,
                    "map_at_1": 0.61097,
                    "map_at_3": 0.66687,
                    "map_at_5": 0.67561,
                    "map_at_10": 0.68139,
                    "map_at_20": 0.68422,
                    "recall_at_1": 0.61097,
                    "recall_at_3": 0.73525,
                    "recall_at_5": 0.77361,
                    "recall_at_10": 0.81643,
                    "recall_at_20": 0.85668,
                    "precision_at_1": 0.61097,
                    "precision_at_3": 0.24508,
                    "precision_at_5": 0.15472,
                    "precision_at_10": 0.08164,
                    "precision_at_20": 0.04283,
                    "mrr_at_1": 0.610969025291276,
                    "mrr_at_3": 0.6668719017397584,
                    "mrr_at_5": 0.6756054434656251,
                    "mrr_at_10": 0.6813939746591041,
                    "mrr_at_20": 0.6842244540548689,
                    "main_score": 0.71417,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 2532.752739906311,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.556,
                    "ndcg_at_3": 0.66831,
                    "ndcg_at_5": 0.69012,
                    "ndcg_at_10": 0.7043,
                    "ndcg_at_20": 0.71591,
                    "map_at_1": 0.556,
                    "map_at_3": 0.64167,
                    "map_at_5": 0.65377,
                    "map_at_10": 0.65978,
                    "map_at_20": 0.66295,
                    "recall_at_1": 0.556,
                    "recall_at_3": 0.745,
                    "recall_at_5": 0.798,
                    "recall_at_10": 0.841,
                    "recall_at_20": 0.887,
                    "precision_at_1": 0.556,
                    "precision_at_3": 0.24833,
                    "precision_at_5": 0.1596,
                    "precision_at_10": 0.0841,
                    "precision_at_20": 0.04435,
                    "mrr_at_1": 0.555,
                    "mrr_at_3": 0.6411666666666667,
                    "mrr_at_5": 0.6532666666666668,
                    "mrr_at_10": 0.6592757936507936,
                    "mrr_at_20": 0.6624521463572545,
                    "main_score": 0.7043,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 177.53019642829895,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.871,
                    "ndcg_at_3": 0.83079,
                    "ndcg_at_5": 0.8188,
                    "ndcg_at_10": 0.84209,
                    "ndcg_at_20": 0.85844,
                    "map_at_1": 0.2479,
                    "map_at_3": 0.52585,
                    "map_at_5": 0.66247,
                    "map_at_10": 0.75968,
                    "map_at_20": 0.78126,
                    "recall_at_1": 0.2479,
                    "recall_at_3": 0.55345,
                    "recall_at_5": 0.71812,
                    "recall_at_10": 0.85742,
                    "recall_at_20": 0.90904,
                    "precision_at_1": 0.871,
                    "precision_at_3": 0.7465,
                    "precision_at_5": 0.6287,
                    "precision_at_10": 0.40505,
                    "precision_at_20": 0.22133,
                    "mrr_at_1": 0.871,
                    "mrr_at_3": 0.9089166666666665,
                    "mrr_at_5": 0.9115416666666665,
                    "mrr_at_10": 0.912674007936508,
                    "mrr_at_20": 0.913122984398642,
                    "main_score": 0.84209,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 293.57323265075684,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.52056,
                    "ndcg_at_3": 0.60497,
                    "ndcg_at_5": 0.62632,
                    "ndcg_at_10": 0.64583,
                    "ndcg_at_20": 0.65858,
                    "map_at_1": 0.52049,
                    "map_at_3": 0.58446,
                    "map_at_5": 0.59633,
                    "map_at_10": 0.60447,
                    "map_at_20": 0.60799,
                    "recall_at_1": 0.52049,
                    "recall_at_3": 0.66412,
                    "recall_at_5": 0.71587,
                    "recall_at_10": 0.77573,
                    "recall_at_20": 0.82596,
                    "precision_at_1": 0.52056,
                    "precision_at_3": 0.22142,
                    "precision_at_5": 0.14322,
                    "precision_at_10": 0.07761,
                    "precision_at_20": 0.04133,
                    "mrr_at_1": 0.5205633260618504,
                    "mrr_at_3": 0.5845202959921346,
                    "mrr_at_5": 0.5964011506052556,
                    "mrr_at_10": 0.6045449187203116,
                    "mrr_at_20": 0.6080701862178031,
                    "main_score": 0.64583,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 91.19751834869385,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.27882,
                    "ndcg_at_3": 0.28205,
                    "ndcg_at_5": 0.29727,
                    "ndcg_at_10": 0.32166,
                    "map_at_1": 0.17538,
                    "map_at_3": 0.23514,
                    "map_at_5": 0.25059,
                    "map_at_10": 0.26473,
                    "recall_at_1": 0.17538,
                    "recall_at_3": 0.28253,
                    "recall_at_5": 0.33268,
                    "recall_at_10": 0.40503,
                    "precision_at_1": 0.27882,
                    "precision_at_3": 0.16212,
                    "precision_at_5": 0.11708,
                    "precision_at_10": 0.07342,
                    "mrr_at_1": 0.27881970492623154,
                    "mrr_at_3": 0.32945736434108486,
                    "mrr_at_5": 0.342135533883471,
                    "mrr_at_10": 0.35133059058415367,
                    "main_score": 0.32166,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1014.4705333709717,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.59796,
                    "ndcg_at_3": 0.65328,
                    "ndcg_at_5": 0.6677,
                    "ndcg_at_10": 0.68204,
                    "ndcg_at_20": 0.69191,
                    "map_at_1": 0.59788,
                    "map_at_3": 0.63984,
                    "map_at_5": 0.64783,
                    "map_at_10": 0.65377,
                    "map_at_20": 0.65649,
                    "recall_at_1": 0.59788,
                    "recall_at_3": 0.69199,
                    "recall_at_5": 0.72703,
                    "recall_at_10": 0.77127,
                    "recall_at_20": 0.8102,
                    "precision_at_1": 0.59796,
                    "precision_at_3": 0.23071,
                    "precision_at_5": 0.14544,
                    "precision_at_10": 0.07715,
                    "precision_at_20": 0.04053,
                    "mrr_at_1": 0.5978816946442845,
                    "mrr_at_3": 0.6399080735411745,
                    "mrr_at_5": 0.647905675459644,
                    "mrr_at_10": 0.6538475885957997,
                    "mrr_at_20": 0.6565709080225048,
                    "main_score": 0.68204,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 79.31380009651184,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.45156,
                    "ndcg_at_3": 0.53179,
                    "ndcg_at_5": 0.55486,
                    "ndcg_at_10": 0.57646,
                    "ndcg_at_20": 0.5914,
                    "map_at_1": 0.4513,
                    "map_at_3": 0.51206,
                    "map_at_5": 0.52487,
                    "map_at_10": 0.53383,
                    "map_at_20": 0.53797,
                    "recall_at_1": 0.4513,
                    "recall_at_3": 0.58861,
                    "recall_at_5": 0.6446,
                    "recall_at_10": 0.71121,
                    "recall_at_20": 0.77002,
                    "precision_at_1": 0.45156,
                    "precision_at_3": 0.19637,
                    "precision_at_5": 0.12903,
                    "precision_at_10": 0.07119,
                    "precision_at_20": 0.03854,
                    "mrr_at_1": 0.45155909149236495,
                    "mrr_at_3": 0.512259934128931,
                    "mrr_at_5": 0.5250743188331601,
                    "mrr_at_10": 0.5340335063620542,
                    "mrr_at_20": 0.5381630913206237,
                    "main_score": 0.57646,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 46.16843390464783,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.24864,
                    "ndcg_at_3": 0.31061,
                    "ndcg_at_5": 0.3313,
                    "ndcg_at_10": 0.35295,
                    "ndcg_at_20": 0.37024,
                    "map_at_1": 0.24815,
                    "map_at_3": 0.29502,
                    "map_at_5": 0.30654,
                    "map_at_10": 0.31551,
                    "map_at_20": 0.32026,
                    "recall_at_1": 0.24815,
                    "recall_at_3": 0.35497,
                    "recall_at_5": 0.40502,
                    "recall_at_10": 0.47171,
                    "recall_at_20": 0.53999,
                    "precision_at_1": 0.24864,
                    "precision_at_3": 0.11879,
                    "precision_at_5": 0.08146,
                    "precision_at_10": 0.04755,
                    "precision_at_20": 0.02726,
                    "mrr_at_1": 0.24863992796308107,
                    "mrr_at_3": 0.2956765342237853,
                    "mrr_at_5": 0.3072249527882967,
                    "mrr_at_10": 0.31617011754238117,
                    "mrr_at_20": 0.3208829657303109,
                    "main_score": 0.35295,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 63.42735409736633,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.439,
                    "ndcg_at_3": 0.53072,
                    "ndcg_at_5": 0.55284,
                    "ndcg_at_10": 0.58424,
                    "ndcg_at_20": 0.59902,
                    "map_at_1": 0.439,
                    "map_at_3": 0.50817,
                    "map_at_5": 0.52037,
                    "map_at_10": 0.53334,
                    "map_at_20": 0.53746,
                    "recall_at_1": 0.439,
                    "recall_at_3": 0.596,
                    "recall_at_5": 0.65,
                    "recall_at_10": 0.747,
                    "recall_at_20": 0.805,
                    "precision_at_1": 0.439,
                    "precision_at_3": 0.19867,
                    "precision_at_5": 0.13,
                    "precision_at_10": 0.0747,
                    "precision_at_20": 0.04025,
                    "mrr_at_1": 0.439,
                    "mrr_at_3": 0.5081666666666662,
                    "mrr_at_5": 0.5203666666666661,
                    "mrr_at_10": 0.533342857142857,
                    "mrr_at_20": 0.537459959175671,
                    "main_score": 0.58424,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 103.81105852127075,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.25036,
                    "ndcg_at_3": 0.4056,
                    "ndcg_at_5": 0.45993,
                    "ndcg_at_10": 0.51093,
                    "ndcg_at_20": 0.53921,
                    "map_at_1": 0.25036,
                    "map_at_3": 0.36712,
                    "map_at_5": 0.39752,
                    "map_at_10": 0.41866,
                    "map_at_20": 0.42655,
                    "recall_at_1": 0.25036,
                    "recall_at_3": 0.51707,
                    "recall_at_5": 0.64794,
                    "recall_at_10": 0.80512,
                    "recall_at_20": 0.91607,
                    "precision_at_1": 0.25036,
                    "precision_at_3": 0.17236,
                    "precision_at_5": 0.12959,
                    "precision_at_10": 0.08051,
                    "precision_at_20": 0.0458,
                    "mrr_at_1": 0.2553342816500711,
                    "mrr_at_3": 0.3690137505926974,
                    "mrr_at_5": 0.3994547178757706,
                    "mrr_at_10": 0.42033772494298866,
                    "mrr_at_20": 0.42835854591191097,
                    "main_score": 0.51093,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 79.08025789260864,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.66844,
                    "ndcg_at_3": 0.74031,
                    "ndcg_at_5": 0.7528,
                    "ndcg_at_10": 0.76458,
                    "ndcg_at_20": 0.77207,
                    "map_at_1": 0.66808,
                    "map_at_3": 0.72343,
                    "map_at_5": 0.73038,
                    "map_at_10": 0.73527,
                    "map_at_20": 0.73734,
                    "recall_at_1": 0.66808,
                    "recall_at_3": 0.78873,
                    "recall_at_5": 0.81892,
                    "recall_at_10": 0.85517,
                    "recall_at_20": 0.88473,
                    "precision_at_1": 0.66844,
                    "precision_at_3": 0.2632,
                    "precision_at_5": 0.16399,
                    "precision_at_10": 0.08566,
                    "precision_at_20": 0.04432,
                    "mrr_at_1": 0.6684380504991192,
                    "mrr_at_3": 0.723536895674292,
                    "mrr_at_5": 0.7304849285574444,
                    "mrr_at_10": 0.735349068870059,
                    "mrr_at_20": 0.7374049332333997,
                    "main_score": 0.76458,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 126.98539972305298,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.463,
                    "ndcg_at_3": 0.55914,
                    "ndcg_at_5": 0.58105,
                    "ndcg_at_10": 0.60654,
                    "ndcg_at_20": 0.62443,
                    "map_at_1": 0.463,
                    "map_at_3": 0.53567,
                    "map_at_5": 0.54787,
                    "map_at_10": 0.55835,
                    "map_at_20": 0.56336,
                    "recall_at_1": 0.463,
                    "recall_at_3": 0.627,
                    "recall_at_5": 0.68,
                    "recall_at_10": 0.759,
                    "recall_at_20": 0.829,
                    "precision_at_1": 0.463,
                    "precision_at_3": 0.209,
                    "precision_at_5": 0.136,
                    "precision_at_10": 0.0759,
                    "precision_at_20": 0.04145,
                    "mrr_at_1": 0.463,
                    "mrr_at_3": 0.5356666666666663,
                    "mrr_at_5": 0.5478666666666661,
                    "mrr_at_10": 0.5583496031746027,
                    "mrr_at_20": 0.563355213899447,
                    "main_score": 0.60654,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 230.31132221221924,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.47945,
                    "ndcg_at_3": 0.55943,
                    "ndcg_at_5": 0.58138,
                    "ndcg_at_10": 0.60529,
                    "ndcg_at_20": 0.6191,
                    "map_at_1": 0.47893,
                    "map_at_3": 0.54013,
                    "map_at_5": 0.55241,
                    "map_at_10": 0.56252,
                    "map_at_20": 0.56629,
                    "recall_at_1": 0.47893,
                    "recall_at_3": 0.61433,
                    "recall_at_5": 0.66754,
                    "recall_at_10": 0.74025,
                    "recall_at_20": 0.79505,
                    "precision_at_1": 0.47945,
                    "precision_at_3": 0.20548,
                    "precision_at_5": 0.13404,
                    "precision_at_10": 0.07439,
                    "precision_at_20": 0.03994,
                    "mrr_at_1": 0.4794520547945205,
                    "mrr_at_3": 0.5407446434843691,
                    "mrr_at_5": 0.5527572883737263,
                    "mrr_at_10": 0.5627628079682873,
                    "mrr_at_20": 0.566527358701906,
                    "main_score": 0.60529,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1393.1561858654022,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.37553,
                    "ndcg_at_3": 0.45529,
                    "ndcg_at_5": 0.47779,
                    "ndcg_at_10": 0.50101,
                    "ndcg_at_20": 0.51734,
                    "map_at_1": 0.37531,
                    "map_at_3": 0.43581,
                    "map_at_5": 0.44833,
                    "map_at_10": 0.45796,
                    "map_at_20": 0.46245,
                    "recall_at_1": 0.37531,
                    "recall_at_3": 0.51135,
                    "recall_at_5": 0.56585,
                    "recall_at_10": 0.63747,
                    "recall_at_20": 0.70195,
                    "precision_at_1": 0.37553,
                    "precision_at_3": 0.17058,
                    "precision_at_5": 0.11326,
                    "precision_at_10": 0.06379,
                    "precision_at_20": 0.03513,
                    "mrr_at_1": 0.37552932118567944,
                    "mrr_at_3": 0.4359842166046529,
                    "mrr_at_5": 0.4485066726549603,
                    "mrr_at_10": 0.45813288380497325,
                    "mrr_at_20": 0.462626392786653,
                    "main_score": 0.50101,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 36.45528769493103,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.47333,
                    "ndcg_at_3": 0.54536,
                    "ndcg_at_5": 0.57963,
                    "ndcg_at_10": 0.60174,
                    "map_at_1": 0.449,
                    "map_at_3": 0.5166,
                    "map_at_5": 0.53806,
                    "map_at_10": 0.54908,
                    "recall_at_1": 0.449,
                    "recall_at_3": 0.59933,
                    "recall_at_5": 0.68389,
                    "recall_at_10": 0.74678,
                    "precision_at_1": 0.47333,
                    "precision_at_3": 0.21667,
                    "precision_at_5": 0.15133,
                    "precision_at_10": 0.08433,
                    "mrr_at_1": 0.47333333333333333,
                    "mrr_at_3": 0.5394444444444445,
                    "mrr_at_5": 0.5574444444444445,
                    "mrr_at_10": 0.5651640211640211,
                    "main_score": 0.60174,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 148.55256819725037,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.804,
                    "ndcg_at_3": 0.76203,
                    "ndcg_at_5": 0.75352,
                    "ndcg_at_10": 0.78648,
                    "ndcg_at_20": 0.81055,
                    "map_at_1": 0.22526,
                    "map_at_3": 0.46815,
                    "map_at_5": 0.59229,
                    "map_at_10": 0.69014,
                    "map_at_20": 0.71488,
                    "recall_at_1": 0.22526,
                    "recall_at_3": 0.50109,
                    "recall_at_5": 0.65989,
                    "recall_at_10": 0.81179,
                    "recall_at_20": 0.88312,
                    "precision_at_1": 0.804,
                    "precision_at_3": 0.68617,
                    "precision_at_5": 0.5815,
                    "precision_at_10": 0.3848,
                    "precision_at_20": 0.2145,
                    "mrr_at_1": 0.804,
                    "mrr_at_3": 0.8626666666666661,
                    "mrr_at_5": 0.8669166666666663,
                    "mrr_at_10": 0.8684190476190473,
                    "mrr_at_20": 0.8693630111610949,
                    "main_score": 0.78648,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1167.2158639431,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.6,
                    "ndcg_at_3": 0.6823,
                    "ndcg_at_5": 0.70602,
                    "ndcg_at_10": 0.72467,
                    "ndcg_at_20": 0.7389,
                    "map_at_1": 0.57622,
                    "map_at_3": 0.65441,
                    "map_at_5": 0.67195,
                    "map_at_10": 0.68086,
                    "map_at_20": 0.68554,
                    "recall_at_1": 0.57622,
                    "recall_at_3": 0.73894,
                    "recall_at_5": 0.79444,
                    "recall_at_10": 0.84756,
                    "recall_at_20": 0.90033,
                    "precision_at_1": 0.6,
                    "precision_at_3": 0.26556,
                    "precision_at_5": 0.17667,
                    "precision_at_10": 0.09567,
                    "precision_at_20": 0.051,
                    "mrr_at_1": 0.6,
                    "mrr_at_3": 0.6705555555555556,
                    "mrr_at_5": 0.6820555555555555,
                    "mrr_at_10": 0.6884735449735448,
                    "mrr_at_20": 0.6919530359990886,
                    "main_score": 0.72467,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 8670.189067602158,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.486,
                    "ndcg_at_3": 0.58882,
                    "ndcg_at_5": 0.61373,
                    "ndcg_at_10": 0.63951,
                    "ndcg_at_20": 0.65447,
                    "map_at_1": 0.486,
                    "map_at_3": 0.56383,
                    "map_at_5": 0.57753,
                    "map_at_10": 0.58831,
                    "map_at_20": 0.59244,
                    "recall_at_1": 0.486,
                    "recall_at_3": 0.661,
                    "recall_at_5": 0.722,
                    "recall_at_10": 0.801,
                    "recall_at_20": 0.86,
                    "precision_at_1": 0.486,
                    "precision_at_3": 0.22033,
                    "precision_at_5": 0.1444,
                    "precision_at_10": 0.0801,
                    "precision_at_20": 0.043,
                    "mrr_at_1": 0.486,
                    "mrr_at_3": 0.5638333333333332,
                    "mrr_at_5": 0.5775333333333331,
                    "mrr_at_10": 0.5883059523809525,
                    "mrr_at_20": 0.5924390182873543,
                    "main_score": 0.63951,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 33.411306619644165,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.879,
                    "ndcg_at_3": 0.83632,
                    "ndcg_at_5": 0.8233,
                    "ndcg_at_10": 0.84658,
                    "ndcg_at_20": 0.86339,
                    "map_at_1": 0.25181,
                    "map_at_3": 0.53093,
                    "map_at_5": 0.66758,
                    "map_at_10": 0.76532,
                    "map_at_20": 0.78734,
                    "recall_at_1": 0.25181,
                    "recall_at_3": 0.55759,
                    "recall_at_5": 0.7213,
                    "recall_at_10": 0.86025,
                    "recall_at_20": 0.91342,
                    "precision_at_1": 0.879,
                    "precision_at_3": 0.75083,
                    "precision_at_5": 0.6309,
                    "precision_at_10": 0.4063,
                    "precision_at_20": 0.22223,
                    "mrr_at_1": 0.879,
                    "mrr_at_3": 0.9131666666666662,
                    "mrr_at_5": 0.9156416666666665,
                    "mrr_at_10": 0.9169325396825394,
                    "mrr_at_20": 0.9174240492544088,
                    "main_score": 0.84658,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 695.2236287593842,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.486,
                    "ndcg_at_3": 0.54049,
                    "ndcg_at_5": 0.5555,
                    "ndcg_at_10": 0.56442,
                    "ndcg_at_20": 0.57789,
                    "map_at_1": 0.486,
                    "map_at_3": 0.52717,
                    "map_at_5": 0.53537,
                    "map_at_10": 0.53916,
                    "map_at_20": 0.54289,
                    "recall_at_1": 0.486,
                    "recall_at_3": 0.579,
                    "recall_at_5": 0.616,
                    "recall_at_10": 0.643,
                    "recall_at_20": 0.696,
                    "precision_at_1": 0.486,
                    "precision_at_3": 0.193,
                    "precision_at_5": 0.1232,
                    "precision_at_10": 0.0643,
                    "precision_at_20": 0.0348,
                    "mrr_at_1": 0.485,
                    "mrr_at_3": 0.5266666666666666,
                    "mrr_at_5": 0.5348666666666667,
                    "mrr_at_10": 0.5386559523809523,
                    "mrr_at_20": 0.5423926536440855,
                    "main_score": 0.56442,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 178.10862827301025,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.33861,
                    "ndcg_at_3": 0.41632,
                    "ndcg_at_5": 0.4382,
                    "ndcg_at_10": 0.45977,
                    "ndcg_at_20": 0.47646,
                    "map_at_1": 0.33799,
                    "map_at_3": 0.39702,
                    "map_at_5": 0.40918,
                    "map_at_10": 0.41809,
                    "map_at_20": 0.42273,
                    "recall_at_1": 0.33799,
                    "recall_at_3": 0.47141,
                    "recall_at_5": 0.52449,
                    "recall_at_10": 0.59088,
                    "recall_at_20": 0.65642,
                    "precision_at_1": 0.33861,
                    "precision_at_3": 0.15768,
                    "precision_at_5": 0.10534,
                    "precision_at_10": 0.05949,
                    "precision_at_20": 0.03311,
                    "mrr_at_1": 0.3386110381570555,
                    "mrr_at_3": 0.3977100764141636,
                    "mrr_at_5": 0.4098175314848901,
                    "mrr_at_10": 0.4187678625771959,
                    "mrr_at_20": 0.423339804545625,
                    "main_score": 0.45977,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 114.3089439868927,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "2e643e7363944af1c33a652d1c87320d0871c4e4",
        "task_name": "NarrativeQAChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.63276,
                    "ndcg_at_3": 0.70344,
                    "ndcg_at_5": 0.72011,
                    "ndcg_at_10": 0.73493,
                    "ndcg_at_20": 0.74402,
                    "map_at_1": 0.63276,
                    "map_at_3": 0.68639,
                    "map_at_5": 0.69564,
                    "map_at_10": 0.70182,
                    "map_at_20": 0.70434,
                    "recall_at_1": 0.63276,
                    "recall_at_3": 0.75268,
                    "recall_at_5": 0.79312,
                    "recall_at_10": 0.83859,
                    "recall_at_20": 0.8744,
                    "precision_at_1": 0.63276,
                    "precision_at_3": 0.25089,
                    "precision_at_5": 0.15862,
                    "precision_at_10": 0.08386,
                    "precision_at_20": 0.04372,
                    "mrr_at_1": 0.6327555176660036,
                    "mrr_at_3": 0.6863850209971227,
                    "mrr_at_5": 0.6956395440623854,
                    "mrr_at_10": 0.7018212545350896,
                    "mrr_at_20": 0.7043388291340413,
                    "main_score": 0.73493,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 3495.6479666233063,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.4784,
                    "ndcg_at_3": 0.4318,
                    "ndcg_at_5": 0.44286,
                    "ndcg_at_10": 0.47311,
                    "map_at_1": 0.2363,
                    "map_at_3": 0.33943,
                    "map_at_5": 0.36581,
                    "map_at_10": 0.39008,
                    "recall_at_1": 0.2363,
                    "recall_at_3": 0.38309,
                    "recall_at_5": 0.45076,
                    "recall_at_10": 0.54229,
                    "precision_at_1": 0.4784,
                    "precision_at_3": 0.29115,
                    "precision_at_5": 0.21204,
                    "precision_at_10": 0.13472,
                    "mrr_at_1": 0.4783950617283951,
                    "mrr_at_3": 0.5303497942386831,
                    "mrr_at_5": 0.5450102880658434,
                    "mrr_at_10": 0.5567350088183423,
                    "main_score": 0.47311,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 1251.8765528202057,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.341,
                    "ndcg_at_3": 0.42668,
                    "ndcg_at_5": 0.45289,
                    "ndcg_at_10": 0.4813,
                    "map_at_1": 0.341,
                    "map_at_3": 0.4055,
                    "map_at_5": 0.4202,
                    "map_at_10": 0.43189,
                    "recall_at_1": 0.341,
                    "recall_at_3": 0.488,
                    "recall_at_5": 0.551,
                    "recall_at_10": 0.639,
                    "precision_at_1": 0.341,
                    "precision_at_3": 0.16267,
                    "precision_at_5": 0.1102,
                    "precision_at_10": 0.0639,
                    "mrr_at_1": 0.341,
                    "mrr_at_3": 0.4054999999999997,
                    "mrr_at_5": 0.4201999999999995,
                    "mrr_at_10": 0.4318888888888887,
                    "main_score": 0.4813,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 649.1673307418823,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.7078,
                    "ndcg_at_3": 0.74951,
                    "ndcg_at_5": 0.75695,
                    "ndcg_at_10": 0.76315,
                    "map_at_1": 0.7078,
                    "map_at_3": 0.73972,
                    "map_at_5": 0.74385,
                    "map_at_10": 0.74642,
                    "recall_at_1": 0.7078,
                    "recall_at_3": 0.77765,
                    "recall_at_5": 0.7957,
                    "recall_at_10": 0.81485,
                    "precision_at_1": 0.7078,
                    "precision_at_3": 0.25922,
                    "precision_at_5": 0.15914,
                    "precision_at_10": 0.08148,
                    "mrr_at_1": 0.7078,
                    "mrr_at_3": 0.7397166666666705,
                    "mrr_at_5": 0.7438541666666724,
                    "mrr_at_10": 0.7464179166666719,
                    "main_score": 0.76315,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 292.8536880016327,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.28521,
                    "ndcg_at_3": 0.43867,
                    "ndcg_at_5": 0.4938,
                    "ndcg_at_10": 0.5396,
                    "ndcg_at_20": 0.5656,
                    "map_at_1": 0.28521,
                    "map_at_3": 0.40078,
                    "map_at_5": 0.43158,
                    "map_at_10": 0.45063,
                    "map_at_20": 0.45791,
                    "recall_at_1": 0.28521,
                    "recall_at_3": 0.54836,
                    "recall_at_5": 0.68137,
                    "recall_at_10": 0.82219,
                    "recall_at_20": 0.9239,
                    "precision_at_1": 0.28521,
                    "precision_at_3": 0.18279,
                    "precision_at_5": 0.13627,
                    "precision_at_10": 0.08222,
                    "precision_at_20": 0.04619,
                    "mrr_at_1": 0.2972972972972973,
                    "mrr_at_3": 0.4062351825509723,
                    "mrr_at_5": 0.43589378852536803,
                    "mrr_at_10": 0.4551353044774102,
                    "mrr_at_20": 0.4623515761775503,
                    "main_score": 0.5396,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 125.41264629364014,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.50667,
                    "ndcg_at_3": 0.56208,
                    "ndcg_at_5": 0.58134,
                    "ndcg_at_10": 0.61075,
                    "ndcg_at_20": 0.62876,
                    "map_at_1": 0.478,
                    "map_at_3": 0.53839,
                    "map_at_5": 0.55071,
                    "map_at_10": 0.56518,
                    "map_at_20": 0.57071,
                    "recall_at_1": 0.478,
                    "recall_at_3": 0.60617,
                    "recall_at_5": 0.65233,
                    "recall_at_10": 0.73606,
                    "recall_at_20": 0.80467,
                    "precision_at_1": 0.50667,
                    "precision_at_3": 0.21889,
                    "precision_at_5": 0.14467,
                    "precision_at_10": 0.084,
                    "precision_at_20": 0.046,
                    "mrr_at_1": 0.5066666666666667,
                    "mrr_at_3": 0.5577777777777778,
                    "mrr_at_5": 0.5697777777777779,
                    "mrr_at_10": 0.5798161375661378,
                    "mrr_at_20": 0.5841927167832742,
                    "main_score": 0.61075,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 43.688153982162476,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.74,
                    "ndcg_at_3": 0.79659,
                    "ndcg_at_5": 0.80949,
                    "ndcg_at_10": 0.81993,
                    "map_at_1": 0.73956,
                    "map_at_3": 0.78335,
                    "map_at_5": 0.79054,
                    "map_at_10": 0.79489,
                    "recall_at_1": 0.73956,
                    "recall_at_3": 0.83435,
                    "recall_at_5": 0.86558,
                    "recall_at_10": 0.89763,
                    "precision_at_1": 0.74,
                    "precision_at_3": 0.2784,
                    "precision_at_5": 0.17335,
                    "precision_at_10": 0.08989,
                    "mrr_at_1": 0.7400622394457166,
                    "mrr_at_3": 0.7836102792946128,
                    "mrr_at_5": 0.7907692834634875,
                    "mrr_at_10": 0.7951146858250095,
                    "main_score": 0.81993,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 278.0101127624512,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.54795,
                    "ndcg_at_3": 0.63098,
                    "ndcg_at_5": 0.6517,
                    "ndcg_at_10": 0.67515,
                    "map_at_1": 0.54689,
                    "map_at_3": 0.61091,
                    "map_at_5": 0.62246,
                    "map_at_10": 0.63231,
                    "recall_at_1": 0.54689,
                    "recall_at_3": 0.68862,
                    "recall_at_5": 0.73841,
                    "recall_at_10": 0.81006,
                    "precision_at_1": 0.54795,
                    "precision_at_3": 0.23042,
                    "precision_at_5": 0.14837,
                    "precision_at_10": 0.08145,
                    "mrr_at_1": 0.547945205479452,
                    "mrr_at_3": 0.6111696522655427,
                    "mrr_at_5": 0.6229188619599578,
                    "mrr_at_10": 0.6326525833375151,
                    "main_score": 0.67515,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1085.3651826381683,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.51667,
                    "ndcg_at_3": 0.58079,
                    "ndcg_at_5": 0.61305,
                    "ndcg_at_10": 0.63735,
                    "map_at_1": 0.49233,
                    "map_at_3": 0.55512,
                    "map_at_5": 0.57591,
                    "map_at_10": 0.58788,
                    "recall_at_1": 0.49233,
                    "recall_at_3": 0.62672,
                    "recall_at_5": 0.70444,
                    "recall_at_10": 0.77444,
                    "precision_at_1": 0.51667,
                    "precision_at_3": 0.22444,
                    "precision_at_5": 0.15533,
                    "precision_at_10": 0.087,
                    "mrr_at_1": 0.5166666666666667,
                    "mrr_at_3": 0.5772222222222223,
                    "mrr_at_5": 0.5933888888888889,
                    "mrr_at_10": 0.6018531746031746,
                    "main_score": 0.63735,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 100.57296633720398,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.52727,
                    "ndcg_at_3": 0.60512,
                    "ndcg_at_5": 0.62418,
                    "ndcg_at_10": 0.64292,
                    "ndcg_at_20": 0.65446,
                    "map_at_1": 0.52712,
                    "map_at_3": 0.58616,
                    "map_at_5": 0.59678,
                    "map_at_10": 0.60456,
                    "map_at_20": 0.60777,
                    "recall_at_1": 0.52712,
                    "recall_at_3": 0.65981,
                    "recall_at_5": 0.70596,
                    "recall_at_10": 0.76361,
                    "recall_at_20": 0.809,
                    "precision_at_1": 0.52727,
                    "precision_at_3": 0.22009,
                    "precision_at_5": 0.1413,
                    "precision_at_10": 0.07642,
                    "precision_at_20": 0.04048,
                    "mrr_at_1": 0.5272680610804569,
                    "mrr_at_3": 0.5862258864793232,
                    "mrr_at_5": 0.5968299542324407,
                    "mrr_at_10": 0.6046097153733901,
                    "mrr_at_20": 0.6078148770704705,
                    "main_score": 0.64292,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 109.94916200637817,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.33591,
                    "ndcg_at_3": 0.29649,
                    "ndcg_at_5": 0.27945,
                    "ndcg_at_10": 0.26001,
                    "ndcg_at_20": 0.24284,
                    "map_at_1": 0.04281,
                    "map_at_3": 0.07273,
                    "map_at_5": 0.08255,
                    "map_at_10": 0.09769,
                    "map_at_20": 0.10736,
                    "recall_at_1": 0.04281,
                    "recall_at_3": 0.08465,
                    "recall_at_5": 0.10167,
                    "recall_at_10": 0.13539,
                    "recall_at_20": 0.16208,
                    "precision_at_1": 0.34675,
                    "precision_at_3": 0.27451,
                    "precision_at_5": 0.23777,
                    "precision_at_10": 0.19009,
                    "precision_at_20": 0.13839,
                    "mrr_at_1": 0.34674922600619196,
                    "mrr_at_3": 0.4138286893704849,
                    "mrr_at_5": 0.4279153766769865,
                    "mrr_at_10": 0.43814683768244134,
                    "mrr_at_20": 0.4414837296843977,
                    "main_score": 0.26001,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 44.21363043785095,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.7176,
                    "ndcg_at_3": 0.80046,
                    "ndcg_at_5": 0.81998,
                    "ndcg_at_10": 0.83331,
                    "ndcg_at_20": 0.83755,
                    "map_at_1": 0.71444,
                    "map_at_3": 0.78091,
                    "map_at_5": 0.79178,
                    "map_at_10": 0.79745,
                    "map_at_20": 0.7986,
                    "recall_at_1": 0.71444,
                    "recall_at_3": 0.85616,
                    "recall_at_5": 0.90306,
                    "recall_at_10": 0.94415,
                    "recall_at_20": 0.96101,
                    "precision_at_1": 0.7176,
                    "precision_at_3": 0.28767,
                    "precision_at_5": 0.1823,
                    "precision_at_10": 0.09547,
                    "precision_at_20": 0.04858,
                    "mrr_at_1": 0.7175974710221286,
                    "mrr_at_3": 0.7813487881981032,
                    "mrr_at_5": 0.7923076923076924,
                    "mrr_at_10": 0.7975237091675448,
                    "mrr_at_20": 0.7986764093996085,
                    "main_score": 0.83331,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 677.5607218742371,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.8495,
                    "ndcg_at_3": 0.81236,
                    "ndcg_at_5": 0.80324,
                    "ndcg_at_10": 0.83162,
                    "map_at_1": 0.23819,
                    "map_at_3": 0.50912,
                    "map_at_5": 0.64552,
                    "map_at_10": 0.74641,
                    "recall_at_1": 0.23819,
                    "recall_at_3": 0.54141,
                    "recall_at_5": 0.70707,
                    "recall_at_10": 0.85386,
                    "precision_at_1": 0.8495,
                    "precision_at_3": 0.73283,
                    "precision_at_5": 0.6208,
                    "precision_at_10": 0.4045,
                    "mrr_at_1": 0.8495,
                    "mrr_at_3": 0.8939166666666658,
                    "mrr_at_5": 0.896166666666666,
                    "mrr_at_10": 0.8976188492063485,
                    "main_score": 0.83162,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2077.7221460342407,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.27582,
                    "ndcg_at_3": 0.27869,
                    "ndcg_at_5": 0.29454,
                    "ndcg_at_10": 0.31861,
                    "map_at_1": 0.17305,
                    "map_at_3": 0.23195,
                    "map_at_5": 0.24782,
                    "map_at_10": 0.26172,
                    "recall_at_1": 0.17305,
                    "recall_at_3": 0.27955,
                    "recall_at_5": 0.33069,
                    "recall_at_10": 0.40179,
                    "precision_at_1": 0.27582,
                    "precision_at_3": 0.16046,
                    "precision_at_5": 0.11648,
                    "precision_at_10": 0.07299,
                    "mrr_at_1": 0.2758189547386847,
                    "mrr_at_3": 0.32612319746603285,
                    "mrr_at_5": 0.33886388263732614,
                    "mrr_at_10": 0.3482142360987069,
                    "main_score": 0.31861,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1008.6619679927826,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.85,
                    "ndcg_at_3": 0.80568,
                    "ndcg_at_5": 0.80014,
                    "ndcg_at_10": 0.82889,
                    "ndcg_at_20": 0.84827,
                    "map_at_1": 0.23987,
                    "map_at_3": 0.50456,
                    "map_at_5": 0.64275,
                    "map_at_10": 0.743,
                    "map_at_20": 0.76591,
                    "recall_at_1": 0.23987,
                    "recall_at_3": 0.53404,
                    "recall_at_5": 0.70452,
                    "recall_at_10": 0.85265,
                    "recall_at_20": 0.91125,
                    "precision_at_1": 0.85,
                    "precision_at_3": 0.72467,
                    "precision_at_5": 0.6186,
                    "precision_at_10": 0.40275,
                    "precision_at_20": 0.2214,
                    "mrr_at_1": 0.85,
                    "mrr_at_3": 0.8930833333333327,
                    "mrr_at_5": 0.8959333333333328,
                    "mrr_at_10": 0.8976121031746024,
                    "mrr_at_20": 0.8982393295730748,
                    "main_score": 0.82889,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 622.4377343654633,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.46802,
                    "ndcg_at_3": 0.55703,
                    "ndcg_at_5": 0.57986,
                    "ndcg_at_10": 0.60074,
                    "ndcg_at_20": 0.61466,
                    "map_at_1": 0.46794,
                    "map_at_3": 0.53538,
                    "map_at_5": 0.54805,
                    "map_at_10": 0.55673,
                    "map_at_20": 0.56059,
                    "recall_at_1": 0.46794,
                    "recall_at_3": 0.6195,
                    "recall_at_5": 0.67491,
                    "recall_at_10": 0.73917,
                    "recall_at_20": 0.79387,
                    "precision_at_1": 0.46802,
                    "precision_at_3": 0.20654,
                    "precision_at_5": 0.13503,
                    "precision_at_10": 0.07395,
                    "precision_at_20": 0.03972,
                    "mrr_at_1": 0.4680161683562171,
                    "mrr_at_3": 0.5354377860473185,
                    "mrr_at_5": 0.5481270584712954,
                    "mrr_at_10": 0.5568023119038608,
                    "mrr_at_20": 0.5606627713813773,
                    "main_score": 0.60074,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 85.87954306602478,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.85459,
                    "ndcg_at_3": 0.89832,
                    "ndcg_at_5": 0.90572,
                    "ndcg_at_10": 0.91082,
                    "ndcg_at_20": 0.91344,
                    "map_at_1": 0.85459,
                    "map_at_3": 0.88804,
                    "map_at_5": 0.89213,
                    "map_at_10": 0.89428,
                    "map_at_20": 0.89501,
                    "recall_at_1": 0.85459,
                    "recall_at_3": 0.92787,
                    "recall_at_5": 0.9459,
                    "recall_at_10": 0.96145,
                    "recall_at_20": 0.97171,
                    "precision_at_1": 0.85459,
                    "precision_at_3": 0.30929,
                    "precision_at_5": 0.18918,
                    "precision_at_10": 0.09614,
                    "precision_at_20": 0.04859,
                    "mrr_at_1": 0.854585831667777,
                    "mrr_at_3": 0.8880376045599223,
                    "mrr_at_5": 0.8921348730475998,
                    "mrr_at_10": 0.8942751569500421,
                    "mrr_at_20": 0.8950078841369395,
                    "main_score": 0.91082,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 32.89302396774292,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.65008,
                    "ndcg_at_3": 0.72482,
                    "ndcg_at_5": 0.73933,
                    "ndcg_at_10": 0.75279,
                    "ndcg_at_20": 0.76163,
                    "map_at_1": 0.64965,
                    "map_at_3": 0.70696,
                    "map_at_5": 0.71504,
                    "map_at_10": 0.72063,
                    "map_at_20": 0.72306,
                    "recall_at_1": 0.64965,
                    "recall_at_3": 0.77603,
                    "recall_at_5": 0.81113,
                    "recall_at_10": 0.85254,
                    "recall_at_20": 0.88743,
                    "precision_at_1": 0.65008,
                    "precision_at_3": 0.25897,
                    "precision_at_5": 0.16243,
                    "precision_at_10": 0.08538,
                    "precision_at_20": 0.04445,
                    "mrr_at_1": 0.6500792672186013,
                    "mrr_at_3": 0.707200594993435,
                    "mrr_at_5": 0.7152682363533138,
                    "mrr_at_10": 0.7208625983617154,
                    "mrr_at_20": 0.7232883388842309,
                    "main_score": 0.75279,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 56.68811583518982,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.26237,
                    "ndcg_at_3": 0.33453,
                    "ndcg_at_5": 0.35697,
                    "ndcg_at_10": 0.37933,
                    "ndcg_at_20": 0.3974,
                    "map_at_1": 0.26162,
                    "map_at_3": 0.31651,
                    "map_at_5": 0.32902,
                    "map_at_10": 0.33826,
                    "map_at_20": 0.34325,
                    "recall_at_1": 0.26162,
                    "recall_at_3": 0.3858,
                    "recall_at_5": 0.4401,
                    "recall_at_10": 0.50904,
                    "recall_at_20": 0.58012,
                    "precision_at_1": 0.26237,
                    "precision_at_3": 0.12914,
                    "precision_at_5": 0.08846,
                    "precision_at_10": 0.05125,
                    "precision_at_20": 0.02927,
                    "mrr_at_1": 0.2623719656323866,
                    "mrr_at_3": 0.31732512912867417,
                    "mrr_at_5": 0.3297946447554326,
                    "mrr_at_10": 0.33904818183604735,
                    "mrr_at_20": 0.3440160609216112,
                    "main_score": 0.37933,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 122.59543442726135,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.39425,
                    "ndcg_at_3": 0.47286,
                    "ndcg_at_5": 0.49354,
                    "ndcg_at_10": 0.51449,
                    "ndcg_at_20": 0.5294,
                    "map_at_1": 0.39372,
                    "map_at_3": 0.45343,
                    "map_at_5": 0.46493,
                    "map_at_10": 0.47361,
                    "map_at_20": 0.47776,
                    "recall_at_1": 0.39372,
                    "recall_at_3": 0.52837,
                    "recall_at_5": 0.57847,
                    "recall_at_10": 0.64289,
                    "recall_at_20": 0.70122,
                    "precision_at_1": 0.39425,
                    "precision_at_3": 0.17673,
                    "precision_at_5": 0.1162,
                    "precision_at_10": 0.06469,
                    "precision_at_20": 0.03537,
                    "mrr_at_1": 0.3942520541777661,
                    "mrr_at_3": 0.45403894495929614,
                    "mrr_at_5": 0.46550106929802426,
                    "mrr_at_10": 0.4741926070444528,
                    "mrr_at_20": 0.4782921566602543,
                    "main_score": 0.51449,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 192.72137999534607,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.27882,
                    "ndcg_at_3": 0.28205,
                    "ndcg_at_5": 0.29722,
                    "ndcg_at_10": 0.32166,
                    "ndcg_at_20": 0.34511,
                    "map_at_1": 0.17538,
                    "map_at_3": 0.23514,
                    "map_at_5": 0.25057,
                    "map_at_10": 0.26472,
                    "map_at_20": 0.27273,
                    "recall_at_1": 0.17538,
                    "recall_at_3": 0.28253,
                    "recall_at_5": 0.3326,
                    "recall_at_10": 0.40503,
                    "recall_at_20": 0.48456,
                    "precision_at_1": 0.27882,
                    "precision_at_3": 0.16212,
                    "precision_at_5": 0.11703,
                    "precision_at_10": 0.07342,
                    "precision_at_20": 0.04454,
                    "mrr_at_1": 0.27881970492623154,
                    "mrr_at_3": 0.32945736434108486,
                    "mrr_at_5": 0.34208552138034515,
                    "mrr_at_10": 0.351322255166966,
                    "mrr_at_20": 0.3567998983964039,
                    "main_score": 0.32166,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 991.6504945755005,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.67933,
                    "ndcg_at_3": 0.75064,
                    "ndcg_at_5": 0.76298,
                    "ndcg_at_10": 0.77388,
                    "ndcg_at_20": 0.78121,
                    "map_at_1": 0.67898,
                    "map_at_3": 0.73387,
                    "map_at_5": 0.74074,
                    "map_at_10": 0.74528,
                    "map_at_20": 0.7473,
                    "recall_at_1": 0.67898,
                    "recall_at_3": 0.79871,
                    "recall_at_5": 0.82854,
                    "recall_at_10": 0.86209,
                    "recall_at_20": 0.89099,
                    "precision_at_1": 0.67933,
                    "precision_at_3": 0.26654,
                    "precision_at_5": 0.16592,
                    "precision_at_10": 0.08635,
                    "precision_at_20": 0.04464,
                    "mrr_at_1": 0.679330593071051,
                    "mrr_at_3": 0.7339792522998544,
                    "mrr_at_5": 0.7408612252887026,
                    "mrr_at_10": 0.7453630381492948,
                    "mrr_at_20": 0.7473662138732188,
                    "main_score": 0.77388,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 107.09006690979004,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.486,
                    "ndcg_at_3": 0.58882,
                    "ndcg_at_5": 0.61373,
                    "ndcg_at_10": 0.63951,
                    "ndcg_at_20": 0.65447,
                    "map_at_1": 0.486,
                    "map_at_3": 0.56383,
                    "map_at_5": 0.57753,
                    "map_at_10": 0.58831,
                    "map_at_20": 0.59244,
                    "recall_at_1": 0.486,
                    "recall_at_3": 0.661,
                    "recall_at_5": 0.722,
                    "recall_at_10": 0.801,
                    "recall_at_20": 0.86,
                    "precision_at_1": 0.486,
                    "precision_at_3": 0.22033,
                    "precision_at_5": 0.1444,
                    "precision_at_10": 0.0801,
                    "precision_at_20": 0.043,
                    "mrr_at_1": 0.486,
                    "mrr_at_3": 0.5638333333333332,
                    "mrr_at_5": 0.5775333333333331,
                    "mrr_at_10": 0.5883059523809525,
                    "mrr_at_20": 0.5924390182873543,
                    "main_score": 0.63951,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 42.35806608200073,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.22127,
                    "ndcg_at_3": 0.28001,
                    "ndcg_at_5": 0.2987,
                    "ndcg_at_10": 0.31886,
                    "ndcg_at_20": 0.33453,
                    "map_at_1": 0.22088,
                    "map_at_3": 0.26538,
                    "map_at_5": 0.27578,
                    "map_at_10": 0.2841,
                    "map_at_20": 0.28844,
                    "recall_at_1": 0.22088,
                    "recall_at_3": 0.32167,
                    "recall_at_5": 0.36698,
                    "recall_at_10": 0.4292,
                    "recall_at_20": 0.49081,
                    "precision_at_1": 0.22127,
                    "precision_at_3": 0.10764,
                    "precision_at_5": 0.07373,
                    "precision_at_10": 0.04322,
                    "precision_at_20": 0.02478,
                    "mrr_at_1": 0.22126717213422414,
                    "mrr_at_3": 0.2659209769036323,
                    "mrr_at_5": 0.27633310812500955,
                    "mrr_at_10": 0.28464685488838787,
                    "mrr_at_20": 0.28893298735490697,
                    "main_score": 0.31886,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 55.333494663238525,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.421,
                    "ndcg_at_3": 0.47672,
                    "ndcg_at_5": 0.49028,
                    "ndcg_at_10": 0.50163,
                    "ndcg_at_20": 0.51273,
                    "map_at_1": 0.421,
                    "map_at_3": 0.46283,
                    "map_at_5": 0.47033,
                    "map_at_10": 0.47504,
                    "map_at_20": 0.47807,
                    "recall_at_1": 0.421,
                    "recall_at_3": 0.517,
                    "recall_at_5": 0.55,
                    "recall_at_10": 0.585,
                    "recall_at_20": 0.629,
                    "precision_at_1": 0.421,
                    "precision_at_3": 0.17233,
                    "precision_at_5": 0.11,
                    "precision_at_10": 0.0585,
                    "precision_at_20": 0.03145,
                    "mrr_at_1": 0.422,
                    "mrr_at_3": 0.463333333333333,
                    "mrr_at_5": 0.47083333333333294,
                    "mrr_at_10": 0.4755369047619045,
                    "mrr_at_20": 0.4785694272359901,
                    "main_score": 0.50163,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1256.4690232276917,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.49667,
                    "ndcg_at_3": 0.55868,
                    "ndcg_at_5": 0.5974,
                    "ndcg_at_10": 0.61862,
                    "ndcg_at_20": 0.6337,
                    "map_at_1": 0.46983,
                    "map_at_3": 0.53296,
                    "map_at_5": 0.55692,
                    "map_at_10": 0.5673,
                    "map_at_20": 0.57149,
                    "recall_at_1": 0.46983,
                    "recall_at_3": 0.60283,
                    "recall_at_5": 0.69889,
                    "recall_at_10": 0.76011,
                    "recall_at_20": 0.82011,
                    "precision_at_1": 0.49667,
                    "precision_at_3": 0.21778,
                    "precision_at_5": 0.154,
                    "precision_at_10": 0.08567,
                    "precision_at_20": 0.046,
                    "mrr_at_1": 0.49666666666666665,
                    "mrr_at_3": 0.5566666666666666,
                    "mrr_at_5": 0.5768333333333334,
                    "mrr_at_10": 0.5840304232804233,
                    "mrr_at_20": 0.5877017125604588,
                    "main_score": 0.61862,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 235.5814516544342,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.421,
                    "ndcg_at_3": 0.47672,
                    "ndcg_at_5": 0.49024,
                    "ndcg_at_10": 0.50159,
                    "ndcg_at_20": 0.51269,
                    "map_at_1": 0.421,
                    "map_at_3": 0.46283,
                    "map_at_5": 0.47028,
                    "map_at_10": 0.47499,
                    "map_at_20": 0.47802,
                    "recall_at_1": 0.421,
                    "recall_at_3": 0.517,
                    "recall_at_5": 0.55,
                    "recall_at_10": 0.585,
                    "recall_at_20": 0.629,
                    "precision_at_1": 0.421,
                    "precision_at_3": 0.17233,
                    "precision_at_5": 0.11,
                    "precision_at_10": 0.0585,
                    "precision_at_20": 0.03145,
                    "mrr_at_1": 0.422,
                    "mrr_at_3": 0.463333333333333,
                    "mrr_at_5": 0.47078333333333294,
                    "mrr_at_10": 0.4754869047619044,
                    "mrr_at_20": 0.47852022088678375,
                    "main_score": 0.50159,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1255.4956185817719,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.84105,
                    "ndcg_at_3": 0.79937,
                    "ndcg_at_5": 0.78319,
                    "ndcg_at_10": 0.78379,
                    "ndcg_at_20": 0.80487,
                    "map_at_1": 0.24658,
                    "map_at_3": 0.48793,
                    "map_at_5": 0.59935,
                    "map_at_10": 0.69523,
                    "map_at_20": 0.72315,
                    "recall_at_1": 0.24658,
                    "recall_at_3": 0.51051,
                    "recall_at_5": 0.64328,
                    "recall_at_10": 0.77813,
                    "recall_at_20": 0.84587,
                    "precision_at_1": 0.84105,
                    "precision_at_3": 0.70347,
                    "precision_at_5": 0.58819,
                    "precision_at_10": 0.3937,
                    "precision_at_20": 0.22128,
                    "mrr_at_1": 0.841048570927582,
                    "mrr_at_3": 0.8734364954117706,
                    "mrr_at_5": 0.8775308317259934,
                    "mrr_at_10": 0.8800815464709473,
                    "mrr_at_20": 0.8810256671245289,
                    "main_score": 0.78379,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2923.70023727417,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.487,
                    "ndcg_at_3": 0.54122,
                    "ndcg_at_5": 0.55401,
                    "ndcg_at_10": 0.5666,
                    "ndcg_at_20": 0.57446,
                    "map_at_1": 0.487,
                    "map_at_3": 0.52783,
                    "map_at_5": 0.53493,
                    "map_at_10": 0.53993,
                    "map_at_20": 0.54211,
                    "recall_at_1": 0.487,
                    "recall_at_3": 0.58,
                    "recall_at_5": 0.611,
                    "recall_at_10": 0.651,
                    "recall_at_20": 0.682,
                    "precision_at_1": 0.487,
                    "precision_at_3": 0.19333,
                    "precision_at_5": 0.1222,
                    "precision_at_10": 0.0651,
                    "precision_at_20": 0.0341,
                    "mrr_at_1": 0.488,
                    "mrr_at_3": 0.528333333333333,
                    "mrr_at_5": 0.535433333333333,
                    "mrr_at_10": 0.5404341269841267,
                    "mrr_at_20": 0.5426114716552793,
                    "main_score": 0.5666,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 203.04189920425415,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.90034,
                    "ndcg_at_3": 0.93271,
                    "ndcg_at_5": 0.93732,
                    "ndcg_at_10": 0.94058,
                    "map_at_1": 0.90029,
                    "map_at_3": 0.92508,
                    "map_at_5": 0.92765,
                    "map_at_10": 0.92903,
                    "recall_at_1": 0.90029,
                    "recall_at_3": 0.95458,
                    "recall_at_5": 0.96578,
                    "recall_at_10": 0.97566,
                    "precision_at_1": 0.90034,
                    "precision_at_3": 0.31821,
                    "precision_at_5": 0.19317,
                    "precision_at_10": 0.09757,
                    "mrr_at_1": 0.9003384396152476,
                    "mrr_at_3": 0.9251276570478555,
                    "mrr_at_5": 0.9276837667735429,
                    "mrr_at_10": 0.9290633782606985,
                    "main_score": 0.94058,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 205.43672275543213,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.59667,
                    "ndcg_at_3": 0.68715,
                    "ndcg_at_5": 0.70318,
                    "ndcg_at_10": 0.71856,
                    "map_at_1": 0.57606,
                    "map_at_3": 0.65778,
                    "map_at_5": 0.66923,
                    "map_at_10": 0.67748,
                    "recall_at_1": 0.57606,
                    "recall_at_3": 0.74822,
                    "recall_at_5": 0.78817,
                    "recall_at_10": 0.83106,
                    "precision_at_1": 0.59667,
                    "precision_at_3": 0.27,
                    "precision_at_5": 0.17467,
                    "precision_at_10": 0.094,
                    "mrr_at_1": 0.5966666666666667,
                    "mrr_at_3": 0.6722222222222222,
                    "mrr_at_5": 0.6802222222222221,
                    "mrr_at_10": 0.6846097883597883,
                    "main_score": 0.71856,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 34.16749382019043,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.32555,
                    "ndcg_at_3": 0.40348,
                    "ndcg_at_5": 0.42581,
                    "ndcg_at_10": 0.4476,
                    "ndcg_at_20": 0.46439,
                    "map_at_1": 0.32504,
                    "map_at_3": 0.38414,
                    "map_at_5": 0.39658,
                    "map_at_10": 0.40561,
                    "map_at_20": 0.41025,
                    "recall_at_1": 0.32504,
                    "recall_at_3": 0.45871,
                    "recall_at_5": 0.51269,
                    "recall_at_10": 0.57971,
                    "recall_at_20": 0.64565,
                    "precision_at_1": 0.32555,
                    "precision_at_3": 0.15339,
                    "precision_at_5": 0.10301,
                    "precision_at_10": 0.05835,
                    "precision_at_20": 0.03257,
                    "mrr_at_1": 0.3255543466026338,
                    "mrr_at_3": 0.3848222213884625,
                    "mrr_at_5": 0.3972242024037345,
                    "mrr_at_10": 0.40625128414026934,
                    "mrr_at_20": 0.41085295812000194,
                    "main_score": 0.4476,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 158.8758294582367,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.437,
                    "ndcg_at_3": 0.49403,
                    "ndcg_at_5": 0.50656,
                    "ndcg_at_10": 0.52331,
                    "ndcg_at_20": 0.53331,
                    "map_at_1": 0.437,
                    "map_at_3": 0.4805,
                    "map_at_5": 0.48755,
                    "map_at_10": 0.49461,
                    "map_at_20": 0.4973,
                    "recall_at_1": 0.437,
                    "recall_at_3": 0.533,
                    "recall_at_5": 0.563,
                    "recall_at_10": 0.614,
                    "recall_at_20": 0.654,
                    "precision_at_1": 0.437,
                    "precision_at_3": 0.17767,
                    "precision_at_5": 0.1126,
                    "precision_at_10": 0.0614,
                    "precision_at_20": 0.0327,
                    "mrr_at_1": 0.436,
                    "mrr_at_3": 0.47999999999999976,
                    "mrr_at_5": 0.48704999999999976,
                    "mrr_at_10": 0.49411031746031775,
                    "mrr_at_20": 0.49679665246604116,
                    "main_score": 0.52331,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 291.45314860343933,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.58667,
                    "ndcg_at_3": 0.67752,
                    "ndcg_at_5": 0.70153,
                    "ndcg_at_10": 0.72207,
                    "ndcg_at_20": 0.73548,
                    "map_at_1": 0.56928,
                    "map_at_3": 0.64904,
                    "map_at_5": 0.66613,
                    "map_at_10": 0.67639,
                    "map_at_20": 0.68085,
                    "recall_at_1": 0.56928,
                    "recall_at_3": 0.73561,
                    "recall_at_5": 0.79167,
                    "recall_at_10": 0.85106,
                    "recall_at_20": 0.901,
                    "precision_at_1": 0.58667,
                    "precision_at_3": 0.26444,
                    "precision_at_5": 0.176,
                    "precision_at_10": 0.096,
                    "precision_at_20": 0.05117,
                    "mrr_at_1": 0.5866666666666667,
                    "mrr_at_3": 0.6649999999999999,
                    "mrr_at_5": 0.6763333333333331,
                    "mrr_at_10": 0.6830343915343913,
                    "mrr_at_20": 0.6861339291799816,
                    "main_score": 0.72207,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 48.23012566566467,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.55727,
                    "ndcg_at_3": 0.61503,
                    "ndcg_at_5": 0.63044,
                    "ndcg_at_10": 0.64491,
                    "ndcg_at_20": 0.65537,
                    "map_at_1": 0.55725,
                    "map_at_3": 0.60105,
                    "map_at_5": 0.6096,
                    "map_at_10": 0.6156,
                    "map_at_20": 0.61848,
                    "recall_at_1": 0.55725,
                    "recall_at_3": 0.65532,
                    "recall_at_5": 0.69275,
                    "recall_at_10": 0.73731,
                    "recall_at_20": 0.77854,
                    "precision_at_1": 0.55727,
                    "precision_at_3": 0.21848,
                    "precision_at_5": 0.13858,
                    "precision_at_10": 0.07376,
                    "precision_at_20": 0.03896,
                    "mrr_at_1": 0.557234212629896,
                    "mrr_at_3": 0.6010924593658477,
                    "mrr_at_5": 0.6096436184385937,
                    "mrr_at_10": 0.615661264639092,
                    "mrr_at_20": 0.6185510977657186,
                    "main_score": 0.64491,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 115.8617377281189,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.85994,
                    "ndcg_at_3": 0.81558,
                    "ndcg_at_5": 0.80024,
                    "ndcg_at_10": 0.8003,
                    "map_at_1": 0.25466,
                    "map_at_3": 0.50164,
                    "map_at_5": 0.61668,
                    "map_at_10": 0.71531,
                    "recall_at_1": 0.25466,
                    "recall_at_3": 0.52198,
                    "recall_at_5": 0.65735,
                    "recall_at_10": 0.79169,
                    "precision_at_1": 0.85994,
                    "precision_at_3": 0.71603,
                    "precision_at_5": 0.60017,
                    "precision_at_10": 0.40131,
                    "mrr_at_1": 0.8599421357180431,
                    "mrr_at_3": 0.8875884037641,
                    "mrr_at_5": 0.8915578058331883,
                    "mrr_at_10": 0.8935408021119504,
                    "main_score": 0.8003,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 870.3638341426849,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.67907,
                    "ndcg_at_3": 0.74925,
                    "ndcg_at_5": 0.76153,
                    "ndcg_at_10": 0.77264,
                    "ndcg_at_20": 0.78017,
                    "map_at_1": 0.67871,
                    "map_at_3": 0.73273,
                    "map_at_5": 0.73957,
                    "map_at_10": 0.74417,
                    "map_at_20": 0.74626,
                    "recall_at_1": 0.67871,
                    "recall_at_3": 0.79663,
                    "recall_at_5": 0.82635,
                    "recall_at_10": 0.86055,
                    "recall_at_20": 0.89018,
                    "precision_at_1": 0.67907,
                    "precision_at_3": 0.26583,
                    "precision_at_5": 0.16549,
                    "precision_at_10": 0.08619,
                    "precision_at_20": 0.04459,
                    "mrr_at_1": 0.6790663534938344,
                    "mrr_at_3": 0.7328244274809075,
                    "mrr_at_5": 0.7396564885496149,
                    "mrr_at_10": 0.7442466841894299,
                    "mrr_at_20": 0.7463122908119524,
                    "main_score": 0.77264,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 121.52120351791382,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.31158,
                    "ndcg_at_3": 0.3129,
                    "ndcg_at_5": 0.32936,
                    "ndcg_at_10": 0.3578,
                    "ndcg_at_20": 0.38252,
                    "map_at_1": 0.2005,
                    "map_at_3": 0.26451,
                    "map_at_5": 0.28188,
                    "map_at_10": 0.29816,
                    "map_at_20": 0.30679,
                    "recall_at_1": 0.2005,
                    "recall_at_3": 0.31091,
                    "recall_at_5": 0.36463,
                    "recall_at_10": 0.44751,
                    "recall_at_20": 0.53139,
                    "precision_at_1": 0.31158,
                    "precision_at_3": 0.17846,
                    "precision_at_5": 0.12863,
                    "precision_at_10": 0.08115,
                    "precision_at_20": 0.04892,
                    "mrr_at_1": 0.3115778944736184,
                    "mrr_at_3": 0.36234058514628614,
                    "mrr_at_5": 0.37474368592148033,
                    "mrr_at_10": 0.3855915367730817,
                    "mrr_at_20": 0.39112446033648945,
                    "main_score": 0.3578,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1828.9996175765991,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.83395,
                    "ndcg_at_3": 0.78582,
                    "ndcg_at_5": 0.76901,
                    "ndcg_at_10": 0.77063,
                    "ndcg_at_20": 0.79352,
                    "map_at_1": 0.24539,
                    "map_at_3": 0.47777,
                    "map_at_5": 0.58537,
                    "map_at_10": 0.67939,
                    "map_at_20": 0.70834,
                    "recall_at_1": 0.24539,
                    "recall_at_3": 0.4996,
                    "recall_at_5": 0.62906,
                    "recall_at_10": 0.76369,
                    "recall_at_20": 0.83439,
                    "precision_at_1": 0.83395,
                    "precision_at_3": 0.68933,
                    "precision_at_5": 0.57576,
                    "precision_at_10": 0.38664,
                    "precision_at_20": 0.21898,
                    "mrr_at_1": 0.833947045414694,
                    "mrr_at_3": 0.8666199076509438,
                    "mrr_at_5": 0.870942194166815,
                    "mrr_at_10": 0.8736350472739247,
                    "mrr_at_20": 0.8745433972593809,
                    "main_score": 0.77063,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2492.59024310112,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.86489,
                    "ndcg_at_3": 0.90269,
                    "ndcg_at_5": 0.90934,
                    "ndcg_at_10": 0.91391,
                    "ndcg_at_20": 0.91678,
                    "map_at_1": 0.86489,
                    "map_at_3": 0.89377,
                    "map_at_5": 0.89748,
                    "map_at_10": 0.89939,
                    "map_at_20": 0.9002,
                    "recall_at_1": 0.86489,
                    "recall_at_3": 0.92835,
                    "recall_at_5": 0.9444,
                    "recall_at_10": 0.95841,
                    "recall_at_20": 0.96963,
                    "precision_at_1": 0.86489,
                    "precision_at_3": 0.30945,
                    "precision_at_5": 0.18888,
                    "precision_at_10": 0.09585,
                    "precision_at_20": 0.04848,
                    "mrr_at_1": 0.8648913430708942,
                    "mrr_at_3": 0.8937700391877452,
                    "mrr_at_5": 0.8974817420733898,
                    "mrr_at_10": 0.899394706968409,
                    "mrr_at_20": 0.9002034446782322,
                    "main_score": 0.91391,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 31.030532836914062,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.7689,
                    "ndcg_at_3": 0.80346,
                    "ndcg_at_5": 0.80983,
                    "ndcg_at_10": 0.81494,
                    "ndcg_at_20": 0.81784,
                    "map_at_1": 0.7689,
                    "map_at_3": 0.79538,
                    "map_at_5": 0.79891,
                    "map_at_10": 0.80104,
                    "map_at_20": 0.80184,
                    "recall_at_1": 0.7689,
                    "recall_at_3": 0.8267,
                    "recall_at_5": 0.84215,
                    "recall_at_10": 0.85785,
                    "recall_at_20": 0.8693,
                    "precision_at_1": 0.7689,
                    "precision_at_3": 0.27557,
                    "precision_at_5": 0.16843,
                    "precision_at_10": 0.08578,
                    "precision_at_20": 0.04346,
                    "mrr_at_1": 0.7689,
                    "mrr_at_3": 0.7953750000000034,
                    "mrr_at_5": 0.7989075000000051,
                    "mrr_at_10": 0.8010405357142901,
                    "mrr_at_20": 0.8018383706773169,
                    "main_score": 0.81494,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 427.9529936313629,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.487,
                    "ndcg_at_3": 0.54122,
                    "ndcg_at_5": 0.55401,
                    "ndcg_at_10": 0.5666,
                    "ndcg_at_20": 0.57446,
                    "map_at_1": 0.487,
                    "map_at_3": 0.52783,
                    "map_at_5": 0.53493,
                    "map_at_10": 0.53993,
                    "map_at_20": 0.54211,
                    "recall_at_1": 0.487,
                    "recall_at_3": 0.58,
                    "recall_at_5": 0.611,
                    "recall_at_10": 0.651,
                    "recall_at_20": 0.682,
                    "precision_at_1": 0.487,
                    "precision_at_3": 0.19333,
                    "precision_at_5": 0.1222,
                    "precision_at_10": 0.0651,
                    "precision_at_20": 0.0341,
                    "mrr_at_1": 0.488,
                    "mrr_at_3": 0.528333333333333,
                    "mrr_at_5": 0.535433333333333,
                    "mrr_at_10": 0.5404341269841267,
                    "mrr_at_20": 0.5426114716552793,
                    "main_score": 0.5666,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 204.2099461555481,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.556,
                    "ndcg_at_3": 0.6646,
                    "ndcg_at_5": 0.68892,
                    "ndcg_at_10": 0.70577,
                    "map_at_1": 0.556,
                    "map_at_3": 0.63817,
                    "map_at_5": 0.65167,
                    "map_at_10": 0.65864,
                    "recall_at_1": 0.556,
                    "recall_at_3": 0.741,
                    "recall_at_5": 0.8,
                    "recall_at_10": 0.852,
                    "precision_at_1": 0.556,
                    "precision_at_3": 0.247,
                    "precision_at_5": 0.16,
                    "precision_at_10": 0.0852,
                    "mrr_at_1": 0.556,
                    "mrr_at_3": 0.6381666666666667,
                    "mrr_at_5": 0.6516666666666668,
                    "mrr_at_10": 0.6586424603174604,
                    "main_score": 0.70577,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 252.12285375595093,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.46122,
                    "ndcg_at_3": 0.55068,
                    "ndcg_at_5": 0.5741,
                    "ndcg_at_10": 0.59467,
                    "ndcg_at_20": 0.60848,
                    "map_at_1": 0.46113,
                    "map_at_3": 0.5289,
                    "map_at_5": 0.54192,
                    "map_at_10": 0.55047,
                    "map_at_20": 0.5543,
                    "recall_at_1": 0.46113,
                    "recall_at_3": 0.61357,
                    "recall_at_5": 0.67032,
                    "recall_at_10": 0.73356,
                    "recall_at_20": 0.78788,
                    "precision_at_1": 0.46122,
                    "precision_at_3": 0.20459,
                    "precision_at_5": 0.13411,
                    "precision_at_10": 0.07338,
                    "precision_at_20": 0.03941,
                    "mrr_at_1": 0.4612151931220326,
                    "mrr_at_3": 0.5289576115317278,
                    "mrr_at_5": 0.5419757046922633,
                    "mrr_at_10": 0.5505270679425516,
                    "mrr_at_20": 0.5543546696045749,
                    "main_score": 0.59467,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 100.22399544715881,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.54526,
                    "ndcg_at_3": 0.60604,
                    "ndcg_at_5": 0.62214,
                    "ndcg_at_10": 0.63778,
                    "ndcg_at_20": 0.64922,
                    "map_at_1": 0.54513,
                    "map_at_3": 0.5913,
                    "map_at_5": 0.60025,
                    "map_at_10": 0.60672,
                    "map_at_20": 0.60986,
                    "recall_at_1": 0.54513,
                    "recall_at_3": 0.64831,
                    "recall_at_5": 0.68741,
                    "recall_at_10": 0.73569,
                    "recall_at_20": 0.78087,
                    "precision_at_1": 0.54526,
                    "precision_at_3": 0.21621,
                    "precision_at_5": 0.13757,
                    "precision_at_10": 0.07363,
                    "precision_at_20": 0.03909,
                    "mrr_at_1": 0.5452585346376523,
                    "mrr_at_3": 0.5915019631330336,
                    "mrr_at_5": 0.6004518533306825,
                    "mrr_at_10": 0.6069329017292786,
                    "mrr_at_20": 0.6100928566267173,
                    "main_score": 0.63778,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 81.36181735992432,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.26173,
                    "ndcg_at_3": 0.32684,
                    "ndcg_at_5": 0.34854,
                    "ndcg_at_10": 0.37009,
                    "ndcg_at_20": 0.38681,
                    "map_at_1": 0.26129,
                    "map_at_3": 0.31061,
                    "map_at_5": 0.32266,
                    "map_at_10": 0.33157,
                    "map_at_20": 0.33619,
                    "recall_at_1": 0.26129,
                    "recall_at_3": 0.37299,
                    "recall_at_5": 0.42563,
                    "recall_at_10": 0.49207,
                    "recall_at_20": 0.55785,
                    "precision_at_1": 0.26173,
                    "precision_at_3": 0.12481,
                    "precision_at_5": 0.08559,
                    "precision_at_10": 0.04957,
                    "precision_at_20": 0.02817,
                    "mrr_at_1": 0.2617341387461074,
                    "mrr_at_3": 0.3112595205042542,
                    "mrr_at_5": 0.32333696019209296,
                    "mrr_at_10": 0.3322395882651753,
                    "mrr_at_20": 0.33682262567278376,
                    "main_score": 0.37009,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 89.68844890594482,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.67169,
                    "ndcg_at_3": 0.74475,
                    "ndcg_at_5": 0.75944,
                    "ndcg_at_10": 0.77193,
                    "map_at_1": 0.67133,
                    "map_at_3": 0.72722,
                    "map_at_5": 0.7354,
                    "map_at_10": 0.7406,
                    "recall_at_1": 0.67133,
                    "recall_at_3": 0.79504,
                    "recall_at_5": 0.83057,
                    "recall_at_10": 0.86899,
                    "precision_at_1": 0.67169,
                    "precision_at_3": 0.26526,
                    "precision_at_5": 0.16632,
                    "precision_at_10": 0.08703,
                    "mrr_at_1": 0.6716869238447537,
                    "mrr_at_3": 0.727477345233192,
                    "mrr_at_5": 0.7356110426085725,
                    "mrr_at_10": 0.7407884012626815,
                    "main_score": 0.77193,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 352.74075388908386,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.493,
                    "ndcg_at_3": 0.54809,
                    "ndcg_at_5": 0.56156,
                    "ndcg_at_10": 0.57157,
                    "ndcg_at_20": 0.58405,
                    "map_at_1": 0.493,
                    "map_at_3": 0.53433,
                    "map_at_5": 0.54173,
                    "map_at_10": 0.54586,
                    "map_at_20": 0.54933,
                    "recall_at_1": 0.493,
                    "recall_at_3": 0.588,
                    "recall_at_5": 0.621,
                    "recall_at_10": 0.652,
                    "recall_at_20": 0.701,
                    "precision_at_1": 0.493,
                    "precision_at_3": 0.196,
                    "precision_at_5": 0.1242,
                    "precision_at_10": 0.0652,
                    "precision_at_20": 0.03505,
                    "mrr_at_1": 0.493,
                    "mrr_at_3": 0.5343333333333332,
                    "mrr_at_5": 0.5417333333333334,
                    "mrr_at_10": 0.5458567460317462,
                    "mrr_at_20": 0.5493389033309312,
                    "main_score": 0.57157,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 245.8511917591095,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.40312,
                    "ndcg_at_3": 0.46516,
                    "ndcg_at_5": 0.48125,
                    "ndcg_at_10": 0.49808,
                    "ndcg_at_20": 0.51088,
                    "map_at_1": 0.40302,
                    "map_at_3": 0.45004,
                    "map_at_5": 0.45894,
                    "map_at_10": 0.4659,
                    "map_at_20": 0.46942,
                    "recall_at_1": 0.40302,
                    "recall_at_3": 0.50859,
                    "recall_at_5": 0.5479,
                    "recall_at_10": 0.59976,
                    "recall_at_20": 0.65013,
                    "precision_at_1": 0.40312,
                    "precision_at_3": 0.16961,
                    "precision_at_5": 0.10963,
                    "precision_at_10": 0.06006,
                    "precision_at_20": 0.03258,
                    "mrr_at_1": 0.40311750599520385,
                    "mrr_at_3": 0.45021316280309387,
                    "mrr_at_5": 0.459116040500938,
                    "mrr_at_10": 0.4661200721962174,
                    "mrr_at_20": 0.4696653182058228,
                    "main_score": 0.49808,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 36.23064303398132,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.47685,
                    "ndcg_at_3": 0.42925,
                    "ndcg_at_5": 0.43985,
                    "ndcg_at_10": 0.47199,
                    "map_at_1": 0.23662,
                    "map_at_3": 0.33711,
                    "map_at_5": 0.36364,
                    "map_at_10": 0.38884,
                    "recall_at_1": 0.23662,
                    "recall_at_3": 0.38116,
                    "recall_at_5": 0.44587,
                    "recall_at_10": 0.54229,
                    "precision_at_1": 0.47685,
                    "precision_at_3": 0.28807,
                    "precision_at_5": 0.21049,
                    "precision_at_10": 0.1341,
                    "mrr_at_1": 0.47685185185185186,
                    "mrr_at_3": 0.5295781893004113,
                    "mrr_at_5": 0.5431584362139915,
                    "mrr_at_10": 0.5553222369194593,
                    "main_score": 0.47199,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 315.3807280063629,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.16714,
                    "ndcg_at_3": 0.2818,
                    "ndcg_at_5": 0.33303,
                    "ndcg_at_10": 0.40303,
                    "ndcg_at_20": 0.44385,
                    "map_at_1": 0.16714,
                    "map_at_3": 0.25273,
                    "map_at_5": 0.28096,
                    "map_at_10": 0.30949,
                    "map_at_20": 0.32097,
                    "recall_at_1": 0.16714,
                    "recall_at_3": 0.36629,
                    "recall_at_5": 0.49147,
                    "recall_at_10": 0.70982,
                    "recall_at_20": 0.86913,
                    "precision_at_1": 0.16714,
                    "precision_at_3": 0.1221,
                    "precision_at_5": 0.09829,
                    "precision_at_10": 0.07098,
                    "precision_at_20": 0.04346,
                    "mrr_at_1": 0.16998577524893316,
                    "mrr_at_3": 0.2537932669511616,
                    "mrr_at_5": 0.28185158843053515,
                    "mrr_at_10": 0.31060393099866757,
                    "mrr_at_20": 0.32221628305830624,
                    "main_score": 0.40303,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 48.28921842575073,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.34259,
                    "ndcg_at_3": 0.34636,
                    "ndcg_at_5": 0.36278,
                    "ndcg_at_10": 0.3915,
                    "ndcg_at_20": 0.41904,
                    "map_at_1": 0.22072,
                    "map_at_3": 0.29357,
                    "map_at_5": 0.31236,
                    "map_at_10": 0.3294,
                    "map_at_20": 0.33928,
                    "recall_at_1": 0.22072,
                    "recall_at_3": 0.34607,
                    "recall_at_5": 0.40064,
                    "recall_at_10": 0.48478,
                    "recall_at_20": 0.57833,
                    "precision_at_1": 0.34259,
                    "precision_at_3": 0.1973,
                    "precision_at_5": 0.14174,
                    "precision_at_10": 0.08812,
                    "precision_at_20": 0.05318,
                    "mrr_at_1": 0.3425856464116029,
                    "mrr_at_3": 0.39722430607651865,
                    "mrr_at_5": 0.40897724431107785,
                    "mrr_at_10": 0.4195652087625073,
                    "mrr_at_20": 0.42546518078973966,
                    "main_score": 0.3915,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 260.7527630329132,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.76324,
                    "ndcg_at_3": 0.71165,
                    "ndcg_at_5": 0.69171,
                    "ndcg_at_10": 0.69123,
                    "map_at_1": 0.21036,
                    "map_at_3": 0.41166,
                    "map_at_5": 0.50549,
                    "map_at_10": 0.58746,
                    "recall_at_1": 0.21036,
                    "recall_at_3": 0.43966,
                    "recall_at_5": 0.55952,
                    "recall_at_10": 0.68881,
                    "precision_at_1": 0.76324,
                    "precision_at_3": 0.62986,
                    "precision_at_5": 0.52445,
                    "precision_at_10": 0.35131,
                    "mrr_at_1": 0.7632386463264949,
                    "mrr_at_3": 0.8076231807820472,
                    "mrr_at_5": 0.8138457829212754,
                    "mrr_at_10": 0.8175539398645706,
                    "main_score": 0.69123,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 5180.208173274994,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.44118,
                    "ndcg_at_3": 0.41206,
                    "ndcg_at_5": 0.39404,
                    "ndcg_at_10": 0.36558,
                    "ndcg_at_20": 0.33969,
                    "map_at_1": 0.045,
                    "map_at_3": 0.08941,
                    "map_at_5": 0.1081,
                    "map_at_10": 0.13023,
                    "map_at_20": 0.14715,
                    "recall_at_1": 0.045,
                    "recall_at_3": 0.10375,
                    "recall_at_5": 0.13409,
                    "recall_at_10": 0.17495,
                    "recall_at_20": 0.21344,
                    "precision_at_1": 0.4613,
                    "precision_at_3": 0.39835,
                    "precision_at_5": 0.35604,
                    "precision_at_10": 0.28607,
                    "precision_at_20": 0.21223,
                    "mrr_at_1": 0.4613003095975232,
                    "mrr_at_3": 0.5371517027863779,
                    "mrr_at_5": 0.5469040247678021,
                    "mrr_at_10": 0.5543454223794781,
                    "mrr_at_20": 0.5560201362350095,
                    "main_score": 0.36558,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 54.692362546920776,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "2e643e7363944af1c33a652d1c87320d0871c4e4",
        "task_name": "NarrativeQAChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.60197,
                    "ndcg_at_3": 0.67509,
                    "ndcg_at_5": 0.69039,
                    "ndcg_at_10": 0.70513,
                    "ndcg_at_20": 0.71548,
                    "map_at_1": 0.60197,
                    "map_at_3": 0.65757,
                    "map_at_5": 0.66609,
                    "map_at_10": 0.67224,
                    "map_at_20": 0.67509,
                    "recall_at_1": 0.60197,
                    "recall_at_3": 0.72558,
                    "recall_at_5": 0.76262,
                    "recall_at_10": 0.8079,
                    "recall_at_20": 0.84873,
                    "precision_at_1": 0.60197,
                    "precision_at_3": 0.24186,
                    "precision_at_5": 0.15252,
                    "precision_at_10": 0.08079,
                    "precision_at_20": 0.04244,
                    "mrr_at_1": 0.6019702567017146,
                    "mrr_at_3": 0.6575731741972116,
                    "mrr_at_5": 0.666093587193326,
                    "mrr_at_10": 0.6722370322256622,
                    "mrr_at_20": 0.6750918442795621,
                    "main_score": 0.70513,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 1200.1970369815826,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.46138,
                    "ndcg_at_3": 0.55085,
                    "ndcg_at_5": 0.57416,
                    "ndcg_at_10": 0.59473,
                    "ndcg_at_20": 0.6086,
                    "map_at_1": 0.4613,
                    "map_at_3": 0.52907,
                    "map_at_5": 0.54202,
                    "map_at_10": 0.55057,
                    "map_at_20": 0.55442,
                    "recall_at_1": 0.4613,
                    "recall_at_3": 0.61373,
                    "recall_at_5": 0.67025,
                    "recall_at_10": 0.73349,
                    "recall_at_20": 0.78804,
                    "precision_at_1": 0.46138,
                    "precision_at_3": 0.20464,
                    "precision_at_5": 0.13409,
                    "precision_at_10": 0.07338,
                    "precision_at_20": 0.03942,
                    "mrr_at_1": 0.4613755934813294,
                    "mrr_at_3": 0.5291287052483112,
                    "mrr_at_5": 0.5420746182471629,
                    "mrr_at_10": 0.5506302970309274,
                    "mrr_at_20": 0.5544738558609807,
                    "main_score": 0.59473,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 108.97498774528503,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.37365,
                    "ndcg_at_3": 0.43095,
                    "ndcg_at_5": 0.44688,
                    "ndcg_at_10": 0.46307,
                    "ndcg_at_20": 0.47505,
                    "map_at_1": 0.37363,
                    "map_at_3": 0.41694,
                    "map_at_5": 0.42577,
                    "map_at_10": 0.43251,
                    "map_at_20": 0.43579,
                    "recall_at_1": 0.37363,
                    "recall_at_3": 0.47145,
                    "recall_at_5": 0.51016,
                    "recall_at_10": 0.55986,
                    "recall_at_20": 0.60725,
                    "precision_at_1": 0.37365,
                    "precision_at_3": 0.15716,
                    "precision_at_5": 0.10204,
                    "precision_at_10": 0.056,
                    "precision_at_20": 0.03037,
                    "mrr_at_1": 0.3736474346176882,
                    "mrr_at_3": 0.41695614560457944,
                    "mrr_at_5": 0.4257902442270613,
                    "mrr_at_10": 0.4325433109292206,
                    "mrr_at_20": 0.43583678126391606,
                    "main_score": 0.46307,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 57.84394669532776,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.72455,
                    "ndcg_at_3": 0.76229,
                    "ndcg_at_5": 0.76926,
                    "ndcg_at_10": 0.77508,
                    "ndcg_at_20": 0.77883,
                    "map_at_1": 0.72455,
                    "map_at_3": 0.75343,
                    "map_at_5": 0.75732,
                    "map_at_10": 0.75974,
                    "map_at_20": 0.76078,
                    "recall_at_1": 0.72455,
                    "recall_at_3": 0.78775,
                    "recall_at_5": 0.8046,
                    "recall_at_10": 0.8225,
                    "recall_at_20": 0.8372,
                    "precision_at_1": 0.72455,
                    "precision_at_3": 0.26258,
                    "precision_at_5": 0.16092,
                    "precision_at_10": 0.08225,
                    "precision_at_20": 0.04186,
                    "mrr_at_1": 0.72455,
                    "mrr_at_3": 0.7534333333333373,
                    "mrr_at_5": 0.7573158333333392,
                    "mrr_at_10": 0.7597423412698464,
                    "mrr_at_20": 0.7607843545547661,
                    "main_score": 0.77508,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 325.4590938091278,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.18279,
                    "ndcg_at_3": 0.29752,
                    "ndcg_at_5": 0.34983,
                    "ndcg_at_10": 0.42,
                    "map_at_1": 0.18279,
                    "map_at_3": 0.26826,
                    "map_at_5": 0.2972,
                    "map_at_10": 0.32616,
                    "recall_at_1": 0.18279,
                    "recall_at_3": 0.38265,
                    "recall_at_5": 0.50996,
                    "recall_at_10": 0.72688,
                    "precision_at_1": 0.18279,
                    "precision_at_3": 0.12755,
                    "precision_at_5": 0.10199,
                    "precision_at_10": 0.07269,
                    "mrr_at_1": 0.18278805120910385,
                    "mrr_at_3": 0.2682550972024654,
                    "mrr_at_5": 0.29720246562351743,
                    "mrr_at_10": 0.3261630991894147,
                    "main_score": 0.42,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 111.24417233467102,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.187,
                    "ndcg_at_3": 0.15525,
                    "ndcg_at_5": 0.13374,
                    "ndcg_at_10": 0.16206,
                    "ndcg_at_20": 0.18546,
                    "map_at_1": 0.03798,
                    "map_at_3": 0.06809,
                    "map_at_5": 0.07988,
                    "map_at_10": 0.09355,
                    "map_at_20": 0.10158,
                    "recall_at_1": 0.03798,
                    "recall_at_3": 0.08873,
                    "recall_at_5": 0.11853,
                    "recall_at_10": 0.17072,
                    "recall_at_20": 0.22608,
                    "precision_at_1": 0.187,
                    "precision_at_3": 0.146,
                    "precision_at_5": 0.117,
                    "precision_at_10": 0.0842,
                    "precision_at_20": 0.05565,
                    "mrr_at_1": 0.187,
                    "mrr_at_3": 0.2563333333333334,
                    "mrr_at_5": 0.27238333333333326,
                    "mrr_at_10": 0.28567460317460297,
                    "mrr_at_20": 0.29185272964909165,
                    "main_score": 0.16206,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 418.8843083381653,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.51,
                    "ndcg_at_3": 0.60409,
                    "ndcg_at_5": 0.6215,
                    "ndcg_at_10": 0.64481,
                    "ndcg_at_20": 0.65672,
                    "map_at_1": 0.48178,
                    "map_at_3": 0.56999,
                    "map_at_5": 0.58167,
                    "map_at_10": 0.59291,
                    "map_at_20": 0.59694,
                    "recall_at_1": 0.48178,
                    "recall_at_3": 0.6735,
                    "recall_at_5": 0.71989,
                    "recall_at_10": 0.78678,
                    "recall_at_20": 0.83022,
                    "precision_at_1": 0.51,
                    "precision_at_3": 0.24444,
                    "precision_at_5": 0.158,
                    "precision_at_10": 0.08833,
                    "precision_at_20": 0.04683,
                    "mrr_at_1": 0.51,
                    "mrr_at_3": 0.5900000000000001,
                    "mrr_at_5": 0.6003333333333333,
                    "mrr_at_10": 0.6087896825396826,
                    "mrr_at_20": 0.6116161523661522,
                    "main_score": 0.64481,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 120.90220093727112,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.44118,
                    "ndcg_at_3": 0.401,
                    "ndcg_at_5": 0.38321,
                    "ndcg_at_10": 0.35414,
                    "map_at_1": 0.04842,
                    "map_at_3": 0.08854,
                    "map_at_5": 0.10645,
                    "map_at_10": 0.12717,
                    "recall_at_1": 0.04842,
                    "recall_at_3": 0.10222,
                    "recall_at_5": 0.13183,
                    "recall_at_10": 0.16688,
                    "precision_at_1": 0.45511,
                    "precision_at_3": 0.38596,
                    "precision_at_5": 0.34365,
                    "precision_at_10": 0.2743,
                    "mrr_at_1": 0.4582043343653251,
                    "mrr_at_3": 0.5309597523219816,
                    "mrr_at_5": 0.5399380804953561,
                    "mrr_at_10": 0.5456889773453241,
                    "main_score": 0.35414,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 36.20045614242554,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.60161,
                    "ndcg_at_3": 0.67765,
                    "ndcg_at_5": 0.69335,
                    "ndcg_at_10": 0.70776,
                    "ndcg_at_20": 0.71747,
                    "map_at_1": 0.60124,
                    "map_at_3": 0.6596,
                    "map_at_5": 0.66835,
                    "map_at_10": 0.67431,
                    "map_at_20": 0.677,
                    "recall_at_1": 0.60124,
                    "recall_at_3": 0.72942,
                    "recall_at_5": 0.7674,
                    "recall_at_10": 0.81187,
                    "recall_at_20": 0.85005,
                    "precision_at_1": 0.60161,
                    "precision_at_3": 0.24343,
                    "precision_at_5": 0.1537,
                    "precision_at_10": 0.08131,
                    "precision_at_20": 0.04258,
                    "mrr_at_1": 0.6016088309553168,
                    "mrr_at_3": 0.6597870549781709,
                    "mrr_at_5": 0.6684947057326834,
                    "mrr_at_10": 0.6744457003242456,
                    "mrr_at_20": 0.677140386108049,
                    "main_score": 0.70776,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 134.32969427108765,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.45,
                    "ndcg_at_3": 0.52008,
                    "ndcg_at_5": 0.56142,
                    "ndcg_at_10": 0.58529,
                    "ndcg_at_20": 0.59894,
                    "map_at_1": 0.429,
                    "map_at_3": 0.49356,
                    "map_at_5": 0.51871,
                    "map_at_10": 0.5301,
                    "map_at_20": 0.53433,
                    "recall_at_1": 0.429,
                    "recall_at_3": 0.56978,
                    "recall_at_5": 0.67167,
                    "recall_at_10": 0.74028,
                    "recall_at_20": 0.79122,
                    "precision_at_1": 0.45,
                    "precision_at_3": 0.20667,
                    "precision_at_5": 0.148,
                    "precision_at_10": 0.083,
                    "precision_at_20": 0.04467,
                    "mrr_at_1": 0.45,
                    "mrr_at_3": 0.5144444444444446,
                    "mrr_at_5": 0.5362777777777781,
                    "mrr_at_10": 0.545043650793651,
                    "mrr_at_20": 0.5485634069089954,
                    "main_score": 0.58529,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 123.8386058807373,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.7719,
                    "ndcg_at_3": 0.80497,
                    "ndcg_at_5": 0.81136,
                    "ndcg_at_10": 0.81673,
                    "ndcg_at_20": 0.81958,
                    "map_at_1": 0.7719,
                    "map_at_3": 0.79723,
                    "map_at_5": 0.80079,
                    "map_at_10": 0.80302,
                    "map_at_20": 0.8038,
                    "recall_at_1": 0.7719,
                    "recall_at_3": 0.8272,
                    "recall_at_5": 0.8427,
                    "recall_at_10": 0.85915,
                    "recall_at_20": 0.8705,
                    "precision_at_1": 0.7719,
                    "precision_at_3": 0.27573,
                    "precision_at_5": 0.16854,
                    "precision_at_10": 0.08591,
                    "precision_at_20": 0.04352,
                    "mrr_at_1": 0.7719,
                    "mrr_at_3": 0.7972333333333368,
                    "mrr_at_5": 0.8007858333333384,
                    "mrr_at_10": 0.8030249801587345,
                    "mrr_at_20": 0.8037988487572428,
                    "main_score": 0.81673,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 404.2583360671997,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.69125,
                    "ndcg_at_3": 0.76916,
                    "ndcg_at_5": 0.78741,
                    "ndcg_at_10": 0.80259,
                    "ndcg_at_20": 0.81112,
                    "map_at_1": 0.68967,
                    "map_at_3": 0.75018,
                    "map_at_5": 0.76025,
                    "map_at_10": 0.7669,
                    "map_at_20": 0.76934,
                    "recall_at_1": 0.68967,
                    "recall_at_3": 0.8235,
                    "recall_at_5": 0.86723,
                    "recall_at_10": 0.91307,
                    "recall_at_20": 0.94626,
                    "precision_at_1": 0.69125,
                    "precision_at_3": 0.27573,
                    "precision_at_5": 0.17471,
                    "precision_at_10": 0.0922,
                    "precision_at_20": 0.04779,
                    "mrr_at_1": 0.6912539515279241,
                    "mrr_at_3": 0.7506146821215315,
                    "mrr_at_5": 0.7609940288022483,
                    "mrr_at_10": 0.7670321307307613,
                    "mrr_at_20": 0.7693750339595573,
                    "main_score": 0.80259,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2000.2580454349518,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.556,
                    "ndcg_at_3": 0.66537,
                    "ndcg_at_5": 0.68925,
                    "ndcg_at_10": 0.70643,
                    "ndcg_at_20": 0.71895,
                    "map_at_1": 0.556,
                    "map_at_3": 0.63883,
                    "map_at_5": 0.65208,
                    "map_at_10": 0.6592,
                    "map_at_20": 0.66257,
                    "recall_at_1": 0.556,
                    "recall_at_3": 0.742,
                    "recall_at_5": 0.8,
                    "recall_at_10": 0.853,
                    "recall_at_20": 0.903,
                    "precision_at_1": 0.556,
                    "precision_at_3": 0.24733,
                    "precision_at_5": 0.16,
                    "precision_at_10": 0.0853,
                    "precision_at_20": 0.04515,
                    "mrr_at_1": 0.556,
                    "mrr_at_3": 0.6388333333333334,
                    "mrr_at_5": 0.6520833333333335,
                    "mrr_at_10": 0.6592007936507936,
                    "mrr_at_20": 0.6625737636288719,
                    "main_score": 0.70643,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 253.41973185539246,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.7984,
                    "ndcg_at_3": 0.75351,
                    "ndcg_at_5": 0.73738,
                    "ndcg_at_10": 0.73893,
                    "map_at_1": 0.2252,
                    "map_at_3": 0.44616,
                    "map_at_5": 0.55028,
                    "map_at_10": 0.64134,
                    "recall_at_1": 0.2252,
                    "recall_at_3": 0.47341,
                    "recall_at_5": 0.60319,
                    "recall_at_10": 0.73906,
                    "precision_at_1": 0.7984,
                    "precision_at_3": 0.6663,
                    "precision_at_5": 0.5586,
                    "precision_at_10": 0.37556,
                    "mrr_at_1": 0.7983955812730142,
                    "mrr_at_3": 0.8386083347945538,
                    "mrr_at_5": 0.8442764042316953,
                    "mrr_at_10": 0.8474085972573641,
                    "main_score": 0.73893,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 4660.29131603241,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.56,
                    "ndcg_at_3": 0.66902,
                    "ndcg_at_5": 0.69166,
                    "ndcg_at_10": 0.7069,
                    "ndcg_at_20": 0.7186,
                    "map_at_1": 0.56,
                    "map_at_3": 0.643,
                    "map_at_5": 0.65555,
                    "map_at_10": 0.66206,
                    "map_at_20": 0.66531,
                    "recall_at_1": 0.56,
                    "recall_at_3": 0.744,
                    "recall_at_5": 0.799,
                    "recall_at_10": 0.845,
                    "recall_at_20": 0.891,
                    "precision_at_1": 0.56,
                    "precision_at_3": 0.248,
                    "precision_at_5": 0.1598,
                    "precision_at_10": 0.0845,
                    "precision_at_20": 0.04455,
                    "mrr_at_1": 0.56,
                    "mrr_at_3": 0.6430000000000001,
                    "mrr_at_5": 0.6555500000000001,
                    "mrr_at_10": 0.662056349206349,
                    "mrr_at_20": 0.6653066414966181,
                    "main_score": 0.7069,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 649.1508295536041,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.44118,
                    "ndcg_at_3": 0.51925,
                    "ndcg_at_5": 0.53802,
                    "ndcg_at_10": 0.55612,
                    "ndcg_at_20": 0.56906,
                    "map_at_1": 0.44066,
                    "map_at_3": 0.50005,
                    "map_at_5": 0.5105,
                    "map_at_10": 0.51807,
                    "map_at_20": 0.52166,
                    "recall_at_1": 0.44066,
                    "recall_at_3": 0.57402,
                    "recall_at_5": 0.61939,
                    "recall_at_10": 0.67482,
                    "recall_at_20": 0.72556,
                    "precision_at_1": 0.44118,
                    "precision_at_3": 0.19189,
                    "precision_at_5": 0.12436,
                    "precision_at_10": 0.06786,
                    "precision_at_20": 0.03655,
                    "mrr_at_1": 0.4411830943622851,
                    "mrr_at_3": 0.5007319270325121,
                    "mrr_at_5": 0.5111440582538966,
                    "mrr_at_10": 0.518662009382499,
                    "mrr_at_20": 0.522206569226194,
                    "main_score": 0.55612,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 109.12721014022827,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.31133,
                    "ndcg_at_3": 0.31269,
                    "ndcg_at_5": 0.32961,
                    "ndcg_at_10": 0.35828,
                    "map_at_1": 0.20049,
                    "map_at_3": 0.26445,
                    "map_at_5": 0.28213,
                    "map_at_10": 0.2984,
                    "recall_at_1": 0.20049,
                    "recall_at_3": 0.31008,
                    "recall_at_5": 0.36482,
                    "recall_at_10": 0.44876,
                    "precision_at_1": 0.31133,
                    "precision_at_3": 0.17829,
                    "precision_at_5": 0.12893,
                    "precision_at_10": 0.08122,
                    "mrr_at_1": 0.3113278319579895,
                    "mrr_at_3": 0.36225723097440976,
                    "mrr_at_5": 0.37487288488788867,
                    "mrr_at_10": 0.3860032468434563,
                    "main_score": 0.35828,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 533.3634402751923,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.39141,
                    "ndcg_at_3": 0.45407,
                    "ndcg_at_5": 0.47096,
                    "ndcg_at_10": 0.48733,
                    "ndcg_at_20": 0.4997,
                    "map_at_1": 0.39109,
                    "map_at_3": 0.43868,
                    "map_at_5": 0.44807,
                    "map_at_10": 0.45485,
                    "map_at_20": 0.45823,
                    "recall_at_1": 0.39109,
                    "recall_at_3": 0.49796,
                    "recall_at_5": 0.53911,
                    "recall_at_10": 0.58955,
                    "recall_at_20": 0.63844,
                    "precision_at_1": 0.39141,
                    "precision_at_3": 0.16617,
                    "precision_at_5": 0.10797,
                    "precision_at_10": 0.05908,
                    "precision_at_20": 0.03201,
                    "mrr_at_1": 0.3914068745003997,
                    "mrr_at_3": 0.4390820676791929,
                    "mrr_at_5": 0.4484865440980599,
                    "mrr_at_10": 0.45530312258130595,
                    "mrr_at_20": 0.4587060679363996,
                    "main_score": 0.48733,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 59.0006468296051,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.89936,
                    "ndcg_at_3": 0.93207,
                    "ndcg_at_5": 0.9368,
                    "ndcg_at_10": 0.93983,
                    "ndcg_at_20": 0.94155,
                    "map_at_1": 0.89936,
                    "map_at_3": 0.92444,
                    "map_at_5": 0.92707,
                    "map_at_10": 0.92834,
                    "map_at_20": 0.92881,
                    "recall_at_1": 0.89936,
                    "recall_at_3": 0.95399,
                    "recall_at_5": 0.96545,
                    "recall_at_10": 0.97473,
                    "recall_at_20": 0.98152,
                    "precision_at_1": 0.89936,
                    "precision_at_3": 0.318,
                    "precision_at_5": 0.19309,
                    "precision_at_10": 0.09747,
                    "precision_at_20": 0.04908,
                    "mrr_at_1": 0.8993559848989563,
                    "mrr_at_3": 0.9244429639499583,
                    "mrr_at_5": 0.9270656599304178,
                    "mrr_at_10": 0.9283368406952693,
                    "mrr_at_20": 0.9288105626423643,
                    "main_score": 0.93983,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 167.13765025138855,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.156,
                    "ndcg_at_3": 0.12758,
                    "ndcg_at_5": 0.11226,
                    "ndcg_at_10": 0.13882,
                    "map_at_1": 0.03188,
                    "map_at_3": 0.0554,
                    "map_at_5": 0.06615,
                    "map_at_10": 0.07844,
                    "recall_at_1": 0.03188,
                    "recall_at_3": 0.07333,
                    "recall_at_5": 0.10068,
                    "recall_at_10": 0.14955,
                    "precision_at_1": 0.156,
                    "precision_at_3": 0.12033,
                    "precision_at_5": 0.0994,
                    "precision_at_10": 0.0737,
                    "mrr_at_1": 0.156,
                    "mrr_at_3": 0.2136666666666669,
                    "mrr_at_5": 0.22951666666666676,
                    "mrr_at_10": 0.24210317460317463,
                    "main_score": 0.13882,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 344.8067977428436,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.8785,
                    "ndcg_at_3": 0.83488,
                    "ndcg_at_5": 0.82156,
                    "ndcg_at_10": 0.84566,
                    "map_at_1": 0.25139,
                    "map_at_3": 0.52968,
                    "map_at_5": 0.66557,
                    "map_at_10": 0.76418,
                    "recall_at_1": 0.25139,
                    "recall_at_3": 0.55615,
                    "recall_at_5": 0.71903,
                    "recall_at_10": 0.85925,
                    "precision_at_1": 0.8785,
                    "precision_at_3": 0.7495,
                    "precision_at_5": 0.6293,
                    "precision_at_10": 0.4062,
                    "mrr_at_1": 0.8785,
                    "mrr_at_3": 0.9124999999999998,
                    "mrr_at_5": 0.9152999999999999,
                    "mrr_at_10": 0.9165700396825395,
                    "main_score": 0.84566,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 491.58931064605713,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.47318,
                    "ndcg_at_3": 0.54027,
                    "ndcg_at_5": 0.55688,
                    "ndcg_at_10": 0.57327,
                    "ndcg_at_20": 0.58603,
                    "map_at_1": 0.47311,
                    "map_at_3": 0.52399,
                    "map_at_5": 0.5332,
                    "map_at_10": 0.53997,
                    "map_at_20": 0.54348,
                    "recall_at_1": 0.47311,
                    "recall_at_3": 0.58694,
                    "recall_at_5": 0.62737,
                    "recall_at_10": 0.67792,
                    "recall_at_20": 0.72832,
                    "precision_at_1": 0.47318,
                    "precision_at_3": 0.1958,
                    "precision_at_5": 0.1256,
                    "precision_at_10": 0.06788,
                    "precision_at_20": 0.03647,
                    "mrr_at_1": 0.4731814548361311,
                    "mrr_at_3": 0.5242139621636074,
                    "mrr_at_5": 0.5334585664801581,
                    "mrr_at_10": 0.5402599190488966,
                    "mrr_at_20": 0.5437704494148178,
                    "main_score": 0.57327,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 73.73582887649536,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.35759,
                    "ndcg_at_3": 0.33054,
                    "ndcg_at_5": 0.31039,
                    "ndcg_at_10": 0.28223,
                    "ndcg_at_20": 0.25984,
                    "map_at_1": 0.04297,
                    "map_at_3": 0.07478,
                    "map_at_5": 0.08616,
                    "map_at_10": 0.10059,
                    "map_at_20": 0.11015,
                    "recall_at_1": 0.04297,
                    "recall_at_3": 0.08407,
                    "recall_at_5": 0.10335,
                    "recall_at_10": 0.1334,
                    "recall_at_20": 0.16626,
                    "precision_at_1": 0.3839,
                    "precision_at_3": 0.31373,
                    "precision_at_5": 0.27059,
                    "precision_at_10": 0.20836,
                    "precision_at_20": 0.15093,
                    "mrr_at_1": 0.39009287925696595,
                    "mrr_at_3": 0.4535603715170279,
                    "mrr_at_5": 0.4674922600619195,
                    "mrr_at_10": 0.47450734679836837,
                    "mrr_at_20": 0.4783315047264907,
                    "main_score": 0.28223,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 68.27749562263489,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.3764,
                    "ndcg_at_3": 0.45351,
                    "ndcg_at_5": 0.47535,
                    "ndcg_at_10": 0.49597,
                    "ndcg_at_20": 0.51128,
                    "map_at_1": 0.37583,
                    "map_at_3": 0.4345,
                    "map_at_5": 0.44665,
                    "map_at_10": 0.45524,
                    "map_at_20": 0.45947,
                    "recall_at_1": 0.37583,
                    "recall_at_3": 0.50773,
                    "recall_at_5": 0.56059,
                    "recall_at_10": 0.62377,
                    "recall_at_20": 0.68391,
                    "precision_at_1": 0.3764,
                    "precision_at_3": 0.16973,
                    "precision_at_5": 0.11257,
                    "precision_at_10": 0.06275,
                    "precision_at_20": 0.03447,
                    "mrr_at_1": 0.37639816830568273,
                    "mrr_at_3": 0.43517128343718336,
                    "mrr_at_5": 0.44733440932863705,
                    "mrr_at_10": 0.45588574193034126,
                    "mrr_at_20": 0.46008600577338865,
                    "main_score": 0.49597,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 97.73059940338135,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.51,
                    "ndcg_at_3": 0.56083,
                    "ndcg_at_5": 0.59441,
                    "ndcg_at_10": 0.61791,
                    "ndcg_at_20": 0.63263,
                    "map_at_1": 0.48133,
                    "map_at_3": 0.53817,
                    "map_at_5": 0.55948,
                    "map_at_10": 0.57048,
                    "map_at_20": 0.5755,
                    "recall_at_1": 0.48133,
                    "recall_at_3": 0.60033,
                    "recall_at_5": 0.68206,
                    "recall_at_10": 0.74967,
                    "recall_at_20": 0.80367,
                    "precision_at_1": 0.51,
                    "precision_at_3": 0.21778,
                    "precision_at_5": 0.152,
                    "precision_at_10": 0.08533,
                    "precision_at_20": 0.04617,
                    "mrr_at_1": 0.51,
                    "mrr_at_3": 0.5583333333333333,
                    "mrr_at_5": 0.5763333333333335,
                    "mrr_at_10": 0.5847698412698413,
                    "mrr_at_20": 0.5878897487960958,
                    "main_score": 0.61791,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 39.59570837020874,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.67249,
                    "ndcg_at_3": 0.74342,
                    "ndcg_at_5": 0.76278,
                    "ndcg_at_10": 0.77963,
                    "ndcg_at_20": 0.78816,
                    "map_at_1": 0.65054,
                    "map_at_3": 0.72269,
                    "map_at_5": 0.7341,
                    "map_at_10": 0.74156,
                    "map_at_20": 0.74406,
                    "recall_at_1": 0.65054,
                    "recall_at_3": 0.79454,
                    "recall_at_5": 0.8406,
                    "recall_at_10": 0.89113,
                    "recall_at_20": 0.92387,
                    "precision_at_1": 0.67249,
                    "precision_at_3": 0.27956,
                    "precision_at_5": 0.17817,
                    "precision_at_10": 0.09466,
                    "precision_at_20": 0.04915,
                    "mrr_at_1": 0.6724928366762177,
                    "mrr_at_3": 0.7313514804202483,
                    "mrr_at_5": 0.7413514804202456,
                    "mrr_at_10": 0.7478446354664099,
                    "mrr_at_20": 0.7500416546085089,
                    "main_score": 0.77963,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 86.63365268707275,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.45762,
                    "ndcg_at_3": 0.52092,
                    "ndcg_at_5": 0.53718,
                    "ndcg_at_10": 0.55385,
                    "ndcg_at_20": 0.56606,
                    "map_at_1": 0.45756,
                    "map_at_3": 0.5056,
                    "map_at_5": 0.51465,
                    "map_at_10": 0.52155,
                    "map_at_20": 0.5249,
                    "recall_at_1": 0.45756,
                    "recall_at_3": 0.56488,
                    "recall_at_5": 0.60435,
                    "recall_at_10": 0.65574,
                    "recall_at_20": 0.70402,
                    "precision_at_1": 0.45762,
                    "precision_at_3": 0.18839,
                    "precision_at_5": 0.12094,
                    "precision_at_10": 0.06563,
                    "precision_at_20": 0.03525,
                    "mrr_at_1": 0.45757636254741463,
                    "mrr_at_3": 0.5057629600053289,
                    "mrr_at_5": 0.5147986956811161,
                    "mrr_at_10": 0.5217147071778825,
                    "mrr_at_20": 0.5250750669606847,
                    "main_score": 0.55385,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 84.99928736686707,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.50759,
                    "ndcg_at_3": 0.57674,
                    "ndcg_at_5": 0.59327,
                    "ndcg_at_10": 0.61036,
                    "ndcg_at_20": 0.62196,
                    "map_at_1": 0.50749,
                    "map_at_3": 0.56002,
                    "map_at_5": 0.5692,
                    "map_at_10": 0.57631,
                    "map_at_20": 0.57951,
                    "recall_at_1": 0.50749,
                    "recall_at_3": 0.62479,
                    "recall_at_5": 0.66486,
                    "recall_at_10": 0.71735,
                    "recall_at_20": 0.76301,
                    "precision_at_1": 0.50759,
                    "precision_at_3": 0.20837,
                    "precision_at_5": 0.13307,
                    "precision_at_10": 0.07181,
                    "precision_at_20": 0.03821,
                    "mrr_at_1": 0.5076338928856915,
                    "mrr_at_3": 0.5602184918731737,
                    "mrr_at_5": 0.5694151345590291,
                    "mrr_at_10": 0.5765539155976889,
                    "mrr_at_20": 0.5797719386686078,
                    "main_score": 0.61036,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 96.07763957977295,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.84419,
                    "ndcg_at_3": 0.88733,
                    "ndcg_at_5": 0.89498,
                    "ndcg_at_10": 0.90099,
                    "ndcg_at_20": 0.90417,
                    "map_at_1": 0.84419,
                    "map_at_3": 0.87716,
                    "map_at_5": 0.88143,
                    "map_at_10": 0.88394,
                    "map_at_20": 0.88482,
                    "recall_at_1": 0.84419,
                    "recall_at_3": 0.91659,
                    "recall_at_5": 0.93507,
                    "recall_at_10": 0.95345,
                    "recall_at_20": 0.96602,
                    "precision_at_1": 0.84419,
                    "precision_at_3": 0.30553,
                    "precision_at_5": 0.18701,
                    "precision_at_10": 0.09535,
                    "precision_at_20": 0.0483,
                    "mrr_at_1": 0.8441927603819676,
                    "mrr_at_3": 0.8771633725664366,
                    "mrr_at_5": 0.8814271966836945,
                    "mrr_at_10": 0.8839412173189679,
                    "mrr_at_20": 0.8848220825487816,
                    "main_score": 0.90099,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 48.3236870765686,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.46798,
                    "ndcg_at_3": 0.55694,
                    "ndcg_at_5": 0.57991,
                    "ndcg_at_10": 0.60065,
                    "ndcg_at_20": 0.61461,
                    "map_at_1": 0.46791,
                    "map_at_3": 0.53531,
                    "map_at_5": 0.54806,
                    "map_at_10": 0.55668,
                    "map_at_20": 0.56056,
                    "recall_at_1": 0.46791,
                    "recall_at_3": 0.61934,
                    "recall_at_5": 0.67507,
                    "recall_at_10": 0.73888,
                    "recall_at_20": 0.79371,
                    "precision_at_1": 0.46798,
                    "precision_at_3": 0.20649,
                    "precision_at_5": 0.13506,
                    "precision_at_10": 0.07393,
                    "precision_at_20": 0.03971,
                    "mrr_at_1": 0.4679840882843578,
                    "mrr_at_3": 0.5353682792249568,
                    "mrr_at_5": 0.548137751828582,
                    "mrr_at_10": 0.5567540135734506,
                    "mrr_at_20": 0.5606362449349408,
                    "main_score": 0.60065,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 89.42725038528442,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.489,
                    "ndcg_at_3": 0.54172,
                    "ndcg_at_5": 0.55524,
                    "ndcg_at_10": 0.56723,
                    "ndcg_at_20": 0.57564,
                    "map_at_1": 0.489,
                    "map_at_3": 0.52883,
                    "map_at_5": 0.53628,
                    "map_at_10": 0.54106,
                    "map_at_20": 0.54341,
                    "recall_at_1": 0.489,
                    "recall_at_3": 0.579,
                    "recall_at_5": 0.612,
                    "recall_at_10": 0.65,
                    "recall_at_20": 0.683,
                    "precision_at_1": 0.489,
                    "precision_at_3": 0.193,
                    "precision_at_5": 0.1224,
                    "precision_at_10": 0.065,
                    "precision_at_20": 0.03415,
                    "mrr_at_1": 0.489,
                    "mrr_at_3": 0.528833333333333,
                    "mrr_at_5": 0.536283333333333,
                    "mrr_at_10": 0.5410630952380951,
                    "mrr_at_20": 0.5434115469454863,
                    "main_score": 0.56723,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 547.4931690692902,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.238,
                    "ndcg_at_3": 0.19151,
                    "ndcg_at_5": 0.16375,
                    "ndcg_at_10": 0.19795,
                    "ndcg_at_20": 0.229,
                    "map_at_1": 0.04843,
                    "map_at_3": 0.08592,
                    "map_at_5": 0.10055,
                    "map_at_10": 0.11739,
                    "map_at_20": 0.1286,
                    "recall_at_1": 0.04843,
                    "recall_at_3": 0.10853,
                    "recall_at_5": 0.14322,
                    "recall_at_10": 0.20615,
                    "recall_at_20": 0.279,
                    "precision_at_1": 0.238,
                    "precision_at_3": 0.17833,
                    "precision_at_5": 0.1412,
                    "precision_at_10": 0.1017,
                    "precision_at_20": 0.0688,
                    "mrr_at_1": 0.238,
                    "mrr_at_3": 0.31366666666666665,
                    "mrr_at_5": 0.3296666666666664,
                    "mrr_at_10": 0.34371587301587275,
                    "mrr_at_20": 0.35129617650581235,
                    "main_score": 0.19795,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 370.5813367366791,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "2e643e7363944af1c33a652d1c87320d0871c4e4",
        "task_name": "NarrativeQAChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.63882,
                    "ndcg_at_3": 0.70918,
                    "ndcg_at_5": 0.72448,
                    "ndcg_at_10": 0.73815,
                    "ndcg_at_20": 0.74713,
                    "map_at_1": 0.63882,
                    "map_at_3": 0.69229,
                    "map_at_5": 0.70081,
                    "map_at_10": 0.70646,
                    "map_at_20": 0.70893,
                    "recall_at_1": 0.63882,
                    "recall_at_3": 0.75789,
                    "recall_at_5": 0.79492,
                    "recall_at_10": 0.83717,
                    "recall_at_20": 0.8726,
                    "precision_at_1": 0.63882,
                    "precision_at_3": 0.25263,
                    "precision_at_5": 0.15898,
                    "precision_at_10": 0.08372,
                    "precision_at_20": 0.04363,
                    "mrr_at_1": 0.6388178459789713,
                    "mrr_at_3": 0.6922894761769407,
                    "mrr_at_5": 0.7008098891730549,
                    "mrr_at_10": 0.7064565600797457,
                    "mrr_at_20": 0.7089336346895885,
                    "main_score": 0.73815,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 1839.2939496040344,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.4321,
                    "ndcg_at_3": 0.39923,
                    "ndcg_at_5": 0.41681,
                    "ndcg_at_10": 0.44318,
                    "ndcg_at_20": 0.46812,
                    "map_at_1": 0.21569,
                    "map_at_3": 0.31196,
                    "map_at_5": 0.33994,
                    "map_at_10": 0.36141,
                    "map_at_20": 0.37111,
                    "recall_at_1": 0.21569,
                    "recall_at_3": 0.36258,
                    "recall_at_5": 0.43465,
                    "recall_at_10": 0.5193,
                    "recall_at_20": 0.59561,
                    "precision_at_1": 0.4321,
                    "precision_at_3": 0.26646,
                    "precision_at_5": 0.20185,
                    "precision_at_10": 0.12407,
                    "precision_at_20": 0.07315,
                    "mrr_at_1": 0.43209876543209874,
                    "mrr_at_3": 0.49537037037037035,
                    "mrr_at_5": 0.511574074074074,
                    "mrr_at_10": 0.5207298402900254,
                    "mrr_at_20": 0.5255242167501368,
                    "main_score": 0.44318,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 228.20745825767517,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.88776,
                    "ndcg_at_3": 0.92216,
                    "ndcg_at_5": 0.92743,
                    "ndcg_at_10": 0.93075,
                    "ndcg_at_20": 0.93277,
                    "map_at_1": 0.88776,
                    "map_at_3": 0.91418,
                    "map_at_5": 0.91713,
                    "map_at_10": 0.91852,
                    "map_at_20": 0.91909,
                    "recall_at_1": 0.88776,
                    "recall_at_3": 0.94506,
                    "recall_at_5": 0.95776,
                    "recall_at_10": 0.96789,
                    "recall_at_20": 0.97584,
                    "precision_at_1": 0.88776,
                    "precision_at_3": 0.31502,
                    "precision_at_5": 0.19155,
                    "precision_at_10": 0.09679,
                    "precision_at_20": 0.04879,
                    "mrr_at_1": 0.8877637130801688,
                    "mrr_at_3": 0.9141757346953877,
                    "mrr_at_5": 0.9171315419350071,
                    "mrr_at_10": 0.9185237531240212,
                    "mrr_at_20": 0.9190850683569382,
                    "main_score": 0.93075,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 81.20652723312378,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.3703,
                    "ndcg_at_3": 0.45076,
                    "ndcg_at_5": 0.47422,
                    "ndcg_at_10": 0.49806,
                    "ndcg_at_20": 0.51421,
                    "map_at_1": 0.37024,
                    "map_at_3": 0.43103,
                    "map_at_5": 0.44406,
                    "map_at_10": 0.45392,
                    "map_at_20": 0.45836,
                    "recall_at_1": 0.37024,
                    "recall_at_3": 0.50776,
                    "recall_at_5": 0.56471,
                    "recall_at_10": 0.63823,
                    "recall_at_20": 0.70208,
                    "precision_at_1": 0.3703,
                    "precision_at_3": 0.16931,
                    "precision_at_5": 0.11298,
                    "precision_at_10": 0.06386,
                    "precision_at_20": 0.03513,
                    "mrr_at_1": 0.37030026947260364,
                    "mrr_at_3": 0.43107596561017103,
                    "mrr_at_5": 0.4440988707814845,
                    "mrr_at_10": 0.4539727222639899,
                    "mrr_at_20": 0.4584082706266569,
                    "main_score": 0.49806,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 36.4927031993866,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.58896,
                    "ndcg_at_3": 0.6649,
                    "ndcg_at_5": 0.6806,
                    "ndcg_at_10": 0.6951,
                    "ndcg_at_20": 0.70541,
                    "map_at_1": 0.5886,
                    "map_at_3": 0.64674,
                    "map_at_5": 0.6555,
                    "map_at_10": 0.66154,
                    "map_at_20": 0.66438,
                    "recall_at_1": 0.5886,
                    "recall_at_3": 0.71697,
                    "recall_at_5": 0.7549,
                    "recall_at_10": 0.79948,
                    "recall_at_20": 0.84017,
                    "precision_at_1": 0.58896,
                    "precision_at_3": 0.23927,
                    "precision_at_5": 0.15118,
                    "precision_at_10": 0.08008,
                    "precision_at_20": 0.04208,
                    "mrr_at_1": 0.5889554342082085,
                    "mrr_at_3": 0.6469477227800228,
                    "mrr_at_5": 0.655696475055291,
                    "mrr_at_10": 0.6616955379219792,
                    "mrr_at_20": 0.6645387374330166,
                    "main_score": 0.6951,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 56.61754631996155,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.8481,
                    "ndcg_at_3": 0.89132,
                    "ndcg_at_5": 0.89875,
                    "ndcg_at_10": 0.90447,
                    "ndcg_at_20": 0.90734,
                    "map_at_1": 0.8481,
                    "map_at_3": 0.88113,
                    "map_at_5": 0.88528,
                    "map_at_10": 0.88769,
                    "map_at_20": 0.88849,
                    "recall_at_1": 0.8481,
                    "recall_at_3": 0.92063,
                    "recall_at_5": 0.93853,
                    "recall_at_10": 0.95598,
                    "recall_at_20": 0.96727,
                    "precision_at_1": 0.8481,
                    "precision_at_3": 0.30688,
                    "precision_at_5": 0.18771,
                    "precision_at_10": 0.0956,
                    "precision_at_20": 0.04836,
                    "mrr_at_1": 0.8481012658227848,
                    "mrr_at_3": 0.8811310977866601,
                    "mrr_at_5": 0.8852838848175308,
                    "mrr_at_10": 0.8876911159755949,
                    "mrr_at_20": 0.8884884510481044,
                    "main_score": 0.90447,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 34.988394260406494,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.32495,
                    "ndcg_at_3": 0.40361,
                    "ndcg_at_5": 0.42668,
                    "ndcg_at_10": 0.45088,
                    "ndcg_at_20": 0.4678,
                    "map_at_1": 0.32431,
                    "map_at_3": 0.38406,
                    "map_at_5": 0.39695,
                    "map_at_10": 0.40699,
                    "map_at_20": 0.41167,
                    "recall_at_1": 0.32431,
                    "recall_at_3": 0.45932,
                    "recall_at_5": 0.51502,
                    "recall_at_10": 0.58956,
                    "recall_at_20": 0.65603,
                    "precision_at_1": 0.32495,
                    "precision_at_3": 0.15372,
                    "precision_at_5": 0.10357,
                    "precision_at_10": 0.05935,
                    "precision_at_20": 0.03311,
                    "mrr_at_1": 0.3248039620305406,
                    "mrr_at_3": 0.3846658912692763,
                    "mrr_at_5": 0.39751059918208437,
                    "mrr_at_10": 0.4075230222155577,
                    "mrr_at_20": 0.41215248774774277,
                    "main_score": 0.45088,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 84.31323575973511,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.44963,
                    "ndcg_at_3": 0.52824,
                    "ndcg_at_5": 0.54963,
                    "ndcg_at_10": 0.57003,
                    "ndcg_at_20": 0.58389,
                    "map_at_1": 0.44897,
                    "map_at_3": 0.5089,
                    "map_at_5": 0.52077,
                    "map_at_10": 0.52932,
                    "map_at_20": 0.53317,
                    "recall_at_1": 0.44897,
                    "recall_at_3": 0.58326,
                    "recall_at_5": 0.63514,
                    "recall_at_10": 0.69761,
                    "recall_at_20": 0.75196,
                    "precision_at_1": 0.44963,
                    "precision_at_3": 0.19506,
                    "precision_at_5": 0.1276,
                    "precision_at_10": 0.0702,
                    "precision_at_20": 0.03791,
                    "mrr_at_1": 0.44951787791243014,
                    "mrr_at_3": 0.5095861629084985,
                    "mrr_at_5": 0.5214403631861465,
                    "mrr_at_10": 0.5298712762910162,
                    "mrr_at_20": 0.5336830726712073,
                    "main_score": 0.57003,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 85.09742593765259,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.439,
                    "ndcg_at_3": 0.53072,
                    "ndcg_at_5": 0.55284,
                    "ndcg_at_10": 0.58424,
                    "ndcg_at_20": 0.59902,
                    "map_at_1": 0.439,
                    "map_at_3": 0.50817,
                    "map_at_5": 0.52037,
                    "map_at_10": 0.53334,
                    "map_at_20": 0.53746,
                    "recall_at_1": 0.439,
                    "recall_at_3": 0.596,
                    "recall_at_5": 0.65,
                    "recall_at_10": 0.747,
                    "recall_at_20": 0.805,
                    "precision_at_1": 0.439,
                    "precision_at_3": 0.19867,
                    "precision_at_5": 0.13,
                    "precision_at_10": 0.0747,
                    "precision_at_20": 0.04025,
                    "mrr_at_1": 0.439,
                    "mrr_at_3": 0.5081666666666662,
                    "mrr_at_5": 0.5203666666666661,
                    "mrr_at_10": 0.533342857142857,
                    "mrr_at_20": 0.537459959175671,
                    "main_score": 0.58424,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 72.86232042312622,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.67439,
                    "ndcg_at_3": 0.76355,
                    "ndcg_at_5": 0.78023,
                    "ndcg_at_10": 0.79573,
                    "ndcg_at_20": 0.80501,
                    "map_at_1": 0.67255,
                    "map_at_3": 0.7421,
                    "map_at_5": 0.75155,
                    "map_at_10": 0.75791,
                    "map_at_20": 0.76043,
                    "recall_at_1": 0.67255,
                    "recall_at_3": 0.82376,
                    "recall_at_5": 0.86486,
                    "recall_at_10": 0.91307,
                    "recall_at_20": 0.94995,
                    "precision_at_1": 0.67439,
                    "precision_at_3": 0.27678,
                    "precision_at_5": 0.17471,
                    "precision_at_10": 0.09231,
                    "precision_at_20": 0.048,
                    "mrr_at_1": 0.6733403582718651,
                    "mrr_at_3": 0.7427116262732704,
                    "mrr_at_5": 0.7512996136283812,
                    "mrr_at_10": 0.7575923695786713,
                    "mrr_at_20": 0.7601315316189539,
                    "main_score": 0.79573,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 598.3582789897919,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.36308,
                    "ndcg_at_3": 0.44427,
                    "ndcg_at_5": 0.46833,
                    "ndcg_at_10": 0.49086,
                    "ndcg_at_20": 0.50693,
                    "map_at_1": 0.36305,
                    "map_at_3": 0.42433,
                    "map_at_5": 0.4377,
                    "map_at_10": 0.44702,
                    "map_at_20": 0.45144,
                    "recall_at_1": 0.36305,
                    "recall_at_3": 0.50192,
                    "recall_at_5": 0.56028,
                    "recall_at_10": 0.62977,
                    "recall_at_20": 0.69324,
                    "precision_at_1": 0.36308,
                    "precision_at_3": 0.16734,
                    "precision_at_5": 0.11209,
                    "precision_at_10": 0.063,
                    "precision_at_20": 0.03468,
                    "mrr_at_1": 0.3630822533042474,
                    "mrr_at_3": 0.4243712305915636,
                    "mrr_at_5": 0.437734184524586,
                    "mrr_at_10": 0.44706450793244584,
                    "mrr_at_20": 0.45148733250823864,
                    "main_score": 0.49086,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 43.32889199256897,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.486,
                    "ndcg_at_3": 0.58882,
                    "ndcg_at_5": 0.61373,
                    "ndcg_at_10": 0.63951,
                    "ndcg_at_20": 0.65447,
                    "map_at_1": 0.486,
                    "map_at_3": 0.56383,
                    "map_at_5": 0.57753,
                    "map_at_10": 0.58831,
                    "map_at_20": 0.59244,
                    "recall_at_1": 0.486,
                    "recall_at_3": 0.661,
                    "recall_at_5": 0.722,
                    "recall_at_10": 0.801,
                    "recall_at_20": 0.86,
                    "precision_at_1": 0.486,
                    "precision_at_3": 0.22033,
                    "precision_at_5": 0.1444,
                    "precision_at_10": 0.0801,
                    "precision_at_20": 0.043,
                    "mrr_at_1": 0.486,
                    "mrr_at_3": 0.5638333333333332,
                    "mrr_at_5": 0.5775333333333331,
                    "mrr_at_10": 0.5883059523809525,
                    "mrr_at_20": 0.5924390182873543,
                    "main_score": 0.63951,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 49.818620681762695,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.33642,
                    "ndcg_at_3": 0.30456,
                    "ndcg_at_5": 0.31897,
                    "ndcg_at_10": 0.34844,
                    "ndcg_at_20": 0.3762,
                    "map_at_1": 0.16384,
                    "map_at_3": 0.22993,
                    "map_at_5": 0.25049,
                    "map_at_10": 0.27026,
                    "map_at_20": 0.28086,
                    "recall_at_1": 0.16384,
                    "recall_at_3": 0.27176,
                    "recall_at_5": 0.33211,
                    "recall_at_10": 0.42425,
                    "recall_at_20": 0.50984,
                    "precision_at_1": 0.33642,
                    "precision_at_3": 0.20525,
                    "precision_at_5": 0.15586,
                    "precision_at_10": 0.10046,
                    "precision_at_20": 0.0615,
                    "mrr_at_1": 0.33641975308641975,
                    "mrr_at_3": 0.3981481481481483,
                    "mrr_at_5": 0.4144290123456789,
                    "mrr_at_10": 0.42602390750538877,
                    "mrr_at_20": 0.4311981901835055,
                    "main_score": 0.34844,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 808.382096529007,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.30901,
                    "ndcg_at_3": 0.38031,
                    "ndcg_at_5": 0.40139,
                    "ndcg_at_10": 0.42465,
                    "ndcg_at_20": 0.44128,
                    "map_at_1": 0.30844,
                    "map_at_3": 0.36256,
                    "map_at_5": 0.37427,
                    "map_at_10": 0.38393,
                    "map_at_20": 0.38855,
                    "recall_at_1": 0.30844,
                    "recall_at_3": 0.4309,
                    "recall_at_5": 0.48194,
                    "recall_at_10": 0.5534,
                    "recall_at_20": 0.61862,
                    "precision_at_1": 0.30901,
                    "precision_at_3": 0.1441,
                    "precision_at_5": 0.09685,
                    "precision_at_10": 0.0557,
                    "precision_at_20": 0.03121,
                    "mrr_at_1": 0.3090458860165835,
                    "mrr_at_3": 0.363211145712177,
                    "mrr_at_5": 0.37500531522405306,
                    "mrr_at_10": 0.38467817435007273,
                    "mrr_at_20": 0.3892439905916435,
                    "main_score": 0.42465,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 49.056007623672485,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.28139,
                    "ndcg_at_3": 0.34904,
                    "ndcg_at_5": 0.37099,
                    "ndcg_at_10": 0.39228,
                    "ndcg_at_20": 0.41024,
                    "map_at_1": 0.28086,
                    "map_at_3": 0.33212,
                    "map_at_5": 0.34434,
                    "map_at_10": 0.35316,
                    "map_at_20": 0.35811,
                    "recall_at_1": 0.28086,
                    "recall_at_3": 0.39715,
                    "recall_at_5": 0.45033,
                    "recall_at_10": 0.51584,
                    "recall_at_20": 0.58659,
                    "precision_at_1": 0.28139,
                    "precision_at_3": 0.13288,
                    "precision_at_5": 0.09051,
                    "precision_at_10": 0.05198,
                    "precision_at_20": 0.02963,
                    "mrr_at_1": 0.28139421453494917,
                    "mrr_at_3": 0.33282682374716777,
                    "mrr_at_5": 0.3450599682337168,
                    "mrr_at_10": 0.3538819597424643,
                    "mrr_at_20": 0.3587884331218377,
                    "main_score": 0.39228,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 51.15035676956177,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.439,
                    "ndcg_at_3": 0.53072,
                    "ndcg_at_5": 0.55284,
                    "ndcg_at_10": 0.58424,
                    "ndcg_at_20": 0.59902,
                    "map_at_1": 0.439,
                    "map_at_3": 0.50817,
                    "map_at_5": 0.52037,
                    "map_at_10": 0.53334,
                    "map_at_20": 0.53746,
                    "recall_at_1": 0.439,
                    "recall_at_3": 0.596,
                    "recall_at_5": 0.65,
                    "recall_at_10": 0.747,
                    "recall_at_20": 0.805,
                    "precision_at_1": 0.439,
                    "precision_at_3": 0.19867,
                    "precision_at_5": 0.13,
                    "precision_at_10": 0.0747,
                    "precision_at_20": 0.04025,
                    "mrr_at_1": 0.439,
                    "mrr_at_3": 0.5081666666666662,
                    "mrr_at_5": 0.5203666666666661,
                    "mrr_at_10": 0.533342857142857,
                    "mrr_at_20": 0.537459959175671,
                    "main_score": 0.58424,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 72.61165928840637,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.66414,
                    "ndcg_at_3": 0.73967,
                    "ndcg_at_5": 0.75359,
                    "ndcg_at_10": 0.76529,
                    "ndcg_at_20": 0.77332,
                    "map_at_1": 0.66378,
                    "map_at_3": 0.72174,
                    "map_at_5": 0.72952,
                    "map_at_10": 0.73439,
                    "map_at_20": 0.73661,
                    "recall_at_1": 0.66378,
                    "recall_at_3": 0.791,
                    "recall_at_5": 0.82463,
                    "recall_at_10": 0.8606,
                    "recall_at_20": 0.89219,
                    "precision_at_1": 0.66414,
                    "precision_at_3": 0.26396,
                    "precision_at_5": 0.16515,
                    "precision_at_10": 0.08619,
                    "precision_at_20": 0.04469,
                    "mrr_at_1": 0.6641418589630673,
                    "mrr_at_3": 0.7219824633511347,
                    "mrr_at_5": 0.7296963380502186,
                    "mrr_at_10": 0.7345491717717335,
                    "mrr_at_20": 0.7367598816447447,
                    "main_score": 0.76529,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 130.71424770355225,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.77205,
                    "ndcg_at_3": 0.80575,
                    "ndcg_at_5": 0.81193,
                    "ndcg_at_10": 0.81726,
                    "map_at_1": 0.77205,
                    "map_at_3": 0.79785,
                    "map_at_5": 0.80127,
                    "map_at_10": 0.80351,
                    "recall_at_1": 0.77205,
                    "recall_at_3": 0.82845,
                    "recall_at_5": 0.8435,
                    "recall_at_10": 0.85975,
                    "precision_at_1": 0.77205,
                    "precision_at_3": 0.27615,
                    "precision_at_5": 0.1687,
                    "precision_at_10": 0.08597,
                    "mrr_at_1": 0.77205,
                    "mrr_at_3": 0.7978500000000034,
                    "mrr_at_5": 0.8012725000000049,
                    "mrr_at_10": 0.8035145436507979,
                    "main_score": 0.81726,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 685.4744794368744,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.28357,
                    "ndcg_at_3": 0.28266,
                    "ndcg_at_5": 0.29905,
                    "ndcg_at_10": 0.3215,
                    "ndcg_at_20": 0.34558,
                    "map_at_1": 0.1793,
                    "map_at_3": 0.23686,
                    "map_at_5": 0.25328,
                    "map_at_10": 0.26623,
                    "map_at_20": 0.27435,
                    "recall_at_1": 0.1793,
                    "recall_at_3": 0.28242,
                    "recall_at_5": 0.33385,
                    "recall_at_10": 0.40054,
                    "recall_at_20": 0.48287,
                    "precision_at_1": 0.28357,
                    "precision_at_3": 0.16112,
                    "precision_at_5": 0.11788,
                    "precision_at_10": 0.07284,
                    "precision_at_20": 0.04429,
                    "mrr_at_1": 0.2835708927231808,
                    "mrr_at_3": 0.3309577394348585,
                    "mrr_at_5": 0.34321080270067533,
                    "mrr_at_10": 0.35233828298344394,
                    "mrr_at_20": 0.35789835517866325,
                    "main_score": 0.3215,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 659.5443956851959,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.35913,
                    "ndcg_at_3": 0.32161,
                    "ndcg_at_5": 0.30836,
                    "ndcg_at_10": 0.27846,
                    "map_at_1": 0.04824,
                    "map_at_3": 0.07765,
                    "map_at_5": 0.09091,
                    "map_at_10": 0.10465,
                    "recall_at_1": 0.04824,
                    "recall_at_3": 0.08691,
                    "recall_at_5": 0.11013,
                    "recall_at_10": 0.137,
                    "precision_at_1": 0.37461,
                    "precision_at_3": 0.30134,
                    "precision_at_5": 0.26935,
                    "precision_at_10": 0.20279,
                    "mrr_at_1": 0.37770897832817335,
                    "mrr_at_3": 0.44994840041279666,
                    "mrr_at_5": 0.46666666666666673,
                    "mrr_at_10": 0.47248636296623914,
                    "main_score": 0.27846,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 38.60058832168579,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.6308,
                    "ndcg_at_3": 0.706,
                    "ndcg_at_5": 0.72735,
                    "ndcg_at_10": 0.74479,
                    "ndcg_at_20": 0.75364,
                    "map_at_1": 0.60996,
                    "map_at_3": 0.68389,
                    "map_at_5": 0.69651,
                    "map_at_10": 0.7041,
                    "map_at_20": 0.70669,
                    "recall_at_1": 0.60996,
                    "recall_at_3": 0.76053,
                    "recall_at_5": 0.8114,
                    "recall_at_10": 0.86399,
                    "recall_at_20": 0.89803,
                    "precision_at_1": 0.6308,
                    "precision_at_3": 0.26786,
                    "precision_at_5": 0.17201,
                    "precision_at_10": 0.09178,
                    "precision_at_20": 0.04777,
                    "mrr_at_1": 0.6308022922636103,
                    "mrr_at_3": 0.6929799426934109,
                    "mrr_at_5": 0.7040042979942681,
                    "mrr_at_10": 0.710813548915268,
                    "mrr_at_20": 0.7131089327414402,
                    "main_score": 0.74479,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 351.3933882713318,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "6e346642246bfb4928c560ee08640dc84d074e8c",
        "task_name": "LEMBWikimQARetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.96,
                    "ndcg_at_3": 0.97806,
                    "ndcg_at_5": 0.97934,
                    "ndcg_at_10": 0.98164,
                    "map_at_1": 0.96,
                    "map_at_3": 0.97389,
                    "map_at_5": 0.97456,
                    "map_at_10": 0.97559,
                    "recall_at_1": 0.96,
                    "recall_at_3": 0.99,
                    "recall_at_5": 0.99333,
                    "recall_at_10": 1.0,
                    "precision_at_1": 0.96,
                    "precision_at_3": 0.33,
                    "precision_at_5": 0.19867,
                    "precision_at_10": 0.1,
                    "mrr_at_1": 0.96,
                    "mrr_at_3": 0.9738888888888889,
                    "mrr_at_5": 0.9745555555555556,
                    "mrr_at_10": 0.9755873015873016,
                    "main_score": 0.98164,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 33.50607752799988,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.25178,
                    "ndcg_at_3": 0.40456,
                    "ndcg_at_5": 0.45992,
                    "ndcg_at_10": 0.50993,
                    "map_at_1": 0.25178,
                    "map_at_3": 0.36605,
                    "map_at_5": 0.3966,
                    "map_at_10": 0.41756,
                    "recall_at_1": 0.25178,
                    "recall_at_3": 0.51636,
                    "recall_at_5": 0.65149,
                    "recall_at_10": 0.80441,
                    "precision_at_1": 0.25178,
                    "precision_at_3": 0.17212,
                    "precision_at_5": 0.1303,
                    "precision_at_10": 0.08044,
                    "mrr_at_1": 0.25889046941678523,
                    "mrr_at_3": 0.36818397344713066,
                    "mrr_at_5": 0.39930061640587944,
                    "mrr_at_10": 0.42001907922960596,
                    "main_score": 0.50993,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 126.50899410247803,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.19772,
                    "ndcg_at_3": 0.31011,
                    "ndcg_at_5": 0.36422,
                    "ndcg_at_10": 0.43354,
                    "ndcg_at_20": 0.47086,
                    "map_at_1": 0.19772,
                    "map_at_3": 0.28106,
                    "map_at_5": 0.31104,
                    "map_at_10": 0.33969,
                    "map_at_20": 0.35017,
                    "recall_at_1": 0.19772,
                    "recall_at_3": 0.39474,
                    "recall_at_5": 0.52632,
                    "recall_at_10": 0.7404,
                    "recall_at_20": 0.8862,
                    "precision_at_1": 0.19772,
                    "precision_at_3": 0.13158,
                    "precision_at_5": 0.10526,
                    "precision_at_10": 0.07404,
                    "precision_at_20": 0.04431,
                    "mrr_at_1": 0.19772403982930298,
                    "mrr_at_3": 0.2809388335704122,
                    "mrr_at_5": 0.3109174964438114,
                    "mrr_at_10": 0.3395721849669213,
                    "mrr_at_20": 0.3500495281393921,
                    "main_score": 0.43354,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 74.61743521690369,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.19701,
                    "ndcg_at_3": 0.30939,
                    "ndcg_at_5": 0.36289,
                    "ndcg_at_10": 0.43247,
                    "ndcg_at_20": 0.47015,
                    "map_at_1": 0.19701,
                    "map_at_3": 0.28035,
                    "map_at_5": 0.30997,
                    "map_at_10": 0.33874,
                    "map_at_20": 0.34932,
                    "recall_at_1": 0.19701,
                    "recall_at_3": 0.39403,
                    "recall_at_5": 0.52418,
                    "recall_at_10": 0.73898,
                    "recall_at_20": 0.8862,
                    "precision_at_1": 0.19701,
                    "precision_at_3": 0.13134,
                    "precision_at_5": 0.10484,
                    "precision_at_10": 0.0739,
                    "precision_at_20": 0.04431,
                    "mrr_at_1": 0.19701280227596016,
                    "mrr_at_3": 0.28034613560929317,
                    "mrr_at_5": 0.30996917970602095,
                    "mrr_at_10": 0.33874494795547383,
                    "mrr_at_20": 0.34931899703367764,
                    "main_score": 0.43247,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 73.90514469146729,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.6904,
                    "ndcg_at_3": 0.7595,
                    "ndcg_at_5": 0.77936,
                    "ndcg_at_10": 0.79599,
                    "ndcg_at_20": 0.80289,
                    "map_at_1": 0.66722,
                    "map_at_3": 0.73946,
                    "map_at_5": 0.75134,
                    "map_at_10": 0.75856,
                    "map_at_20": 0.7606,
                    "recall_at_1": 0.66722,
                    "recall_at_3": 0.80889,
                    "recall_at_5": 0.85608,
                    "recall_at_10": 0.90611,
                    "recall_at_20": 0.93255,
                    "precision_at_1": 0.6904,
                    "precision_at_3": 0.28529,
                    "precision_at_5": 0.18178,
                    "precision_at_10": 0.09628,
                    "precision_at_20": 0.0496,
                    "mrr_at_1": 0.6904011461318051,
                    "mrr_at_3": 0.7477077363896851,
                    "mrr_at_5": 0.7578510028653274,
                    "mrr_at_10": 0.7645012393687177,
                    "mrr_at_20": 0.7662835884026064,
                    "main_score": 0.79599,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 421.0220239162445,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.48148,
                    "ndcg_at_3": 0.43073,
                    "ndcg_at_5": 0.44175,
                    "ndcg_at_10": 0.47246,
                    "ndcg_at_20": 0.50161,
                    "map_at_1": 0.2381,
                    "map_at_3": 0.33948,
                    "map_at_5": 0.36561,
                    "map_at_10": 0.39014,
                    "map_at_20": 0.40217,
                    "recall_at_1": 0.2381,
                    "recall_at_3": 0.38114,
                    "recall_at_5": 0.44789,
                    "recall_at_10": 0.54069,
                    "recall_at_20": 0.63172,
                    "precision_at_1": 0.48148,
                    "precision_at_3": 0.28858,
                    "precision_at_5": 0.21049,
                    "precision_at_10": 0.1338,
                    "precision_at_20": 0.07894,
                    "mrr_at_1": 0.48148148148148145,
                    "mrr_at_3": 0.5298353909465019,
                    "mrr_at_5": 0.5454989711934154,
                    "mrr_at_10": 0.5569113756613755,
                    "mrr_at_20": 0.561989301464598,
                    "main_score": 0.47246,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 231.98330760002136,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.7716,
                    "ndcg_at_3": 0.80484,
                    "ndcg_at_5": 0.81118,
                    "ndcg_at_10": 0.81652,
                    "ndcg_at_20": 0.81944,
                    "map_at_1": 0.7716,
                    "map_at_3": 0.79708,
                    "map_at_5": 0.8006,
                    "map_at_10": 0.80284,
                    "map_at_20": 0.80364,
                    "recall_at_1": 0.7716,
                    "recall_at_3": 0.82715,
                    "recall_at_5": 0.8425,
                    "recall_at_10": 0.85885,
                    "recall_at_20": 0.8704,
                    "precision_at_1": 0.7716,
                    "precision_at_3": 0.27572,
                    "precision_at_5": 0.1685,
                    "precision_at_10": 0.08588,
                    "precision_at_20": 0.04352,
                    "mrr_at_1": 0.7716,
                    "mrr_at_3": 0.7970750000000034,
                    "mrr_at_5": 0.8006000000000051,
                    "mrr_at_10": 0.80284055555556,
                    "mrr_at_20": 0.8036398170169248,
                    "main_score": 0.81652,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 756.2451887130737,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.42404,
                    "ndcg_at_3": 0.48195,
                    "ndcg_at_5": 0.49799,
                    "ndcg_at_10": 0.5136,
                    "ndcg_at_20": 0.5256,
                    "map_at_1": 0.42401,
                    "map_at_3": 0.46786,
                    "map_at_5": 0.47676,
                    "map_at_10": 0.48319,
                    "map_at_20": 0.48648,
                    "recall_at_1": 0.42401,
                    "recall_at_3": 0.52261,
                    "recall_at_5": 0.56156,
                    "recall_at_10": 0.60991,
                    "recall_at_20": 0.65737,
                    "precision_at_1": 0.42404,
                    "precision_at_3": 0.17422,
                    "precision_at_5": 0.11233,
                    "precision_at_10": 0.06101,
                    "precision_at_20": 0.03288,
                    "mrr_at_1": 0.42399680574965065,
                    "mrr_at_3": 0.46786451054768385,
                    "mrr_at_5": 0.47678046183536893,
                    "mrr_at_10": 0.48321502248334613,
                    "mrr_at_20": 0.48650634295933604,
                    "main_score": 0.5136,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 59.64418363571167,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.18208,
                    "ndcg_at_3": 0.28177,
                    "ndcg_at_5": 0.33175,
                    "ndcg_at_10": 0.39087,
                    "map_at_1": 0.18208,
                    "map_at_3": 0.25616,
                    "map_at_5": 0.28383,
                    "map_at_10": 0.30837,
                    "recall_at_1": 0.18208,
                    "recall_at_3": 0.35633,
                    "recall_at_5": 0.47795,
                    "recall_at_10": 0.66003,
                    "precision_at_1": 0.18208,
                    "precision_at_3": 0.11878,
                    "precision_at_5": 0.09559,
                    "precision_at_10": 0.066,
                    "mrr_at_1": 0.18421052631578946,
                    "mrr_at_3": 0.2569938359412042,
                    "mrr_at_5": 0.2846254148885721,
                    "mrr_at_10": 0.3093541850120794,
                    "main_score": 0.39087,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 45.53056740760803,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.29146,
                    "ndcg_at_3": 0.35899,
                    "ndcg_at_5": 0.37913,
                    "ndcg_at_10": 0.3999,
                    "ndcg_at_20": 0.41634,
                    "map_at_1": 0.29094,
                    "map_at_3": 0.34224,
                    "map_at_5": 0.35343,
                    "map_at_10": 0.36205,
                    "map_at_20": 0.36659,
                    "recall_at_1": 0.29094,
                    "recall_at_3": 0.40677,
                    "recall_at_5": 0.45551,
                    "recall_at_10": 0.5194,
                    "recall_at_20": 0.58404,
                    "precision_at_1": 0.29146,
                    "precision_at_3": 0.13605,
                    "precision_at_5": 0.0915,
                    "precision_at_10": 0.05225,
                    "precision_at_20": 0.02946,
                    "mrr_at_1": 0.29149463253509494,
                    "mrr_at_3": 0.34283587318269126,
                    "mrr_at_5": 0.3541000425393472,
                    "mrr_at_10": 0.3627114902713589,
                    "mrr_at_20": 0.36720388113785896,
                    "main_score": 0.3999,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1172.1167125701904,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.7747,
                    "ndcg_at_3": 0.80806,
                    "ndcg_at_5": 0.81372,
                    "ndcg_at_10": 0.81828,
                    "ndcg_at_20": 0.82164,
                    "map_at_1": 0.7747,
                    "map_at_3": 0.80023,
                    "map_at_5": 0.80338,
                    "map_at_10": 0.80529,
                    "map_at_20": 0.80622,
                    "recall_at_1": 0.7747,
                    "recall_at_3": 0.83055,
                    "recall_at_5": 0.84425,
                    "recall_at_10": 0.8582,
                    "recall_at_20": 0.8715,
                    "precision_at_1": 0.7747,
                    "precision_at_3": 0.27685,
                    "precision_at_5": 0.16885,
                    "precision_at_10": 0.08582,
                    "precision_at_20": 0.04357,
                    "mrr_at_1": 0.7747,
                    "mrr_at_3": 0.8002333333333369,
                    "mrr_at_5": 0.8033833333333387,
                    "mrr_at_10": 0.8052924007936555,
                    "mrr_at_20": 0.8062168827019275,
                    "main_score": 0.81828,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 601.7018723487854,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.37142,
                    "ndcg_at_3": 0.45271,
                    "ndcg_at_5": 0.47683,
                    "ndcg_at_10": 0.49917,
                    "ndcg_at_20": 0.51491,
                    "map_at_1": 0.37137,
                    "map_at_3": 0.43269,
                    "map_at_5": 0.44609,
                    "map_at_10": 0.45534,
                    "map_at_20": 0.45967,
                    "recall_at_1": 0.37137,
                    "recall_at_3": 0.51062,
                    "recall_at_5": 0.56911,
                    "recall_at_10": 0.63801,
                    "recall_at_20": 0.70017,
                    "precision_at_1": 0.37142,
                    "precision_at_3": 0.17023,
                    "precision_at_5": 0.11385,
                    "precision_at_10": 0.06382,
                    "precision_at_20": 0.03503,
                    "mrr_at_1": 0.37142307198768126,
                    "mrr_at_3": 0.43272274263228416,
                    "mrr_at_5": 0.4461338166730957,
                    "mrr_at_10": 0.45538842092721765,
                    "mrr_at_20": 0.4597187433570271,
                    "main_score": 0.49917,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 76.34574484825134,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.47278,
                    "ndcg_at_3": 0.53996,
                    "ndcg_at_5": 0.55638,
                    "ndcg_at_10": 0.57272,
                    "ndcg_at_20": 0.58571,
                    "map_at_1": 0.47271,
                    "map_at_3": 0.52364,
                    "map_at_5": 0.53274,
                    "map_at_10": 0.53951,
                    "map_at_20": 0.54308,
                    "recall_at_1": 0.47271,
                    "recall_at_3": 0.58674,
                    "recall_at_5": 0.62672,
                    "recall_at_10": 0.67708,
                    "recall_at_20": 0.72836,
                    "precision_at_1": 0.47278,
                    "precision_at_3": 0.19574,
                    "precision_at_5": 0.12546,
                    "precision_at_10": 0.0678,
                    "precision_at_20": 0.03647,
                    "mrr_at_1": 0.4727817745803357,
                    "mrr_at_3": 0.5238542499333915,
                    "mrr_at_5": 0.5329849453770404,
                    "mrr_at_10": 0.5397836334107402,
                    "mrr_at_20": 0.5433598506435824,
                    "main_score": 0.57272,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 114.34714841842651,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.72795,
                    "ndcg_at_3": 0.76473,
                    "ndcg_at_5": 0.77211,
                    "ndcg_at_10": 0.77741,
                    "map_at_1": 0.72795,
                    "map_at_3": 0.75609,
                    "map_at_5": 0.76021,
                    "map_at_10": 0.76242,
                    "recall_at_1": 0.72795,
                    "recall_at_3": 0.78955,
                    "recall_at_5": 0.8074,
                    "recall_at_10": 0.82365,
                    "precision_at_1": 0.72795,
                    "precision_at_3": 0.26318,
                    "precision_at_5": 0.16148,
                    "precision_at_10": 0.08236,
                    "mrr_at_1": 0.72795,
                    "mrr_at_3": 0.75609166666667,
                    "mrr_at_5": 0.760209166666672,
                    "mrr_at_10": 0.7624247817460362,
                    "main_score": 0.77741,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 577.9820046424866,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.43034,
                    "ndcg_at_3": 0.3703,
                    "ndcg_at_5": 0.34785,
                    "ndcg_at_10": 0.31226,
                    "ndcg_at_20": 0.28924,
                    "map_at_1": 0.05818,
                    "map_at_3": 0.08449,
                    "map_at_5": 0.09923,
                    "map_at_10": 0.11399,
                    "map_at_20": 0.1246,
                    "recall_at_1": 0.05818,
                    "recall_at_3": 0.09097,
                    "recall_at_5": 0.11563,
                    "recall_at_10": 0.14457,
                    "recall_at_20": 0.17538,
                    "precision_at_1": 0.44582,
                    "precision_at_3": 0.33746,
                    "precision_at_5": 0.2935,
                    "precision_at_10": 0.22384,
                    "precision_at_20": 0.16579,
                    "mrr_at_1": 0.4458204334365325,
                    "mrr_at_3": 0.5025799793601652,
                    "mrr_at_5": 0.5118679050567596,
                    "mrr_at_10": 0.5180672268907563,
                    "mrr_at_20": 0.5226447455800035,
                    "main_score": 0.31226,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 57.442004680633545,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.49667,
                    "ndcg_at_3": 0.58321,
                    "ndcg_at_5": 0.60646,
                    "ndcg_at_10": 0.63284,
                    "ndcg_at_20": 0.64725,
                    "map_at_1": 0.47011,
                    "map_at_3": 0.55086,
                    "map_at_5": 0.56661,
                    "map_at_10": 0.57927,
                    "map_at_20": 0.58391,
                    "recall_at_1": 0.47011,
                    "recall_at_3": 0.64656,
                    "recall_at_5": 0.70528,
                    "recall_at_10": 0.78011,
                    "recall_at_20": 0.83356,
                    "precision_at_1": 0.49667,
                    "precision_at_3": 0.23333,
                    "precision_at_5": 0.15533,
                    "precision_at_10": 0.08767,
                    "precision_at_20": 0.047,
                    "mrr_at_1": 0.49666666666666665,
                    "mrr_at_3": 0.5727777777777779,
                    "mrr_at_5": 0.5847777777777778,
                    "mrr_at_10": 0.5950939153439153,
                    "mrr_at_20": 0.5986691317941318,
                    "main_score": 0.63284,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 111.49837160110474,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.42879,
                    "ndcg_at_3": 0.36646,
                    "ndcg_at_5": 0.33705,
                    "ndcg_at_10": 0.30596,
                    "ndcg_at_20": 0.28237,
                    "map_at_1": 0.05604,
                    "map_at_3": 0.08215,
                    "map_at_5": 0.09621,
                    "map_at_10": 0.11048,
                    "map_at_20": 0.12036,
                    "recall_at_1": 0.05604,
                    "recall_at_3": 0.08961,
                    "recall_at_5": 0.11392,
                    "recall_at_10": 0.142,
                    "recall_at_20": 0.1734,
                    "precision_at_1": 0.43963,
                    "precision_at_3": 0.33746,
                    "precision_at_5": 0.2805,
                    "precision_at_10": 0.21981,
                    "precision_at_20": 0.1613,
                    "mrr_at_1": 0.43962848297213625,
                    "mrr_at_3": 0.49638802889576905,
                    "mrr_at_5": 0.5036635706914345,
                    "mrr_at_10": 0.5106749717430833,
                    "mrr_at_20": 0.5163458536413326,
                    "main_score": 0.30596,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 1900.9055240154266,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.74195,
                    "ndcg_at_3": 0.78001,
                    "ndcg_at_5": 0.78706,
                    "ndcg_at_10": 0.79291,
                    "ndcg_at_20": 0.79666,
                    "map_at_1": 0.74195,
                    "map_at_3": 0.77106,
                    "map_at_5": 0.77499,
                    "map_at_10": 0.77743,
                    "map_at_20": 0.77847,
                    "recall_at_1": 0.74195,
                    "recall_at_3": 0.80575,
                    "recall_at_5": 0.8228,
                    "recall_at_10": 0.84075,
                    "recall_at_20": 0.85545,
                    "precision_at_1": 0.74195,
                    "precision_at_3": 0.26858,
                    "precision_at_5": 0.16456,
                    "precision_at_10": 0.08407,
                    "precision_at_20": 0.04277,
                    "mrr_at_1": 0.74195,
                    "mrr_at_3": 0.7710583333333365,
                    "mrr_at_5": 0.7749858333333386,
                    "mrr_at_10": 0.7774270833333374,
                    "mrr_at_20": 0.7784741379993053,
                    "main_score": 0.79291,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1521.902253627777,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.24864,
                    "ndcg_at_3": 0.31061,
                    "ndcg_at_5": 0.3313,
                    "ndcg_at_10": 0.35295,
                    "ndcg_at_20": 0.37024,
                    "map_at_1": 0.24815,
                    "map_at_3": 0.29502,
                    "map_at_5": 0.30654,
                    "map_at_10": 0.31551,
                    "map_at_20": 0.32026,
                    "recall_at_1": 0.24815,
                    "recall_at_3": 0.35497,
                    "recall_at_5": 0.40502,
                    "recall_at_10": 0.47171,
                    "recall_at_20": 0.53999,
                    "precision_at_1": 0.24864,
                    "precision_at_3": 0.11879,
                    "precision_at_5": 0.08146,
                    "precision_at_10": 0.04755,
                    "precision_at_20": 0.02726,
                    "mrr_at_1": 0.24863992796308107,
                    "mrr_at_3": 0.2956765342237853,
                    "mrr_at_5": 0.3072249527882967,
                    "mrr_at_10": 0.3161710108573479,
                    "mrr_at_20": 0.3208837603104655,
                    "main_score": 0.35295,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 72.08566451072693,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.51333,
                    "ndcg_at_3": 0.58332,
                    "ndcg_at_5": 0.61103,
                    "ndcg_at_10": 0.63826,
                    "ndcg_at_20": 0.65091,
                    "map_at_1": 0.489,
                    "map_at_3": 0.55703,
                    "map_at_5": 0.57529,
                    "map_at_10": 0.58836,
                    "map_at_20": 0.59252,
                    "recall_at_1": 0.489,
                    "recall_at_3": 0.63117,
                    "recall_at_5": 0.69878,
                    "recall_at_10": 0.77722,
                    "recall_at_20": 0.82344,
                    "precision_at_1": 0.51333,
                    "precision_at_3": 0.22778,
                    "precision_at_5": 0.15333,
                    "precision_at_10": 0.087,
                    "precision_at_20": 0.04633,
                    "mrr_at_1": 0.5133333333333333,
                    "mrr_at_3": 0.5783333333333334,
                    "mrr_at_5": 0.5925,
                    "mrr_at_10": 0.6025145502645503,
                    "mrr_at_20": 0.605578641531041,
                    "main_score": 0.63826,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 97.7526171207428,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.86713,
                    "ndcg_at_3": 0.8241,
                    "ndcg_at_5": 0.80921,
                    "ndcg_at_10": 0.80909,
                    "map_at_1": 0.25929,
                    "map_at_3": 0.50997,
                    "map_at_5": 0.62685,
                    "map_at_10": 0.72598,
                    "recall_at_1": 0.25929,
                    "recall_at_3": 0.52898,
                    "recall_at_5": 0.66566,
                    "recall_at_10": 0.79964,
                    "precision_at_1": 0.86713,
                    "precision_at_3": 0.72273,
                    "precision_at_5": 0.60569,
                    "precision_at_10": 0.40435,
                    "mrr_at_1": 0.8671313343854112,
                    "mrr_at_3": 0.8939666257525253,
                    "mrr_at_5": 0.8974932783914895,
                    "mrr_at_10": 0.8995051859366701,
                    "main_score": 0.80909,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2779.1111018657684,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.59667,
                    "ndcg_at_3": 0.68246,
                    "ndcg_at_5": 0.70465,
                    "ndcg_at_10": 0.72512,
                    "ndcg_at_20": 0.73763,
                    "map_at_1": 0.57289,
                    "map_at_3": 0.65385,
                    "map_at_5": 0.6704,
                    "map_at_10": 0.68036,
                    "map_at_20": 0.68454,
                    "recall_at_1": 0.57289,
                    "recall_at_3": 0.73978,
                    "recall_at_5": 0.7925,
                    "recall_at_10": 0.85089,
                    "recall_at_20": 0.897,
                    "precision_at_1": 0.59667,
                    "precision_at_3": 0.26667,
                    "precision_at_5": 0.176,
                    "precision_at_10": 0.096,
                    "precision_at_20": 0.05083,
                    "mrr_at_1": 0.5966666666666667,
                    "mrr_at_3": 0.6705555555555556,
                    "mrr_at_5": 0.6813888888888887,
                    "mrr_at_10": 0.6882328042328042,
                    "mrr_at_20": 0.6912094631947573,
                    "main_score": 0.72512,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 53.893102169036865,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.78507,
                    "ndcg_at_3": 0.73948,
                    "ndcg_at_5": 0.72281,
                    "ndcg_at_10": 0.72409,
                    "ndcg_at_20": 0.74937,
                    "map_at_1": 0.21974,
                    "map_at_3": 0.43456,
                    "map_at_5": 0.53609,
                    "map_at_10": 0.62467,
                    "map_at_20": 0.65352,
                    "recall_at_1": 0.21974,
                    "recall_at_3": 0.46246,
                    "recall_at_5": 0.58978,
                    "recall_at_10": 0.72447,
                    "recall_at_20": 0.80221,
                    "precision_at_1": 0.78507,
                    "precision_at_3": 0.65454,
                    "precision_at_5": 0.54844,
                    "precision_at_10": 0.36871,
                    "precision_at_20": 0.21047,
                    "mrr_at_1": 0.7850692617920393,
                    "mrr_at_3": 0.8272838856742085,
                    "mrr_at_5": 0.833230317376824,
                    "mrr_at_10": 0.8366181541878587,
                    "mrr_at_20": 0.8378925630546855,
                    "main_score": 0.72409,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 4432.128052473068,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.238,
                    "ndcg_at_3": 0.19175,
                    "ndcg_at_5": 0.16408,
                    "ndcg_at_10": 0.19876,
                    "map_at_1": 0.04843,
                    "map_at_3": 0.08602,
                    "map_at_5": 0.10056,
                    "map_at_10": 0.11772,
                    "recall_at_1": 0.04843,
                    "recall_at_3": 0.10873,
                    "recall_at_5": 0.14362,
                    "recall_at_10": 0.2076,
                    "precision_at_1": 0.238,
                    "precision_at_3": 0.17867,
                    "precision_at_5": 0.1416,
                    "precision_at_10": 0.1024,
                    "mrr_at_1": 0.238,
                    "mrr_at_3": 0.31383333333333335,
                    "mrr_at_5": 0.3308333333333331,
                    "mrr_at_10": 0.3442186507936506,
                    "main_score": 0.19876,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 430.36703181266785,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.66275,
                    "ndcg_at_3": 0.73644,
                    "ndcg_at_5": 0.75695,
                    "ndcg_at_10": 0.77335,
                    "ndcg_at_20": 0.7825,
                    "map_at_1": 0.64103,
                    "map_at_3": 0.71514,
                    "map_at_5": 0.72716,
                    "map_at_10": 0.73443,
                    "map_at_20": 0.73711,
                    "recall_at_1": 0.64103,
                    "recall_at_3": 0.78924,
                    "recall_at_5": 0.8381,
                    "recall_at_10": 0.88726,
                    "recall_at_20": 0.92243,
                    "precision_at_1": 0.66275,
                    "precision_at_3": 0.27775,
                    "precision_at_5": 0.17765,
                    "precision_at_10": 0.09426,
                    "precision_at_20": 0.04908,
                    "mrr_at_1": 0.6627507163323783,
                    "mrr_at_3": 0.7237344794651387,
                    "mrr_at_5": 0.7343648519579726,
                    "mrr_at_10": 0.7406798903897738,
                    "mrr_at_20": 0.7430520509609343,
                    "main_score": 0.77335,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2732.161968231201,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.67756,
                    "ndcg_at_3": 0.76723,
                    "ndcg_at_5": 0.78227,
                    "ndcg_at_10": 0.79568,
                    "ndcg_at_20": 0.80569,
                    "map_at_1": 0.67518,
                    "map_at_3": 0.74552,
                    "map_at_5": 0.75416,
                    "map_at_10": 0.75994,
                    "map_at_20": 0.76267,
                    "recall_at_1": 0.67518,
                    "recall_at_3": 0.82824,
                    "recall_at_5": 0.86433,
                    "recall_at_10": 0.90516,
                    "recall_at_20": 0.94468,
                    "precision_at_1": 0.67756,
                    "precision_at_3": 0.27854,
                    "precision_at_5": 0.1745,
                    "precision_at_10": 0.09146,
                    "precision_at_20": 0.04773,
                    "mrr_at_1": 0.6765015806111696,
                    "mrr_at_3": 0.7460484720758696,
                    "mrr_at_5": 0.7542676501580614,
                    "mrr_at_10": 0.7598022981584628,
                    "mrr_at_20": 0.7624763947143383,
                    "main_score": 0.79568,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 582.6218073368073,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.90154,
                    "ndcg_at_3": 0.93242,
                    "ndcg_at_5": 0.93649,
                    "ndcg_at_10": 0.93968,
                    "map_at_1": 0.90152,
                    "map_at_3": 0.92511,
                    "map_at_5": 0.92737,
                    "map_at_10": 0.9287,
                    "recall_at_1": 0.90152,
                    "recall_at_3": 0.95344,
                    "recall_at_5": 0.96328,
                    "recall_at_10": 0.97308,
                    "precision_at_1": 0.90154,
                    "precision_at_3": 0.31782,
                    "precision_at_5": 0.19266,
                    "precision_at_10": 0.09731,
                    "mrr_at_1": 0.901540790879943,
                    "mrr_at_3": 0.9251276570478549,
                    "mrr_at_5": 0.9273965384158653,
                    "mrr_at_10": 0.9287229241239299,
                    "main_score": 0.93968,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 106.5210292339325,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.484,
                    "ndcg_at_3": 0.5337,
                    "ndcg_at_5": 0.5485,
                    "ndcg_at_10": 0.55969,
                    "ndcg_at_20": 0.56902,
                    "map_at_1": 0.484,
                    "map_at_3": 0.5215,
                    "map_at_5": 0.5297,
                    "map_at_10": 0.53424,
                    "map_at_20": 0.53693,
                    "recall_at_1": 0.484,
                    "recall_at_3": 0.569,
                    "recall_at_5": 0.605,
                    "recall_at_10": 0.64,
                    "recall_at_20": 0.676,
                    "precision_at_1": 0.484,
                    "precision_at_3": 0.18967,
                    "precision_at_5": 0.121,
                    "precision_at_10": 0.064,
                    "precision_at_20": 0.0338,
                    "mrr_at_1": 0.485,
                    "mrr_at_3": 0.5219999999999998,
                    "mrr_at_5": 0.5301999999999996,
                    "mrr_at_10": 0.5347416666666664,
                    "mrr_at_20": 0.5374283072921225,
                    "main_score": 0.55969,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 218.06816482543945,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.69112,
                    "ndcg_at_3": 0.75923,
                    "ndcg_at_5": 0.77979,
                    "ndcg_at_10": 0.79644,
                    "map_at_1": 0.668,
                    "map_at_3": 0.73949,
                    "map_at_5": 0.75174,
                    "map_at_10": 0.759,
                    "recall_at_1": 0.668,
                    "recall_at_3": 0.80782,
                    "recall_at_5": 0.85665,
                    "recall_at_10": 0.90669,
                    "precision_at_1": 0.69112,
                    "precision_at_3": 0.28491,
                    "precision_at_5": 0.18189,
                    "precision_at_10": 0.09633,
                    "mrr_at_1": 0.6911174785100287,
                    "mrr_at_3": 0.7476838586437441,
                    "mrr_at_5": 0.7582282712511914,
                    "mrr_at_10": 0.7648986332833035,
                    "main_score": 0.79644,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 370.7610330581665,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.39815,
                    "ndcg_at_3": 0.3674,
                    "ndcg_at_5": 0.37477,
                    "ndcg_at_10": 0.39791,
                    "ndcg_at_20": 0.42357,
                    "map_at_1": 0.19755,
                    "map_at_3": 0.28076,
                    "map_at_5": 0.30237,
                    "map_at_10": 0.31966,
                    "map_at_20": 0.32943,
                    "recall_at_1": 0.19755,
                    "recall_at_3": 0.33413,
                    "recall_at_5": 0.39013,
                    "recall_at_10": 0.46166,
                    "recall_at_20": 0.54086,
                    "precision_at_1": 0.39815,
                    "precision_at_3": 0.2464,
                    "precision_at_5": 0.17593,
                    "precision_at_10": 0.11049,
                    "precision_at_20": 0.06628,
                    "mrr_at_1": 0.39814814814814814,
                    "mrr_at_3": 0.46579218106995873,
                    "mrr_at_5": 0.47674897119341536,
                    "mrr_at_10": 0.4865520282186948,
                    "mrr_at_20": 0.49104135819248734,
                    "main_score": 0.39791,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 282.88946628570557,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.42366,
                    "ndcg_at_3": 0.48836,
                    "ndcg_at_5": 0.50478,
                    "ndcg_at_10": 0.52196,
                    "ndcg_at_20": 0.53501,
                    "map_at_1": 0.42342,
                    "map_at_3": 0.47247,
                    "map_at_5": 0.4816,
                    "map_at_10": 0.48871,
                    "map_at_20": 0.49229,
                    "recall_at_1": 0.42342,
                    "recall_at_3": 0.53375,
                    "recall_at_5": 0.57374,
                    "recall_at_10": 0.62667,
                    "recall_at_20": 0.67819,
                    "precision_at_1": 0.42366,
                    "precision_at_3": 0.17808,
                    "precision_at_5": 0.11488,
                    "precision_at_10": 0.06279,
                    "precision_at_20": 0.034,
                    "mrr_at_1": 0.42366107114308554,
                    "mrr_at_3": 0.47280841993072664,
                    "mrr_at_5": 0.4819491073807696,
                    "mrr_at_10": 0.4890995616205526,
                    "mrr_at_20": 0.4926941074653936,
                    "main_score": 0.52196,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 64.28832650184631,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.70725,
                    "ndcg_at_3": 0.77555,
                    "ndcg_at_5": 0.78729,
                    "ndcg_at_10": 0.79747,
                    "ndcg_at_20": 0.80442,
                    "map_at_1": 0.70689,
                    "map_at_3": 0.75948,
                    "map_at_5": 0.76604,
                    "map_at_10": 0.77028,
                    "map_at_20": 0.7722,
                    "recall_at_1": 0.70689,
                    "recall_at_3": 0.82163,
                    "recall_at_5": 0.84995,
                    "recall_at_10": 0.88122,
                    "recall_at_20": 0.90859,
                    "precision_at_1": 0.70725,
                    "precision_at_3": 0.27418,
                    "precision_at_5": 0.17021,
                    "precision_at_10": 0.08826,
                    "precision_at_20": 0.04552,
                    "mrr_at_1": 0.7072519083969465,
                    "mrr_at_3": 0.759576238011344,
                    "mrr_at_5": 0.7661293795263223,
                    "mrr_at_10": 0.7703539388940127,
                    "mrr_at_20": 0.7722577127187608,
                    "main_score": 0.79747,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 187.8762218952179,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.89522,
                    "ndcg_at_3": 0.92932,
                    "ndcg_at_5": 0.93401,
                    "ndcg_at_10": 0.93713,
                    "ndcg_at_20": 0.93871,
                    "map_at_1": 0.89522,
                    "map_at_3": 0.92135,
                    "map_at_5": 0.92397,
                    "map_at_10": 0.92527,
                    "map_at_20": 0.92571,
                    "recall_at_1": 0.89522,
                    "recall_at_3": 0.9522,
                    "recall_at_5": 0.96353,
                    "recall_at_10": 0.9731,
                    "recall_at_20": 0.97929,
                    "precision_at_1": 0.89522,
                    "precision_at_3": 0.31741,
                    "precision_at_5": 0.19271,
                    "precision_at_10": 0.09731,
                    "precision_at_20": 0.04897,
                    "mrr_at_1": 0.8952173138582116,
                    "mrr_at_3": 0.9213647429046415,
                    "mrr_at_5": 0.9239854233463958,
                    "mrr_at_10": 0.9252877231524363,
                    "mrr_at_20": 0.9257247197336803,
                    "main_score": 0.93713,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 84.28017282485962,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.41512,
                    "ndcg_at_3": 0.38417,
                    "ndcg_at_5": 0.3877,
                    "ndcg_at_10": 0.4097,
                    "map_at_1": 0.20681,
                    "map_at_3": 0.29595,
                    "map_at_5": 0.31484,
                    "map_at_10": 0.33289,
                    "recall_at_1": 0.20681,
                    "recall_at_3": 0.35242,
                    "recall_at_5": 0.39826,
                    "recall_at_10": 0.4692,
                    "precision_at_1": 0.41512,
                    "precision_at_3": 0.25772,
                    "precision_at_5": 0.18179,
                    "precision_at_10": 0.11219,
                    "mrr_at_1": 0.41512345679012347,
                    "mrr_at_3": 0.4822530864197529,
                    "mrr_at_5": 0.4914351851851849,
                    "mrr_at_10": 0.49998591514795193,
                    "main_score": 0.4097,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 302.4865369796753,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.70783,
                    "ndcg_at_3": 0.77748,
                    "ndcg_at_5": 0.79055,
                    "ndcg_at_10": 0.80136,
                    "map_at_1": 0.70742,
                    "map_at_3": 0.76106,
                    "map_at_5": 0.76836,
                    "map_at_10": 0.77281,
                    "recall_at_1": 0.70742,
                    "recall_at_3": 0.82442,
                    "recall_at_5": 0.85598,
                    "recall_at_10": 0.88946,
                    "precision_at_1": 0.70783,
                    "precision_at_3": 0.27509,
                    "precision_at_5": 0.17142,
                    "precision_at_10": 0.08908,
                    "mrr_at_1": 0.7078562621102695,
                    "mrr_at_3": 0.7613567416280017,
                    "mrr_at_5": 0.7686082242185771,
                    "mrr_at_10": 0.7730500660327118,
                    "main_score": 0.80136,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 150.05669736862183,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.17781,
                    "ndcg_at_3": 0.28293,
                    "ndcg_at_5": 0.33386,
                    "ndcg_at_10": 0.39488,
                    "ndcg_at_20": 0.43331,
                    "map_at_1": 0.17781,
                    "map_at_3": 0.25664,
                    "map_at_5": 0.28487,
                    "map_at_10": 0.3101,
                    "map_at_20": 0.3208,
                    "recall_at_1": 0.17781,
                    "recall_at_3": 0.35917,
                    "recall_at_5": 0.48293,
                    "recall_at_10": 0.67141,
                    "recall_at_20": 0.82219,
                    "precision_at_1": 0.17781,
                    "precision_at_3": 0.11972,
                    "precision_at_5": 0.09659,
                    "precision_at_10": 0.06714,
                    "precision_at_20": 0.04111,
                    "mrr_at_1": 0.17923186344238975,
                    "mrr_at_3": 0.2571123755334281,
                    "mrr_at_5": 0.28552631578947313,
                    "mrr_at_10": 0.3108082706766915,
                    "mrr_at_20": 0.32145020225006293,
                    "main_score": 0.39488,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 49.38380575180054,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.41639,
                    "ndcg_at_3": 0.49359,
                    "ndcg_at_5": 0.51417,
                    "ndcg_at_10": 0.53504,
                    "ndcg_at_20": 0.55018,
                    "map_at_1": 0.41581,
                    "map_at_3": 0.47466,
                    "map_at_5": 0.48611,
                    "map_at_10": 0.49475,
                    "map_at_20": 0.49893,
                    "recall_at_1": 0.41581,
                    "recall_at_3": 0.54748,
                    "recall_at_5": 0.59737,
                    "recall_at_10": 0.66158,
                    "recall_at_20": 0.72116,
                    "precision_at_1": 0.41639,
                    "precision_at_3": 0.18308,
                    "precision_at_5": 0.11999,
                    "precision_at_10": 0.06656,
                    "precision_at_20": 0.03635,
                    "mrr_at_1": 0.4163883990545154,
                    "mrr_at_3": 0.47536237321627944,
                    "mrr_at_5": 0.4867325754449264,
                    "mrr_at_10": 0.49538020676073713,
                    "mrr_at_20": 0.4995123775492597,
                    "main_score": 0.53504,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 126.7701187133789,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.29082,
                    "ndcg_at_3": 0.29262,
                    "ndcg_at_5": 0.3102,
                    "ndcg_at_10": 0.33503,
                    "ndcg_at_20": 0.35832,
                    "map_at_1": 0.18432,
                    "map_at_3": 0.24521,
                    "map_at_5": 0.26284,
                    "map_at_10": 0.27707,
                    "map_at_20": 0.28502,
                    "recall_at_1": 0.18432,
                    "recall_at_3": 0.29248,
                    "recall_at_5": 0.34717,
                    "recall_at_10": 0.42096,
                    "recall_at_20": 0.50044,
                    "precision_at_1": 0.29082,
                    "precision_at_3": 0.16729,
                    "precision_at_5": 0.12263,
                    "precision_at_10": 0.07624,
                    "precision_at_20": 0.04585,
                    "mrr_at_1": 0.2908227056764191,
                    "mrr_at_3": 0.341877135950654,
                    "mrr_at_5": 0.3546678336250731,
                    "mrr_at_10": 0.36429375200943054,
                    "mrr_at_20": 0.36956584988291974,
                    "main_score": 0.33503,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 659.3023788928986,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.6308,
                    "ndcg_at_3": 0.706,
                    "ndcg_at_5": 0.72735,
                    "ndcg_at_10": 0.74479,
                    "ndcg_at_20": 0.75364,
                    "map_at_1": 0.60996,
                    "map_at_3": 0.68389,
                    "map_at_5": 0.69651,
                    "map_at_10": 0.7041,
                    "map_at_20": 0.70669,
                    "recall_at_1": 0.60996,
                    "recall_at_3": 0.76053,
                    "recall_at_5": 0.8114,
                    "recall_at_10": 0.86399,
                    "recall_at_20": 0.89803,
                    "precision_at_1": 0.6308,
                    "precision_at_3": 0.26786,
                    "precision_at_5": 0.17201,
                    "precision_at_10": 0.09178,
                    "precision_at_20": 0.04777,
                    "mrr_at_1": 0.6308022922636103,
                    "mrr_at_3": 0.6929799426934109,
                    "mrr_at_5": 0.7040042979942681,
                    "mrr_at_10": 0.710813548915268,
                    "mrr_at_20": 0.7131089327414402,
                    "main_score": 0.74479,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 506.24852108955383,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.556,
                    "ndcg_at_3": 0.6682,
                    "ndcg_at_5": 0.6904,
                    "ndcg_at_10": 0.70391,
                    "ndcg_at_20": 0.71585,
                    "map_at_1": 0.556,
                    "map_at_3": 0.64183,
                    "map_at_5": 0.65413,
                    "map_at_10": 0.65985,
                    "map_at_20": 0.66316,
                    "recall_at_1": 0.556,
                    "recall_at_3": 0.744,
                    "recall_at_5": 0.798,
                    "recall_at_10": 0.839,
                    "recall_at_20": 0.886,
                    "precision_at_1": 0.556,
                    "precision_at_3": 0.248,
                    "precision_at_5": 0.1596,
                    "precision_at_10": 0.0839,
                    "precision_at_20": 0.0443,
                    "mrr_at_1": 0.555,
                    "mrr_at_3": 0.6413333333333334,
                    "mrr_at_5": 0.6536333333333335,
                    "mrr_at_10": 0.6593519841269843,
                    "mrr_at_20": 0.662658524336001,
                    "main_score": 0.70391,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 395.46872448921204,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.54733,
                    "ndcg_at_3": 0.60818,
                    "ndcg_at_5": 0.62426,
                    "ndcg_at_10": 0.63977,
                    "ndcg_at_20": 0.65125,
                    "map_at_1": 0.54718,
                    "map_at_3": 0.59343,
                    "map_at_5": 0.60237,
                    "map_at_10": 0.6088,
                    "map_at_20": 0.61195,
                    "recall_at_1": 0.54718,
                    "recall_at_3": 0.65048,
                    "recall_at_5": 0.6895,
                    "recall_at_10": 0.73734,
                    "recall_at_20": 0.78261,
                    "precision_at_1": 0.54733,
                    "precision_at_3": 0.21693,
                    "precision_at_5": 0.13798,
                    "precision_at_10": 0.07379,
                    "precision_at_20": 0.03918,
                    "mrr_at_1": 0.5473347973647434,
                    "mrr_at_3": 0.593638118054176,
                    "mrr_at_5": 0.6025860118453563,
                    "mrr_at_10": 0.609018179974469,
                    "mrr_at_20": 0.6121954124565194,
                    "main_score": 0.63977,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 120.847971200943,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.18137,
                    "ndcg_at_3": 0.28448,
                    "ndcg_at_5": 0.33443,
                    "ndcg_at_10": 0.39277,
                    "ndcg_at_20": 0.43179,
                    "map_at_1": 0.18137,
                    "map_at_3": 0.2583,
                    "map_at_5": 0.28593,
                    "map_at_10": 0.30982,
                    "map_at_20": 0.32072,
                    "recall_at_1": 0.18137,
                    "recall_at_3": 0.3606,
                    "recall_at_5": 0.48222,
                    "recall_at_10": 0.66358,
                    "recall_at_20": 0.8165,
                    "precision_at_1": 0.18137,
                    "precision_at_3": 0.1202,
                    "precision_at_5": 0.09644,
                    "precision_at_10": 0.06636,
                    "precision_at_20": 0.04083,
                    "mrr_at_1": 0.18278805120910385,
                    "mrr_at_3": 0.2590090090090088,
                    "mrr_at_5": 0.28632053105737254,
                    "mrr_at_10": 0.31034765968976463,
                    "mrr_at_20": 0.32120939620837696,
                    "main_score": 0.39277,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 54.686076164245605,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.33598,
                    "ndcg_at_3": 0.41391,
                    "ndcg_at_5": 0.43553,
                    "ndcg_at_10": 0.45776,
                    "ndcg_at_20": 0.47433,
                    "map_at_1": 0.33545,
                    "map_at_3": 0.39456,
                    "map_at_5": 0.4066,
                    "map_at_10": 0.41578,
                    "map_at_20": 0.42036,
                    "recall_at_1": 0.33545,
                    "recall_at_3": 0.46922,
                    "recall_at_5": 0.52148,
                    "recall_at_10": 0.59,
                    "recall_at_20": 0.65517,
                    "precision_at_1": 0.33598,
                    "precision_at_3": 0.15691,
                    "precision_at_5": 0.10475,
                    "precision_at_10": 0.05939,
                    "precision_at_20": 0.03305,
                    "mrr_at_1": 0.3359846921547293,
                    "mrr_at_3": 0.39520879450718577,
                    "mrr_at_5": 0.4072337072749819,
                    "mrr_at_10": 0.41641390319682314,
                    "mrr_at_20": 0.4209399995314592,
                    "main_score": 0.45776,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 162.70750093460083,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.43963,
                    "ndcg_at_3": 0.40667,
                    "ndcg_at_5": 0.3936,
                    "ndcg_at_10": 0.3668,
                    "ndcg_at_20": 0.34324,
                    "map_at_1": 0.04807,
                    "map_at_3": 0.08907,
                    "map_at_5": 0.11009,
                    "map_at_10": 0.13194,
                    "map_at_20": 0.14907,
                    "recall_at_1": 0.04807,
                    "recall_at_3": 0.10214,
                    "recall_at_5": 0.13938,
                    "recall_at_10": 0.17715,
                    "recall_at_20": 0.21879,
                    "precision_at_1": 0.4613,
                    "precision_at_3": 0.39216,
                    "precision_at_5": 0.35418,
                    "precision_at_10": 0.287,
                    "precision_at_20": 0.21455,
                    "mrr_at_1": 0.4613003095975232,
                    "mrr_at_3": 0.5350877192982456,
                    "mrr_at_5": 0.5493292053663571,
                    "mrr_at_10": 0.5548098186643078,
                    "mrr_at_20": 0.5567467187340376,
                    "main_score": 0.3668,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 58.033323764801025,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.68282,
                    "ndcg_at_3": 0.75799,
                    "ndcg_at_5": 0.77875,
                    "ndcg_at_10": 0.79706,
                    "map_at_1": 0.68124,
                    "map_at_3": 0.73955,
                    "map_at_5": 0.75123,
                    "map_at_10": 0.75898,
                    "recall_at_1": 0.68124,
                    "recall_at_3": 0.81085,
                    "recall_at_5": 0.86012,
                    "recall_at_10": 0.91623,
                    "precision_at_1": 0.68282,
                    "precision_at_3": 0.27151,
                    "precision_at_5": 0.17323,
                    "precision_at_10": 0.09252,
                    "mrr_at_1": 0.6817702845100105,
                    "mrr_at_3": 0.7393747804706708,
                    "mrr_at_5": 0.751229364243063,
                    "mrr_at_10": 0.7583998193587235,
                    "main_score": 0.79706,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 418.0206604003906,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.42879,
                    "ndcg_at_3": 0.3661,
                    "ndcg_at_5": 0.33702,
                    "ndcg_at_10": 0.30613,
                    "ndcg_at_20": 0.28246,
                    "map_at_1": 0.05604,
                    "map_at_3": 0.0821,
                    "map_at_5": 0.0962,
                    "map_at_10": 0.11048,
                    "map_at_20": 0.12036,
                    "recall_at_1": 0.05604,
                    "recall_at_3": 0.08956,
                    "recall_at_5": 0.11392,
                    "recall_at_10": 0.14201,
                    "recall_at_20": 0.17356,
                    "precision_at_1": 0.43963,
                    "precision_at_3": 0.33643,
                    "precision_at_5": 0.2805,
                    "precision_at_10": 0.22012,
                    "precision_at_20": 0.16146,
                    "mrr_at_1": 0.44272445820433437,
                    "mrr_at_3": 0.4984520123839011,
                    "mrr_at_5": 0.5057275541795667,
                    "mrr_at_10": 0.5127942405032189,
                    "mrr_at_20": 0.5186199211630781,
                    "main_score": 0.30613,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 17.358458280563354,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.53667,
                    "ndcg_at_3": 0.59593,
                    "ndcg_at_5": 0.62439,
                    "ndcg_at_10": 0.6437,
                    "ndcg_at_20": 0.65889,
                    "map_at_1": 0.50578,
                    "map_at_3": 0.5701,
                    "map_at_5": 0.589,
                    "map_at_10": 0.59959,
                    "map_at_20": 0.60383,
                    "recall_at_1": 0.50578,
                    "recall_at_3": 0.63811,
                    "recall_at_5": 0.709,
                    "recall_at_10": 0.76133,
                    "recall_at_20": 0.82133,
                    "precision_at_1": 0.53667,
                    "precision_at_3": 0.23222,
                    "precision_at_5": 0.15733,
                    "precision_at_10": 0.087,
                    "precision_at_20": 0.04667,
                    "mrr_at_1": 0.5366666666666666,
                    "mrr_at_3": 0.5950000000000001,
                    "mrr_at_5": 0.6095000000000002,
                    "mrr_at_10": 0.6156468253968255,
                    "mrr_at_20": 0.6194509729033724,
                    "main_score": 0.6437,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 17.182257413864136,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.29332,
                    "ndcg_at_3": 0.29475,
                    "ndcg_at_5": 0.31256,
                    "ndcg_at_10": 0.33727,
                    "map_at_1": 0.18585,
                    "map_at_3": 0.24713,
                    "map_at_5": 0.26489,
                    "map_at_10": 0.27913,
                    "recall_at_1": 0.18585,
                    "recall_at_3": 0.29448,
                    "recall_at_5": 0.35004,
                    "recall_at_10": 0.42329,
                    "precision_at_1": 0.29332,
                    "precision_at_3": 0.16846,
                    "precision_at_5": 0.12343,
                    "precision_at_10": 0.07672,
                    "mrr_at_1": 0.2933233308327082,
                    "mrr_at_3": 0.34412769859131426,
                    "mrr_at_5": 0.3571809619071437,
                    "mrr_at_10": 0.36671995379797295,
                    "main_score": 0.33727,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 564.1362879276276,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.66877,
                    "ndcg_at_3": 0.73639,
                    "ndcg_at_5": 0.75635,
                    "ndcg_at_10": 0.77272,
                    "ndcg_at_20": 0.78071,
                    "map_at_1": 0.64633,
                    "map_at_3": 0.71618,
                    "map_at_5": 0.72806,
                    "map_at_10": 0.73525,
                    "map_at_20": 0.73754,
                    "recall_at_1": 0.64633,
                    "recall_at_3": 0.78521,
                    "recall_at_5": 0.83269,
                    "recall_at_10": 0.88194,
                    "recall_at_20": 0.91305,
                    "precision_at_1": 0.66877,
                    "precision_at_3": 0.27679,
                    "precision_at_5": 0.17673,
                    "precision_at_10": 0.0938,
                    "precision_at_20": 0.04857,
                    "mrr_at_1": 0.6687679083094555,
                    "mrr_at_3": 0.7255730659025794,
                    "mrr_at_5": 0.735716332378222,
                    "mrr_at_10": 0.7420031723291038,
                    "mrr_at_20": 0.744075456587027,
                    "main_score": 0.77272,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 208.0239598751068,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.35185,
                    "ndcg_at_3": 0.31744,
                    "ndcg_at_5": 0.32998,
                    "ndcg_at_10": 0.35227,
                    "ndcg_at_20": 0.37437,
                    "map_at_1": 0.17342,
                    "map_at_3": 0.24064,
                    "map_at_5": 0.26294,
                    "map_at_10": 0.28017,
                    "map_at_20": 0.2881,
                    "recall_at_1": 0.17342,
                    "recall_at_3": 0.28074,
                    "recall_at_5": 0.34037,
                    "recall_at_10": 0.41453,
                    "recall_at_20": 0.48159,
                    "precision_at_1": 0.35185,
                    "precision_at_3": 0.21296,
                    "precision_at_5": 0.16019,
                    "precision_at_10": 0.09969,
                    "precision_at_20": 0.05926,
                    "mrr_at_1": 0.35185185185185186,
                    "mrr_at_3": 0.40534979423868334,
                    "mrr_at_5": 0.4210133744855967,
                    "mrr_at_10": 0.4306241426611796,
                    "mrr_at_20": 0.4355644041622927,
                    "main_score": 0.35227,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 321.0361976623535,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "6e346642246bfb4928c560ee08640dc84d074e8c",
        "task_name": "LEMBWikimQARetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.93333,
                    "ndcg_at_3": 0.95139,
                    "ndcg_at_5": 0.95139,
                    "ndcg_at_10": 0.95667,
                    "ndcg_at_20": 0.95922,
                    "map_at_1": 0.93333,
                    "map_at_3": 0.94722,
                    "map_at_5": 0.94722,
                    "map_at_10": 0.94934,
                    "map_at_20": 0.95005,
                    "recall_at_1": 0.93333,
                    "recall_at_3": 0.96333,
                    "recall_at_5": 0.96333,
                    "recall_at_10": 0.98,
                    "recall_at_20": 0.99,
                    "precision_at_1": 0.93333,
                    "precision_at_3": 0.32111,
                    "precision_at_5": 0.19267,
                    "precision_at_10": 0.098,
                    "precision_at_20": 0.0495,
                    "mrr_at_1": 0.9333333333333333,
                    "mrr_at_3": 0.9472222222222223,
                    "mrr_at_5": 0.9472222222222223,
                    "mrr_at_10": 0.9493373015873016,
                    "mrr_at_20": 0.9500456349206349,
                    "main_score": 0.95667,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 99.65023899078369,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.68704,
                    "ndcg_at_3": 0.7614,
                    "ndcg_at_5": 0.78284,
                    "ndcg_at_10": 0.79865,
                    "ndcg_at_20": 0.80659,
                    "map_at_1": 0.68546,
                    "map_at_3": 0.74368,
                    "map_at_5": 0.75555,
                    "map_at_10": 0.76247,
                    "map_at_20": 0.76472,
                    "recall_at_1": 0.68546,
                    "recall_at_3": 0.81191,
                    "recall_at_5": 0.86354,
                    "recall_at_10": 0.91096,
                    "recall_at_20": 0.94204,
                    "precision_at_1": 0.68704,
                    "precision_at_3": 0.27187,
                    "precision_at_5": 0.17387,
                    "precision_at_10": 0.09199,
                    "precision_at_20": 0.04758,
                    "mrr_at_1": 0.6870389884088515,
                    "mrr_at_3": 0.7441166139796275,
                    "mrr_at_5": 0.7561819459079734,
                    "mrr_at_10": 0.7626202184421362,
                    "mrr_at_20": 0.7647708210137459,
                    "main_score": 0.79865,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2715.071979522705,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.7716,
                    "ndcg_at_3": 0.80476,
                    "ndcg_at_5": 0.8112,
                    "ndcg_at_10": 0.8166,
                    "ndcg_at_20": 0.81945,
                    "map_at_1": 0.7716,
                    "map_at_3": 0.79702,
                    "map_at_5": 0.8006,
                    "map_at_10": 0.80286,
                    "map_at_20": 0.80363,
                    "recall_at_1": 0.7716,
                    "recall_at_3": 0.827,
                    "recall_at_5": 0.8426,
                    "recall_at_10": 0.85915,
                    "recall_at_20": 0.87045,
                    "precision_at_1": 0.7716,
                    "precision_at_3": 0.27567,
                    "precision_at_5": 0.16852,
                    "precision_at_10": 0.08591,
                    "precision_at_20": 0.04352,
                    "mrr_at_1": 0.7716,
                    "mrr_at_3": 0.7970166666666699,
                    "mrr_at_5": 0.8005991666666719,
                    "mrr_at_10": 0.8028589880952425,
                    "mrr_at_20": 0.8036329392969063,
                    "main_score": 0.8166,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 410.27479362487793,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.422,
                    "ndcg_at_3": 0.47709,
                    "ndcg_at_5": 0.49069,
                    "ndcg_at_10": 0.50205,
                    "ndcg_at_20": 0.51314,
                    "map_at_1": 0.422,
                    "map_at_3": 0.46333,
                    "map_at_5": 0.47088,
                    "map_at_10": 0.47559,
                    "map_at_20": 0.47862,
                    "recall_at_1": 0.422,
                    "recall_at_3": 0.517,
                    "recall_at_5": 0.55,
                    "recall_at_10": 0.585,
                    "recall_at_20": 0.629,
                    "precision_at_1": 0.422,
                    "precision_at_3": 0.17233,
                    "precision_at_5": 0.11,
                    "precision_at_10": 0.0585,
                    "precision_at_20": 0.03145,
                    "mrr_at_1": 0.423,
                    "mrr_at_3": 0.463833333333333,
                    "mrr_at_5": 0.471383333333333,
                    "mrr_at_10": 0.47608690476190446,
                    "mrr_at_20": 0.47911942723599016,
                    "main_score": 0.50205,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 889.3833706378937,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.7039,
                    "ndcg_at_3": 0.78852,
                    "ndcg_at_5": 0.80547,
                    "ndcg_at_10": 0.821,
                    "ndcg_at_20": 0.82831,
                    "map_at_1": 0.70047,
                    "map_at_3": 0.76739,
                    "map_at_5": 0.77713,
                    "map_at_10": 0.78382,
                    "map_at_20": 0.78589,
                    "recall_at_1": 0.70047,
                    "recall_at_3": 0.84747,
                    "recall_at_5": 0.88857,
                    "recall_at_10": 0.93572,
                    "recall_at_20": 0.96417,
                    "precision_at_1": 0.7039,
                    "precision_at_3": 0.28521,
                    "precision_at_5": 0.17956,
                    "precision_at_10": 0.09463,
                    "precision_at_20": 0.04874,
                    "mrr_at_1": 0.702845100105374,
                    "mrr_at_3": 0.768703898840885,
                    "mrr_at_5": 0.7779768177028451,
                    "mrr_at_10": 0.7841508187398597,
                    "mrr_at_20": 0.7862256678919648,
                    "main_score": 0.821,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 403.57432532310486,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.89089,
                    "ndcg_at_3": 0.84903,
                    "ndcg_at_5": 0.83313,
                    "ndcg_at_10": 0.83138,
                    "map_at_1": 0.27011,
                    "map_at_3": 0.53257,
                    "map_at_5": 0.65315,
                    "map_at_10": 0.75408,
                    "recall_at_1": 0.27011,
                    "recall_at_3": 0.54875,
                    "recall_at_5": 0.68597,
                    "recall_at_10": 0.8181,
                    "precision_at_1": 0.89089,
                    "precision_at_3": 0.74328,
                    "precision_at_5": 0.62121,
                    "precision_at_10": 0.41294,
                    "mrr_at_1": 0.8908907592495178,
                    "mrr_at_3": 0.9116035419954405,
                    "mrr_at_5": 0.9145405926705256,
                    "mrr_at_10": 0.9162402515802064,
                    "main_score": 0.83138,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 5944.500059127808,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.81488,
                    "ndcg_at_3": 0.77145,
                    "ndcg_at_5": 0.75617,
                    "ndcg_at_10": 0.75826,
                    "ndcg_at_20": 0.78122,
                    "map_at_1": 0.23643,
                    "map_at_3": 0.46536,
                    "map_at_5": 0.57207,
                    "map_at_10": 0.66482,
                    "map_at_20": 0.69323,
                    "recall_at_1": 0.23643,
                    "recall_at_3": 0.49007,
                    "recall_at_5": 0.62087,
                    "recall_at_10": 0.75611,
                    "recall_at_20": 0.82769,
                    "precision_at_1": 0.81488,
                    "precision_at_3": 0.67923,
                    "precision_at_5": 0.569,
                    "precision_at_10": 0.38254,
                    "precision_at_20": 0.2166,
                    "mrr_at_1": 0.8149219708925127,
                    "mrr_at_3": 0.8516424104272597,
                    "mrr_at_5": 0.8569663627330666,
                    "mrr_at_10": 0.8600134745288632,
                    "mrr_at_20": 0.8610541494156928,
                    "main_score": 0.75826,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 4781.671217441559,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.60678,
                    "ndcg_at_3": 0.68014,
                    "ndcg_at_5": 0.69509,
                    "ndcg_at_10": 0.70778,
                    "ndcg_at_20": 0.71707,
                    "map_at_1": 0.60643,
                    "map_at_3": 0.6627,
                    "map_at_5": 0.67105,
                    "map_at_10": 0.67629,
                    "map_at_20": 0.67886,
                    "recall_at_1": 0.60643,
                    "recall_at_3": 0.73019,
                    "recall_at_5": 0.76632,
                    "recall_at_10": 0.80548,
                    "recall_at_20": 0.84206,
                    "precision_at_1": 0.60678,
                    "precision_at_3": 0.24368,
                    "precision_at_5": 0.15346,
                    "precision_at_10": 0.08067,
                    "precision_at_20": 0.04218,
                    "mrr_at_1": 0.6067821491485613,
                    "mrr_at_3": 0.6628351927970197,
                    "mrr_at_5": 0.6711469954981409,
                    "mrr_at_10": 0.6763959725600953,
                    "mrr_at_20": 0.6789596010010387,
                    "main_score": 0.70778,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 124.99739241600037,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "6e346642246bfb4928c560ee08640dc84d074e8c",
        "task_name": "LEMBWikimQARetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.97333,
                    "ndcg_at_3": 0.98385,
                    "ndcg_at_5": 0.98801,
                    "ndcg_at_10": 0.98801,
                    "map_at_1": 0.97333,
                    "map_at_3": 0.98167,
                    "map_at_5": 0.984,
                    "map_at_10": 0.984,
                    "recall_at_1": 0.97333,
                    "recall_at_3": 0.99,
                    "recall_at_5": 1.0,
                    "recall_at_10": 1.0,
                    "precision_at_1": 0.97333,
                    "precision_at_3": 0.33,
                    "precision_at_5": 0.2,
                    "precision_at_10": 0.1,
                    "mrr_at_1": 0.9733333333333334,
                    "mrr_at_3": 0.9816666666666667,
                    "mrr_at_5": 0.984,
                    "mrr_at_10": 0.984,
                    "main_score": 0.98801,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 64.98908758163452,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.396,
                    "ndcg_at_3": 0.49285,
                    "ndcg_at_5": 0.51988,
                    "ndcg_at_10": 0.55026,
                    "ndcg_at_20": 0.56607,
                    "map_at_1": 0.396,
                    "map_at_3": 0.46867,
                    "map_at_5": 0.48382,
                    "map_at_10": 0.49633,
                    "map_at_20": 0.50073,
                    "recall_at_1": 0.396,
                    "recall_at_3": 0.563,
                    "recall_at_5": 0.628,
                    "recall_at_10": 0.722,
                    "recall_at_20": 0.784,
                    "precision_at_1": 0.396,
                    "precision_at_3": 0.18767,
                    "precision_at_5": 0.1256,
                    "precision_at_10": 0.0722,
                    "precision_at_20": 0.0392,
                    "mrr_at_1": 0.396,
                    "mrr_at_3": 0.468666666666666,
                    "mrr_at_5": 0.4838166666666658,
                    "mrr_at_10": 0.49632857142857106,
                    "mrr_at_20": 0.5007310757611835,
                    "main_score": 0.55026,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 222.09704089164734,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.37361,
                    "ndcg_at_3": 0.43094,
                    "ndcg_at_5": 0.44687,
                    "ndcg_at_10": 0.46305,
                    "ndcg_at_20": 0.47503,
                    "map_at_1": 0.37359,
                    "map_at_3": 0.41692,
                    "map_at_5": 0.42575,
                    "map_at_10": 0.43249,
                    "map_at_20": 0.43577,
                    "recall_at_1": 0.37359,
                    "recall_at_3": 0.47145,
                    "recall_at_5": 0.51016,
                    "recall_at_10": 0.55986,
                    "recall_at_20": 0.60725,
                    "precision_at_1": 0.37361,
                    "precision_at_3": 0.15716,
                    "precision_at_5": 0.10204,
                    "precision_at_10": 0.056,
                    "precision_at_20": 0.03037,
                    "mrr_at_1": 0.37360750648832103,
                    "mrr_at_3": 0.41693618153989587,
                    "mrr_at_5": 0.4257702801623777,
                    "mrr_at_10": 0.4325233468645371,
                    "mrr_at_20": 0.4358168171992325,
                    "main_score": 0.46305,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 68.9355583190918,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.396,
                    "ndcg_at_3": 0.49285,
                    "ndcg_at_5": 0.51988,
                    "ndcg_at_10": 0.55026,
                    "ndcg_at_20": 0.56607,
                    "map_at_1": 0.396,
                    "map_at_3": 0.46867,
                    "map_at_5": 0.48382,
                    "map_at_10": 0.49633,
                    "map_at_20": 0.50073,
                    "recall_at_1": 0.396,
                    "recall_at_3": 0.563,
                    "recall_at_5": 0.628,
                    "recall_at_10": 0.722,
                    "recall_at_20": 0.784,
                    "precision_at_1": 0.396,
                    "precision_at_3": 0.18767,
                    "precision_at_5": 0.1256,
                    "precision_at_10": 0.0722,
                    "precision_at_20": 0.0392,
                    "mrr_at_1": 0.396,
                    "mrr_at_3": 0.468666666666666,
                    "mrr_at_5": 0.4838166666666658,
                    "mrr_at_10": 0.49632857142857106,
                    "mrr_at_20": 0.5007310757611835,
                    "main_score": 0.55026,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 221.25792002677917,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.34259,
                    "ndcg_at_3": 0.34628,
                    "ndcg_at_5": 0.36277,
                    "ndcg_at_10": 0.39152,
                    "map_at_1": 0.22072,
                    "map_at_3": 0.29353,
                    "map_at_5": 0.31235,
                    "map_at_10": 0.32941,
                    "recall_at_1": 0.22072,
                    "recall_at_3": 0.34594,
                    "recall_at_5": 0.40064,
                    "recall_at_10": 0.48484,
                    "precision_at_1": 0.34259,
                    "precision_at_3": 0.19722,
                    "precision_at_5": 0.14174,
                    "precision_at_10": 0.08815,
                    "mrr_at_1": 0.3425856464116029,
                    "mrr_at_3": 0.3971409519046423,
                    "mrr_at_5": 0.4089564057681088,
                    "mrr_at_10": 0.41954714869193405,
                    "main_score": 0.39152,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 735.503711938858,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.61564,
                    "ndcg_at_3": 0.69209,
                    "ndcg_at_5": 0.70641,
                    "ndcg_at_10": 0.72065,
                    "ndcg_at_20": 0.73047,
                    "map_at_1": 0.61529,
                    "map_at_3": 0.67385,
                    "map_at_5": 0.68183,
                    "map_at_10": 0.68774,
                    "map_at_20": 0.69046,
                    "recall_at_1": 0.61529,
                    "recall_at_3": 0.74444,
                    "recall_at_5": 0.77913,
                    "recall_at_10": 0.82295,
                    "recall_at_20": 0.86157,
                    "precision_at_1": 0.61564,
                    "precision_at_3": 0.24845,
                    "precision_at_5": 0.15604,
                    "precision_at_10": 0.08241,
                    "precision_at_20": 0.04316,
                    "mrr_at_1": 0.6156420644706712,
                    "mrr_at_3": 0.6740013309063793,
                    "mrr_at_5": 0.6819515393498117,
                    "mrr_at_10": 0.687858100494617,
                    "mrr_at_20": 0.6905802681467476,
                    "main_score": 0.72065,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 135.2435028553009,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.67439,
                    "ndcg_at_3": 0.75149,
                    "ndcg_at_5": 0.77775,
                    "ndcg_at_10": 0.79178,
                    "ndcg_at_20": 0.79891,
                    "map_at_1": 0.67281,
                    "map_at_3": 0.7327,
                    "map_at_5": 0.74747,
                    "map_at_10": 0.75354,
                    "map_at_20": 0.75546,
                    "recall_at_1": 0.67281,
                    "recall_at_3": 0.80506,
                    "recall_at_5": 0.86776,
                    "recall_at_10": 0.91043,
                    "recall_at_20": 0.93888,
                    "precision_at_1": 0.67439,
                    "precision_at_3": 0.26976,
                    "precision_at_5": 0.17492,
                    "precision_at_10": 0.09199,
                    "precision_at_20": 0.04742,
                    "mrr_at_1": 0.6733403582718651,
                    "mrr_at_3": 0.7330523357920616,
                    "mrr_at_5": 0.7474885844748861,
                    "mrr_at_10": 0.7530428855771325,
                    "mrr_at_20": 0.754966805248184,
                    "main_score": 0.79178,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 431.87434816360474,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.65831,
                    "ndcg_at_3": 0.72973,
                    "ndcg_at_5": 0.743,
                    "ndcg_at_10": 0.7551,
                    "ndcg_at_20": 0.76379,
                    "map_at_1": 0.65789,
                    "map_at_3": 0.71274,
                    "map_at_5": 0.72014,
                    "map_at_10": 0.72517,
                    "map_at_20": 0.72756,
                    "recall_at_1": 0.65789,
                    "recall_at_3": 0.7784,
                    "recall_at_5": 0.81051,
                    "recall_at_10": 0.84778,
                    "recall_at_20": 0.88202,
                    "precision_at_1": 0.65831,
                    "precision_at_3": 0.25979,
                    "precision_at_5": 0.16235,
                    "precision_at_10": 0.08492,
                    "precision_at_20": 0.04419,
                    "mrr_at_1": 0.6583088667058132,
                    "mrr_at_3": 0.7129477392836088,
                    "mrr_at_5": 0.7203112155020526,
                    "mrr_at_10": 0.725320559423613,
                    "mrr_at_20": 0.7277066711608019,
                    "main_score": 0.7551,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 309.83593678474426,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.54796,
                    "ndcg_at_3": 0.6326,
                    "ndcg_at_5": 0.65297,
                    "ndcg_at_10": 0.67127,
                    "ndcg_at_20": 0.68327,
                    "map_at_1": 0.54793,
                    "map_at_3": 0.61208,
                    "map_at_5": 0.62341,
                    "map_at_10": 0.63102,
                    "map_at_20": 0.63432,
                    "recall_at_1": 0.54793,
                    "recall_at_3": 0.69176,
                    "recall_at_5": 0.7411,
                    "recall_at_10": 0.79746,
                    "recall_at_20": 0.84483,
                    "precision_at_1": 0.54796,
                    "precision_at_3": 0.23068,
                    "precision_at_5": 0.14831,
                    "precision_at_10": 0.07981,
                    "precision_at_20": 0.04228,
                    "mrr_at_1": 0.5479597074297446,
                    "mrr_at_3": 0.6121733179349018,
                    "mrr_at_5": 0.623468711236589,
                    "mrr_at_10": 0.6310513581582251,
                    "mrr_at_20": 0.6343577453618894,
                    "main_score": 0.67127,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 79.1958839893341,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.49249,
                    "ndcg_at_3": 0.5808,
                    "ndcg_at_5": 0.60302,
                    "ndcg_at_10": 0.62365,
                    "ndcg_at_20": 0.63643,
                    "map_at_1": 0.49239,
                    "map_at_3": 0.5594,
                    "map_at_5": 0.57177,
                    "map_at_10": 0.58036,
                    "map_at_20": 0.5839,
                    "recall_at_1": 0.49239,
                    "recall_at_3": 0.64248,
                    "recall_at_5": 0.69634,
                    "recall_at_10": 0.75968,
                    "recall_at_20": 0.80995,
                    "precision_at_1": 0.49249,
                    "precision_at_3": 0.21424,
                    "precision_at_5": 0.13932,
                    "precision_at_10": 0.07601,
                    "precision_at_20": 0.04053,
                    "mrr_at_1": 0.49249326318490955,
                    "mrr_at_3": 0.559476453227264,
                    "mrr_at_5": 0.5718272808931241,
                    "mrr_at_10": 0.5804283555246079,
                    "mrr_at_20": 0.5839642488092665,
                    "main_score": 0.62365,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 124.48485279083252,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.463,
                    "ndcg_at_3": 0.55914,
                    "ndcg_at_5": 0.58105,
                    "ndcg_at_10": 0.60654,
                    "ndcg_at_20": 0.62443,
                    "map_at_1": 0.463,
                    "map_at_3": 0.53567,
                    "map_at_5": 0.54787,
                    "map_at_10": 0.55835,
                    "map_at_20": 0.56336,
                    "recall_at_1": 0.463,
                    "recall_at_3": 0.627,
                    "recall_at_5": 0.68,
                    "recall_at_10": 0.759,
                    "recall_at_20": 0.829,
                    "precision_at_1": 0.463,
                    "precision_at_3": 0.209,
                    "precision_at_5": 0.136,
                    "precision_at_10": 0.0759,
                    "precision_at_20": 0.04145,
                    "mrr_at_1": 0.463,
                    "mrr_at_3": 0.5356666666666663,
                    "mrr_at_5": 0.5478666666666661,
                    "mrr_at_10": 0.5583496031746027,
                    "mrr_at_20": 0.563355213899447,
                    "main_score": 0.60654,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 179.4110825061798,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.59419,
                    "ndcg_at_3": 0.6669,
                    "ndcg_at_5": 0.68348,
                    "ndcg_at_10": 0.69991,
                    "ndcg_at_20": 0.71032,
                    "map_at_1": 0.59407,
                    "map_at_3": 0.64926,
                    "map_at_5": 0.65847,
                    "map_at_10": 0.66532,
                    "map_at_20": 0.66819,
                    "recall_at_1": 0.59407,
                    "recall_at_3": 0.7177,
                    "recall_at_5": 0.75795,
                    "recall_at_10": 0.80847,
                    "recall_at_20": 0.84951,
                    "precision_at_1": 0.59419,
                    "precision_at_3": 0.23938,
                    "precision_at_5": 0.15169,
                    "precision_at_10": 0.08091,
                    "precision_at_20": 0.04251,
                    "mrr_at_1": 0.5941870909790838,
                    "mrr_at_3": 0.6493327345053241,
                    "mrr_at_5": 0.658536507121782,
                    "mrr_at_10": 0.6653701480164398,
                    "mrr_at_20": 0.6682448764146836,
                    "main_score": 0.69991,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 106.54507637023926,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.415,
                    "ndcg_at_3": 0.5221,
                    "ndcg_at_5": 0.54732,
                    "ndcg_at_10": 0.56835,
                    "map_at_1": 0.415,
                    "map_at_3": 0.49617,
                    "map_at_5": 0.51022,
                    "map_at_10": 0.51891,
                    "recall_at_1": 0.415,
                    "recall_at_3": 0.597,
                    "recall_at_5": 0.658,
                    "recall_at_10": 0.723,
                    "precision_at_1": 0.415,
                    "precision_at_3": 0.199,
                    "precision_at_5": 0.1316,
                    "precision_at_10": 0.0723,
                    "mrr_at_1": 0.415,
                    "mrr_at_3": 0.4961666666666661,
                    "mrr_at_5": 0.510216666666666,
                    "mrr_at_10": 0.5189051587301583,
                    "main_score": 0.56835,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 99.30980038642883,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.65837,
                    "ndcg_at_3": 0.72975,
                    "ndcg_at_5": 0.74302,
                    "ndcg_at_10": 0.75514,
                    "ndcg_at_20": 0.76383,
                    "map_at_1": 0.65795,
                    "map_at_3": 0.71278,
                    "map_at_5": 0.72017,
                    "map_at_10": 0.72521,
                    "map_at_20": 0.72761,
                    "recall_at_1": 0.65795,
                    "recall_at_3": 0.7784,
                    "recall_at_5": 0.81049,
                    "recall_at_10": 0.84781,
                    "recall_at_20": 0.88211,
                    "precision_at_1": 0.65837,
                    "precision_at_3": 0.25979,
                    "precision_at_5": 0.16235,
                    "precision_at_10": 0.08492,
                    "precision_at_20": 0.04419,
                    "mrr_at_1": 0.6583675866118615,
                    "mrr_at_3": 0.7129819925621369,
                    "mrr_at_5": 0.7203381287923247,
                    "mrr_at_10": 0.7253586807594441,
                    "mrr_at_20": 0.7277462534785699,
                    "main_score": 0.75514,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 148.3529393672943,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.37046,
                    "ndcg_at_3": 0.45086,
                    "ndcg_at_5": 0.47433,
                    "ndcg_at_10": 0.49818,
                    "ndcg_at_20": 0.51431,
                    "map_at_1": 0.3704,
                    "map_at_3": 0.43115,
                    "map_at_5": 0.44418,
                    "map_at_10": 0.45405,
                    "map_at_20": 0.45848,
                    "recall_at_1": 0.3704,
                    "recall_at_3": 0.50782,
                    "recall_at_5": 0.56478,
                    "recall_at_10": 0.63833,
                    "recall_at_20": 0.70211,
                    "precision_at_1": 0.37046,
                    "precision_at_3": 0.16933,
                    "precision_at_5": 0.11299,
                    "precision_at_10": 0.06387,
                    "precision_at_20": 0.03513,
                    "mrr_at_1": 0.3704606698319004,
                    "mrr_at_3": 0.431193592540322,
                    "mrr_at_5": 0.4442197057188214,
                    "mrr_at_10": 0.45410045696281404,
                    "mrr_at_20": 0.4585304929201346,
                    "main_score": 0.49818,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 58.833850622177124,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.489,
                    "ndcg_at_3": 0.57616,
                    "ndcg_at_5": 0.59891,
                    "ndcg_at_10": 0.61897,
                    "ndcg_at_20": 0.63227,
                    "map_at_1": 0.48892,
                    "map_at_3": 0.55497,
                    "map_at_5": 0.56756,
                    "map_at_10": 0.57589,
                    "map_at_20": 0.57958,
                    "recall_at_1": 0.48892,
                    "recall_at_3": 0.63731,
                    "recall_at_5": 0.69263,
                    "recall_at_10": 0.75439,
                    "recall_at_20": 0.80671,
                    "precision_at_1": 0.489,
                    "precision_at_3": 0.21249,
                    "precision_at_5": 0.13857,
                    "precision_at_10": 0.07548,
                    "precision_at_20": 0.04036,
                    "mrr_at_1": 0.4889965353522392,
                    "mrr_at_3": 0.5550280165960987,
                    "mrr_at_5": 0.5676354848368339,
                    "mrr_at_10": 0.5759691109644719,
                    "mrr_at_20": 0.5796552052998972,
                    "main_score": 0.61897,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 113.08009362220764,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.69183,
                    "ndcg_at_3": 0.7598,
                    "ndcg_at_5": 0.78057,
                    "ndcg_at_10": 0.79666,
                    "map_at_1": 0.66879,
                    "map_at_3": 0.74014,
                    "map_at_5": 0.75248,
                    "map_at_10": 0.75948,
                    "recall_at_1": 0.66879,
                    "recall_at_3": 0.80818,
                    "recall_at_5": 0.8577,
                    "recall_at_10": 0.90602,
                    "precision_at_1": 0.69183,
                    "precision_at_3": 0.28505,
                    "precision_at_5": 0.18212,
                    "precision_at_10": 0.09628,
                    "mrr_at_1": 0.6918338108882521,
                    "mrr_at_3": 0.7482569245463231,
                    "mrr_at_5": 0.7588944603629394,
                    "mrr_at_10": 0.7653400304725514,
                    "main_score": 0.79666,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 216.4439845085144,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.4582,
                    "ndcg_at_3": 0.41429,
                    "ndcg_at_5": 0.39503,
                    "ndcg_at_10": 0.36488,
                    "map_at_1": 0.0459,
                    "map_at_3": 0.08804,
                    "map_at_5": 0.10721,
                    "map_at_10": 0.12948,
                    "recall_at_1": 0.0459,
                    "recall_at_3": 0.10223,
                    "recall_at_5": 0.13416,
                    "recall_at_10": 0.1718,
                    "precision_at_1": 0.47988,
                    "precision_at_3": 0.39732,
                    "precision_at_5": 0.35418,
                    "precision_at_10": 0.28452,
                    "mrr_at_1": 0.47987616099071206,
                    "mrr_at_3": 0.5448916408668733,
                    "mrr_at_5": 0.5565015479876161,
                    "mrr_at_10": 0.5622733303847854,
                    "main_score": 0.36488,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 57.3673210144043,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.459,
                    "ndcg_at_3": 0.51667,
                    "ndcg_at_5": 0.52484,
                    "ndcg_at_10": 0.54173,
                    "ndcg_at_20": 0.5501,
                    "map_at_1": 0.459,
                    "map_at_3": 0.503,
                    "map_at_5": 0.5075,
                    "map_at_10": 0.51452,
                    "map_at_20": 0.51683,
                    "recall_at_1": 0.459,
                    "recall_at_3": 0.556,
                    "recall_at_5": 0.576,
                    "recall_at_10": 0.628,
                    "recall_at_20": 0.661,
                    "precision_at_1": 0.459,
                    "precision_at_3": 0.18533,
                    "precision_at_5": 0.1152,
                    "precision_at_10": 0.0628,
                    "precision_at_20": 0.03305,
                    "mrr_at_1": 0.459,
                    "mrr_at_3": 0.5029999999999998,
                    "mrr_at_5": 0.5074999999999997,
                    "mrr_at_10": 0.5145162698412699,
                    "mrr_at_20": 0.5168250576607775,
                    "main_score": 0.54173,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 307.39094853401184,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.68701,
                    "ndcg_at_3": 0.75858,
                    "ndcg_at_5": 0.77185,
                    "ndcg_at_10": 0.78306,
                    "map_at_1": 0.68661,
                    "map_at_3": 0.7416,
                    "map_at_5": 0.74902,
                    "map_at_10": 0.75369,
                    "recall_at_1": 0.68661,
                    "recall_at_3": 0.80724,
                    "recall_at_5": 0.83926,
                    "recall_at_10": 0.87371,
                    "precision_at_1": 0.68701,
                    "precision_at_3": 0.26939,
                    "precision_at_5": 0.16809,
                    "precision_at_10": 0.08751,
                    "mrr_at_1": 0.6870119194410194,
                    "mrr_at_3": 0.7418090540778483,
                    "mrr_at_5": 0.7491897128765147,
                    "mrr_at_10": 0.7538397884157063,
                    "main_score": 0.78306,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 181.40500140190125,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.64636,
                    "ndcg_at_3": 0.71929,
                    "ndcg_at_5": 0.73315,
                    "ndcg_at_10": 0.74534,
                    "ndcg_at_20": 0.75373,
                    "map_at_1": 0.646,
                    "map_at_3": 0.70191,
                    "map_at_5": 0.70963,
                    "map_at_10": 0.71471,
                    "map_at_20": 0.71703,
                    "recall_at_1": 0.646,
                    "recall_at_3": 0.76913,
                    "recall_at_5": 0.80274,
                    "recall_at_10": 0.84015,
                    "recall_at_20": 0.87324,
                    "precision_at_1": 0.64636,
                    "precision_at_3": 0.25666,
                    "precision_at_5": 0.16076,
                    "precision_at_10": 0.08414,
                    "precision_at_20": 0.04374,
                    "mrr_at_1": 0.6463593658250146,
                    "mrr_at_3": 0.7020845566647025,
                    "mrr_at_5": 0.7097651203758061,
                    "mrr_at_10": 0.7148302249065611,
                    "mrr_at_20": 0.7171414605677141,
                    "main_score": 0.74534,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1794.6355149745941,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.74345,
                    "ndcg_at_3": 0.78137,
                    "ndcg_at_5": 0.78849,
                    "ndcg_at_10": 0.79405,
                    "ndcg_at_20": 0.79771,
                    "map_at_1": 0.74345,
                    "map_at_3": 0.77243,
                    "map_at_5": 0.7764,
                    "map_at_10": 0.77871,
                    "map_at_20": 0.77974,
                    "recall_at_1": 0.74345,
                    "recall_at_3": 0.8071,
                    "recall_at_5": 0.8243,
                    "recall_at_10": 0.8414,
                    "recall_at_20": 0.8557,
                    "precision_at_1": 0.74345,
                    "precision_at_3": 0.26903,
                    "precision_at_5": 0.16486,
                    "precision_at_10": 0.08414,
                    "precision_at_20": 0.04278,
                    "mrr_at_1": 0.74345,
                    "mrr_at_3": 0.7724250000000031,
                    "mrr_at_5": 0.7763975000000052,
                    "mrr_at_10": 0.7787093055555598,
                    "mrr_at_20": 0.7797395170054042,
                    "main_score": 0.79405,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1530.3247804641724,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.72455,
                    "ndcg_at_3": 0.76229,
                    "ndcg_at_5": 0.76926,
                    "ndcg_at_10": 0.77508,
                    "ndcg_at_20": 0.77883,
                    "map_at_1": 0.72455,
                    "map_at_3": 0.75343,
                    "map_at_5": 0.75732,
                    "map_at_10": 0.75974,
                    "map_at_20": 0.76078,
                    "recall_at_1": 0.72455,
                    "recall_at_3": 0.78775,
                    "recall_at_5": 0.8046,
                    "recall_at_10": 0.8225,
                    "recall_at_20": 0.8372,
                    "precision_at_1": 0.72455,
                    "precision_at_3": 0.26258,
                    "precision_at_5": 0.16092,
                    "precision_at_10": 0.08225,
                    "precision_at_20": 0.04186,
                    "mrr_at_1": 0.72455,
                    "mrr_at_3": 0.7534333333333373,
                    "mrr_at_5": 0.7573158333333392,
                    "mrr_at_10": 0.7597423412698464,
                    "mrr_at_20": 0.7607843545547661,
                    "main_score": 0.77508,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 569.7566268444061,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.36068,
                    "ndcg_at_3": 0.33397,
                    "ndcg_at_5": 0.31342,
                    "ndcg_at_10": 0.28677,
                    "ndcg_at_20": 0.26535,
                    "map_at_1": 0.04344,
                    "map_at_3": 0.07628,
                    "map_at_5": 0.08778,
                    "map_at_10": 0.10246,
                    "map_at_20": 0.11277,
                    "recall_at_1": 0.04344,
                    "recall_at_3": 0.08598,
                    "recall_at_5": 0.10564,
                    "recall_at_10": 0.13591,
                    "recall_at_20": 0.17049,
                    "precision_at_1": 0.3808,
                    "precision_at_3": 0.31579,
                    "precision_at_5": 0.27245,
                    "precision_at_10": 0.21207,
                    "precision_at_20": 0.15495,
                    "mrr_at_1": 0.38080495356037153,
                    "mrr_at_3": 0.4540763673890609,
                    "mrr_at_5": 0.46986584107327145,
                    "mrr_at_10": 0.4754840532704309,
                    "mrr_at_20": 0.4795940565663029,
                    "main_score": 0.28677,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 157.4404764175415,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.34084,
                    "ndcg_at_3": 0.3443,
                    "ndcg_at_5": 0.35995,
                    "ndcg_at_10": 0.38956,
                    "map_at_1": 0.21896,
                    "map_at_3": 0.29154,
                    "map_at_5": 0.30983,
                    "map_at_10": 0.32711,
                    "recall_at_1": 0.21896,
                    "recall_at_3": 0.34442,
                    "recall_at_5": 0.39695,
                    "recall_at_10": 0.48389,
                    "precision_at_1": 0.34084,
                    "precision_at_3": 0.19613,
                    "precision_at_5": 0.14049,
                    "precision_at_10": 0.08772,
                    "mrr_at_1": 0.34083520880220053,
                    "mrr_at_3": 0.395348837209302,
                    "mrr_at_5": 0.4067766941735435,
                    "mrr_at_10": 0.417745805498993,
                    "main_score": 0.38956,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 709.6533396244049,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.22127,
                    "ndcg_at_3": 0.28001,
                    "ndcg_at_5": 0.2987,
                    "ndcg_at_10": 0.31886,
                    "ndcg_at_20": 0.33453,
                    "map_at_1": 0.22088,
                    "map_at_3": 0.26538,
                    "map_at_5": 0.27578,
                    "map_at_10": 0.2841,
                    "map_at_20": 0.28844,
                    "recall_at_1": 0.22088,
                    "recall_at_3": 0.32167,
                    "recall_at_5": 0.36698,
                    "recall_at_10": 0.4292,
                    "recall_at_20": 0.49081,
                    "precision_at_1": 0.22127,
                    "precision_at_3": 0.10764,
                    "precision_at_5": 0.07373,
                    "precision_at_10": 0.04322,
                    "precision_at_20": 0.02478,
                    "mrr_at_1": 0.22126717213422414,
                    "mrr_at_3": 0.2659209769036323,
                    "mrr_at_5": 0.27633310812500955,
                    "mrr_at_10": 0.28464633357283764,
                    "mrr_at_20": 0.28893270664653375,
                    "main_score": 0.31886,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 44.53587794303894,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.8592,
                    "ndcg_at_3": 0.81777,
                    "ndcg_at_5": 0.8016,
                    "ndcg_at_10": 0.80193,
                    "map_at_1": 0.25379,
                    "map_at_3": 0.50321,
                    "map_at_5": 0.6179,
                    "map_at_10": 0.71655,
                    "recall_at_1": 0.25379,
                    "recall_at_3": 0.52481,
                    "recall_at_5": 0.65959,
                    "recall_at_10": 0.79516,
                    "precision_at_1": 0.8592,
                    "precision_at_3": 0.71888,
                    "precision_at_5": 0.60088,
                    "precision_at_10": 0.40166,
                    "mrr_at_1": 0.8591969139049623,
                    "mrr_at_3": 0.8878806476123664,
                    "mrr_at_5": 0.8916242913086686,
                    "mrr_at_10": 0.8938185207451389,
                    "main_score": 0.80193,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2073.6049888134003,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.66223,
                    "ndcg_at_3": 0.73622,
                    "ndcg_at_5": 0.75132,
                    "ndcg_at_10": 0.7645,
                    "ndcg_at_20": 0.77335,
                    "map_at_1": 0.66188,
                    "map_at_3": 0.71841,
                    "map_at_5": 0.72682,
                    "map_at_10": 0.73232,
                    "map_at_20": 0.73477,
                    "recall_at_1": 0.66188,
                    "recall_at_3": 0.7873,
                    "recall_at_5": 0.82386,
                    "recall_at_10": 0.86436,
                    "recall_at_20": 0.89918,
                    "precision_at_1": 0.66223,
                    "precision_at_3": 0.26268,
                    "precision_at_5": 0.16495,
                    "precision_at_10": 0.08657,
                    "precision_at_20": 0.04504,
                    "mrr_at_1": 0.6622335740708121,
                    "mrr_at_3": 0.7186649834615221,
                    "mrr_at_5": 0.7270540974301735,
                    "mrr_at_10": 0.7325124213269342,
                    "mrr_at_20": 0.7349600105743306,
                    "main_score": 0.7645,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 173.52619075775146,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.66218,
                    "ndcg_at_3": 0.73404,
                    "ndcg_at_5": 0.7473,
                    "ndcg_at_10": 0.75866,
                    "ndcg_at_20": 0.76644,
                    "map_at_1": 0.66183,
                    "map_at_3": 0.71712,
                    "map_at_5": 0.72451,
                    "map_at_10": 0.72924,
                    "map_at_20": 0.73138,
                    "recall_at_1": 0.66183,
                    "recall_at_3": 0.78257,
                    "recall_at_5": 0.81463,
                    "recall_at_10": 0.84954,
                    "recall_at_20": 0.88025,
                    "precision_at_1": 0.66218,
                    "precision_at_3": 0.26115,
                    "precision_at_5": 0.16315,
                    "precision_at_10": 0.08509,
                    "precision_at_20": 0.0441,
                    "mrr_at_1": 0.6621843805049912,
                    "mrr_at_3": 0.7172245057741156,
                    "mrr_at_5": 0.7245923859855125,
                    "mrr_at_10": 0.7293109265628338,
                    "mrr_at_20": 0.7314392637383385,
                    "main_score": 0.75866,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 109.66536808013916,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "6e346642246bfb4928c560ee08640dc84d074e8c",
        "task_name": "LEMBWikimQARetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.94667,
                    "ndcg_at_3": 0.96849,
                    "ndcg_at_5": 0.96849,
                    "ndcg_at_10": 0.97057,
                    "ndcg_at_20": 0.97221,
                    "map_at_1": 0.94667,
                    "map_at_3": 0.96333,
                    "map_at_5": 0.96333,
                    "map_at_10": 0.96414,
                    "map_at_20": 0.96457,
                    "recall_at_1": 0.94667,
                    "recall_at_3": 0.98333,
                    "recall_at_5": 0.98333,
                    "recall_at_10": 0.99,
                    "recall_at_20": 0.99667,
                    "precision_at_1": 0.94667,
                    "precision_at_3": 0.32778,
                    "precision_at_5": 0.19667,
                    "precision_at_10": 0.099,
                    "precision_at_20": 0.04983,
                    "mrr_at_1": 0.9466666666666667,
                    "mrr_at_3": 0.9633333333333334,
                    "mrr_at_5": 0.9633333333333334,
                    "mrr_at_10": 0.9641428571428571,
                    "mrr_at_20": 0.9645734126984127,
                    "main_score": 0.97057,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 71.60374212265015,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.396,
                    "ndcg_at_3": 0.49285,
                    "ndcg_at_5": 0.51988,
                    "ndcg_at_10": 0.55026,
                    "ndcg_at_20": 0.56607,
                    "map_at_1": 0.396,
                    "map_at_3": 0.46867,
                    "map_at_5": 0.48382,
                    "map_at_10": 0.49633,
                    "map_at_20": 0.50073,
                    "recall_at_1": 0.396,
                    "recall_at_3": 0.563,
                    "recall_at_5": 0.628,
                    "recall_at_10": 0.722,
                    "recall_at_20": 0.784,
                    "precision_at_1": 0.396,
                    "precision_at_3": 0.18767,
                    "precision_at_5": 0.1256,
                    "precision_at_10": 0.0722,
                    "precision_at_20": 0.0392,
                    "mrr_at_1": 0.396,
                    "mrr_at_3": 0.468666666666666,
                    "mrr_at_5": 0.4838166666666658,
                    "mrr_at_10": 0.49632857142857106,
                    "mrr_at_20": 0.5007310757611835,
                    "main_score": 0.55026,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 104.33704829216003,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.415,
                    "ndcg_at_3": 0.5226,
                    "ndcg_at_5": 0.54782,
                    "ndcg_at_10": 0.5685,
                    "ndcg_at_20": 0.58947,
                    "map_at_1": 0.415,
                    "map_at_3": 0.4965,
                    "map_at_5": 0.51055,
                    "map_at_10": 0.51907,
                    "map_at_20": 0.52482,
                    "recall_at_1": 0.415,
                    "recall_at_3": 0.598,
                    "recall_at_5": 0.659,
                    "recall_at_10": 0.723,
                    "recall_at_20": 0.806,
                    "precision_at_1": 0.415,
                    "precision_at_3": 0.19933,
                    "precision_at_5": 0.1318,
                    "precision_at_10": 0.0723,
                    "precision_at_20": 0.0403,
                    "mrr_at_1": 0.415,
                    "mrr_at_3": 0.49649999999999944,
                    "mrr_at_5": 0.5105499999999994,
                    "mrr_at_10": 0.5190718253968251,
                    "mrr_at_20": 0.5248209007452811,
                    "main_score": 0.5685,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 73.32701659202576,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.36883,
                    "ndcg_at_3": 0.33566,
                    "ndcg_at_5": 0.34302,
                    "ndcg_at_10": 0.36859,
                    "ndcg_at_20": 0.39176,
                    "map_at_1": 0.18124,
                    "map_at_3": 0.25644,
                    "map_at_5": 0.27581,
                    "map_at_10": 0.29429,
                    "map_at_20": 0.30264,
                    "recall_at_1": 0.18124,
                    "recall_at_3": 0.30629,
                    "recall_at_5": 0.35715,
                    "recall_at_10": 0.43344,
                    "recall_at_20": 0.50401,
                    "precision_at_1": 0.36883,
                    "precision_at_3": 0.22171,
                    "precision_at_5": 0.15926,
                    "precision_at_10": 0.10108,
                    "precision_at_20": 0.06057,
                    "mrr_at_1": 0.36882716049382713,
                    "mrr_at_3": 0.4295267489711935,
                    "mrr_at_5": 0.44102366255144027,
                    "mrr_at_10": 0.45066627474034865,
                    "mrr_at_20": 0.4559246403644981,
                    "main_score": 0.36859,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 564.8707978725433,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.6876,
                    "ndcg_at_3": 0.75991,
                    "ndcg_at_5": 0.77332,
                    "ndcg_at_10": 0.78461,
                    "ndcg_at_20": 0.79198,
                    "map_at_1": 0.68722,
                    "map_at_3": 0.74291,
                    "map_at_5": 0.7504,
                    "map_at_10": 0.75511,
                    "map_at_20": 0.75715,
                    "recall_at_1": 0.68722,
                    "recall_at_3": 0.80853,
                    "recall_at_5": 0.84095,
                    "recall_at_10": 0.87561,
                    "recall_at_20": 0.90462,
                    "precision_at_1": 0.6876,
                    "precision_at_3": 0.26979,
                    "precision_at_5": 0.1684,
                    "precision_at_10": 0.08769,
                    "precision_at_20": 0.04531,
                    "mrr_at_1": 0.6875990840232518,
                    "mrr_at_3": 0.7431252813496871,
                    "mrr_at_5": 0.7505675924294878,
                    "mrr_at_10": 0.7552528861935227,
                    "mrr_at_20": 0.7572862353184936,
                    "main_score": 0.78461,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 163.29493069648743,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.59605,
                    "ndcg_at_3": 0.65124,
                    "ndcg_at_5": 0.66395,
                    "ndcg_at_10": 0.67812,
                    "ndcg_at_20": 0.68808,
                    "map_at_1": 0.59597,
                    "map_at_3": 0.63787,
                    "map_at_5": 0.64491,
                    "map_at_10": 0.65081,
                    "map_at_20": 0.65355,
                    "recall_at_1": 0.59597,
                    "recall_at_3": 0.6897,
                    "recall_at_5": 0.7206,
                    "recall_at_10": 0.76411,
                    "recall_at_20": 0.80346,
                    "precision_at_1": 0.59605,
                    "precision_at_3": 0.22996,
                    "precision_at_5": 0.14417,
                    "precision_at_10": 0.07646,
                    "precision_at_20": 0.04021,
                    "mrr_at_1": 0.5960471151926532,
                    "mrr_at_3": 0.6379916150928394,
                    "mrr_at_5": 0.6450389299261435,
                    "mrr_at_10": 0.650960334889272,
                    "mrr_at_20": 0.653699506667881,
                    "main_score": 0.67812,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2591.5352580547333,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.8,
                    "ndcg_at_3": 0.75721,
                    "ndcg_at_5": 0.74773,
                    "ndcg_at_10": 0.78054,
                    "ndcg_at_20": 0.80496,
                    "map_at_1": 0.22296,
                    "map_at_3": 0.46384,
                    "map_at_5": 0.58602,
                    "map_at_10": 0.6824,
                    "map_at_20": 0.70739,
                    "recall_at_1": 0.22296,
                    "recall_at_3": 0.49774,
                    "recall_at_5": 0.65407,
                    "recall_at_10": 0.8059,
                    "recall_at_20": 0.87792,
                    "precision_at_1": 0.8,
                    "precision_at_3": 0.68183,
                    "precision_at_5": 0.5769,
                    "precision_at_10": 0.382,
                    "precision_at_20": 0.21328,
                    "mrr_at_1": 0.8,
                    "mrr_at_3": 0.8594999999999996,
                    "mrr_at_5": 0.8636999999999998,
                    "mrr_at_10": 0.8655126984126981,
                    "mrr_at_20": 0.866479698099028,
                    "main_score": 0.78054,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1395.0305116176605,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.86462,
                    "ndcg_at_3": 0.90218,
                    "ndcg_at_5": 0.90894,
                    "ndcg_at_10": 0.9137,
                    "ndcg_at_20": 0.91649,
                    "map_at_1": 0.86462,
                    "map_at_3": 0.8933,
                    "map_at_5": 0.89706,
                    "map_at_10": 0.89904,
                    "map_at_20": 0.89982,
                    "recall_at_1": 0.86462,
                    "recall_at_3": 0.9277,
                    "recall_at_5": 0.94411,
                    "recall_at_10": 0.95876,
                    "recall_at_20": 0.96967,
                    "precision_at_1": 0.86462,
                    "precision_at_3": 0.30924,
                    "precision_at_5": 0.18883,
                    "precision_at_10": 0.09588,
                    "precision_at_20": 0.04849,
                    "mrr_at_1": 0.8646241539009619,
                    "mrr_at_3": 0.8933098800617507,
                    "mrr_at_5": 0.897075020781382,
                    "mrr_at_10": 0.8990517788578465,
                    "mrr_at_20": 0.8998346809447451,
                    "main_score": 0.9137,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 59.07467484474182,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.66877,
                    "ndcg_at_3": 0.73639,
                    "ndcg_at_5": 0.75635,
                    "ndcg_at_10": 0.77272,
                    "ndcg_at_20": 0.78071,
                    "map_at_1": 0.64633,
                    "map_at_3": 0.71618,
                    "map_at_5": 0.72806,
                    "map_at_10": 0.73525,
                    "map_at_20": 0.73754,
                    "recall_at_1": 0.64633,
                    "recall_at_3": 0.78521,
                    "recall_at_5": 0.83269,
                    "recall_at_10": 0.88194,
                    "recall_at_20": 0.91305,
                    "precision_at_1": 0.66877,
                    "precision_at_3": 0.27679,
                    "precision_at_5": 0.17673,
                    "precision_at_10": 0.0938,
                    "precision_at_20": 0.04857,
                    "mrr_at_1": 0.6687679083094555,
                    "mrr_at_3": 0.7255730659025794,
                    "mrr_at_5": 0.735716332378222,
                    "mrr_at_10": 0.7420031723291038,
                    "mrr_at_20": 0.744075456587027,
                    "main_score": 0.77272,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 457.11723804473877,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.90675,
                    "ndcg_at_3": 0.93725,
                    "ndcg_at_5": 0.94153,
                    "ndcg_at_10": 0.94466,
                    "ndcg_at_20": 0.94609,
                    "map_at_1": 0.90671,
                    "map_at_3": 0.93006,
                    "map_at_5": 0.93244,
                    "map_at_10": 0.93374,
                    "map_at_20": 0.93414,
                    "recall_at_1": 0.90671,
                    "recall_at_3": 0.95787,
                    "recall_at_5": 0.96825,
                    "recall_at_10": 0.97789,
                    "recall_at_20": 0.9835,
                    "precision_at_1": 0.90675,
                    "precision_at_3": 0.31931,
                    "precision_at_5": 0.19366,
                    "precision_at_10": 0.0978,
                    "precision_at_20": 0.04918,
                    "mrr_at_1": 0.9067509796936231,
                    "mrr_at_3": 0.9301077662985379,
                    "mrr_at_5": 0.9324835233345212,
                    "mrr_at_10": 0.9337774116296558,
                    "mrr_at_20": 0.9341798711700423,
                    "main_score": 0.94466,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 109.76518321037292,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.69231,
                    "ndcg_at_3": 0.77895,
                    "ndcg_at_5": 0.79618,
                    "ndcg_at_10": 0.8132,
                    "map_at_1": 0.68967,
                    "map_at_3": 0.75825,
                    "map_at_5": 0.76796,
                    "map_at_10": 0.77529,
                    "recall_at_1": 0.68967,
                    "recall_at_3": 0.83772,
                    "recall_at_5": 0.87882,
                    "recall_at_10": 0.93045,
                    "precision_at_1": 0.69231,
                    "precision_at_3": 0.281,
                    "precision_at_5": 0.17724,
                    "precision_at_10": 0.09399,
                    "mrr_at_1": 0.6923076923076923,
                    "mrr_at_3": 0.7590446083596771,
                    "mrr_at_5": 0.7686336494555677,
                    "mrr_at_10": 0.7755636676869554,
                    "main_score": 0.8132,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 685.6170499324799,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.19488,
                    "ndcg_at_3": 0.31121,
                    "ndcg_at_5": 0.36473,
                    "ndcg_at_10": 0.43319,
                    "ndcg_at_20": 0.47066,
                    "map_at_1": 0.19488,
                    "map_at_3": 0.28129,
                    "map_at_5": 0.31078,
                    "map_at_10": 0.33911,
                    "map_at_20": 0.34961,
                    "recall_at_1": 0.19488,
                    "recall_at_3": 0.39829,
                    "recall_at_5": 0.52916,
                    "recall_at_10": 0.7404,
                    "recall_at_20": 0.88691,
                    "precision_at_1": 0.19488,
                    "precision_at_3": 0.13276,
                    "precision_at_5": 0.10583,
                    "precision_at_10": 0.07404,
                    "precision_at_20": 0.04435,
                    "mrr_at_1": 0.19772403982930298,
                    "mrr_at_3": 0.2823613086770979,
                    "mrr_at_5": 0.311842105263157,
                    "mrr_at_10": 0.3402969699022326,
                    "mrr_at_20": 0.35083744628819513,
                    "main_score": 0.43319,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 235.73032140731812,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.64327,
                    "ndcg_at_3": 0.71613,
                    "ndcg_at_5": 0.73716,
                    "ndcg_at_10": 0.75478,
                    "ndcg_at_20": 0.76337,
                    "map_at_1": 0.6217,
                    "map_at_3": 0.69466,
                    "map_at_5": 0.7072,
                    "map_at_10": 0.71496,
                    "map_at_20": 0.71745,
                    "recall_at_1": 0.6217,
                    "recall_at_3": 0.76846,
                    "recall_at_5": 0.81821,
                    "recall_at_10": 0.87098,
                    "recall_at_20": 0.90426,
                    "precision_at_1": 0.64327,
                    "precision_at_3": 0.27058,
                    "precision_at_5": 0.17361,
                    "precision_at_10": 0.09262,
                    "precision_at_20": 0.04809,
                    "mrr_at_1": 0.6432664756446992,
                    "mrr_at_3": 0.7041547277936968,
                    "mrr_at_5": 0.7149426934097405,
                    "mrr_at_10": 0.7218128894346658,
                    "mrr_at_20": 0.7240623042168418,
                    "main_score": 0.75478,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 218.80535864830017,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.5061,
                    "ndcg_at_3": 0.58189,
                    "ndcg_at_5": 0.60093,
                    "ndcg_at_10": 0.61918,
                    "ndcg_at_20": 0.63101,
                    "map_at_1": 0.50593,
                    "map_at_3": 0.56342,
                    "map_at_5": 0.57401,
                    "map_at_10": 0.58159,
                    "map_at_20": 0.58484,
                    "recall_at_1": 0.50593,
                    "recall_at_3": 0.63508,
                    "recall_at_5": 0.68123,
                    "recall_at_10": 0.73746,
                    "recall_at_20": 0.78421,
                    "precision_at_1": 0.5061,
                    "precision_at_3": 0.2118,
                    "precision_at_5": 0.13633,
                    "precision_at_10": 0.07379,
                    "precision_at_20": 0.03924,
                    "mrr_at_1": 0.5060952136532786,
                    "mrr_at_3": 0.5635559690320437,
                    "mrr_at_5": 0.5741327687240803,
                    "mrr_at_10": 0.581701374249184,
                    "mrr_at_20": 0.5849540225254211,
                    "main_score": 0.61918,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 103.66553568840027,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.72076,
                    "ndcg_at_3": 0.80483,
                    "ndcg_at_5": 0.82427,
                    "ndcg_at_10": 0.83671,
                    "map_at_1": 0.7176,
                    "map_at_3": 0.78425,
                    "map_at_5": 0.79517,
                    "map_at_10": 0.80055,
                    "recall_at_1": 0.7176,
                    "recall_at_3": 0.86249,
                    "recall_at_5": 0.90938,
                    "recall_at_10": 0.94731,
                    "precision_at_1": 0.72076,
                    "precision_at_3": 0.28943,
                    "precision_at_5": 0.18356,
                    "precision_at_10": 0.09579,
                    "mrr_at_1": 0.7207586933614331,
                    "mrr_at_3": 0.7859149982437654,
                    "mrr_at_5": 0.7963997190024591,
                    "mrr_at_10": 0.8013288842055969,
                    "main_score": 0.83671,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 690.5180063247681,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.557,
                    "ndcg_at_3": 0.6675,
                    "ndcg_at_5": 0.69056,
                    "ndcg_at_10": 0.7068,
                    "ndcg_at_20": 0.71937,
                    "map_at_1": 0.557,
                    "map_at_3": 0.64067,
                    "map_at_5": 0.65347,
                    "map_at_10": 0.66021,
                    "map_at_20": 0.66362,
                    "recall_at_1": 0.557,
                    "recall_at_3": 0.745,
                    "recall_at_5": 0.801,
                    "recall_at_10": 0.851,
                    "recall_at_20": 0.901,
                    "precision_at_1": 0.557,
                    "precision_at_3": 0.24833,
                    "precision_at_5": 0.1602,
                    "precision_at_10": 0.0851,
                    "precision_at_20": 0.04505,
                    "mrr_at_1": 0.557,
                    "mrr_at_3": 0.6406666666666666,
                    "mrr_at_5": 0.6534666666666668,
                    "mrr_at_10": 0.6602123015873015,
                    "mrr_at_20": 0.6636173292737534,
                    "main_score": 0.7068,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 116.34171485900879,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.17852,
                    "ndcg_at_3": 0.28319,
                    "ndcg_at_5": 0.33528,
                    "ndcg_at_10": 0.39548,
                    "ndcg_at_20": 0.43395,
                    "map_at_1": 0.17852,
                    "map_at_3": 0.25699,
                    "map_at_5": 0.28587,
                    "map_at_10": 0.31081,
                    "map_at_20": 0.32154,
                    "recall_at_1": 0.17852,
                    "recall_at_3": 0.35917,
                    "recall_at_5": 0.48578,
                    "recall_at_10": 0.67141,
                    "recall_at_20": 0.82219,
                    "precision_at_1": 0.17852,
                    "precision_at_3": 0.11972,
                    "precision_at_5": 0.09716,
                    "precision_at_10": 0.06714,
                    "precision_at_20": 0.04111,
                    "mrr_at_1": 0.1813655761024182,
                    "mrr_at_3": 0.2584163110478899,
                    "mrr_at_5": 0.28661688003793206,
                    "mrr_at_10": 0.31222481880376596,
                    "mrr_at_20": 0.3228940948123767,
                    "main_score": 0.39548,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 24.559934377670288,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.35494,
                    "ndcg_at_3": 0.32218,
                    "ndcg_at_5": 0.33372,
                    "ndcg_at_10": 0.35307,
                    "ndcg_at_20": 0.37766,
                    "map_at_1": 0.17472,
                    "map_at_3": 0.24595,
                    "map_at_5": 0.26783,
                    "map_at_10": 0.28337,
                    "map_at_20": 0.29214,
                    "recall_at_1": 0.17472,
                    "recall_at_3": 0.28625,
                    "recall_at_5": 0.34418,
                    "recall_at_10": 0.40903,
                    "recall_at_20": 0.48656,
                    "precision_at_1": 0.35494,
                    "precision_at_3": 0.21553,
                    "precision_at_5": 0.16142,
                    "precision_at_10": 0.09938,
                    "precision_at_20": 0.05934,
                    "mrr_at_1": 0.3549382716049383,
                    "mrr_at_3": 0.40689300411522655,
                    "mrr_at_5": 0.4221707818930041,
                    "mrr_at_10": 0.43120223398001173,
                    "mrr_at_20": 0.43723360186817645,
                    "main_score": 0.35307,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 322.38638710975647,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.39787,
                    "ndcg_at_3": 0.47297,
                    "ndcg_at_5": 0.49308,
                    "ndcg_at_10": 0.51097,
                    "ndcg_at_20": 0.52439,
                    "map_at_1": 0.39737,
                    "map_at_3": 0.45466,
                    "map_at_5": 0.46582,
                    "map_at_10": 0.47327,
                    "map_at_20": 0.47697,
                    "recall_at_1": 0.39737,
                    "recall_at_3": 0.52521,
                    "recall_at_5": 0.57393,
                    "recall_at_10": 0.6288,
                    "recall_at_20": 0.68157,
                    "precision_at_1": 0.39787,
                    "precision_at_3": 0.1755,
                    "precision_at_5": 0.1152,
                    "precision_at_10": 0.0632,
                    "precision_at_20": 0.03432,
                    "mrr_at_1": 0.39786802792583137,
                    "mrr_at_3": 0.45528363736456745,
                    "mrr_at_5": 0.4664727372819949,
                    "mrr_at_10": 0.4739096908688246,
                    "mrr_at_20": 0.47757603205260135,
                    "main_score": 0.51097,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 113.16385793685913,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.35307,
                    "ndcg_at_3": 0.43293,
                    "ndcg_at_5": 0.45698,
                    "ndcg_at_10": 0.48018,
                    "ndcg_at_20": 0.49659,
                    "map_at_1": 0.35294,
                    "map_at_3": 0.41331,
                    "map_at_5": 0.42666,
                    "map_at_10": 0.43629,
                    "map_at_20": 0.44082,
                    "recall_at_1": 0.35294,
                    "recall_at_3": 0.48957,
                    "recall_at_5": 0.54792,
                    "recall_at_10": 0.61941,
                    "recall_at_20": 0.68406,
                    "precision_at_1": 0.35307,
                    "precision_at_3": 0.16324,
                    "precision_at_5": 0.10963,
                    "precision_at_10": 0.06197,
                    "precision_at_20": 0.03422,
                    "mrr_at_1": 0.35307327088412677,
                    "mrr_at_3": 0.4134319260875216,
                    "mrr_at_5": 0.4267980880277301,
                    "mrr_at_10": 0.4364218167912317,
                    "mrr_at_20": 0.4409492040594418,
                    "main_score": 0.48018,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 46.0395393371582,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.463,
                    "ndcg_at_3": 0.55951,
                    "ndcg_at_5": 0.58055,
                    "ndcg_at_10": 0.60725,
                    "ndcg_at_20": 0.62412,
                    "map_at_1": 0.463,
                    "map_at_3": 0.53583,
                    "map_at_5": 0.54753,
                    "map_at_10": 0.55846,
                    "map_at_20": 0.56319,
                    "recall_at_1": 0.463,
                    "recall_at_3": 0.628,
                    "recall_at_5": 0.679,
                    "recall_at_10": 0.762,
                    "recall_at_20": 0.828,
                    "precision_at_1": 0.463,
                    "precision_at_3": 0.20933,
                    "precision_at_5": 0.1358,
                    "precision_at_10": 0.0762,
                    "precision_at_20": 0.0414,
                    "mrr_at_1": 0.463,
                    "mrr_at_3": 0.5358333333333328,
                    "mrr_at_5": 0.5475333333333328,
                    "mrr_at_10": 0.5584630952380948,
                    "mrr_at_20": 0.5631889455487747,
                    "main_score": 0.60725,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 169.13521027565002,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.31233,
                    "ndcg_at_3": 0.31364,
                    "ndcg_at_5": 0.33012,
                    "ndcg_at_10": 0.35847,
                    "ndcg_at_20": 0.38329,
                    "map_at_1": 0.20125,
                    "map_at_3": 0.2653,
                    "map_at_5": 0.28265,
                    "map_at_10": 0.2989,
                    "map_at_20": 0.30757,
                    "recall_at_1": 0.20125,
                    "recall_at_3": 0.31147,
                    "recall_at_5": 0.36521,
                    "recall_at_10": 0.44804,
                    "recall_at_20": 0.53217,
                    "precision_at_1": 0.31233,
                    "precision_at_3": 0.17888,
                    "precision_at_5": 0.12893,
                    "precision_at_10": 0.08122,
                    "precision_at_20": 0.049,
                    "mrr_at_1": 0.3123280820205051,
                    "mrr_at_3": 0.36304909560723475,
                    "mrr_at_5": 0.3755397182628991,
                    "mrr_at_10": 0.38630312339989714,
                    "mrr_at_20": 0.39186085490616235,
                    "main_score": 0.35847,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1827.726261138916,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.89856,
                    "ndcg_at_3": 0.93263,
                    "ndcg_at_5": 0.93683,
                    "ndcg_at_10": 0.93967,
                    "ndcg_at_20": 0.94135,
                    "map_at_1": 0.89856,
                    "map_at_3": 0.92469,
                    "map_at_5": 0.92703,
                    "map_at_10": 0.92823,
                    "map_at_20": 0.92869,
                    "recall_at_1": 0.89856,
                    "recall_at_3": 0.95542,
                    "recall_at_5": 0.96558,
                    "recall_at_10": 0.97422,
                    "recall_at_20": 0.98085,
                    "precision_at_1": 0.89856,
                    "precision_at_3": 0.31849,
                    "precision_at_5": 0.19312,
                    "precision_at_10": 0.09743,
                    "precision_at_20": 0.04904,
                    "mrr_at_1": 0.8985571784823655,
                    "mrr_at_3": 0.9247046075287961,
                    "mrr_at_5": 0.9270469659185377,
                    "mrr_at_10": 0.9282461010172993,
                    "mrr_at_20": 0.9287078248215541,
                    "main_score": 0.93967,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 136.543199300766,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.27352,
                    "ndcg_at_3": 0.3466,
                    "ndcg_at_5": 0.36942,
                    "ndcg_at_10": 0.39159,
                    "ndcg_at_20": 0.4089,
                    "map_at_1": 0.2727,
                    "map_at_3": 0.32833,
                    "map_at_5": 0.34103,
                    "map_at_10": 0.35021,
                    "map_at_20": 0.35499,
                    "recall_at_1": 0.2727,
                    "recall_at_3": 0.3985,
                    "recall_at_5": 0.45385,
                    "recall_at_10": 0.52208,
                    "recall_at_20": 0.5902,
                    "precision_at_1": 0.27352,
                    "precision_at_3": 0.13346,
                    "precision_at_5": 0.09125,
                    "precision_at_10": 0.05259,
                    "precision_at_20": 0.02979,
                    "mrr_at_1": 0.2735151765279706,
                    "mrr_at_3": 0.3292062181868178,
                    "mrr_at_5": 0.341846446303728,
                    "mrr_at_10": 0.3510526674682686,
                    "mrr_at_20": 0.3557744832980685,
                    "main_score": 0.39159,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 91.97947406768799,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.66476,
                    "ndcg_at_3": 0.7403,
                    "ndcg_at_5": 0.75405,
                    "ndcg_at_10": 0.7658,
                    "ndcg_at_20": 0.77381,
                    "map_at_1": 0.6644,
                    "map_at_3": 0.7224,
                    "map_at_5": 0.73008,
                    "map_at_10": 0.73496,
                    "map_at_20": 0.73718,
                    "recall_at_1": 0.6644,
                    "recall_at_3": 0.79153,
                    "recall_at_5": 0.82479,
                    "recall_at_10": 0.86091,
                    "recall_at_20": 0.89246,
                    "precision_at_1": 0.66476,
                    "precision_at_3": 0.26414,
                    "precision_at_5": 0.16518,
                    "precision_at_10": 0.08623,
                    "precision_at_20": 0.0447,
                    "mrr_at_1": 0.6647583817744114,
                    "mrr_at_3": 0.7226430235061467,
                    "mrr_at_5": 0.7302644197835294,
                    "mrr_at_10": 0.7351319209695097,
                    "mrr_at_20": 0.7373334738375139,
                    "main_score": 0.7658,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 165.41820073127747,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.53076,
                    "ndcg_at_3": 0.61722,
                    "ndcg_at_5": 0.63922,
                    "ndcg_at_10": 0.65803,
                    "ndcg_at_20": 0.67032,
                    "map_at_1": 0.53064,
                    "map_at_3": 0.59613,
                    "map_at_5": 0.60832,
                    "map_at_10": 0.61613,
                    "map_at_20": 0.61954,
                    "recall_at_1": 0.53064,
                    "recall_at_3": 0.67805,
                    "recall_at_5": 0.73156,
                    "recall_at_10": 0.78946,
                    "recall_at_20": 0.83778,
                    "precision_at_1": 0.53076,
                    "precision_at_3": 0.2261,
                    "precision_at_5": 0.14637,
                    "precision_at_10": 0.07898,
                    "precision_at_20": 0.04192,
                    "mrr_at_1": 0.5307647889131272,
                    "mrr_at_3": 0.5962241755421567,
                    "mrr_at_5": 0.6084081868343495,
                    "mrr_at_10": 0.6162258712031047,
                    "mrr_at_20": 0.6196350300279344,
                    "main_score": 0.65803,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 79.59716939926147,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.84419,
                    "ndcg_at_3": 0.88733,
                    "ndcg_at_5": 0.89498,
                    "ndcg_at_10": 0.90099,
                    "ndcg_at_20": 0.90417,
                    "map_at_1": 0.84419,
                    "map_at_3": 0.87716,
                    "map_at_5": 0.88143,
                    "map_at_10": 0.88394,
                    "map_at_20": 0.88482,
                    "recall_at_1": 0.84419,
                    "recall_at_3": 0.91659,
                    "recall_at_5": 0.93507,
                    "recall_at_10": 0.95345,
                    "recall_at_20": 0.96602,
                    "precision_at_1": 0.84419,
                    "precision_at_3": 0.30553,
                    "precision_at_5": 0.18701,
                    "precision_at_10": 0.09535,
                    "precision_at_20": 0.0483,
                    "mrr_at_1": 0.8441927603819676,
                    "mrr_at_3": 0.8771633725664366,
                    "mrr_at_5": 0.8814271966836945,
                    "mrr_at_10": 0.8839420104410135,
                    "mrr_at_20": 0.884823060732638,
                    "main_score": 0.90099,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 82.02930998802185,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "6e346642246bfb4928c560ee08640dc84d074e8c",
        "task_name": "LEMBWikimQARetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.90667,
                    "ndcg_at_3": 0.92726,
                    "ndcg_at_5": 0.93558,
                    "ndcg_at_10": 0.93669,
                    "ndcg_at_20": 0.94001,
                    "map_at_1": 0.90667,
                    "map_at_3": 0.92278,
                    "map_at_5": 0.92744,
                    "map_at_10": 0.92792,
                    "map_at_20": 0.9288,
                    "recall_at_1": 0.90667,
                    "recall_at_3": 0.94,
                    "recall_at_5": 0.96,
                    "recall_at_10": 0.96333,
                    "recall_at_20": 0.97667,
                    "precision_at_1": 0.90667,
                    "precision_at_3": 0.31333,
                    "precision_at_5": 0.192,
                    "precision_at_10": 0.09633,
                    "precision_at_20": 0.04883,
                    "mrr_at_1": 0.9066666666666666,
                    "mrr_at_3": 0.9227777777777777,
                    "mrr_at_5": 0.9274444444444445,
                    "mrr_at_10": 0.9279206349206348,
                    "mrr_at_20": 0.9287976190476191,
                    "main_score": 0.93669,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 78.57745337486267,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.6,
                    "ndcg_at_3": 0.68064,
                    "ndcg_at_5": 0.7036,
                    "ndcg_at_10": 0.72424,
                    "ndcg_at_20": 0.73847,
                    "map_at_1": 0.57789,
                    "map_at_3": 0.65441,
                    "map_at_5": 0.67,
                    "map_at_10": 0.68062,
                    "map_at_20": 0.68528,
                    "recall_at_1": 0.57789,
                    "recall_at_3": 0.73394,
                    "recall_at_5": 0.79,
                    "recall_at_10": 0.84756,
                    "recall_at_20": 0.90033,
                    "precision_at_1": 0.6,
                    "precision_at_3": 0.26444,
                    "precision_at_5": 0.174,
                    "precision_at_10": 0.09567,
                    "precision_at_20": 0.051,
                    "mrr_at_1": 0.6,
                    "mrr_at_3": 0.6683333333333333,
                    "mrr_at_5": 0.6804999999999999,
                    "mrr_at_10": 0.6872817460317459,
                    "mrr_at_20": 0.6907721303034771,
                    "main_score": 0.72424,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 104.53932404518127,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.33046,
                    "ndcg_at_3": 0.41159,
                    "ndcg_at_5": 0.43403,
                    "ndcg_at_10": 0.45477,
                    "ndcg_at_20": 0.47007,
                    "map_at_1": 0.32989,
                    "map_at_3": 0.39144,
                    "map_at_5": 0.40396,
                    "map_at_10": 0.41254,
                    "map_at_20": 0.41679,
                    "recall_at_1": 0.32989,
                    "recall_at_3": 0.46905,
                    "recall_at_5": 0.52334,
                    "recall_at_10": 0.58718,
                    "recall_at_20": 0.64725,
                    "precision_at_1": 0.33046,
                    "precision_at_3": 0.15686,
                    "precision_at_5": 0.1051,
                    "precision_at_10": 0.05907,
                    "precision_at_20": 0.03262,
                    "mrr_at_1": 0.3304556714961339,
                    "mrr_at_3": 0.3921690063308573,
                    "mrr_at_5": 0.40460050546756016,
                    "mrr_at_10": 0.41322562656171674,
                    "mrr_at_20": 0.41743366357703204,
                    "main_score": 0.45477,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 113.15181016921997,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.48242,
                    "ndcg_at_3": 0.57332,
                    "ndcg_at_5": 0.59644,
                    "ndcg_at_10": 0.61797,
                    "ndcg_at_20": 0.63232,
                    "map_at_1": 0.48236,
                    "map_at_3": 0.55121,
                    "map_at_5": 0.56406,
                    "map_at_10": 0.573,
                    "map_at_20": 0.577,
                    "recall_at_1": 0.48236,
                    "recall_at_3": 0.637,
                    "recall_at_5": 0.69314,
                    "recall_at_10": 0.75942,
                    "recall_at_20": 0.81578,
                    "precision_at_1": 0.48242,
                    "precision_at_3": 0.21246,
                    "precision_at_5": 0.13875,
                    "precision_at_10": 0.07601,
                    "precision_at_20": 0.04083,
                    "mrr_at_1": 0.4824201206210702,
                    "mrr_at_3": 0.5513334616536298,
                    "mrr_at_5": 0.5641269943111492,
                    "mrr_at_10": 0.5730701799946761,
                    "mrr_at_20": 0.5770622078889963,
                    "main_score": 0.61797,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 95.99227738380432,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.2596,
                    "ndcg_at_3": 0.41051,
                    "ndcg_at_5": 0.46624,
                    "ndcg_at_10": 0.51527,
                    "ndcg_at_20": 0.54101,
                    "map_at_1": 0.2596,
                    "map_at_3": 0.37257,
                    "map_at_5": 0.40337,
                    "map_at_10": 0.42403,
                    "map_at_20": 0.4312,
                    "recall_at_1": 0.2596,
                    "recall_at_3": 0.52063,
                    "recall_at_5": 0.65647,
                    "recall_at_10": 0.80583,
                    "recall_at_20": 0.90683,
                    "precision_at_1": 0.2596,
                    "precision_at_3": 0.17354,
                    "precision_at_5": 0.13129,
                    "precision_at_10": 0.08058,
                    "precision_at_20": 0.04534,
                    "mrr_at_1": 0.2631578947368421,
                    "mrr_at_3": 0.3737553342816494,
                    "mrr_at_5": 0.40497866287339956,
                    "mrr_at_10": 0.4253567477251688,
                    "mrr_at_20": 0.4325274202382317,
                    "main_score": 0.51527,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 123.66276144981384,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.88776,
                    "ndcg_at_3": 0.92216,
                    "ndcg_at_5": 0.92744,
                    "ndcg_at_10": 0.93076,
                    "ndcg_at_20": 0.93278,
                    "map_at_1": 0.88776,
                    "map_at_3": 0.91418,
                    "map_at_5": 0.91714,
                    "map_at_10": 0.91853,
                    "map_at_20": 0.91909,
                    "recall_at_1": 0.88776,
                    "recall_at_3": 0.94506,
                    "recall_at_5": 0.95776,
                    "recall_at_10": 0.96789,
                    "recall_at_20": 0.97584,
                    "precision_at_1": 0.88776,
                    "precision_at_3": 0.31502,
                    "precision_at_5": 0.19155,
                    "precision_at_10": 0.09679,
                    "precision_at_20": 0.04879,
                    "mrr_at_1": 0.8877637130801688,
                    "mrr_at_3": 0.9141831371678133,
                    "mrr_at_5": 0.9171389444074332,
                    "mrr_at_10": 0.9185311555964469,
                    "mrr_at_20": 0.9190926558911746,
                    "main_score": 0.93076,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 79.90919351577759,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.22754,
                    "ndcg_at_3": 0.28677,
                    "ndcg_at_5": 0.3056,
                    "ndcg_at_10": 0.32589,
                    "ndcg_at_20": 0.34231,
                    "map_at_1": 0.22715,
                    "map_at_3": 0.27197,
                    "map_at_5": 0.28244,
                    "map_at_10": 0.29088,
                    "map_at_20": 0.29544,
                    "recall_at_1": 0.22715,
                    "recall_at_3": 0.32899,
                    "recall_at_5": 0.37462,
                    "recall_at_10": 0.43692,
                    "recall_at_20": 0.50134,
                    "precision_at_1": 0.22754,
                    "precision_at_3": 0.11006,
                    "precision_at_5": 0.07526,
                    "precision_at_10": 0.04398,
                    "precision_at_20": 0.0253,
                    "mrr_at_1": 0.2275354703100368,
                    "mrr_at_3": 0.2724895528363697,
                    "mrr_at_5": 0.2829861371768821,
                    "mrr_at_10": 0.2914127413095177,
                    "mrr_at_20": 0.2959188148510325,
                    "main_score": 0.32589,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 44.096208572387695,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.54847,
                    "ndcg_at_3": 0.63304,
                    "ndcg_at_5": 0.6534,
                    "ndcg_at_10": 0.67168,
                    "ndcg_at_20": 0.68365,
                    "map_at_1": 0.54844,
                    "map_at_3": 0.61254,
                    "map_at_5": 0.62389,
                    "map_at_10": 0.63148,
                    "map_at_20": 0.63477,
                    "recall_at_1": 0.54844,
                    "recall_at_3": 0.69213,
                    "recall_at_5": 0.74142,
                    "recall_at_10": 0.79769,
                    "recall_at_20": 0.84493,
                    "precision_at_1": 0.54847,
                    "precision_at_3": 0.23082,
                    "precision_at_5": 0.14838,
                    "precision_at_10": 0.07983,
                    "precision_at_20": 0.04229,
                    "mrr_at_1": 0.5484729885794944,
                    "mrr_at_3": 0.612627785619576,
                    "mrr_at_5": 0.623924782924856,
                    "mrr_at_10": 0.6315050493014772,
                    "mrr_at_20": 0.6348057182048843,
                    "main_score": 0.67168,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 76.24317717552185,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.808,
                    "ndcg_at_3": 0.76624,
                    "ndcg_at_5": 0.75789,
                    "ndcg_at_10": 0.7906,
                    "map_at_1": 0.22546,
                    "map_at_3": 0.47174,
                    "map_at_5": 0.59724,
                    "map_at_10": 0.69482,
                    "recall_at_1": 0.22546,
                    "recall_at_3": 0.50504,
                    "recall_at_5": 0.66485,
                    "recall_at_10": 0.81671,
                    "precision_at_1": 0.808,
                    "precision_at_3": 0.68967,
                    "precision_at_5": 0.5851,
                    "precision_at_10": 0.38665,
                    "mrr_at_1": 0.808,
                    "mrr_at_3": 0.8657499999999996,
                    "mrr_at_5": 0.8695999999999997,
                    "mrr_at_10": 0.8712295634920633,
                    "main_score": 0.7906,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1288.6121153831482,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.66204,
                    "ndcg_at_3": 0.73403,
                    "ndcg_at_5": 0.7473,
                    "ndcg_at_10": 0.75863,
                    "ndcg_at_20": 0.76643,
                    "map_at_1": 0.66168,
                    "map_at_3": 0.71707,
                    "map_at_5": 0.72448,
                    "map_at_10": 0.72919,
                    "map_at_20": 0.73134,
                    "recall_at_1": 0.66168,
                    "recall_at_3": 0.78264,
                    "recall_at_5": 0.81472,
                    "recall_at_10": 0.84951,
                    "recall_at_20": 0.88031,
                    "precision_at_1": 0.66204,
                    "precision_at_3": 0.26118,
                    "precision_at_5": 0.16317,
                    "precision_at_10": 0.08509,
                    "precision_at_20": 0.0441,
                    "mrr_at_1": 0.6620375807398708,
                    "mrr_at_3": 0.7171853591700835,
                    "mrr_at_5": 0.7245649833626899,
                    "mrr_at_10": 0.7292643234627953,
                    "mrr_at_20": 0.7314000073535804,
                    "main_score": 0.75863,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 116.22860383987427,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "6e346642246bfb4928c560ee08640dc84d074e8c",
        "task_name": "LEMBWikimQARetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.96,
                    "ndcg_at_3": 0.97341,
                    "ndcg_at_5": 0.97614,
                    "ndcg_at_10": 0.97732,
                    "ndcg_at_20": 0.97905,
                    "map_at_1": 0.96,
                    "map_at_3": 0.97,
                    "map_at_5": 0.9715,
                    "map_at_10": 0.97206,
                    "map_at_20": 0.97255,
                    "recall_at_1": 0.96,
                    "recall_at_3": 0.98333,
                    "recall_at_5": 0.99,
                    "recall_at_10": 0.99333,
                    "recall_at_20": 1.0,
                    "precision_at_1": 0.96,
                    "precision_at_3": 0.32778,
                    "precision_at_5": 0.198,
                    "precision_at_10": 0.09933,
                    "precision_at_20": 0.05,
                    "mrr_at_1": 0.96,
                    "mrr_at_3": 0.9699999999999999,
                    "mrr_at_5": 0.9714999999999998,
                    "mrr_at_10": 0.9720555555555553,
                    "mrr_at_20": 0.9725500610500609,
                    "main_score": 0.97732,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 60.937519788742065,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.86498,
                    "ndcg_at_3": 0.82127,
                    "ndcg_at_5": 0.80584,
                    "ndcg_at_10": 0.8055,
                    "map_at_1": 0.25714,
                    "map_at_3": 0.50653,
                    "map_at_5": 0.62283,
                    "map_at_10": 0.72204,
                    "recall_at_1": 0.25714,
                    "recall_at_3": 0.52597,
                    "recall_at_5": 0.66175,
                    "recall_at_10": 0.79565,
                    "precision_at_1": 0.86498,
                    "precision_at_3": 0.72086,
                    "precision_at_5": 0.60419,
                    "precision_at_10": 0.40372,
                    "mrr_at_1": 0.8649833421006488,
                    "mrr_at_3": 0.8916286749663911,
                    "mrr_at_5": 0.8952714945350414,
                    "mrr_at_10": 0.8971895883258342,
                    "main_score": 0.8055,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 4086.3794503211975,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.23013,
                    "ndcg_at_3": 0.29207,
                    "ndcg_at_5": 0.31075,
                    "ndcg_at_10": 0.33073,
                    "ndcg_at_20": 0.34631,
                    "map_at_1": 0.22977,
                    "map_at_3": 0.27659,
                    "map_at_5": 0.28697,
                    "map_at_10": 0.29524,
                    "map_at_20": 0.29956,
                    "recall_at_1": 0.22977,
                    "recall_at_3": 0.33631,
                    "recall_at_5": 0.38157,
                    "recall_at_10": 0.44309,
                    "recall_at_20": 0.50421,
                    "precision_at_1": 0.23013,
                    "precision_at_3": 0.11248,
                    "precision_at_5": 0.07664,
                    "precision_at_10": 0.04459,
                    "precision_at_20": 0.02544,
                    "mrr_at_1": 0.23012536596351627,
                    "mrr_at_3": 0.2771000675624909,
                    "mrr_at_5": 0.2875084453119065,
                    "mrr_at_10": 0.2957971242446843,
                    "mrr_at_20": 0.3000741821257279,
                    "main_score": 0.33073,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 65.05498313903809,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.50667,
                    "ndcg_at_3": 0.56208,
                    "ndcg_at_5": 0.58144,
                    "ndcg_at_10": 0.6108,
                    "ndcg_at_20": 0.62883,
                    "map_at_1": 0.478,
                    "map_at_3": 0.53839,
                    "map_at_5": 0.55105,
                    "map_at_10": 0.56528,
                    "map_at_20": 0.57082,
                    "recall_at_1": 0.478,
                    "recall_at_3": 0.60617,
                    "recall_at_5": 0.65261,
                    "recall_at_10": 0.73606,
                    "recall_at_20": 0.80467,
                    "precision_at_1": 0.50667,
                    "precision_at_3": 0.21889,
                    "precision_at_5": 0.14467,
                    "precision_at_10": 0.084,
                    "precision_at_20": 0.046,
                    "mrr_at_1": 0.5066666666666667,
                    "mrr_at_3": 0.5577777777777778,
                    "mrr_at_5": 0.5697777777777779,
                    "mrr_at_10": 0.579862433862434,
                    "mrr_at_20": 0.5842512679815313,
                    "main_score": 0.6108,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 81.6044054031372,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.45722,
                    "ndcg_at_3": 0.52111,
                    "ndcg_at_5": 0.5377,
                    "ndcg_at_10": 0.5546,
                    "ndcg_at_20": 0.56662,
                    "map_at_1": 0.45703,
                    "map_at_3": 0.50566,
                    "map_at_5": 0.51487,
                    "map_at_10": 0.5219,
                    "map_at_20": 0.52521,
                    "recall_at_1": 0.45703,
                    "recall_at_3": 0.56544,
                    "recall_at_5": 0.60574,
                    "recall_at_10": 0.65769,
                    "recall_at_20": 0.70514,
                    "precision_at_1": 0.45722,
                    "precision_at_3": 0.18859,
                    "precision_at_5": 0.12124,
                    "precision_at_10": 0.06584,
                    "precision_at_20": 0.03531,
                    "mrr_at_1": 0.4572170093831104,
                    "mrr_at_3": 0.5058760897052018,
                    "mrr_at_5": 0.5150895055566724,
                    "mrr_at_10": 0.5221345704715709,
                    "mrr_at_20": 0.5254578233374927,
                    "main_score": 0.5546,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 90.7151300907135,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.85587,
                    "ndcg_at_3": 0.80968,
                    "ndcg_at_5": 0.7932,
                    "ndcg_at_10": 0.79307,
                    "ndcg_at_20": 0.81345,
                    "map_at_1": 0.25443,
                    "map_at_3": 0.49836,
                    "map_at_5": 0.61061,
                    "map_at_10": 0.7063,
                    "map_at_20": 0.73393,
                    "recall_at_1": 0.25443,
                    "recall_at_3": 0.51902,
                    "recall_at_5": 0.65152,
                    "recall_at_10": 0.78407,
                    "recall_at_20": 0.84934,
                    "precision_at_1": 0.85587,
                    "precision_at_3": 0.70907,
                    "precision_at_5": 0.59216,
                    "precision_at_10": 0.3953,
                    "precision_at_20": 0.22187,
                    "mrr_at_1": 0.8558653340347185,
                    "mrr_at_3": 0.8844906189724694,
                    "mrr_at_5": 0.8883679642293547,
                    "mrr_at_10": 0.890604116741678,
                    "mrr_at_20": 0.8914358380226949,
                    "main_score": 0.79307,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 3337.5443518161774,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.4103,
                    "ndcg_at_3": 0.49053,
                    "ndcg_at_5": 0.51309,
                    "ndcg_at_10": 0.53509,
                    "ndcg_at_20": 0.54986,
                    "map_at_1": 0.41023,
                    "map_at_3": 0.47086,
                    "map_at_5": 0.48341,
                    "map_at_10": 0.49254,
                    "map_at_20": 0.4966,
                    "recall_at_1": 0.41023,
                    "recall_at_3": 0.54734,
                    "recall_at_5": 0.60202,
                    "recall_at_10": 0.66975,
                    "recall_at_20": 0.72804,
                    "precision_at_1": 0.4103,
                    "precision_at_3": 0.18248,
                    "precision_at_5": 0.12044,
                    "precision_at_10": 0.067,
                    "precision_at_20": 0.03642,
                    "mrr_at_1": 0.4103041190812267,
                    "mrr_at_3": 0.4709301082167854,
                    "mrr_at_5": 0.4834766243209878,
                    "mrr_at_10": 0.49261207402248863,
                    "mrr_at_20": 0.4966829529318472,
                    "main_score": 0.53509,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 77.33146643638611,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.19844,
                    "ndcg_at_3": 0.31287,
                    "ndcg_at_5": 0.36619,
                    "ndcg_at_10": 0.43427,
                    "ndcg_at_20": 0.47162,
                    "map_at_1": 0.19844,
                    "map_at_3": 0.28331,
                    "map_at_5": 0.31272,
                    "map_at_10": 0.34081,
                    "map_at_20": 0.35131,
                    "recall_at_1": 0.19844,
                    "recall_at_3": 0.399,
                    "recall_at_5": 0.52916,
                    "recall_at_10": 0.73969,
                    "recall_at_20": 0.88549,
                    "precision_at_1": 0.19844,
                    "precision_at_3": 0.133,
                    "precision_at_5": 0.10583,
                    "precision_at_10": 0.07397,
                    "precision_at_20": 0.04427,
                    "mrr_at_1": 0.20270270270270271,
                    "mrr_at_3": 0.2847321005215739,
                    "mrr_at_5": 0.3142484589853001,
                    "mrr_at_10": 0.34258224389803293,
                    "mrr_at_20": 0.35311648241825777,
                    "main_score": 0.43427,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 55.95736742019653,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.26256,
                    "ndcg_at_3": 0.33479,
                    "ndcg_at_5": 0.35717,
                    "ndcg_at_10": 0.37943,
                    "ndcg_at_20": 0.39739,
                    "map_at_1": 0.2618,
                    "map_at_3": 0.31671,
                    "map_at_5": 0.32915,
                    "map_at_10": 0.33834,
                    "map_at_20": 0.34329,
                    "recall_at_1": 0.2618,
                    "recall_at_3": 0.38626,
                    "recall_at_5": 0.44056,
                    "recall_at_10": 0.50922,
                    "recall_at_20": 0.57995,
                    "precision_at_1": 0.26256,
                    "precision_at_3": 0.1293,
                    "precision_at_5": 0.08855,
                    "precision_at_10": 0.05127,
                    "precision_at_20": 0.02926,
                    "mrr_at_1": 0.2625595617754099,
                    "mrr_at_3": 0.31751272527169727,
                    "mrr_at_5": 0.32992033417125805,
                    "mrr_at_10": 0.3391267488873757,
                    "mrr_at_20": 0.3440565400052431,
                    "main_score": 0.37943,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 100.45046663284302,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.4052,
                    "ndcg_at_3": 0.46859,
                    "ndcg_at_5": 0.48542,
                    "ndcg_at_10": 0.50207,
                    "ndcg_at_20": 0.51484,
                    "map_at_1": 0.40498,
                    "map_at_3": 0.45305,
                    "map_at_5": 0.4624,
                    "map_at_10": 0.46932,
                    "map_at_20": 0.47283,
                    "recall_at_1": 0.40498,
                    "recall_at_3": 0.51301,
                    "recall_at_5": 0.55396,
                    "recall_at_10": 0.60512,
                    "recall_at_20": 0.6555,
                    "precision_at_1": 0.4052,
                    "precision_at_3": 0.17117,
                    "precision_at_5": 0.11093,
                    "precision_at_10": 0.06064,
                    "precision_at_20": 0.03287,
                    "mrr_at_1": 0.40519584332533976,
                    "mrr_at_3": 0.4533772981614744,
                    "mrr_at_5": 0.462747801758599,
                    "mrr_at_10": 0.46970036669078036,
                    "mrr_at_20": 0.4732317500505538,
                    "main_score": 0.50207,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 62.18406105041504,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.86836,
                    "ndcg_at_3": 0.82654,
                    "ndcg_at_5": 0.81083,
                    "ndcg_at_10": 0.81079,
                    "ndcg_at_20": 0.82938,
                    "map_at_1": 0.25808,
                    "map_at_3": 0.51092,
                    "map_at_5": 0.62774,
                    "map_at_10": 0.72752,
                    "map_at_20": 0.75456,
                    "recall_at_1": 0.25808,
                    "recall_at_3": 0.53129,
                    "recall_at_5": 0.66734,
                    "recall_at_10": 0.80234,
                    "recall_at_20": 0.86444,
                    "precision_at_1": 0.86836,
                    "precision_at_3": 0.7255,
                    "precision_at_5": 0.60717,
                    "precision_at_10": 0.40537,
                    "precision_at_20": 0.22585,
                    "mrr_at_1": 0.8683587585481326,
                    "mrr_at_3": 0.8952086621076618,
                    "mrr_at_5": 0.8985687357531136,
                    "mrr_at_10": 0.9005661180832156,
                    "mrr_at_20": 0.9013039598114501,
                    "main_score": 0.81079,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2517.137034893036,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.89731,
                    "ndcg_at_3": 0.93113,
                    "ndcg_at_5": 0.93575,
                    "ndcg_at_10": 0.93876,
                    "ndcg_at_20": 0.94061,
                    "map_at_1": 0.89731,
                    "map_at_3": 0.92329,
                    "map_at_5": 0.92585,
                    "map_at_10": 0.92711,
                    "map_at_20": 0.92763,
                    "recall_at_1": 0.89731,
                    "recall_at_3": 0.95362,
                    "recall_at_5": 0.96482,
                    "recall_at_10": 0.97404,
                    "recall_at_20": 0.98132,
                    "precision_at_1": 0.89731,
                    "precision_at_3": 0.31788,
                    "precision_at_5": 0.19297,
                    "precision_at_10": 0.09741,
                    "precision_at_20": 0.04907,
                    "mrr_at_1": 0.8973102956893481,
                    "mrr_at_3": 0.9233018643866513,
                    "mrr_at_5": 0.9258691069944196,
                    "mrr_at_10": 0.9271280062315883,
                    "mrr_at_20": 0.927636828638228,
                    "main_score": 0.93876,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 704.7290623188019,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.44427,
                    "ndcg_at_3": 0.41232,
                    "ndcg_at_5": 0.39291,
                    "ndcg_at_10": 0.36489,
                    "ndcg_at_20": 0.3395,
                    "map_at_1": 0.04529,
                    "map_at_3": 0.08854,
                    "map_at_5": 0.10787,
                    "map_at_10": 0.13003,
                    "map_at_20": 0.14677,
                    "recall_at_1": 0.04529,
                    "recall_at_3": 0.10272,
                    "recall_at_5": 0.13377,
                    "recall_at_10": 0.17452,
                    "recall_at_20": 0.21302,
                    "precision_at_1": 0.4644,
                    "precision_at_3": 0.39732,
                    "precision_at_5": 0.35418,
                    "precision_at_10": 0.28545,
                    "precision_at_20": 0.21192,
                    "mrr_at_1": 0.4674922600619195,
                    "mrr_at_3": 0.541279669762642,
                    "mrr_at_5": 0.5504127966976265,
                    "mrr_at_10": 0.5577595950660967,
                    "mrr_at_20": 0.5597265546513839,
                    "main_score": 0.36489,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 97.31417441368103,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.32524,
                    "ndcg_at_3": 0.40841,
                    "ndcg_at_5": 0.43022,
                    "ndcg_at_10": 0.45141,
                    "ndcg_at_20": 0.46678,
                    "map_at_1": 0.32466,
                    "map_at_3": 0.38784,
                    "map_at_5": 0.4,
                    "map_at_10": 0.40878,
                    "map_at_20": 0.41303,
                    "recall_at_1": 0.32466,
                    "recall_at_3": 0.46706,
                    "recall_at_5": 0.51986,
                    "recall_at_10": 0.58507,
                    "recall_at_20": 0.64539,
                    "precision_at_1": 0.32524,
                    "precision_at_3": 0.15621,
                    "precision_at_5": 0.10443,
                    "precision_at_10": 0.05887,
                    "precision_at_20": 0.03254,
                    "mrr_at_1": 0.3252383454695593,
                    "mrr_at_3": 0.3886032079673708,
                    "mrr_at_5": 0.400691264419591,
                    "mrr_at_10": 0.40948478533119836,
                    "mrr_at_20": 0.4137061438145758,
                    "main_score": 0.45141,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 89.81216835975647,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.8652,
                    "ndcg_at_3": 0.90311,
                    "ndcg_at_5": 0.90957,
                    "ndcg_at_10": 0.91438,
                    "ndcg_at_20": 0.91711,
                    "map_at_1": 0.8652,
                    "map_at_3": 0.89414,
                    "map_at_5": 0.89774,
                    "map_at_10": 0.89974,
                    "map_at_20": 0.90051,
                    "recall_at_1": 0.8652,
                    "recall_at_3": 0.92891,
                    "recall_at_5": 0.94451,
                    "recall_at_10": 0.9593,
                    "recall_at_20": 0.96999,
                    "precision_at_1": 0.8652,
                    "precision_at_3": 0.30964,
                    "precision_at_5": 0.18891,
                    "precision_at_10": 0.09593,
                    "precision_at_20": 0.0485,
                    "mrr_at_1": 0.8652030637691486,
                    "mrr_at_3": 0.8941559790998692,
                    "mrr_at_5": 0.8977585797411249,
                    "mrr_at_10": 0.8997567376909221,
                    "mrr_at_20": 0.9005265344789024,
                    "main_score": 0.91438,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 59.27095174789429,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.89967,
                    "ndcg_at_3": 0.93262,
                    "ndcg_at_5": 0.93719,
                    "ndcg_at_10": 0.94016,
                    "ndcg_at_20": 0.94183,
                    "map_at_1": 0.89967,
                    "map_at_3": 0.92499,
                    "map_at_5": 0.92752,
                    "map_at_10": 0.92876,
                    "map_at_20": 0.92922,
                    "recall_at_1": 0.89967,
                    "recall_at_3": 0.95452,
                    "recall_at_5": 0.96562,
                    "recall_at_10": 0.97473,
                    "recall_at_20": 0.9813,
                    "precision_at_1": 0.89967,
                    "precision_at_3": 0.31817,
                    "precision_at_5": 0.19312,
                    "precision_at_10": 0.09747,
                    "precision_at_20": 0.04907,
                    "mrr_at_1": 0.8996668887408394,
                    "mrr_at_3": 0.924990746909466,
                    "mrr_at_5": 0.9275246132208163,
                    "mrr_at_10": 0.928759803869732,
                    "mrr_at_20": 0.9292243501235249,
                    "main_score": 0.94016,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 117.53236055374146,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.492,
                    "ndcg_at_3": 0.54772,
                    "ndcg_at_5": 0.56158,
                    "ndcg_at_10": 0.57123,
                    "ndcg_at_20": 0.58373,
                    "map_at_1": 0.492,
                    "map_at_3": 0.53383,
                    "map_at_5": 0.54143,
                    "map_at_10": 0.54539,
                    "map_at_20": 0.54888,
                    "recall_at_1": 0.492,
                    "recall_at_3": 0.588,
                    "recall_at_5": 0.622,
                    "recall_at_10": 0.652,
                    "recall_at_20": 0.701,
                    "precision_at_1": 0.492,
                    "precision_at_3": 0.196,
                    "precision_at_5": 0.1244,
                    "precision_at_10": 0.0652,
                    "precision_at_20": 0.03505,
                    "mrr_at_1": 0.495,
                    "mrr_at_3": 0.5353333333333332,
                    "mrr_at_5": 0.5429333333333333,
                    "mrr_at_10": 0.5468900793650795,
                    "mrr_at_20": 0.550382323391263,
                    "main_score": 0.57123,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 124.19642305374146,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.6618,
                    "ndcg_at_3": 0.73401,
                    "ndcg_at_5": 0.74718,
                    "ndcg_at_10": 0.75854,
                    "ndcg_at_20": 0.76632,
                    "map_at_1": 0.66145,
                    "map_at_3": 0.71699,
                    "map_at_5": 0.72434,
                    "map_at_10": 0.72906,
                    "map_at_20": 0.73121,
                    "recall_at_1": 0.66145,
                    "recall_at_3": 0.78281,
                    "recall_at_5": 0.81466,
                    "recall_at_10": 0.84957,
                    "recall_at_20": 0.8803,
                    "precision_at_1": 0.6618,
                    "precision_at_3": 0.26123,
                    "precision_at_5": 0.16315,
                    "precision_at_10": 0.08509,
                    "precision_at_20": 0.0441,
                    "mrr_at_1": 0.6618027011156782,
                    "mrr_at_3": 0.7170972793110113,
                    "mrr_at_5": 0.7244211195928721,
                    "mrr_at_10": 0.7291327163082872,
                    "mrr_at_20": 0.7312646474535169,
                    "main_score": 0.75854,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 172.0165684223175,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.33179,
                    "ndcg_at_3": 0.29554,
                    "ndcg_at_5": 0.30966,
                    "ndcg_at_10": 0.34357,
                    "map_at_1": 0.1605,
                    "map_at_3": 0.22357,
                    "map_at_5": 0.24368,
                    "map_at_10": 0.26479,
                    "recall_at_1": 0.1605,
                    "recall_at_3": 0.26219,
                    "recall_at_5": 0.31982,
                    "recall_at_10": 0.42274,
                    "precision_at_1": 0.33179,
                    "precision_at_3": 0.19805,
                    "precision_at_5": 0.15031,
                    "precision_at_10": 0.09938,
                    "mrr_at_1": 0.3317901234567901,
                    "mrr_at_3": 0.38837448559670795,
                    "mrr_at_5": 0.4058127572016461,
                    "mrr_at_10": 0.42029994611013116,
                    "main_score": 0.34357,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 577.6888742446899,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "2e643e7363944af1c33a652d1c87320d0871c4e4",
        "task_name": "NarrativeQAChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.66278,
                    "ndcg_at_3": 0.73158,
                    "ndcg_at_5": 0.74528,
                    "ndcg_at_10": 0.75681,
                    "ndcg_at_20": 0.76499,
                    "map_at_1": 0.66278,
                    "map_at_3": 0.71518,
                    "map_at_5": 0.72281,
                    "map_at_10": 0.72759,
                    "map_at_20": 0.72986,
                    "recall_at_1": 0.66278,
                    "recall_at_3": 0.77882,
                    "recall_at_5": 0.81197,
                    "recall_at_10": 0.84749,
                    "recall_at_20": 0.8797,
                    "precision_at_1": 0.66278,
                    "precision_at_3": 0.25961,
                    "precision_at_5": 0.16239,
                    "precision_at_10": 0.08475,
                    "precision_at_20": 0.04399,
                    "mrr_at_1": 0.6627829875911717,
                    "mrr_at_3": 0.7151810804837196,
                    "mrr_at_5": 0.7228063528148726,
                    "mrr_at_10": 0.7275913747141334,
                    "mrr_at_20": 0.729855547342282,
                    "main_score": 0.75681,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 3801.41365981102,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.72455,
                    "ndcg_at_3": 0.76229,
                    "ndcg_at_5": 0.76926,
                    "ndcg_at_10": 0.77508,
                    "ndcg_at_20": 0.77883,
                    "map_at_1": 0.72455,
                    "map_at_3": 0.75343,
                    "map_at_5": 0.75732,
                    "map_at_10": 0.75974,
                    "map_at_20": 0.76078,
                    "recall_at_1": 0.72455,
                    "recall_at_3": 0.78775,
                    "recall_at_5": 0.8046,
                    "recall_at_10": 0.8225,
                    "recall_at_20": 0.8372,
                    "precision_at_1": 0.72455,
                    "precision_at_3": 0.26258,
                    "precision_at_5": 0.16092,
                    "precision_at_10": 0.08225,
                    "precision_at_20": 0.04186,
                    "mrr_at_1": 0.72455,
                    "mrr_at_3": 0.7534333333333373,
                    "mrr_at_5": 0.7573158333333392,
                    "mrr_at_10": 0.7597423412698464,
                    "mrr_at_20": 0.7607843545547661,
                    "main_score": 0.77508,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 354.2575874328613,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.841,
                    "ndcg_at_3": 0.79753,
                    "ndcg_at_5": 0.78718,
                    "ndcg_at_10": 0.81616,
                    "ndcg_at_20": 0.83709,
                    "map_at_1": 0.23812,
                    "map_at_3": 0.49982,
                    "map_at_5": 0.62972,
                    "map_at_10": 0.7281,
                    "map_at_20": 0.75205,
                    "recall_at_1": 0.23812,
                    "recall_at_3": 0.53042,
                    "recall_at_5": 0.69038,
                    "recall_at_10": 0.83455,
                    "recall_at_20": 0.89699,
                    "precision_at_1": 0.841,
                    "precision_at_3": 0.717,
                    "precision_at_5": 0.6052,
                    "precision_at_10": 0.39575,
                    "precision_at_20": 0.21893,
                    "mrr_at_1": 0.841,
                    "mrr_at_3": 0.8874999999999993,
                    "mrr_at_5": 0.8902499999999995,
                    "mrr_at_10": 0.8913853174603171,
                    "mrr_at_20": 0.8920679546545638,
                    "main_score": 0.81616,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 535.2696170806885,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.84419,
                    "ndcg_at_3": 0.88733,
                    "ndcg_at_5": 0.89498,
                    "ndcg_at_10": 0.90099,
                    "ndcg_at_20": 0.90417,
                    "map_at_1": 0.84419,
                    "map_at_3": 0.87716,
                    "map_at_5": 0.88143,
                    "map_at_10": 0.88394,
                    "map_at_20": 0.88482,
                    "recall_at_1": 0.84419,
                    "recall_at_3": 0.91659,
                    "recall_at_5": 0.93507,
                    "recall_at_10": 0.95345,
                    "recall_at_20": 0.96602,
                    "precision_at_1": 0.84419,
                    "precision_at_3": 0.30553,
                    "precision_at_5": 0.18701,
                    "precision_at_10": 0.09535,
                    "precision_at_20": 0.0483,
                    "mrr_at_1": 0.8441927603819676,
                    "mrr_at_3": 0.8771633725664366,
                    "mrr_at_5": 0.8814271966836945,
                    "mrr_at_10": 0.8839420104410135,
                    "mrr_at_20": 0.884823060732638,
                    "main_score": 0.90099,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 32.002007246017456,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.89535,
                    "ndcg_at_3": 0.9264,
                    "ndcg_at_5": 0.93147,
                    "ndcg_at_10": 0.93479,
                    "ndcg_at_20": 0.93673,
                    "map_at_1": 0.89533,
                    "map_at_3": 0.91919,
                    "map_at_5": 0.92201,
                    "map_at_10": 0.9234,
                    "map_at_20": 0.92394,
                    "recall_at_1": 0.89533,
                    "recall_at_3": 0.94707,
                    "recall_at_5": 0.95936,
                    "recall_at_10": 0.96952,
                    "recall_at_20": 0.97709,
                    "precision_at_1": 0.89535,
                    "precision_at_3": 0.31571,
                    "precision_at_5": 0.19189,
                    "precision_at_10": 0.09696,
                    "precision_at_20": 0.04886,
                    "mrr_at_1": 0.8953509084431778,
                    "mrr_at_3": 0.9191975418596356,
                    "mrr_at_5": 0.9220141610260075,
                    "mrr_at_10": 0.9234114790970439,
                    "mrr_at_20": 0.9239512000009688,
                    "main_score": 0.93479,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 130.80734777450562,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.44995,
                    "ndcg_at_3": 0.52951,
                    "ndcg_at_5": 0.55209,
                    "ndcg_at_10": 0.57267,
                    "map_at_1": 0.44942,
                    "map_at_3": 0.5108,
                    "map_at_5": 0.52329,
                    "map_at_10": 0.53186,
                    "recall_at_1": 0.44942,
                    "recall_at_3": 0.58272,
                    "recall_at_5": 0.63804,
                    "recall_at_10": 0.70126,
                    "precision_at_1": 0.44995,
                    "precision_at_3": 0.19494,
                    "precision_at_5": 0.12813,
                    "precision_at_10": 0.0705,
                    "mrr_at_1": 0.4499473129610116,
                    "mrr_at_3": 0.5112399016508602,
                    "mrr_at_5": 0.5234632946961708,
                    "mrr_at_10": 0.531986886781407,
                    "main_score": 0.57267,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1272.790050983429,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.46808,
                    "ndcg_at_3": 0.55689,
                    "ndcg_at_5": 0.58001,
                    "ndcg_at_10": 0.60076,
                    "ndcg_at_20": 0.61462,
                    "map_at_1": 0.468,
                    "map_at_3": 0.53527,
                    "map_at_5": 0.54811,
                    "map_at_10": 0.55673,
                    "map_at_20": 0.56057,
                    "recall_at_1": 0.468,
                    "recall_at_3": 0.61926,
                    "recall_at_5": 0.67539,
                    "recall_at_10": 0.73923,
                    "recall_at_20": 0.79374,
                    "precision_at_1": 0.46808,
                    "precision_at_3": 0.20647,
                    "precision_at_5": 0.13512,
                    "precision_at_10": 0.07396,
                    "precision_at_20": 0.03971,
                    "mrr_at_1": 0.46808032849993586,
                    "mrr_at_3": 0.5353308524744538,
                    "mrr_at_5": 0.5481821292613203,
                    "mrr_at_10": 0.556802515586856,
                    "mrr_at_20": 0.5606462476229984,
                    "main_score": 0.60076,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 80.56499528884888,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.69652,
                    "ndcg_at_3": 0.78097,
                    "ndcg_at_5": 0.79987,
                    "ndcg_at_10": 0.8162,
                    "map_at_1": 0.69336,
                    "map_at_3": 0.76089,
                    "map_at_5": 0.77149,
                    "map_at_10": 0.77861,
                    "recall_at_1": 0.69336,
                    "recall_at_3": 0.83825,
                    "recall_at_5": 0.88356,
                    "recall_at_10": 0.93256,
                    "precision_at_1": 0.69652,
                    "precision_at_3": 0.2817,
                    "precision_at_5": 0.1785,
                    "precision_at_10": 0.09431,
                    "mrr_at_1": 0.6954689146469969,
                    "mrr_at_3": 0.7615033368458026,
                    "mrr_at_5": 0.7714611872146121,
                    "mrr_at_10": 0.7782778864970644,
                    "main_score": 0.8162,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 245.2350447177887,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.86349,
                    "ndcg_at_3": 0.8192,
                    "ndcg_at_5": 0.80381,
                    "ndcg_at_10": 0.80342,
                    "ndcg_at_20": 0.82379,
                    "map_at_1": 0.25654,
                    "map_at_3": 0.50482,
                    "map_at_5": 0.62057,
                    "map_at_10": 0.7195,
                    "map_at_20": 0.74782,
                    "recall_at_1": 0.25654,
                    "recall_at_3": 0.52427,
                    "recall_at_5": 0.66002,
                    "recall_at_10": 0.79342,
                    "recall_at_20": 0.85936,
                    "precision_at_1": 0.86349,
                    "precision_at_3": 0.71883,
                    "precision_at_5": 0.6024,
                    "precision_at_10": 0.40255,
                    "precision_at_20": 0.22567,
                    "mrr_at_1": 0.8634928984744871,
                    "mrr_at_3": 0.8905108422467696,
                    "mrr_at_5": 0.8943640773861722,
                    "mrr_at_10": 0.8961994731260925,
                    "mrr_at_20": 0.8970302339928934,
                    "main_score": 0.80342,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1110.9059748649597,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.45686,
                    "ndcg_at_3": 0.52095,
                    "ndcg_at_5": 0.53757,
                    "ndcg_at_10": 0.5543,
                    "ndcg_at_20": 0.56643,
                    "map_at_1": 0.45668,
                    "map_at_3": 0.50542,
                    "map_at_5": 0.51466,
                    "map_at_10": 0.52161,
                    "map_at_20": 0.52494,
                    "recall_at_1": 0.45668,
                    "recall_at_3": 0.56552,
                    "recall_at_5": 0.60585,
                    "recall_at_10": 0.65731,
                    "recall_at_20": 0.70518,
                    "precision_at_1": 0.45686,
                    "precision_at_3": 0.18862,
                    "precision_at_5": 0.12127,
                    "precision_at_10": 0.0658,
                    "precision_at_20": 0.03531,
                    "mrr_at_1": 0.45685765621880614,
                    "mrr_at_3": 0.5056232115525433,
                    "mrr_at_5": 0.5148625806881023,
                    "mrr_at_10": 0.5218311959108594,
                    "mrr_at_20": 0.5251842803736634,
                    "main_score": 0.5543,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 70.18177533149719,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.22127,
                    "ndcg_at_3": 0.28,
                    "ndcg_at_5": 0.2987,
                    "ndcg_at_10": 0.31885,
                    "ndcg_at_20": 0.33453,
                    "map_at_1": 0.22088,
                    "map_at_3": 0.26537,
                    "map_at_5": 0.27578,
                    "map_at_10": 0.28409,
                    "map_at_20": 0.28843,
                    "recall_at_1": 0.22088,
                    "recall_at_3": 0.32167,
                    "recall_at_5": 0.36698,
                    "recall_at_10": 0.4292,
                    "recall_at_20": 0.49081,
                    "precision_at_1": 0.22127,
                    "precision_at_3": 0.10764,
                    "precision_at_5": 0.07373,
                    "precision_at_10": 0.04322,
                    "precision_at_20": 0.02478,
                    "mrr_at_1": 0.22126717213422414,
                    "mrr_at_3": 0.2659147211170297,
                    "mrr_at_5": 0.2763268523384069,
                    "mrr_at_10": 0.28464007778623507,
                    "mrr_at_20": 0.2889264508599311,
                    "main_score": 0.31885,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 40.52180552482605,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.242,
                    "ndcg_at_3": 0.19161,
                    "ndcg_at_5": 0.164,
                    "ndcg_at_10": 0.19833,
                    "ndcg_at_20": 0.22856,
                    "map_at_1": 0.04928,
                    "map_at_3": 0.08594,
                    "map_at_5": 0.10058,
                    "map_at_10": 0.1173,
                    "map_at_20": 0.12842,
                    "recall_at_1": 0.04928,
                    "recall_at_3": 0.10813,
                    "recall_at_5": 0.14302,
                    "recall_at_10": 0.20635,
                    "recall_at_20": 0.27725,
                    "precision_at_1": 0.242,
                    "precision_at_3": 0.17767,
                    "precision_at_5": 0.141,
                    "precision_at_10": 0.1018,
                    "precision_at_20": 0.0684,
                    "mrr_at_1": 0.242,
                    "mrr_at_3": 0.31566666666666665,
                    "mrr_at_5": 0.33221666666666644,
                    "mrr_at_10": 0.346274603174603,
                    "mrr_at_20": 0.353175338790896,
                    "main_score": 0.19833,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 132.90076303482056,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.30783,
                    "ndcg_at_3": 0.31095,
                    "ndcg_at_5": 0.32698,
                    "ndcg_at_10": 0.35485,
                    "map_at_1": 0.19784,
                    "map_at_3": 0.26265,
                    "map_at_5": 0.27972,
                    "map_at_10": 0.29552,
                    "recall_at_1": 0.19784,
                    "recall_at_3": 0.30955,
                    "recall_at_5": 0.36211,
                    "recall_at_10": 0.44404,
                    "precision_at_1": 0.30783,
                    "precision_at_3": 0.17763,
                    "precision_at_5": 0.12818,
                    "precision_at_10": 0.08062,
                    "mrr_at_1": 0.3078269567391848,
                    "mrr_at_3": 0.35913144952904846,
                    "mrr_at_5": 0.3715970659331499,
                    "mrr_at_10": 0.38235997491436285,
                    "main_score": 0.35485,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2657.653815507889,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.158,
                    "ndcg_at_3": 0.12854,
                    "ndcg_at_5": 0.11206,
                    "ndcg_at_10": 0.13657,
                    "map_at_1": 0.03218,
                    "map_at_3": 0.05645,
                    "map_at_5": 0.0668,
                    "map_at_10": 0.07764,
                    "recall_at_1": 0.03218,
                    "recall_at_3": 0.07318,
                    "recall_at_5": 0.09958,
                    "recall_at_10": 0.14453,
                    "precision_at_1": 0.158,
                    "precision_at_3": 0.12033,
                    "precision_at_5": 0.0984,
                    "precision_at_10": 0.0714,
                    "mrr_at_1": 0.158,
                    "mrr_at_3": 0.2135000000000001,
                    "mrr_at_5": 0.22799999999999998,
                    "mrr_at_10": 0.2417984126984126,
                    "main_score": 0.13657,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 228.0643665790558,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.33473,
                    "ndcg_at_3": 0.41892,
                    "ndcg_at_5": 0.44108,
                    "ndcg_at_10": 0.46214,
                    "ndcg_at_20": 0.47725,
                    "map_at_1": 0.33407,
                    "map_at_3": 0.39799,
                    "map_at_5": 0.41034,
                    "map_at_10": 0.41906,
                    "map_at_20": 0.42327,
                    "recall_at_1": 0.33407,
                    "recall_at_3": 0.47863,
                    "recall_at_5": 0.5323,
                    "recall_at_10": 0.5971,
                    "recall_at_20": 0.65622,
                    "precision_at_1": 0.33473,
                    "precision_at_3": 0.16005,
                    "precision_at_5": 0.10692,
                    "precision_at_10": 0.06006,
                    "precision_at_20": 0.03308,
                    "mrr_at_1": 0.334772164251933,
                    "mrr_at_3": 0.39881265170282654,
                    "mrr_at_5": 0.41110527237695343,
                    "mrr_at_10": 0.4198588456226838,
                    "mrr_at_20": 0.4240235484987422,
                    "main_score": 0.46214,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 93.01300954818726,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.34517,
                    "ndcg_at_3": 0.42717,
                    "ndcg_at_5": 0.44906,
                    "ndcg_at_10": 0.47028,
                    "ndcg_at_20": 0.48516,
                    "map_at_1": 0.34451,
                    "map_at_3": 0.40689,
                    "map_at_5": 0.41912,
                    "map_at_10": 0.42792,
                    "map_at_20": 0.43203,
                    "recall_at_1": 0.34451,
                    "recall_at_3": 0.48501,
                    "recall_at_5": 0.53787,
                    "recall_at_10": 0.60313,
                    "recall_at_20": 0.66161,
                    "precision_at_1": 0.34517,
                    "precision_at_3": 0.16224,
                    "precision_at_5": 0.10806,
                    "precision_at_10": 0.0607,
                    "precision_at_20": 0.03336,
                    "mrr_at_1": 0.34516928158546656,
                    "mrr_at_3": 0.4075895203062859,
                    "mrr_at_5": 0.4197807972374497,
                    "mrr_at_10": 0.4285720094659052,
                    "mrr_at_20": 0.4326608988129517,
                    "main_score": 0.47028,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 106.48919606208801,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.49257,
                    "ndcg_at_3": 0.56089,
                    "ndcg_at_5": 0.57801,
                    "ndcg_at_10": 0.59461,
                    "ndcg_at_20": 0.60756,
                    "map_at_1": 0.49251,
                    "map_at_3": 0.54428,
                    "map_at_5": 0.55377,
                    "map_at_10": 0.56066,
                    "map_at_20": 0.56421,
                    "recall_at_1": 0.49251,
                    "recall_at_3": 0.60873,
                    "recall_at_5": 0.65036,
                    "recall_at_10": 0.7014,
                    "recall_at_20": 0.75254,
                    "precision_at_1": 0.49257,
                    "precision_at_3": 0.20297,
                    "precision_at_5": 0.13012,
                    "precision_at_10": 0.0702,
                    "precision_at_20": 0.03768,
                    "mrr_at_1": 0.49256594724220626,
                    "mrr_at_3": 0.5443844924060819,
                    "mrr_at_5": 0.5538848920863421,
                    "mrr_at_10": 0.5607989957240663,
                    "mrr_at_20": 0.5643686491821845,
                    "main_score": 0.59461,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 144.36229801177979,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.37043,
                    "ndcg_at_3": 0.4508,
                    "ndcg_at_5": 0.47427,
                    "ndcg_at_10": 0.49811,
                    "ndcg_at_20": 0.51426,
                    "map_at_1": 0.37036,
                    "map_at_3": 0.43109,
                    "map_at_5": 0.44413,
                    "map_at_10": 0.45399,
                    "map_at_20": 0.45843,
                    "recall_at_1": 0.37036,
                    "recall_at_3": 0.50776,
                    "recall_at_5": 0.56471,
                    "recall_at_10": 0.63824,
                    "recall_at_20": 0.70208,
                    "precision_at_1": 0.37043,
                    "precision_at_3": 0.16931,
                    "precision_at_5": 0.11298,
                    "precision_at_10": 0.06386,
                    "precision_at_20": 0.03513,
                    "mrr_at_1": 0.37042858976004106,
                    "mrr_at_3": 0.43114012575388977,
                    "mrr_at_5": 0.4441662389323892,
                    "mrr_at_10": 0.45404342572395295,
                    "mrr_at_20": 0.4584778425407107,
                    "main_score": 0.49811,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 56.306177377700806,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.66233,
                    "ndcg_at_3": 0.73405,
                    "ndcg_at_5": 0.74737,
                    "ndcg_at_10": 0.75872,
                    "ndcg_at_20": 0.76645,
                    "map_at_1": 0.66198,
                    "map_at_3": 0.71715,
                    "map_at_5": 0.72457,
                    "map_at_10": 0.72929,
                    "map_at_20": 0.73142,
                    "recall_at_1": 0.66198,
                    "recall_at_3": 0.78251,
                    "recall_at_5": 0.81475,
                    "recall_at_10": 0.84966,
                    "recall_at_20": 0.88018,
                    "precision_at_1": 0.66233,
                    "precision_at_3": 0.26113,
                    "precision_at_5": 0.16317,
                    "precision_at_10": 0.0851,
                    "precision_at_20": 0.04409,
                    "mrr_at_1": 0.6623311802701116,
                    "mrr_at_3": 0.7172538657271397,
                    "mrr_at_5": 0.7246525738892119,
                    "mrr_at_10": 0.7293616423864505,
                    "mrr_at_20": 0.7314780089475819,
                    "main_score": 0.75872,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 165.97019290924072,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.66465,
                    "ndcg_at_3": 0.73461,
                    "ndcg_at_5": 0.74816,
                    "ndcg_at_10": 0.76016,
                    "ndcg_at_20": 0.76867,
                    "map_at_1": 0.66423,
                    "map_at_3": 0.71801,
                    "map_at_5": 0.72556,
                    "map_at_10": 0.73055,
                    "map_at_20": 0.73289,
                    "recall_at_1": 0.66423,
                    "recall_at_3": 0.78214,
                    "recall_at_5": 0.81494,
                    "recall_at_10": 0.85192,
                    "recall_at_20": 0.88547,
                    "precision_at_1": 0.66465,
                    "precision_at_3": 0.26105,
                    "precision_at_5": 0.16323,
                    "precision_at_10": 0.08533,
                    "precision_at_20": 0.04436,
                    "mrr_at_1": 0.6646506165590135,
                    "mrr_at_3": 0.7182031708749188,
                    "mrr_at_5": 0.7257251908396923,
                    "mrr_at_10": 0.7306914618460413,
                    "mrr_at_20": 0.7330237372821882,
                    "main_score": 0.76016,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 151.74528312683105,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.50532,
                    "ndcg_at_3": 0.57224,
                    "ndcg_at_5": 0.58941,
                    "ndcg_at_10": 0.60565,
                    "ndcg_at_20": 0.61841,
                    "map_at_1": 0.50524,
                    "map_at_3": 0.55604,
                    "map_at_5": 0.56556,
                    "map_at_10": 0.57229,
                    "map_at_20": 0.5758,
                    "recall_at_1": 0.50524,
                    "recall_at_3": 0.61887,
                    "recall_at_5": 0.66059,
                    "recall_at_10": 0.71056,
                    "recall_at_20": 0.76091,
                    "precision_at_1": 0.50532,
                    "precision_at_3": 0.20634,
                    "precision_at_5": 0.13217,
                    "precision_at_10": 0.07112,
                    "precision_at_20": 0.0381,
                    "mrr_at_1": 0.5053157474020783,
                    "mrr_at_3": 0.5561484146016585,
                    "mrr_at_5": 0.5656847855049403,
                    "mrr_at_10": 0.572458430081342,
                    "mrr_at_20": 0.5759751507131463,
                    "main_score": 0.60565,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 101.29748916625977,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.58893,
                    "ndcg_at_3": 0.66487,
                    "ndcg_at_5": 0.68055,
                    "ndcg_at_10": 0.69506,
                    "ndcg_at_20": 0.70539,
                    "map_at_1": 0.58857,
                    "map_at_3": 0.64672,
                    "map_at_5": 0.65547,
                    "map_at_10": 0.66152,
                    "map_at_20": 0.66436,
                    "recall_at_1": 0.58857,
                    "recall_at_3": 0.71694,
                    "recall_at_5": 0.75481,
                    "recall_at_10": 0.79942,
                    "recall_at_20": 0.84014,
                    "precision_at_1": 0.58893,
                    "precision_at_3": 0.23926,
                    "precision_at_5": 0.15117,
                    "precision_at_10": 0.08007,
                    "precision_at_20": 0.04208,
                    "mrr_at_1": 0.588926075979097,
                    "mrr_at_3": 0.6469281506272818,
                    "mrr_at_5": 0.6556651596109054,
                    "mrr_at_10": 0.6616719697880534,
                    "mrr_at_20": 0.6645177120679513,
                    "main_score": 0.69506,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 131.99741315841675,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.50491,
                    "ndcg_at_3": 0.59192,
                    "ndcg_at_5": 0.61374,
                    "ndcg_at_10": 0.63271,
                    "ndcg_at_20": 0.64495,
                    "map_at_1": 0.50484,
                    "map_at_3": 0.57082,
                    "map_at_5": 0.58296,
                    "map_at_10": 0.59083,
                    "map_at_20": 0.59421,
                    "recall_at_1": 0.50484,
                    "recall_at_3": 0.6528,
                    "recall_at_5": 0.70564,
                    "recall_at_10": 0.7641,
                    "recall_at_20": 0.81233,
                    "precision_at_1": 0.50491,
                    "precision_at_3": 0.21765,
                    "precision_at_5": 0.14117,
                    "precision_at_10": 0.07644,
                    "precision_at_20": 0.04063,
                    "mrr_at_1": 0.5049082509944822,
                    "mrr_at_3": 0.5708648787373345,
                    "mrr_at_5": 0.5830039779289233,
                    "mrr_at_10": 0.5908694132300366,
                    "mrr_at_20": 0.5942562104226246,
                    "main_score": 0.63271,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 114.60768175125122,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.492,
                    "ndcg_at_3": 0.54672,
                    "ndcg_at_5": 0.56062,
                    "ndcg_at_10": 0.57028,
                    "ndcg_at_20": 0.58307,
                    "map_at_1": 0.492,
                    "map_at_3": 0.53317,
                    "map_at_5": 0.54082,
                    "map_at_10": 0.54478,
                    "map_at_20": 0.54837,
                    "recall_at_1": 0.492,
                    "recall_at_3": 0.586,
                    "recall_at_5": 0.62,
                    "recall_at_10": 0.65,
                    "recall_at_20": 0.7,
                    "precision_at_1": 0.492,
                    "precision_at_3": 0.19533,
                    "precision_at_5": 0.124,
                    "precision_at_10": 0.065,
                    "precision_at_20": 0.035,
                    "mrr_at_1": 0.491,
                    "mrr_at_3": 0.5326666666666665,
                    "mrr_at_5": 0.5403166666666666,
                    "mrr_at_10": 0.5442793650793651,
                    "mrr_at_20": 0.5478680120876716,
                    "main_score": 0.57028,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 121.86078476905823,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.22,
                    "ndcg_at_3": 0.17632,
                    "ndcg_at_5": 0.1508,
                    "ndcg_at_10": 0.17992,
                    "ndcg_at_20": 0.20414,
                    "map_at_1": 0.04473,
                    "map_at_3": 0.07843,
                    "map_at_5": 0.09207,
                    "map_at_10": 0.10572,
                    "map_at_20": 0.1145,
                    "recall_at_1": 0.04473,
                    "recall_at_3": 0.10003,
                    "recall_at_5": 0.13258,
                    "recall_at_10": 0.18583,
                    "recall_at_20": 0.24228,
                    "precision_at_1": 0.22,
                    "precision_at_3": 0.16467,
                    "precision_at_5": 0.1306,
                    "precision_at_10": 0.0916,
                    "precision_at_20": 0.0598,
                    "mrr_at_1": 0.22,
                    "mrr_at_3": 0.29066666666666663,
                    "mrr_at_5": 0.3056166666666663,
                    "mrr_at_10": 0.3210190476190472,
                    "mrr_at_20": 0.3265152248422369,
                    "main_score": 0.17992,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 119.9546160697937,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.27952,
                    "ndcg_at_3": 0.4353,
                    "ndcg_at_5": 0.4911,
                    "ndcg_at_10": 0.53643,
                    "map_at_1": 0.27952,
                    "map_at_3": 0.39675,
                    "map_at_5": 0.4278,
                    "map_at_10": 0.44678,
                    "recall_at_1": 0.27952,
                    "recall_at_3": 0.54694,
                    "recall_at_5": 0.68208,
                    "recall_at_10": 0.82077,
                    "precision_at_1": 0.27952,
                    "precision_at_3": 0.18231,
                    "precision_at_5": 0.13642,
                    "precision_at_10": 0.08208,
                    "mrr_at_1": 0.2894736842105263,
                    "mrr_at_3": 0.40173067804646756,
                    "mrr_at_5": 0.43131816026552905,
                    "mrr_at_10": 0.45049617286459415,
                    "main_score": 0.53643,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 57.098124504089355,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.43963,
                    "ndcg_at_3": 0.40179,
                    "ndcg_at_5": 0.38347,
                    "ndcg_at_10": 0.35666,
                    "ndcg_at_20": 0.33025,
                    "map_at_1": 0.04789,
                    "map_at_3": 0.08727,
                    "map_at_5": 0.10562,
                    "map_at_10": 0.12749,
                    "map_at_20": 0.14335,
                    "recall_at_1": 0.04789,
                    "recall_at_3": 0.09947,
                    "recall_at_5": 0.12932,
                    "recall_at_10": 0.17365,
                    "recall_at_20": 0.21111,
                    "precision_at_1": 0.45201,
                    "precision_at_3": 0.38287,
                    "precision_at_5": 0.34056,
                    "precision_at_10": 0.27368,
                    "precision_at_20": 0.20093,
                    "mrr_at_1": 0.4551083591331269,
                    "mrr_at_3": 0.5252837977296181,
                    "mrr_at_5": 0.5339525283797729,
                    "mrr_at_10": 0.5398287385129491,
                    "mrr_at_20": 0.5437772406716804,
                    "main_score": 0.35666,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 36.18243598937988,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.34414,
                    "ndcg_at_3": 0.31295,
                    "ndcg_at_5": 0.32523,
                    "ndcg_at_10": 0.34682,
                    "ndcg_at_20": 0.36959,
                    "map_at_1": 0.16955,
                    "map_at_3": 0.23743,
                    "map_at_5": 0.25974,
                    "map_at_10": 0.27609,
                    "map_at_20": 0.2844,
                    "recall_at_1": 0.16955,
                    "recall_at_3": 0.27721,
                    "recall_at_5": 0.33624,
                    "recall_at_10": 0.40704,
                    "recall_at_20": 0.47609,
                    "precision_at_1": 0.34414,
                    "precision_at_3": 0.21142,
                    "precision_at_5": 0.15864,
                    "precision_at_10": 0.0983,
                    "precision_at_20": 0.05903,
                    "mrr_at_1": 0.3441358024691358,
                    "mrr_at_3": 0.3981481481481484,
                    "mrr_at_5": 0.4129629629629631,
                    "mrr_at_10": 0.42306792572996277,
                    "mrr_at_20": 0.4277982910866181,
                    "main_score": 0.34682,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 320.0951361656189,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.53608,
                    "ndcg_at_3": 0.59201,
                    "ndcg_at_5": 0.60639,
                    "ndcg_at_10": 0.62217,
                    "ndcg_at_20": 0.63404,
                    "map_at_1": 0.53601,
                    "map_at_3": 0.57846,
                    "map_at_5": 0.58645,
                    "map_at_10": 0.59297,
                    "map_at_20": 0.59623,
                    "recall_at_1": 0.53601,
                    "recall_at_3": 0.63099,
                    "recall_at_5": 0.66587,
                    "recall_at_10": 0.71461,
                    "recall_at_20": 0.76152,
                    "precision_at_1": 0.53608,
                    "precision_at_3": 0.21038,
                    "precision_at_5": 0.13322,
                    "precision_at_10": 0.0715,
                    "precision_at_20": 0.03812,
                    "mrr_at_1": 0.5361149930125774,
                    "mrr_at_3": 0.5786051773474471,
                    "mrr_at_5": 0.5866087708790929,
                    "mrr_at_10": 0.5931358475379311,
                    "mrr_at_20": 0.5964041515583591,
                    "main_score": 0.62217,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 70.42004895210266,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.34259,
                    "ndcg_at_3": 0.31238,
                    "ndcg_at_5": 0.32437,
                    "ndcg_at_10": 0.34629,
                    "ndcg_at_20": 0.36911,
                    "map_at_1": 0.16801,
                    "map_at_3": 0.23666,
                    "map_at_5": 0.25857,
                    "map_at_10": 0.27522,
                    "map_at_20": 0.28351,
                    "recall_at_1": 0.16801,
                    "recall_at_3": 0.27721,
                    "recall_at_5": 0.33585,
                    "recall_at_10": 0.40752,
                    "recall_at_20": 0.47733,
                    "precision_at_1": 0.34259,
                    "precision_at_3": 0.21142,
                    "precision_at_5": 0.15833,
                    "precision_at_10": 0.09846,
                    "precision_at_20": 0.05903,
                    "mrr_at_1": 0.3425925925925926,
                    "mrr_at_3": 0.3973765432098768,
                    "mrr_at_5": 0.4121913580246915,
                    "mrr_at_10": 0.4221199539486576,
                    "mrr_at_20": 0.42685766792377283,
                    "main_score": 0.34629,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 202.2068133354187,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.486,
                    "ndcg_at_3": 0.58882,
                    "ndcg_at_5": 0.61373,
                    "ndcg_at_10": 0.63951,
                    "ndcg_at_20": 0.65447,
                    "map_at_1": 0.486,
                    "map_at_3": 0.56383,
                    "map_at_5": 0.57753,
                    "map_at_10": 0.58831,
                    "map_at_20": 0.59244,
                    "recall_at_1": 0.486,
                    "recall_at_3": 0.661,
                    "recall_at_5": 0.722,
                    "recall_at_10": 0.801,
                    "recall_at_20": 0.86,
                    "precision_at_1": 0.486,
                    "precision_at_3": 0.22033,
                    "precision_at_5": 0.1444,
                    "precision_at_10": 0.0801,
                    "precision_at_20": 0.043,
                    "mrr_at_1": 0.486,
                    "mrr_at_3": 0.5638333333333332,
                    "mrr_at_5": 0.5775333333333331,
                    "mrr_at_10": 0.5883059523809525,
                    "mrr_at_20": 0.5924390182873543,
                    "main_score": 0.63951,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 50.92634725570679,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.66426,
                    "ndcg_at_3": 0.73976,
                    "ndcg_at_5": 0.75373,
                    "ndcg_at_10": 0.76545,
                    "ndcg_at_20": 0.77338,
                    "map_at_1": 0.6639,
                    "map_at_3": 0.7219,
                    "map_at_5": 0.7297,
                    "map_at_10": 0.73456,
                    "map_at_20": 0.73676,
                    "recall_at_1": 0.6639,
                    "recall_at_3": 0.79088,
                    "recall_at_5": 0.82463,
                    "recall_at_10": 0.86075,
                    "recall_at_20": 0.89199,
                    "precision_at_1": 0.66426,
                    "precision_at_3": 0.26392,
                    "precision_at_5": 0.16515,
                    "precision_at_10": 0.08621,
                    "precision_at_20": 0.04468,
                    "mrr_at_1": 0.6642592918795138,
                    "mrr_at_3": 0.7221439336112492,
                    "mrr_at_5": 0.7298871665394451,
                    "mrr_at_10": 0.7347288511239524,
                    "mrr_at_20": 0.7369106950246133,
                    "main_score": 0.76545,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 201.26610016822815,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.48845,
                    "ndcg_at_3": 0.55467,
                    "ndcg_at_5": 0.57139,
                    "ndcg_at_10": 0.5876,
                    "ndcg_at_20": 0.59962,
                    "map_at_1": 0.48841,
                    "map_at_3": 0.53862,
                    "map_at_5": 0.54793,
                    "map_at_10": 0.55465,
                    "map_at_20": 0.55797,
                    "recall_at_1": 0.48841,
                    "recall_at_3": 0.60076,
                    "recall_at_5": 0.64126,
                    "recall_at_10": 0.6911,
                    "recall_at_20": 0.73845,
                    "precision_at_1": 0.48845,
                    "precision_at_3": 0.20037,
                    "precision_at_5": 0.12835,
                    "precision_at_10": 0.06919,
                    "precision_at_20": 0.03698,
                    "mrr_at_1": 0.488449240607514,
                    "mrr_at_3": 0.5387889688249458,
                    "mrr_at_5": 0.5481274980016085,
                    "mrr_at_10": 0.5548860594064519,
                    "mrr_at_20": 0.5582153818702021,
                    "main_score": 0.5876,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 115.6832160949707,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.72525,
                    "ndcg_at_3": 0.76273,
                    "ndcg_at_5": 0.77001,
                    "ndcg_at_10": 0.77566,
                    "ndcg_at_20": 0.77943,
                    "map_at_1": 0.72525,
                    "map_at_3": 0.75395,
                    "map_at_5": 0.75801,
                    "map_at_10": 0.76035,
                    "map_at_20": 0.7614,
                    "recall_at_1": 0.72525,
                    "recall_at_3": 0.78795,
                    "recall_at_5": 0.80555,
                    "recall_at_10": 0.823,
                    "recall_at_20": 0.8378,
                    "precision_at_1": 0.72525,
                    "precision_at_3": 0.26265,
                    "precision_at_5": 0.16111,
                    "precision_at_10": 0.0823,
                    "precision_at_20": 0.04189,
                    "mrr_at_1": 0.72525,
                    "mrr_at_3": 0.7539500000000038,
                    "mrr_at_5": 0.7580075000000058,
                    "mrr_at_10": 0.7603501984127036,
                    "mrr_at_20": 0.7613977205218748,
                    "main_score": 0.77566,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 308.41446137428284,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.45706,
                    "ndcg_at_3": 0.52114,
                    "ndcg_at_5": 0.53758,
                    "ndcg_at_10": 0.55437,
                    "ndcg_at_20": 0.56652,
                    "map_at_1": 0.45687,
                    "map_at_3": 0.50559,
                    "map_at_5": 0.51472,
                    "map_at_10": 0.5217,
                    "map_at_20": 0.52504,
                    "recall_at_1": 0.45687,
                    "recall_at_3": 0.56575,
                    "recall_at_5": 0.6057,
                    "recall_at_10": 0.65733,
                    "recall_at_20": 0.70526,
                    "precision_at_1": 0.45706,
                    "precision_at_3": 0.1887,
                    "precision_at_5": 0.12123,
                    "precision_at_10": 0.06581,
                    "precision_at_20": 0.03531,
                    "mrr_at_1": 0.45705729686564184,
                    "mrr_at_3": 0.5058028881346955,
                    "mrr_at_5": 0.5149384441339,
                    "mrr_at_10": 0.5219342168224252,
                    "mrr_at_20": 0.5252956101573059,
                    "main_score": 0.55437,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 64.6000247001648,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.167,
                    "ndcg_at_3": 0.13499,
                    "ndcg_at_5": 0.12,
                    "ndcg_at_10": 0.14458,
                    "ndcg_at_20": 0.16654,
                    "map_at_1": 0.03398,
                    "map_at_3": 0.0592,
                    "map_at_5": 0.0714,
                    "map_at_10": 0.08269,
                    "map_at_20": 0.0901,
                    "recall_at_1": 0.03398,
                    "recall_at_3": 0.07678,
                    "recall_at_5": 0.10763,
                    "recall_at_10": 0.15282,
                    "recall_at_20": 0.20428,
                    "precision_at_1": 0.167,
                    "precision_at_3": 0.12633,
                    "precision_at_5": 0.1064,
                    "precision_at_10": 0.0754,
                    "precision_at_20": 0.0503,
                    "mrr_at_1": 0.167,
                    "mrr_at_3": 0.22383333333333347,
                    "mrr_at_5": 0.24208333333333334,
                    "mrr_at_10": 0.25515992063492055,
                    "mrr_at_20": 0.26179826125027356,
                    "main_score": 0.14458,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 260.7162301540375,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.87781,
                    "ndcg_at_3": 0.91625,
                    "ndcg_at_5": 0.9229,
                    "ndcg_at_10": 0.92713,
                    "ndcg_at_20": 0.92925,
                    "map_at_1": 0.87781,
                    "map_at_3": 0.90728,
                    "map_at_5": 0.91097,
                    "map_at_10": 0.91274,
                    "map_at_20": 0.91333,
                    "recall_at_1": 0.87781,
                    "recall_at_3": 0.94199,
                    "recall_at_5": 0.95816,
                    "recall_at_10": 0.97109,
                    "recall_at_20": 0.97939,
                    "precision_at_1": 0.87781,
                    "precision_at_3": 0.314,
                    "precision_at_5": 0.19163,
                    "precision_at_10": 0.09711,
                    "precision_at_20": 0.04897,
                    "mrr_at_1": 0.8778147901399067,
                    "mrr_at_3": 0.9072840328669768,
                    "mrr_at_5": 0.9109726848767509,
                    "mrr_at_10": 0.912744325652389,
                    "mrr_at_20": 0.9133342729181699,
                    "main_score": 0.92713,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 105.62520861625671,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.29876,
                    "ndcg_at_3": 0.27728,
                    "ndcg_at_5": 0.26556,
                    "ndcg_at_10": 0.24249,
                    "ndcg_at_20": 0.22782,
                    "map_at_1": 0.04124,
                    "map_at_3": 0.0654,
                    "map_at_5": 0.07764,
                    "map_at_10": 0.09146,
                    "map_at_20": 0.10036,
                    "recall_at_1": 0.04124,
                    "recall_at_3": 0.07384,
                    "recall_at_5": 0.09652,
                    "recall_at_10": 0.12908,
                    "recall_at_20": 0.15574,
                    "precision_at_1": 0.31269,
                    "precision_at_3": 0.26316,
                    "precision_at_5": 0.23096,
                    "precision_at_10": 0.17647,
                    "precision_at_20": 0.12895,
                    "mrr_at_1": 0.3157894736842105,
                    "mrr_at_3": 0.3833849329205366,
                    "mrr_at_5": 0.40041279669762636,
                    "mrr_at_10": 0.4081171064917196,
                    "mrr_at_20": 0.41227012979150446,
                    "main_score": 0.24249,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 17.150715351104736,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.553,
                    "ndcg_at_3": 0.66796,
                    "ndcg_at_5": 0.69047,
                    "ndcg_at_10": 0.70296,
                    "ndcg_at_20": 0.71511,
                    "map_at_1": 0.553,
                    "map_at_3": 0.64083,
                    "map_at_5": 0.65323,
                    "map_at_10": 0.65851,
                    "map_at_20": 0.66185,
                    "recall_at_1": 0.553,
                    "recall_at_3": 0.746,
                    "recall_at_5": 0.801,
                    "recall_at_10": 0.839,
                    "recall_at_20": 0.887,
                    "precision_at_1": 0.553,
                    "precision_at_3": 0.24867,
                    "precision_at_5": 0.1602,
                    "precision_at_10": 0.0839,
                    "precision_at_20": 0.04435,
                    "mrr_at_1": 0.553,
                    "mrr_at_3": 0.6408333333333334,
                    "mrr_at_5": 0.6532333333333334,
                    "mrr_at_10": 0.6585107142857145,
                    "mrr_at_20": 0.6618501526809961,
                    "main_score": 0.70296,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 182.42080950737,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.463,
                    "ndcg_at_3": 0.55914,
                    "ndcg_at_5": 0.58105,
                    "ndcg_at_10": 0.60654,
                    "ndcg_at_20": 0.62443,
                    "map_at_1": 0.463,
                    "map_at_3": 0.53567,
                    "map_at_5": 0.54787,
                    "map_at_10": 0.55835,
                    "map_at_20": 0.56336,
                    "recall_at_1": 0.463,
                    "recall_at_3": 0.627,
                    "recall_at_5": 0.68,
                    "recall_at_10": 0.759,
                    "recall_at_20": 0.829,
                    "precision_at_1": 0.463,
                    "precision_at_3": 0.209,
                    "precision_at_5": 0.136,
                    "precision_at_10": 0.0759,
                    "precision_at_20": 0.04145,
                    "mrr_at_1": 0.463,
                    "mrr_at_3": 0.5356666666666663,
                    "mrr_at_5": 0.5478666666666661,
                    "mrr_at_10": 0.5583496031746027,
                    "mrr_at_20": 0.563355213899447,
                    "main_score": 0.60654,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 178.72771668434143,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.465,
                    "ndcg_at_3": 0.55999,
                    "ndcg_at_5": 0.58026,
                    "ndcg_at_10": 0.60689,
                    "ndcg_at_20": 0.62521,
                    "map_at_1": 0.465,
                    "map_at_3": 0.5365,
                    "map_at_5": 0.5478,
                    "map_at_10": 0.55885,
                    "map_at_20": 0.56394,
                    "recall_at_1": 0.465,
                    "recall_at_3": 0.628,
                    "recall_at_5": 0.677,
                    "recall_at_10": 0.759,
                    "recall_at_20": 0.831,
                    "precision_at_1": 0.465,
                    "precision_at_3": 0.20933,
                    "precision_at_5": 0.1354,
                    "precision_at_10": 0.0759,
                    "precision_at_20": 0.04155,
                    "mrr_at_1": 0.465,
                    "mrr_at_3": 0.5364999999999995,
                    "mrr_at_5": 0.5477999999999994,
                    "mrr_at_10": 0.5588496031746026,
                    "mrr_at_20": 0.5639376162193495,
                    "main_score": 0.60689,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 154.06078720092773,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.414,
                    "ndcg_at_3": 0.52134,
                    "ndcg_at_5": 0.54536,
                    "ndcg_at_10": 0.56711,
                    "ndcg_at_20": 0.58794,
                    "map_at_1": 0.414,
                    "map_at_3": 0.49517,
                    "map_at_5": 0.50857,
                    "map_at_10": 0.5176,
                    "map_at_20": 0.52336,
                    "recall_at_1": 0.414,
                    "recall_at_3": 0.597,
                    "recall_at_5": 0.655,
                    "recall_at_10": 0.722,
                    "recall_at_20": 0.804,
                    "precision_at_1": 0.414,
                    "precision_at_3": 0.199,
                    "precision_at_5": 0.131,
                    "precision_at_10": 0.0722,
                    "precision_at_20": 0.0402,
                    "mrr_at_1": 0.414,
                    "mrr_at_3": 0.49516666666666603,
                    "mrr_at_5": 0.508566666666666,
                    "mrr_at_10": 0.5176023809523806,
                    "mrr_at_20": 0.5233600209817696,
                    "main_score": 0.56711,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2328.628045320511,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.50667,
                    "ndcg_at_3": 0.55849,
                    "ndcg_at_5": 0.58358,
                    "ndcg_at_10": 0.60873,
                    "map_at_1": 0.478,
                    "map_at_3": 0.53539,
                    "map_at_5": 0.55153,
                    "map_at_10": 0.56378,
                    "recall_at_1": 0.478,
                    "recall_at_3": 0.5995,
                    "recall_at_5": 0.66122,
                    "recall_at_10": 0.73106,
                    "precision_at_1": 0.50667,
                    "precision_at_3": 0.21778,
                    "precision_at_5": 0.146,
                    "precision_at_10": 0.08367,
                    "mrr_at_1": 0.5066666666666667,
                    "mrr_at_3": 0.5561111111111111,
                    "mrr_at_5": 0.5701111111111112,
                    "mrr_at_10": 0.5789087301587302,
                    "main_score": 0.60873,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 46.07862973213196,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "6e346642246bfb4928c560ee08640dc84d074e8c",
        "task_name": "LEMBWikimQARetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.96333,
                    "ndcg_at_3": 0.97175,
                    "ndcg_at_5": 0.97462,
                    "ndcg_at_10": 0.97658,
                    "map_at_1": 0.96333,
                    "map_at_3": 0.97,
                    "map_at_5": 0.97167,
                    "map_at_10": 0.97237,
                    "recall_at_1": 0.96333,
                    "recall_at_3": 0.97667,
                    "recall_at_5": 0.98333,
                    "recall_at_10": 0.99,
                    "precision_at_1": 0.96333,
                    "precision_at_3": 0.32556,
                    "precision_at_5": 0.19667,
                    "precision_at_10": 0.099,
                    "mrr_at_1": 0.9633333333333334,
                    "mrr_at_3": 0.97,
                    "mrr_at_5": 0.9716666666666667,
                    "mrr_at_10": 0.9723703703703703,
                    "main_score": 0.97658,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 63.32843041419983,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.46125,
                    "ndcg_at_3": 0.55104,
                    "ndcg_at_5": 0.57426,
                    "ndcg_at_10": 0.5947,
                    "ndcg_at_20": 0.60862,
                    "map_at_1": 0.46117,
                    "map_at_3": 0.52917,
                    "map_at_5": 0.54208,
                    "map_at_10": 0.55057,
                    "map_at_20": 0.55443,
                    "recall_at_1": 0.46117,
                    "recall_at_3": 0.61418,
                    "recall_at_5": 0.67045,
                    "recall_at_10": 0.73333,
                    "recall_at_20": 0.78811,
                    "precision_at_1": 0.46125,
                    "precision_at_3": 0.20479,
                    "precision_at_5": 0.13413,
                    "precision_at_10": 0.07336,
                    "precision_at_20": 0.03942,
                    "mrr_at_1": 0.46124727319389197,
                    "mrr_at_3": 0.5292302921425326,
                    "mrr_at_5": 0.5421377090551528,
                    "mrr_at_10": 0.5506318119232095,
                    "mrr_at_20": 0.5544858914430012,
                    "main_score": 0.5947,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 81.14604020118713,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.152,
                    "ndcg_at_3": 0.1283,
                    "ndcg_at_5": 0.11234,
                    "ndcg_at_10": 0.13877,
                    "ndcg_at_20": 0.1641,
                    "map_at_1": 0.03108,
                    "map_at_3": 0.05549,
                    "map_at_5": 0.06604,
                    "map_at_10": 0.07833,
                    "map_at_20": 0.08695,
                    "recall_at_1": 0.03108,
                    "recall_at_3": 0.07433,
                    "recall_at_5": 0.10108,
                    "recall_at_10": 0.14965,
                    "recall_at_20": 0.20885,
                    "precision_at_1": 0.152,
                    "precision_at_3": 0.122,
                    "precision_at_5": 0.0998,
                    "precision_at_10": 0.0738,
                    "precision_at_20": 0.05155,
                    "mrr_at_1": 0.152,
                    "mrr_at_3": 0.21383333333333351,
                    "mrr_at_5": 0.22903333333333345,
                    "mrr_at_10": 0.2415757936507937,
                    "mrr_at_20": 0.2495878334470828,
                    "main_score": 0.13877,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 345.87154936790466,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.89958,
                    "ndcg_at_3": 0.93209,
                    "ndcg_at_5": 0.93676,
                    "ndcg_at_10": 0.94019,
                    "ndcg_at_20": 0.94182,
                    "map_at_1": 0.89954,
                    "map_at_3": 0.92445,
                    "map_at_5": 0.92705,
                    "map_at_10": 0.92851,
                    "map_at_20": 0.92896,
                    "recall_at_1": 0.89954,
                    "recall_at_3": 0.954,
                    "recall_at_5": 0.96529,
                    "recall_at_10": 0.97571,
                    "recall_at_20": 0.98212,
                    "precision_at_1": 0.89958,
                    "precision_at_3": 0.31801,
                    "precision_at_5": 0.19307,
                    "precision_at_10": 0.09758,
                    "precision_at_20": 0.04911,
                    "mrr_at_1": 0.8995814036337727,
                    "mrr_at_3": 0.9244967937299602,
                    "mrr_at_5": 0.9270885286783053,
                    "mrr_at_10": 0.9285416171871922,
                    "mrr_at_20": 0.9289919832839575,
                    "main_score": 0.94019,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 98.84125590324402,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.557,
                    "ndcg_at_3": 0.66547,
                    "ndcg_at_5": 0.68936,
                    "ndcg_at_10": 0.70621,
                    "map_at_1": 0.557,
                    "map_at_3": 0.639,
                    "map_at_5": 0.65225,
                    "map_at_10": 0.65923,
                    "recall_at_1": 0.557,
                    "recall_at_3": 0.742,
                    "recall_at_5": 0.8,
                    "recall_at_10": 0.852,
                    "precision_at_1": 0.557,
                    "precision_at_3": 0.24733,
                    "precision_at_5": 0.16,
                    "precision_at_10": 0.0852,
                    "mrr_at_1": 0.557,
                    "mrr_at_3": 0.639,
                    "mrr_at_5": 0.6522500000000002,
                    "mrr_at_10": 0.6592257936507938,
                    "main_score": 0.70621,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 58.56835579872131,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.36068,
                    "ndcg_at_3": 0.33314,
                    "ndcg_at_5": 0.31162,
                    "ndcg_at_10": 0.28256,
                    "map_at_1": 0.04302,
                    "map_at_3": 0.07524,
                    "map_at_5": 0.08654,
                    "map_at_10": 0.10063,
                    "recall_at_1": 0.04302,
                    "recall_at_3": 0.08469,
                    "recall_at_5": 0.10377,
                    "recall_at_10": 0.13232,
                    "precision_at_1": 0.387,
                    "precision_at_3": 0.31579,
                    "precision_at_5": 0.27121,
                    "precision_at_10": 0.20805,
                    "mrr_at_1": 0.3931888544891641,
                    "mrr_at_3": 0.4561403508771929,
                    "mrr_at_5": 0.4705366357069143,
                    "mrr_at_10": 0.4766671580913066,
                    "main_score": 0.28256,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 67.96622014045715,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.51,
                    "ndcg_at_3": 0.56331,
                    "ndcg_at_5": 0.58397,
                    "ndcg_at_10": 0.61207,
                    "ndcg_at_20": 0.62998,
                    "map_at_1": 0.48133,
                    "map_at_3": 0.54006,
                    "map_at_5": 0.55351,
                    "map_at_10": 0.56711,
                    "map_at_20": 0.57256,
                    "recall_at_1": 0.48133,
                    "recall_at_3": 0.60617,
                    "recall_at_5": 0.65594,
                    "recall_at_10": 0.73606,
                    "recall_at_20": 0.80467,
                    "precision_at_1": 0.51,
                    "precision_at_3": 0.21889,
                    "precision_at_5": 0.14533,
                    "precision_at_10": 0.084,
                    "precision_at_20": 0.046,
                    "mrr_at_1": 0.51,
                    "mrr_at_3": 0.5594444444444445,
                    "mrr_at_5": 0.5719444444444445,
                    "mrr_at_10": 0.5813941798941799,
                    "mrr_at_20": 0.5856756601098708,
                    "main_score": 0.61207,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 38.55588388442993,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.59124,
                    "ndcg_at_3": 0.66095,
                    "ndcg_at_5": 0.67862,
                    "ndcg_at_10": 0.69314,
                    "ndcg_at_20": 0.70305,
                    "map_at_1": 0.5911,
                    "map_at_3": 0.64391,
                    "map_at_5": 0.65374,
                    "map_at_10": 0.65975,
                    "map_at_20": 0.6625,
                    "recall_at_1": 0.5911,
                    "recall_at_3": 0.71007,
                    "recall_at_5": 0.75288,
                    "recall_at_10": 0.79773,
                    "recall_at_20": 0.8367,
                    "precision_at_1": 0.59124,
                    "precision_at_3": 0.23679,
                    "precision_at_5": 0.15066,
                    "precision_at_10": 0.07982,
                    "precision_at_20": 0.04186,
                    "mrr_at_1": 0.5912357243680226,
                    "mrr_at_3": 0.6440288292912433,
                    "mrr_at_5": 0.653842123273028,
                    "mrr_at_10": 0.6598480473929647,
                    "mrr_at_20": 0.6625933111076455,
                    "main_score": 0.69314,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 154.61646795272827,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.3252,
                    "ndcg_at_3": 0.40842,
                    "ndcg_at_5": 0.43029,
                    "ndcg_at_10": 0.45132,
                    "ndcg_at_20": 0.4668,
                    "map_at_1": 0.3246,
                    "map_at_3": 0.38782,
                    "map_at_5": 0.40001,
                    "map_at_10": 0.40872,
                    "map_at_20": 0.41302,
                    "recall_at_1": 0.3246,
                    "recall_at_3": 0.46713,
                    "recall_at_5": 0.5201,
                    "recall_at_10": 0.58485,
                    "recall_at_20": 0.64556,
                    "precision_at_1": 0.3252,
                    "precision_at_3": 0.15623,
                    "precision_at_5": 0.10447,
                    "precision_at_10": 0.05884,
                    "precision_at_20": 0.03255,
                    "mrr_at_1": 0.3252008107499437,
                    "mrr_at_3": 0.38861571954057617,
                    "mrr_at_5": 0.4007094062007385,
                    "mrr_at_10": 0.4094454185597917,
                    "mrr_at_20": 0.413700307314832,
                    "main_score": 0.45132,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 99.02788758277893,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.42724,
                    "ndcg_at_3": 0.36591,
                    "ndcg_at_5": 0.3414,
                    "ndcg_at_10": 0.30796,
                    "map_at_1": 0.05632,
                    "map_at_3": 0.08203,
                    "map_at_5": 0.09662,
                    "map_at_10": 0.11141,
                    "recall_at_1": 0.05632,
                    "recall_at_3": 0.08916,
                    "recall_at_5": 0.11395,
                    "recall_at_10": 0.14229,
                    "precision_at_1": 0.43963,
                    "precision_at_3": 0.33333,
                    "precision_at_5": 0.28607,
                    "precision_at_10": 0.22136,
                    "mrr_at_1": 0.43962848297213625,
                    "mrr_at_3": 0.4989680082559341,
                    "mrr_at_5": 0.5062435500515997,
                    "mrr_at_10": 0.5132893508280505,
                    "main_score": 0.30796,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 57.694918632507324,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.488,
                    "ndcg_at_3": 0.54122,
                    "ndcg_at_5": 0.55478,
                    "ndcg_at_10": 0.56676,
                    "ndcg_at_20": 0.57491,
                    "map_at_1": 0.488,
                    "map_at_3": 0.52817,
                    "map_at_5": 0.53567,
                    "map_at_10": 0.54044,
                    "map_at_20": 0.54271,
                    "recall_at_1": 0.488,
                    "recall_at_3": 0.579,
                    "recall_at_5": 0.612,
                    "recall_at_10": 0.65,
                    "recall_at_20": 0.682,
                    "precision_at_1": 0.488,
                    "precision_at_3": 0.193,
                    "precision_at_5": 0.1224,
                    "precision_at_10": 0.065,
                    "precision_at_20": 0.0341,
                    "mrr_at_1": 0.488,
                    "mrr_at_3": 0.5281666666666665,
                    "mrr_at_5": 0.5356666666666663,
                    "mrr_at_10": 0.5404353174603174,
                    "mrr_at_20": 0.5427123405962799,
                    "main_score": 0.56676,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 547.6351850032806,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.90175,
                    "ndcg_at_3": 0.9344,
                    "ndcg_at_5": 0.93912,
                    "ndcg_at_10": 0.94196,
                    "ndcg_at_20": 0.94379,
                    "map_at_1": 0.90175,
                    "map_at_3": 0.92673,
                    "map_at_5": 0.92935,
                    "map_at_10": 0.93054,
                    "map_at_20": 0.93106,
                    "recall_at_1": 0.90175,
                    "recall_at_3": 0.95643,
                    "recall_at_5": 0.96793,
                    "recall_at_10": 0.97659,
                    "recall_at_20": 0.9837,
                    "precision_at_1": 0.90175,
                    "precision_at_3": 0.31881,
                    "precision_at_5": 0.19359,
                    "precision_at_10": 0.09766,
                    "precision_at_20": 0.04918,
                    "mrr_at_1": 0.9017543859649123,
                    "mrr_at_3": 0.9267303279295269,
                    "mrr_at_5": 0.9293485824265311,
                    "mrr_at_10": 0.930535692254547,
                    "mrr_at_20": 0.9310574138609936,
                    "main_score": 0.94196,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 119.68750190734863,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.59667,
                    "ndcg_at_3": 0.67723,
                    "ndcg_at_5": 0.70282,
                    "ndcg_at_10": 0.72424,
                    "ndcg_at_20": 0.73561,
                    "map_at_1": 0.57189,
                    "map_at_3": 0.649,
                    "map_at_5": 0.6663,
                    "map_at_10": 0.67696,
                    "map_at_20": 0.68055,
                    "recall_at_1": 0.57189,
                    "recall_at_3": 0.73533,
                    "recall_at_5": 0.79567,
                    "recall_at_10": 0.857,
                    "recall_at_20": 0.90033,
                    "precision_at_1": 0.59667,
                    "precision_at_3": 0.26333,
                    "precision_at_5": 0.17667,
                    "precision_at_10": 0.09667,
                    "precision_at_20": 0.051,
                    "mrr_at_1": 0.5966666666666667,
                    "mrr_at_3": 0.6655555555555556,
                    "mrr_at_5": 0.6793888888888888,
                    "mrr_at_10": 0.6866362433862433,
                    "mrr_at_20": 0.6890595452305978,
                    "main_score": 0.72424,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 61.1157112121582,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.486,
                    "ndcg_at_3": 0.58882,
                    "ndcg_at_5": 0.61373,
                    "ndcg_at_10": 0.63951,
                    "ndcg_at_20": 0.65447,
                    "map_at_1": 0.486,
                    "map_at_3": 0.56383,
                    "map_at_5": 0.57753,
                    "map_at_10": 0.58831,
                    "map_at_20": 0.59244,
                    "recall_at_1": 0.486,
                    "recall_at_3": 0.661,
                    "recall_at_5": 0.722,
                    "recall_at_10": 0.801,
                    "recall_at_20": 0.86,
                    "precision_at_1": 0.486,
                    "precision_at_3": 0.22033,
                    "precision_at_5": 0.1444,
                    "precision_at_10": 0.0801,
                    "precision_at_20": 0.043,
                    "mrr_at_1": 0.486,
                    "mrr_at_3": 0.5638333333333332,
                    "mrr_at_5": 0.5775333333333331,
                    "mrr_at_10": 0.5883059523809525,
                    "mrr_at_20": 0.5924390182873543,
                    "main_score": 0.63951,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 34.85272765159607,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.70601,
                    "ndcg_at_3": 0.78683,
                    "ndcg_at_5": 0.80787,
                    "ndcg_at_10": 0.82018,
                    "ndcg_at_20": 0.82725,
                    "map_at_1": 0.70337,
                    "map_at_3": 0.768,
                    "map_at_5": 0.77976,
                    "map_at_10": 0.78507,
                    "map_at_20": 0.78708,
                    "recall_at_1": 0.70337,
                    "recall_at_3": 0.84036,
                    "recall_at_5": 0.89094,
                    "recall_at_10": 0.92835,
                    "recall_at_20": 0.95574,
                    "precision_at_1": 0.70601,
                    "precision_at_3": 0.2824,
                    "precision_at_5": 0.17998,
                    "precision_at_10": 0.09389,
                    "precision_at_20": 0.04831,
                    "mrr_at_1": 0.7060063224446786,
                    "mrr_at_3": 0.7683526519142959,
                    "mrr_at_5": 0.7799964875307346,
                    "mrr_at_10": 0.7850209911853749,
                    "mrr_at_20": 0.7870318436098124,
                    "main_score": 0.82018,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 802.1606051921844,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.36308,
                    "ndcg_at_3": 0.44427,
                    "ndcg_at_5": 0.46833,
                    "ndcg_at_10": 0.49086,
                    "ndcg_at_20": 0.50694,
                    "map_at_1": 0.36305,
                    "map_at_3": 0.42433,
                    "map_at_5": 0.4377,
                    "map_at_10": 0.44702,
                    "map_at_20": 0.45144,
                    "recall_at_1": 0.36305,
                    "recall_at_3": 0.50192,
                    "recall_at_5": 0.56028,
                    "recall_at_10": 0.62977,
                    "recall_at_20": 0.69324,
                    "precision_at_1": 0.36308,
                    "precision_at_3": 0.16734,
                    "precision_at_5": 0.11209,
                    "precision_at_10": 0.063,
                    "precision_at_20": 0.03468,
                    "mrr_at_1": 0.3630822533042474,
                    "mrr_at_3": 0.4243712305915636,
                    "mrr_at_5": 0.437734184524586,
                    "mrr_at_10": 0.44706450793244584,
                    "mrr_at_20": 0.4514874852704856,
                    "main_score": 0.49086,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 72.31547784805298,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.489,
                    "ndcg_at_3": 0.54259,
                    "ndcg_at_5": 0.55451,
                    "ndcg_at_10": 0.56722,
                    "ndcg_at_20": 0.57537,
                    "map_at_1": 0.489,
                    "map_at_3": 0.52933,
                    "map_at_5": 0.53593,
                    "map_at_10": 0.54105,
                    "map_at_20": 0.54332,
                    "recall_at_1": 0.489,
                    "recall_at_3": 0.581,
                    "recall_at_5": 0.61,
                    "recall_at_10": 0.65,
                    "recall_at_20": 0.682,
                    "precision_at_1": 0.489,
                    "precision_at_3": 0.19367,
                    "precision_at_5": 0.122,
                    "precision_at_10": 0.065,
                    "precision_at_20": 0.0341,
                    "mrr_at_1": 0.489,
                    "mrr_at_3": 0.529333333333333,
                    "mrr_at_5": 0.5359333333333329,
                    "mrr_at_10": 0.5410464285714286,
                    "mrr_at_20": 0.5433187799902193,
                    "main_score": 0.56722,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 393.83993554115295,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.5393,
                    "ndcg_at_3": 0.61976,
                    "ndcg_at_5": 0.63945,
                    "ndcg_at_10": 0.65753,
                    "ndcg_at_20": 0.66938,
                    "map_at_1": 0.53923,
                    "map_at_3": 0.60025,
                    "map_at_5": 0.6112,
                    "map_at_10": 0.61871,
                    "map_at_20": 0.622,
                    "recall_at_1": 0.53923,
                    "recall_at_3": 0.67604,
                    "recall_at_5": 0.72374,
                    "recall_at_10": 0.77934,
                    "recall_at_20": 0.82599,
                    "precision_at_1": 0.5393,
                    "precision_at_3": 0.22541,
                    "precision_at_5": 0.14481,
                    "precision_at_10": 0.07798,
                    "precision_at_20": 0.04133,
                    "mrr_at_1": 0.5392980880277172,
                    "mrr_at_3": 0.6002929979896524,
                    "mrr_at_5": 0.6112515505368158,
                    "mrr_at_10": 0.6187689679790048,
                    "mrr_at_20": 0.6220407765003307,
                    "main_score": 0.65753,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 105.65335416793823,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.86997,
                    "ndcg_at_3": 0.90656,
                    "ndcg_at_5": 0.91309,
                    "ndcg_at_10": 0.91803,
                    "map_at_1": 0.86997,
                    "map_at_3": 0.89795,
                    "map_at_5": 0.90158,
                    "map_at_10": 0.90365,
                    "recall_at_1": 0.86997,
                    "recall_at_3": 0.93131,
                    "recall_at_5": 0.94712,
                    "recall_at_10": 0.96226,
                    "precision_at_1": 0.86997,
                    "precision_at_3": 0.31044,
                    "precision_at_5": 0.18943,
                    "precision_at_10": 0.09623,
                    "mrr_at_1": 0.8699679372996081,
                    "mrr_at_3": 0.8979560028500173,
                    "mrr_at_5": 0.9015897755610991,
                    "mrr_at_10": 0.9036565509412432,
                    "main_score": 0.91803,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 44.772040605545044,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.492,
                    "ndcg_at_3": 0.54786,
                    "ndcg_at_5": 0.56214,
                    "ndcg_at_10": 0.57205,
                    "ndcg_at_20": 0.58374,
                    "map_at_1": 0.492,
                    "map_at_3": 0.534,
                    "map_at_5": 0.54185,
                    "map_at_10": 0.54588,
                    "map_at_20": 0.54912,
                    "recall_at_1": 0.492,
                    "recall_at_3": 0.588,
                    "recall_at_5": 0.623,
                    "recall_at_10": 0.654,
                    "recall_at_20": 0.7,
                    "precision_at_1": 0.492,
                    "precision_at_3": 0.196,
                    "precision_at_5": 0.1246,
                    "precision_at_10": 0.0654,
                    "precision_at_20": 0.035,
                    "mrr_at_1": 0.492,
                    "mrr_at_3": 0.5339999999999999,
                    "mrr_at_5": 0.54185,
                    "mrr_at_10": 0.5458837301587304,
                    "mrr_at_20": 0.5491224600519882,
                    "main_score": 0.57205,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 486.0661690235138,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "6e346642246bfb4928c560ee08640dc84d074e8c",
        "task_name": "LEMBWikimQARetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.97333,
                    "ndcg_at_3": 0.98298,
                    "ndcg_at_5": 0.98585,
                    "ndcg_at_10": 0.98585,
                    "ndcg_at_20": 0.98663,
                    "map_at_1": 0.97333,
                    "map_at_3": 0.98056,
                    "map_at_5": 0.98222,
                    "map_at_10": 0.98222,
                    "map_at_20": 0.98241,
                    "recall_at_1": 0.97333,
                    "recall_at_3": 0.99,
                    "recall_at_5": 0.99667,
                    "recall_at_10": 0.99667,
                    "recall_at_20": 1.0,
                    "precision_at_1": 0.97333,
                    "precision_at_3": 0.33,
                    "precision_at_5": 0.19933,
                    "precision_at_10": 0.09967,
                    "precision_at_20": 0.05,
                    "mrr_at_1": 0.9733333333333334,
                    "mrr_at_3": 0.9805555555555556,
                    "mrr_at_5": 0.9822222222222223,
                    "mrr_at_10": 0.9822222222222223,
                    "mrr_at_20": 0.9824074074074074,
                    "main_score": 0.98585,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 66.45967650413513,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.84526,
                    "ndcg_at_3": 0.88857,
                    "ndcg_at_5": 0.8963,
                    "ndcg_at_10": 0.90236,
                    "ndcg_at_20": 0.90528,
                    "map_at_1": 0.84526,
                    "map_at_3": 0.87833,
                    "map_at_5": 0.88264,
                    "map_at_10": 0.88519,
                    "map_at_20": 0.88599,
                    "recall_at_1": 0.84526,
                    "recall_at_3": 0.91801,
                    "recall_at_5": 0.93671,
                    "recall_at_10": 0.95523,
                    "recall_at_20": 0.96673,
                    "precision_at_1": 0.84526,
                    "precision_at_3": 0.306,
                    "precision_at_5": 0.18734,
                    "precision_at_10": 0.09552,
                    "precision_at_20": 0.04834,
                    "mrr_at_1": 0.8452587164112814,
                    "mrr_at_3": 0.8783329632097114,
                    "mrr_at_5": 0.8826434229032518,
                    "mrr_at_10": 0.8851852028101217,
                    "mrr_at_20": 0.8859938673271502,
                    "main_score": 0.90236,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 55.07985186576843,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.64717,
                    "ndcg_at_3": 0.72375,
                    "ndcg_at_5": 0.73877,
                    "ndcg_at_10": 0.75308,
                    "ndcg_at_20": 0.76234,
                    "map_at_1": 0.64681,
                    "map_at_3": 0.70536,
                    "map_at_5": 0.71371,
                    "map_at_10": 0.71966,
                    "map_at_20": 0.72222,
                    "recall_at_1": 0.64681,
                    "recall_at_3": 0.77647,
                    "recall_at_5": 0.81291,
                    "recall_at_10": 0.85693,
                    "recall_at_20": 0.89341,
                    "precision_at_1": 0.64717,
                    "precision_at_3": 0.25907,
                    "precision_at_5": 0.16277,
                    "precision_at_10": 0.08582,
                    "precision_at_20": 0.04475,
                    "mrr_at_1": 0.647172802536551,
                    "mrr_at_3": 0.7056299297359632,
                    "mrr_at_5": 0.7139544556005692,
                    "mrr_at_10": 0.7198805422977527,
                    "mrr_at_20": 0.722433547103511,
                    "main_score": 0.75308,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 346.1333019733429,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.22127,
                    "ndcg_at_3": 0.28001,
                    "ndcg_at_5": 0.2987,
                    "ndcg_at_10": 0.31886,
                    "ndcg_at_20": 0.33453,
                    "map_at_1": 0.22088,
                    "map_at_3": 0.26538,
                    "map_at_5": 0.27578,
                    "map_at_10": 0.2841,
                    "map_at_20": 0.28844,
                    "recall_at_1": 0.22088,
                    "recall_at_3": 0.32167,
                    "recall_at_5": 0.36698,
                    "recall_at_10": 0.4292,
                    "recall_at_20": 0.49081,
                    "precision_at_1": 0.22127,
                    "precision_at_3": 0.10764,
                    "precision_at_5": 0.07373,
                    "precision_at_10": 0.04322,
                    "precision_at_20": 0.02478,
                    "mrr_at_1": 0.22126717213422414,
                    "mrr_at_3": 0.2659209769036323,
                    "mrr_at_5": 0.27633310812500955,
                    "mrr_at_10": 0.28464633357283764,
                    "mrr_at_20": 0.28893270664653375,
                    "main_score": 0.31886,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 31.854851961135864,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.67264,
                    "ndcg_at_3": 0.74344,
                    "ndcg_at_5": 0.76271,
                    "ndcg_at_10": 0.77946,
                    "ndcg_at_20": 0.78819,
                    "map_at_1": 0.65068,
                    "map_at_3": 0.72278,
                    "map_at_5": 0.73411,
                    "map_at_10": 0.74155,
                    "map_at_20": 0.7441,
                    "recall_at_1": 0.65068,
                    "recall_at_3": 0.7944,
                    "recall_at_5": 0.84025,
                    "recall_at_10": 0.89041,
                    "recall_at_20": 0.92401,
                    "precision_at_1": 0.67264,
                    "precision_at_3": 0.27951,
                    "precision_at_5": 0.17808,
                    "precision_at_10": 0.09458,
                    "precision_at_20": 0.04916,
                    "mrr_at_1": 0.6726361031518625,
                    "mrr_at_3": 0.7314231136580707,
                    "mrr_at_5": 0.7413801337153746,
                    "mrr_at_10": 0.7478251921590007,
                    "mrr_at_20": 0.7500762617938598,
                    "main_score": 0.77946,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 188.32007884979248,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "6e346642246bfb4928c560ee08640dc84d074e8c",
        "task_name": "LEMBWikimQARetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.88667,
                    "ndcg_at_3": 0.91734,
                    "ndcg_at_5": 0.92437,
                    "ndcg_at_10": 0.92979,
                    "ndcg_at_20": 0.93245,
                    "map_at_1": 0.88667,
                    "map_at_3": 0.91056,
                    "map_at_5": 0.91456,
                    "map_at_10": 0.9168,
                    "map_at_20": 0.91761,
                    "recall_at_1": 0.88667,
                    "recall_at_3": 0.93667,
                    "recall_at_5": 0.95333,
                    "recall_at_10": 0.97,
                    "recall_at_20": 0.98,
                    "precision_at_1": 0.88667,
                    "precision_at_3": 0.31222,
                    "precision_at_5": 0.19067,
                    "precision_at_10": 0.097,
                    "precision_at_20": 0.049,
                    "mrr_at_1": 0.8866666666666667,
                    "mrr_at_3": 0.9105555555555557,
                    "mrr_at_5": 0.9145555555555556,
                    "mrr_at_10": 0.9168042328042328,
                    "mrr_at_20": 0.917606371841666,
                    "main_score": 0.92979,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 107.37526679039001,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.848,
                    "ndcg_at_3": 0.81184,
                    "ndcg_at_5": 0.80193,
                    "ndcg_at_10": 0.83119,
                    "ndcg_at_20": 0.85085,
                    "map_at_1": 0.23857,
                    "map_at_3": 0.5089,
                    "map_at_5": 0.64419,
                    "map_at_10": 0.7454,
                    "map_at_20": 0.76928,
                    "recall_at_1": 0.23857,
                    "recall_at_3": 0.54076,
                    "recall_at_5": 0.70512,
                    "recall_at_10": 0.85362,
                    "recall_at_20": 0.91401,
                    "precision_at_1": 0.848,
                    "precision_at_3": 0.732,
                    "precision_at_5": 0.6188,
                    "precision_at_10": 0.404,
                    "precision_at_20": 0.22258,
                    "mrr_at_1": 0.848,
                    "mrr_at_3": 0.8931666666666659,
                    "mrr_at_5": 0.895791666666666,
                    "mrr_at_10": 0.8972371031746024,
                    "mrr_at_20": 0.8978696032102566,
                    "main_score": 0.83119,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1643.1039900779724,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.58896,
                    "ndcg_at_3": 0.6649,
                    "ndcg_at_5": 0.6806,
                    "ndcg_at_10": 0.6951,
                    "ndcg_at_20": 0.70541,
                    "map_at_1": 0.5886,
                    "map_at_3": 0.64674,
                    "map_at_5": 0.6555,
                    "map_at_10": 0.66154,
                    "map_at_20": 0.66438,
                    "recall_at_1": 0.5886,
                    "recall_at_3": 0.71697,
                    "recall_at_5": 0.7549,
                    "recall_at_10": 0.79948,
                    "recall_at_20": 0.84017,
                    "precision_at_1": 0.58896,
                    "precision_at_3": 0.23927,
                    "precision_at_5": 0.15118,
                    "precision_at_10": 0.08008,
                    "precision_at_20": 0.04208,
                    "mrr_at_1": 0.5889554342082085,
                    "mrr_at_3": 0.6469477227800228,
                    "mrr_at_5": 0.655696475055291,
                    "mrr_at_10": 0.6616955379219792,
                    "mrr_at_20": 0.6645387374330166,
                    "main_score": 0.6951,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 122.60795569419861,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.39968,
                    "ndcg_at_3": 0.45963,
                    "ndcg_at_5": 0.47527,
                    "ndcg_at_10": 0.4921,
                    "ndcg_at_20": 0.50407,
                    "map_at_1": 0.39964,
                    "map_at_3": 0.44509,
                    "map_at_5": 0.45375,
                    "map_at_10": 0.46076,
                    "map_at_20": 0.46404,
                    "recall_at_1": 0.39964,
                    "recall_at_3": 0.50162,
                    "recall_at_5": 0.53961,
                    "recall_at_10": 0.59133,
                    "recall_at_20": 0.63861,
                    "precision_at_1": 0.39968,
                    "precision_at_3": 0.16722,
                    "precision_at_5": 0.10793,
                    "precision_at_10": 0.05915,
                    "precision_at_20": 0.03194,
                    "mrr_at_1": 0.3996805749650629,
                    "mrr_at_3": 0.4451254408730971,
                    "mrr_at_5": 0.45379982697811105,
                    "mrr_at_10": 0.4608137416143065,
                    "mrr_at_20": 0.46410640332811587,
                    "main_score": 0.4921,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 40.83069682121277,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.51391,
                    "ndcg_at_3": 0.57568,
                    "ndcg_at_5": 0.59191,
                    "ndcg_at_10": 0.60704,
                    "ndcg_at_20": 0.61814,
                    "map_at_1": 0.51383,
                    "map_at_3": 0.56072,
                    "map_at_5": 0.56975,
                    "map_at_10": 0.57604,
                    "map_at_20": 0.57908,
                    "recall_at_1": 0.51383,
                    "recall_at_3": 0.61864,
                    "recall_at_5": 0.65801,
                    "recall_at_10": 0.70447,
                    "recall_at_20": 0.74834,
                    "precision_at_1": 0.51391,
                    "precision_at_3": 0.20631,
                    "precision_at_5": 0.13167,
                    "precision_at_10": 0.07051,
                    "precision_at_20": 0.03747,
                    "mrr_at_1": 0.5139548812138152,
                    "mrr_at_3": 0.5609103613495764,
                    "mrr_at_5": 0.5699401078059595,
                    "mrr_at_10": 0.5762614278425908,
                    "mrr_at_20": 0.5793114650714735,
                    "main_score": 0.60704,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 71.44031095504761,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.67334,
                    "ndcg_at_3": 0.76713,
                    "ndcg_at_5": 0.78547,
                    "ndcg_at_10": 0.79747,
                    "ndcg_at_20": 0.80463,
                    "map_at_1": 0.67097,
                    "map_at_3": 0.74438,
                    "map_at_5": 0.75497,
                    "map_at_10": 0.76013,
                    "map_at_20": 0.76217,
                    "recall_at_1": 0.67097,
                    "recall_at_3": 0.83008,
                    "recall_at_5": 0.87434,
                    "recall_at_10": 0.91096,
                    "recall_at_20": 0.93888,
                    "precision_at_1": 0.67334,
                    "precision_at_3": 0.27854,
                    "precision_at_5": 0.1764,
                    "precision_at_10": 0.09199,
                    "precision_at_20": 0.04742,
                    "mrr_at_1": 0.6733403582718651,
                    "mrr_at_3": 0.7467509659290483,
                    "mrr_at_5": 0.7564453811029158,
                    "mrr_at_10": 0.761101911786844,
                    "mrr_at_20": 0.7630486477208797,
                    "main_score": 0.79747,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1147.7612445354462,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.71675,
                    "ndcg_at_3": 0.75637,
                    "ndcg_at_5": 0.76395,
                    "ndcg_at_10": 0.76985,
                    "ndcg_at_20": 0.77383,
                    "map_at_1": 0.71675,
                    "map_at_3": 0.74714,
                    "map_at_5": 0.75136,
                    "map_at_10": 0.75381,
                    "map_at_20": 0.75491,
                    "recall_at_1": 0.71675,
                    "recall_at_3": 0.78285,
                    "recall_at_5": 0.80125,
                    "recall_at_10": 0.81935,
                    "recall_at_20": 0.83505,
                    "precision_at_1": 0.71675,
                    "precision_at_3": 0.26095,
                    "precision_at_5": 0.16025,
                    "precision_at_10": 0.08193,
                    "precision_at_20": 0.04175,
                    "mrr_at_1": 0.71675,
                    "mrr_at_3": 0.7471416666666701,
                    "mrr_at_5": 0.7513566666666728,
                    "mrr_at_10": 0.7538135317460372,
                    "mrr_at_20": 0.7549100455682595,
                    "main_score": 0.76985,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 157.9238007068634,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "2e643e7363944af1c33a652d1c87320d0871c4e4",
        "task_name": "NarrativeQAChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.58359,
                    "ndcg_at_3": 0.65702,
                    "ndcg_at_5": 0.67316,
                    "ndcg_at_10": 0.68745,
                    "map_at_1": 0.58359,
                    "map_at_3": 0.63953,
                    "map_at_5": 0.64848,
                    "map_at_10": 0.65437,
                    "recall_at_1": 0.58359,
                    "recall_at_3": 0.7074,
                    "recall_at_5": 0.74661,
                    "recall_at_10": 0.79085,
                    "precision_at_1": 0.58359,
                    "precision_at_3": 0.2358,
                    "precision_at_5": 0.14932,
                    "precision_at_10": 0.07908,
                    "mrr_at_1": 0.5835938240030312,
                    "mrr_at_3": 0.6395282750781436,
                    "mrr_at_5": 0.6484844179217523,
                    "mrr_at_10": 0.6543716950011316,
                    "main_score": 0.68745,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 654.7977995872498,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.64761,
                    "ndcg_at_3": 0.72432,
                    "ndcg_at_5": 0.73925,
                    "ndcg_at_10": 0.75349,
                    "ndcg_at_20": 0.76282,
                    "map_at_1": 0.64725,
                    "map_at_3": 0.7059,
                    "map_at_5": 0.7142,
                    "map_at_10": 0.72012,
                    "map_at_20": 0.7227,
                    "recall_at_1": 0.64725,
                    "recall_at_3": 0.77714,
                    "recall_at_5": 0.81336,
                    "recall_at_10": 0.85713,
                    "recall_at_20": 0.89389,
                    "precision_at_1": 0.64761,
                    "precision_at_3": 0.25929,
                    "precision_at_5": 0.16286,
                    "precision_at_10": 0.08584,
                    "precision_at_20": 0.04477,
                    "mrr_at_1": 0.6476131759732253,
                    "mrr_at_3": 0.7061632708981578,
                    "mrr_at_5": 0.7144408235961853,
                    "mrr_at_10": 0.7203459401297175,
                    "mrr_at_20": 0.7229139618647081,
                    "main_score": 0.75349,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 168.10432744026184,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.67214,
                    "ndcg_at_3": 0.74055,
                    "ndcg_at_5": 0.75372,
                    "ndcg_at_10": 0.76575,
                    "ndcg_at_20": 0.77398,
                    "map_at_1": 0.6717,
                    "map_at_3": 0.72431,
                    "map_at_5": 0.73164,
                    "map_at_10": 0.73668,
                    "map_at_20": 0.73895,
                    "recall_at_1": 0.6717,
                    "recall_at_3": 0.78707,
                    "recall_at_5": 0.81896,
                    "recall_at_10": 0.8558,
                    "recall_at_20": 0.88825,
                    "precision_at_1": 0.67214,
                    "precision_at_3": 0.26266,
                    "precision_at_5": 0.16404,
                    "precision_at_10": 0.08573,
                    "precision_at_20": 0.0445,
                    "mrr_at_1": 0.6721374045801527,
                    "mrr_at_3": 0.7245106674495904,
                    "mrr_at_5": 0.7318168917596372,
                    "mrr_at_10": 0.7368251055560193,
                    "mrr_at_20": 0.739085149068587,
                    "main_score": 0.76575,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 312.79744005203247,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.61013,
                    "ndcg_at_3": 0.68402,
                    "ndcg_at_5": 0.69858,
                    "ndcg_at_10": 0.71211,
                    "ndcg_at_20": 0.72101,
                    "map_at_1": 0.60983,
                    "map_at_3": 0.66649,
                    "map_at_5": 0.67456,
                    "map_at_10": 0.6802,
                    "map_at_20": 0.68265,
                    "recall_at_1": 0.60983,
                    "recall_at_3": 0.73431,
                    "recall_at_5": 0.76967,
                    "recall_at_10": 0.81123,
                    "recall_at_20": 0.8463,
                    "precision_at_1": 0.61013,
                    "precision_at_3": 0.24504,
                    "precision_at_5": 0.15412,
                    "precision_at_10": 0.08124,
                    "precision_at_20": 0.04239,
                    "mrr_at_1": 0.6101291837933059,
                    "mrr_at_3": 0.6666373067136376,
                    "mrr_at_5": 0.6746922098257989,
                    "mrr_at_10": 0.6803278062056717,
                    "mrr_at_20": 0.6827725599941168,
                    "main_score": 0.71211,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 274.555148601532,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.34259,
                    "ndcg_at_3": 0.3463,
                    "ndcg_at_5": 0.36269,
                    "ndcg_at_10": 0.39144,
                    "ndcg_at_20": 0.41895,
                    "map_at_1": 0.22072,
                    "map_at_3": 0.29356,
                    "map_at_5": 0.31233,
                    "map_at_10": 0.32934,
                    "map_at_20": 0.33923,
                    "recall_at_1": 0.22072,
                    "recall_at_3": 0.34594,
                    "recall_at_5": 0.40045,
                    "recall_at_10": 0.48469,
                    "recall_at_20": 0.57814,
                    "precision_at_1": 0.34259,
                    "precision_at_3": 0.19722,
                    "precision_at_5": 0.14169,
                    "precision_at_10": 0.0881,
                    "precision_at_20": 0.05315,
                    "mrr_at_1": 0.3425856464116029,
                    "mrr_at_3": 0.3971826289905805,
                    "mrr_at_5": 0.40893556722513974,
                    "mrr_at_10": 0.41955131640052795,
                    "mrr_at_20": 0.4254342064433115,
                    "main_score": 0.39144,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 705.0123841762543,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.19132,
                    "ndcg_at_3": 0.28946,
                    "ndcg_at_5": 0.32995,
                    "ndcg_at_10": 0.37427,
                    "ndcg_at_20": 0.39935,
                    "map_at_1": 0.19132,
                    "map_at_3": 0.26494,
                    "map_at_5": 0.28727,
                    "map_at_10": 0.30564,
                    "map_at_20": 0.31258,
                    "recall_at_1": 0.19132,
                    "recall_at_3": 0.3606,
                    "recall_at_5": 0.45946,
                    "recall_at_10": 0.59602,
                    "recall_at_20": 0.69488,
                    "precision_at_1": 0.19132,
                    "precision_at_3": 0.1202,
                    "precision_at_5": 0.09189,
                    "precision_at_10": 0.0596,
                    "precision_at_20": 0.03474,
                    "mrr_at_1": 0.19914651493598862,
                    "mrr_at_3": 0.2682550972024654,
                    "mrr_at_5": 0.28959222380274935,
                    "mrr_at_10": 0.3083988123461802,
                    "mrr_at_20": 0.3152325316086103,
                    "main_score": 0.37427,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 67.30837655067444,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.758,
                    "ndcg_at_3": 0.81812,
                    "ndcg_at_5": 0.82977,
                    "ndcg_at_10": 0.83989,
                    "ndcg_at_20": 0.84618,
                    "map_at_1": 0.75774,
                    "map_at_3": 0.80378,
                    "map_at_5": 0.81027,
                    "map_at_10": 0.81447,
                    "map_at_20": 0.81622,
                    "recall_at_1": 0.75774,
                    "recall_at_3": 0.85882,
                    "recall_at_5": 0.88706,
                    "recall_at_10": 0.91805,
                    "recall_at_20": 0.94263,
                    "precision_at_1": 0.758,
                    "precision_at_3": 0.28656,
                    "precision_at_5": 0.17771,
                    "precision_at_10": 0.09208,
                    "precision_at_20": 0.04736,
                    "mrr_at_1": 0.7580355360351367,
                    "mrr_at_3": 0.804179144207092,
                    "mrr_at_5": 0.8106994077327504,
                    "mrr_at_10": 0.8149567286820268,
                    "mrr_at_20": 0.8166833665808396,
                    "main_score": 0.83989,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 37.29082274436951,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.65198,
                    "ndcg_at_3": 0.74488,
                    "ndcg_at_5": 0.76477,
                    "ndcg_at_10": 0.78083,
                    "ndcg_at_20": 0.78931,
                    "map_at_1": 0.65044,
                    "map_at_3": 0.7218,
                    "map_at_5": 0.73295,
                    "map_at_10": 0.73976,
                    "map_at_20": 0.74219,
                    "recall_at_1": 0.65044,
                    "recall_at_3": 0.80927,
                    "recall_at_5": 0.85736,
                    "recall_at_10": 0.90622,
                    "recall_at_20": 0.9389,
                    "precision_at_1": 0.65198,
                    "precision_at_3": 0.27109,
                    "precision_at_5": 0.17256,
                    "precision_at_10": 0.09149,
                    "precision_at_20": 0.04758,
                    "mrr_at_1": 0.6520156144433601,
                    "mrr_at_3": 0.723588068963793,
                    "mrr_at_5": 0.7346964692340493,
                    "mrr_at_10": 0.7412970092573802,
                    "mrr_at_20": 0.7435935434806504,
                    "main_score": 0.78083,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 54.23808836936951,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.271,
                    "ndcg_at_3": 0.35859,
                    "ndcg_at_5": 0.39,
                    "ndcg_at_10": 0.4158,
                    "ndcg_at_20": 0.43681,
                    "map_at_1": 0.271,
                    "map_at_3": 0.33733,
                    "map_at_5": 0.35458,
                    "map_at_10": 0.36518,
                    "map_at_20": 0.37097,
                    "recall_at_1": 0.271,
                    "recall_at_3": 0.42,
                    "recall_at_5": 0.497,
                    "recall_at_10": 0.577,
                    "recall_at_20": 0.66,
                    "precision_at_1": 0.271,
                    "precision_at_3": 0.14,
                    "precision_at_5": 0.0994,
                    "precision_at_10": 0.0577,
                    "precision_at_20": 0.033,
                    "mrr_at_1": 0.271,
                    "mrr_at_3": 0.33733333333333326,
                    "mrr_at_5": 0.354583333333333,
                    "mrr_at_10": 0.36518253968253933,
                    "mrr_at_20": 0.3709673859164566,
                    "main_score": 0.4158,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 51.70998525619507,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.30093,
                    "ndcg_at_3": 0.27587,
                    "ndcg_at_5": 0.28413,
                    "ndcg_at_10": 0.31063,
                    "ndcg_at_20": 0.33218,
                    "map_at_1": 0.15191,
                    "map_at_3": 0.20871,
                    "map_at_5": 0.22565,
                    "map_at_10": 0.24247,
                    "map_at_20": 0.25042,
                    "recall_at_1": 0.15191,
                    "recall_at_3": 0.24818,
                    "recall_at_5": 0.2953,
                    "recall_at_10": 0.37379,
                    "recall_at_20": 0.44038,
                    "precision_at_1": 0.30093,
                    "precision_at_3": 0.18261,
                    "precision_at_5": 0.13519,
                    "precision_at_10": 0.08889,
                    "precision_at_20": 0.0534,
                    "mrr_at_1": 0.30092592592592593,
                    "mrr_at_3": 0.3554526748971195,
                    "mrr_at_5": 0.3693415637860083,
                    "mrr_at_10": 0.3817772633744854,
                    "mrr_at_20": 0.38637661634683895,
                    "main_score": 0.31063,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 202.818297624588,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.43667,
                    "ndcg_at_3": 0.47508,
                    "ndcg_at_5": 0.50363,
                    "ndcg_at_10": 0.52771,
                    "ndcg_at_20": 0.55088,
                    "map_at_1": 0.41667,
                    "map_at_3": 0.45773,
                    "map_at_5": 0.47476,
                    "map_at_10": 0.48572,
                    "map_at_20": 0.49321,
                    "recall_at_1": 0.41667,
                    "recall_at_3": 0.50389,
                    "recall_at_5": 0.57233,
                    "recall_at_10": 0.64117,
                    "recall_at_20": 0.72528,
                    "precision_at_1": 0.43667,
                    "precision_at_3": 0.17889,
                    "precision_at_5": 0.124,
                    "precision_at_10": 0.071,
                    "precision_at_20": 0.041,
                    "mrr_at_1": 0.43666666666666665,
                    "mrr_at_3": 0.4777777777777778,
                    "mrr_at_5": 0.4929444444444445,
                    "mrr_at_10": 0.5023306878306879,
                    "mrr_at_20": 0.5083752648423703,
                    "main_score": 0.52771,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 33.890605211257935,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.097,
                    "ndcg_at_3": 0.0771,
                    "ndcg_at_5": 0.06805,
                    "ndcg_at_10": 0.08458,
                    "map_at_1": 0.01965,
                    "map_at_3": 0.03313,
                    "map_at_5": 0.03836,
                    "map_at_10": 0.0446,
                    "recall_at_1": 0.01965,
                    "recall_at_3": 0.04328,
                    "recall_at_5": 0.06043,
                    "recall_at_10": 0.09093,
                    "precision_at_1": 0.097,
                    "precision_at_3": 0.071,
                    "precision_at_5": 0.0594,
                    "precision_at_10": 0.0447,
                    "mrr_at_1": 0.097,
                    "mrr_at_3": 0.13249999999999995,
                    "mrr_at_5": 0.14679999999999999,
                    "mrr_at_10": 0.15836904761904758,
                    "main_score": 0.08458,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 125.65823531150818,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.23056,
                    "ndcg_at_3": 0.23618,
                    "ndcg_at_5": 0.25241,
                    "ndcg_at_10": 0.27806,
                    "ndcg_at_20": 0.30355,
                    "map_at_1": 0.14218,
                    "map_at_3": 0.19431,
                    "map_at_5": 0.20931,
                    "map_at_10": 0.22335,
                    "map_at_20": 0.23172,
                    "recall_at_1": 0.14218,
                    "recall_at_3": 0.23843,
                    "recall_at_5": 0.28813,
                    "recall_at_10": 0.36318,
                    "recall_at_20": 0.45088,
                    "precision_at_1": 0.23056,
                    "precision_at_3": 0.13803,
                    "precision_at_5": 0.10218,
                    "precision_at_10": 0.06569,
                    "precision_at_20": 0.04124,
                    "mrr_at_1": 0.23055763940985247,
                    "mrr_at_3": 0.27915312161373695,
                    "mrr_at_5": 0.2920188380428446,
                    "mrr_at_10": 0.30229928513874516,
                    "mrr_at_20": 0.3083708068629417,
                    "main_score": 0.27806,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 438.55598187446594,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.111,
                    "ndcg_at_3": 0.1007,
                    "ndcg_at_5": 0.09152,
                    "ndcg_at_10": 0.1138,
                    "ndcg_at_20": 0.13652,
                    "map_at_1": 0.02268,
                    "map_at_3": 0.04311,
                    "map_at_5": 0.05298,
                    "map_at_10": 0.0626,
                    "map_at_20": 0.06963,
                    "recall_at_1": 0.02268,
                    "recall_at_3": 0.05953,
                    "recall_at_5": 0.08533,
                    "recall_at_10": 0.12652,
                    "recall_at_20": 0.18028,
                    "precision_at_1": 0.111,
                    "precision_at_3": 0.09733,
                    "precision_at_5": 0.0838,
                    "precision_at_10": 0.0622,
                    "precision_at_20": 0.04425,
                    "mrr_at_1": 0.111,
                    "mrr_at_3": 0.1666666666666667,
                    "mrr_at_5": 0.18191666666666673,
                    "mrr_at_10": 0.19480039682539682,
                    "mrr_at_20": 0.202370155141556,
                    "main_score": 0.1138,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 134.92849159240723,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.95587,
                    "ndcg_at_3": 0.97329,
                    "ndcg_at_5": 0.97516,
                    "ndcg_at_10": 0.97653,
                    "ndcg_at_20": 0.97718,
                    "map_at_1": 0.9558,
                    "map_at_3": 0.96937,
                    "map_at_5": 0.97042,
                    "map_at_10": 0.97099,
                    "map_at_20": 0.97117,
                    "recall_at_1": 0.9558,
                    "recall_at_3": 0.98448,
                    "recall_at_5": 0.98898,
                    "recall_at_10": 0.99316,
                    "recall_at_20": 0.9957,
                    "precision_at_1": 0.95587,
                    "precision_at_3": 0.3282,
                    "precision_at_5": 0.19782,
                    "precision_at_10": 0.09933,
                    "precision_at_20": 0.04979,
                    "mrr_at_1": 0.9558692554328465,
                    "mrr_at_3": 0.9693919961999758,
                    "mrr_at_5": 0.9704384871155448,
                    "mrr_at_10": 0.971011759857726,
                    "mrr_at_20": 0.9711965969919298,
                    "main_score": 0.97653,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 63.417603969573975,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.49506,
                    "ndcg_at_3": 0.57292,
                    "ndcg_at_5": 0.59389,
                    "ndcg_at_10": 0.61361,
                    "ndcg_at_20": 0.62715,
                    "map_at_1": 0.49483,
                    "map_at_3": 0.55384,
                    "map_at_5": 0.56549,
                    "map_at_10": 0.5737,
                    "map_at_20": 0.57744,
                    "recall_at_1": 0.49483,
                    "recall_at_3": 0.62777,
                    "recall_at_5": 0.67866,
                    "recall_at_10": 0.7393,
                    "recall_at_20": 0.79267,
                    "precision_at_1": 0.49506,
                    "precision_at_3": 0.20953,
                    "precision_at_5": 0.13592,
                    "precision_at_10": 0.07404,
                    "precision_at_20": 0.0397,
                    "mrr_at_1": 0.49505966893365844,
                    "mrr_at_3": 0.5540709611189604,
                    "mrr_at_5": 0.5657240472218799,
                    "mrr_at_10": 0.5739140386468263,
                    "mrr_at_20": 0.5776464394567372,
                    "main_score": 0.61361,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 59.721951723098755,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.76462,
                    "ndcg_at_3": 0.82472,
                    "ndcg_at_5": 0.83715,
                    "ndcg_at_10": 0.8475,
                    "ndcg_at_20": 0.85347,
                    "map_at_1": 0.76419,
                    "map_at_3": 0.81026,
                    "map_at_5": 0.81722,
                    "map_at_10": 0.82156,
                    "map_at_20": 0.82325,
                    "recall_at_1": 0.76419,
                    "recall_at_3": 0.86552,
                    "recall_at_5": 0.89568,
                    "recall_at_10": 0.92718,
                    "recall_at_20": 0.95032,
                    "precision_at_1": 0.76462,
                    "precision_at_3": 0.28899,
                    "precision_at_5": 0.17952,
                    "precision_at_10": 0.09304,
                    "precision_at_20": 0.04777,
                    "mrr_at_1": 0.7646236773807147,
                    "mrr_at_3": 0.810813868370265,
                    "mrr_at_5": 0.8177813269448351,
                    "mrr_at_10": 0.8221539166009155,
                    "mrr_at_20": 0.8238085536911753,
                    "main_score": 0.8475,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 50.77182698249817,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.65187,
                    "ndcg_at_3": 0.74581,
                    "ndcg_at_5": 0.76707,
                    "ndcg_at_10": 0.78274,
                    "ndcg_at_20": 0.79192,
                    "map_at_1": 0.65158,
                    "map_at_3": 0.72309,
                    "map_at_5": 0.73493,
                    "map_at_10": 0.74149,
                    "map_at_20": 0.74405,
                    "recall_at_1": 0.65158,
                    "recall_at_3": 0.81103,
                    "recall_at_5": 0.86255,
                    "recall_at_10": 0.91055,
                    "recall_at_20": 0.94649,
                    "precision_at_1": 0.65187,
                    "precision_at_3": 0.27064,
                    "precision_at_5": 0.17273,
                    "precision_at_10": 0.0912,
                    "precision_at_20": 0.04742,
                    "mrr_at_1": 0.6518670601822149,
                    "mrr_at_3": 0.7233414602848618,
                    "mrr_at_5": 0.7351581547542654,
                    "mrr_at_10": 0.7417019292853374,
                    "mrr_at_20": 0.7442524746513319,
                    "main_score": 0.78274,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 55.95242404937744,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.61632,
                    "ndcg_at_3": 0.71638,
                    "ndcg_at_5": 0.73868,
                    "ndcg_at_10": 0.75638,
                    "ndcg_at_20": 0.76645,
                    "map_at_1": 0.61609,
                    "map_at_3": 0.69209,
                    "map_at_5": 0.7045,
                    "map_at_10": 0.71188,
                    "map_at_20": 0.71468,
                    "recall_at_1": 0.61609,
                    "recall_at_3": 0.78626,
                    "recall_at_5": 0.84025,
                    "recall_at_10": 0.89461,
                    "recall_at_20": 0.93415,
                    "precision_at_1": 0.61632,
                    "precision_at_3": 0.26227,
                    "precision_at_5": 0.16821,
                    "precision_at_10": 0.08956,
                    "precision_at_20": 0.04678,
                    "mrr_at_1": 0.6163223405620428,
                    "mrr_at_3": 0.692287950725003,
                    "mrr_at_5": 0.7047093545489557,
                    "mrr_at_10": 0.7120881529822272,
                    "mrr_at_20": 0.7148724918350899,
                    "main_score": 0.75638,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 56.06713938713074,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "2e643e7363944af1c33a652d1c87320d0871c4e4",
        "task_name": "NarrativeQAChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.32566,
                    "ndcg_at_3": 0.41281,
                    "ndcg_at_5": 0.44087,
                    "ndcg_at_10": 0.46785,
                    "ndcg_at_20": 0.48954,
                    "map_at_1": 0.32566,
                    "map_at_3": 0.39143,
                    "map_at_5": 0.40701,
                    "map_at_10": 0.41824,
                    "map_at_20": 0.42423,
                    "recall_at_1": 0.32566,
                    "recall_at_3": 0.47466,
                    "recall_at_5": 0.54277,
                    "recall_at_10": 0.62565,
                    "recall_at_20": 0.71119,
                    "precision_at_1": 0.32566,
                    "precision_at_3": 0.15822,
                    "precision_at_5": 0.10855,
                    "precision_at_10": 0.06257,
                    "precision_at_20": 0.03556,
                    "mrr_at_1": 0.3256606990622336,
                    "mrr_at_3": 0.3914306463326102,
                    "mrr_at_5": 0.4070079883805368,
                    "mrr_at_10": 0.4182440823887258,
                    "mrr_at_20": 0.4242293698378164,
                    "main_score": 0.46785,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 374.6802406311035,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.83429,
                    "ndcg_at_3": 0.89408,
                    "ndcg_at_5": 0.90201,
                    "ndcg_at_10": 0.90761,
                    "ndcg_at_20": 0.91037,
                    "map_at_1": 0.83364,
                    "map_at_3": 0.88009,
                    "map_at_5": 0.88456,
                    "map_at_10": 0.88691,
                    "map_at_20": 0.88771,
                    "recall_at_1": 0.83364,
                    "recall_at_3": 0.93381,
                    "recall_at_5": 0.95289,
                    "recall_at_10": 0.96996,
                    "recall_at_20": 0.98061,
                    "precision_at_1": 0.83429,
                    "precision_at_3": 0.31186,
                    "precision_at_5": 0.191,
                    "precision_at_10": 0.09726,
                    "precision_at_20": 0.04921,
                    "mrr_at_1": 0.8342924251321198,
                    "mrr_at_3": 0.880402231356419,
                    "mrr_at_5": 0.8848355842630575,
                    "mrr_at_10": 0.8871733588718267,
                    "mrr_at_20": 0.8879182535179038,
                    "main_score": 0.90761,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1454.4624631404877,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.74347,
                    "ndcg_at_3": 0.68106,
                    "ndcg_at_5": 0.65955,
                    "ndcg_at_10": 0.66064,
                    "ndcg_at_20": 0.6889,
                    "map_at_1": 0.20206,
                    "map_at_3": 0.38765,
                    "map_at_5": 0.47446,
                    "map_at_10": 0.55274,
                    "map_at_20": 0.58153,
                    "recall_at_1": 0.20206,
                    "recall_at_3": 0.4143,
                    "recall_at_5": 0.52798,
                    "recall_at_10": 0.65714,
                    "recall_at_20": 0.74131,
                    "precision_at_1": 0.74347,
                    "precision_at_3": 0.60112,
                    "precision_at_5": 0.49939,
                    "precision_at_10": 0.33755,
                    "precision_at_20": 0.19635,
                    "mrr_at_1": 0.7434683499912327,
                    "mrr_at_3": 0.7864720322637239,
                    "mrr_at_5": 0.7933543748904156,
                    "mrr_at_10": 0.7974456843933513,
                    "mrr_at_20": 0.7991400186808069,
                    "main_score": 0.66064,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1923.5048763751984,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.31424,
                    "ndcg_at_3": 0.27388,
                    "ndcg_at_5": 0.26247,
                    "ndcg_at_10": 0.24273,
                    "ndcg_at_20": 0.22965,
                    "map_at_1": 0.0324,
                    "map_at_3": 0.05273,
                    "map_at_5": 0.06238,
                    "map_at_10": 0.07487,
                    "map_at_20": 0.08443,
                    "recall_at_1": 0.0324,
                    "recall_at_3": 0.06056,
                    "recall_at_5": 0.08143,
                    "recall_at_10": 0.11551,
                    "recall_at_20": 0.15017,
                    "precision_at_1": 0.32508,
                    "precision_at_3": 0.25903,
                    "precision_at_5": 0.23591,
                    "precision_at_10": 0.18916,
                    "precision_at_20": 0.14458,
                    "mrr_at_1": 0.32507739938080493,
                    "mrr_at_3": 0.3885448916408668,
                    "mrr_at_5": 0.40665634674922596,
                    "mrr_at_10": 0.41703400658509016,
                    "mrr_at_20": 0.42163974130912857,
                    "main_score": 0.24273,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 27.00623345375061,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.233,
                    "ndcg_at_3": 0.29072,
                    "ndcg_at_5": 0.30863,
                    "ndcg_at_10": 0.32856,
                    "ndcg_at_20": 0.34811,
                    "map_at_1": 0.233,
                    "map_at_3": 0.27617,
                    "map_at_5": 0.28622,
                    "map_at_10": 0.29438,
                    "map_at_20": 0.29964,
                    "recall_at_1": 0.233,
                    "recall_at_3": 0.333,
                    "recall_at_5": 0.376,
                    "recall_at_10": 0.438,
                    "recall_at_20": 0.516,
                    "precision_at_1": 0.233,
                    "precision_at_3": 0.111,
                    "precision_at_5": 0.0752,
                    "precision_at_10": 0.0438,
                    "precision_at_20": 0.0258,
                    "mrr_at_1": 0.233,
                    "mrr_at_3": 0.2761666666666667,
                    "mrr_at_5": 0.28621666666666673,
                    "mrr_at_10": 0.2943761904761905,
                    "mrr_at_20": 0.2996433102801911,
                    "main_score": 0.32856,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 942.9844303131104,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.231,
                    "ndcg_at_3": 0.28783,
                    "ndcg_at_5": 0.30574,
                    "ndcg_at_10": 0.32685,
                    "ndcg_at_20": 0.34613,
                    "map_at_1": 0.231,
                    "map_at_3": 0.27333,
                    "map_at_5": 0.28338,
                    "map_at_10": 0.29196,
                    "map_at_20": 0.29714,
                    "recall_at_1": 0.231,
                    "recall_at_3": 0.33,
                    "recall_at_5": 0.373,
                    "recall_at_10": 0.439,
                    "recall_at_20": 0.516,
                    "precision_at_1": 0.231,
                    "precision_at_3": 0.11,
                    "precision_at_5": 0.0746,
                    "precision_at_10": 0.0439,
                    "precision_at_20": 0.0258,
                    "mrr_at_1": 0.231,
                    "mrr_at_3": 0.2733333333333335,
                    "mrr_at_5": 0.2833833333333334,
                    "mrr_at_10": 0.29195674603174604,
                    "mrr_at_20": 0.2971418163492853,
                    "main_score": 0.32685,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 65.64487266540527,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.13016,
                    "ndcg_at_3": 0.20582,
                    "ndcg_at_5": 0.23808,
                    "ndcg_at_10": 0.27732,
                    "ndcg_at_20": 0.3039,
                    "map_at_1": 0.13016,
                    "map_at_3": 0.18658,
                    "map_at_5": 0.2045,
                    "map_at_10": 0.22066,
                    "map_at_20": 0.22793,
                    "recall_at_1": 0.13016,
                    "recall_at_3": 0.26174,
                    "recall_at_5": 0.33997,
                    "recall_at_10": 0.46159,
                    "recall_at_20": 0.56686,
                    "precision_at_1": 0.13016,
                    "precision_at_3": 0.08725,
                    "precision_at_5": 0.06799,
                    "precision_at_10": 0.04616,
                    "precision_at_20": 0.02834,
                    "mrr_at_1": 0.13229018492176386,
                    "mrr_at_3": 0.18729255571360853,
                    "mrr_at_5": 0.20532242769084855,
                    "mrr_at_10": 0.22134898055950675,
                    "mrr_at_20": 0.22862922935535765,
                    "main_score": 0.27732,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 42.6008734703064,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.271,
                    "ndcg_at_3": 0.35859,
                    "ndcg_at_5": 0.39,
                    "ndcg_at_10": 0.4158,
                    "ndcg_at_20": 0.43681,
                    "map_at_1": 0.271,
                    "map_at_3": 0.33733,
                    "map_at_5": 0.35458,
                    "map_at_10": 0.36518,
                    "map_at_20": 0.37097,
                    "recall_at_1": 0.271,
                    "recall_at_3": 0.42,
                    "recall_at_5": 0.497,
                    "recall_at_10": 0.577,
                    "recall_at_20": 0.66,
                    "precision_at_1": 0.271,
                    "precision_at_3": 0.14,
                    "precision_at_5": 0.0994,
                    "precision_at_10": 0.0577,
                    "precision_at_20": 0.033,
                    "mrr_at_1": 0.271,
                    "mrr_at_3": 0.33733333333333326,
                    "mrr_at_5": 0.354583333333333,
                    "mrr_at_10": 0.36518253968253933,
                    "mrr_at_20": 0.3709673859164566,
                    "main_score": 0.4158,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 61.58500671386719,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.24631,
                    "ndcg_at_3": 0.25355,
                    "ndcg_at_5": 0.269,
                    "ndcg_at_10": 0.29551,
                    "ndcg_at_20": 0.32189,
                    "map_at_1": 0.15275,
                    "map_at_3": 0.20909,
                    "map_at_5": 0.22431,
                    "map_at_10": 0.2389,
                    "map_at_20": 0.24763,
                    "recall_at_1": 0.15275,
                    "recall_at_3": 0.25716,
                    "recall_at_5": 0.30628,
                    "recall_at_10": 0.38331,
                    "recall_at_20": 0.47454,
                    "precision_at_1": 0.24631,
                    "precision_at_3": 0.1477,
                    "precision_at_5": 0.10818,
                    "precision_at_10": 0.06959,
                    "precision_at_20": 0.04342,
                    "mrr_at_1": 0.2463115778944736,
                    "mrr_at_3": 0.297616070684338,
                    "mrr_at_5": 0.30976910894390325,
                    "mrr_at_10": 0.32034526488765075,
                    "mrr_at_20": 0.32645648218656215,
                    "main_score": 0.29551,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 324.9906015396118,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.19203,
                    "ndcg_at_3": 0.28973,
                    "ndcg_at_5": 0.33021,
                    "ndcg_at_10": 0.37478,
                    "ndcg_at_20": 0.39987,
                    "map_at_1": 0.19203,
                    "map_at_3": 0.26529,
                    "map_at_5": 0.28762,
                    "map_at_10": 0.30612,
                    "map_at_20": 0.31305,
                    "recall_at_1": 0.19203,
                    "recall_at_3": 0.3606,
                    "recall_at_5": 0.45946,
                    "recall_at_10": 0.59673,
                    "recall_at_20": 0.69559,
                    "precision_at_1": 0.19203,
                    "precision_at_3": 0.1202,
                    "precision_at_5": 0.09189,
                    "precision_at_10": 0.05967,
                    "precision_at_20": 0.03478,
                    "mrr_at_1": 0.19914651493598862,
                    "mrr_at_3": 0.2683736367946891,
                    "mrr_at_5": 0.2897107633949732,
                    "mrr_at_10": 0.3086339158707574,
                    "mrr_at_20": 0.3154681190498764,
                    "main_score": 0.37478,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 21.008511066436768,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.83127,
                    "ndcg_at_3": 0.89318,
                    "ndcg_at_5": 0.90141,
                    "ndcg_at_10": 0.90676,
                    "ndcg_at_20": 0.90968,
                    "map_at_1": 0.83062,
                    "map_at_3": 0.87867,
                    "map_at_5": 0.88331,
                    "map_at_10": 0.88558,
                    "map_at_20": 0.88642,
                    "recall_at_1": 0.83062,
                    "recall_at_3": 0.9344,
                    "recall_at_5": 0.95418,
                    "recall_at_10": 0.97042,
                    "recall_at_20": 0.9817,
                    "precision_at_1": 0.83127,
                    "precision_at_3": 0.31208,
                    "precision_at_5": 0.19129,
                    "precision_at_10": 0.09733,
                    "precision_at_20": 0.04927,
                    "mrr_at_1": 0.83126834997064,
                    "mrr_at_3": 0.8789880602857602,
                    "mrr_at_5": 0.8835814249363803,
                    "mrr_at_10": 0.8858204592269427,
                    "mrr_at_20": 0.8866139350048324,
                    "main_score": 0.90676,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 85.62385177612305,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.51175,
                    "ndcg_at_3": 0.59185,
                    "ndcg_at_5": 0.618,
                    "ndcg_at_10": 0.64063,
                    "ndcg_at_20": 0.65434,
                    "map_at_1": 0.49314,
                    "map_at_3": 0.568,
                    "map_at_5": 0.58321,
                    "map_at_10": 0.59306,
                    "map_at_20": 0.59698,
                    "recall_at_1": 0.49314,
                    "recall_at_3": 0.65025,
                    "recall_at_5": 0.71286,
                    "recall_at_10": 0.78095,
                    "recall_at_20": 0.83413,
                    "precision_at_1": 0.51175,
                    "precision_at_3": 0.22899,
                    "precision_at_5": 0.15115,
                    "precision_at_10": 0.08297,
                    "precision_at_20": 0.04437,
                    "mrr_at_1": 0.5117478510028654,
                    "mrr_at_3": 0.578462273161417,
                    "mrr_at_5": 0.5920940783190077,
                    "mrr_at_10": 0.6010881429935884,
                    "mrr_at_20": 0.6046716859825694,
                    "main_score": 0.64063,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 82.79374623298645,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.80641,
                    "ndcg_at_3": 0.87174,
                    "ndcg_at_5": 0.88117,
                    "ndcg_at_10": 0.8876,
                    "ndcg_at_20": 0.89135,
                    "map_at_1": 0.80591,
                    "map_at_3": 0.85634,
                    "map_at_5": 0.86164,
                    "map_at_10": 0.86435,
                    "map_at_20": 0.86542,
                    "recall_at_1": 0.80591,
                    "recall_at_3": 0.91564,
                    "recall_at_5": 0.93829,
                    "recall_at_10": 0.95788,
                    "recall_at_20": 0.97241,
                    "precision_at_1": 0.80641,
                    "precision_at_3": 0.30571,
                    "precision_at_5": 0.18804,
                    "precision_at_10": 0.09606,
                    "precision_at_20": 0.04879,
                    "mrr_at_1": 0.8064118372379778,
                    "mrr_at_3": 0.8566241950952067,
                    "mrr_at_5": 0.8619204196269467,
                    "mrr_at_10": 0.8645692658485448,
                    "mrr_at_20": 0.8656133006114617,
                    "main_score": 0.8876,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 96.61048197746277,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.234,
                    "ndcg_at_3": 0.29109,
                    "ndcg_at_5": 0.309,
                    "ndcg_at_10": 0.32893,
                    "map_at_1": 0.234,
                    "map_at_3": 0.27667,
                    "map_at_5": 0.28672,
                    "map_at_10": 0.29488,
                    "recall_at_1": 0.234,
                    "recall_at_3": 0.333,
                    "recall_at_5": 0.376,
                    "recall_at_10": 0.438,
                    "precision_at_1": 0.234,
                    "precision_at_3": 0.111,
                    "precision_at_5": 0.0752,
                    "precision_at_10": 0.0438,
                    "mrr_at_1": 0.234,
                    "mrr_at_3": 0.2766666666666667,
                    "mrr_at_5": 0.28671666666666673,
                    "mrr_at_10": 0.2948761904761905,
                    "main_score": 0.32893,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 56.80797719955444,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.74889,
                    "ndcg_at_3": 0.81324,
                    "ndcg_at_5": 0.82601,
                    "ndcg_at_10": 0.83719,
                    "ndcg_at_20": 0.84353,
                    "map_at_1": 0.74852,
                    "map_at_3": 0.7977,
                    "map_at_5": 0.80483,
                    "map_at_10": 0.80949,
                    "map_at_20": 0.81126,
                    "recall_at_1": 0.74852,
                    "recall_at_3": 0.85728,
                    "recall_at_5": 0.8883,
                    "recall_at_10": 0.9225,
                    "recall_at_20": 0.94715,
                    "precision_at_1": 0.74889,
                    "precision_at_3": 0.28615,
                    "precision_at_5": 0.17798,
                    "precision_at_10": 0.09255,
                    "precision_at_20": 0.0476,
                    "mrr_at_1": 0.748931922539429,
                    "mrr_at_3": 0.7982098888667049,
                    "mrr_at_5": 0.805347041991086,
                    "mrr_at_10": 0.8100419879138224,
                    "mrr_at_20": 0.8117992168127822,
                    "main_score": 0.83719,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 52.507729053497314,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.81484,
                    "ndcg_at_3": 0.87566,
                    "ndcg_at_5": 0.88424,
                    "ndcg_at_10": 0.89089,
                    "ndcg_at_20": 0.89451,
                    "map_at_1": 0.81431,
                    "map_at_3": 0.86138,
                    "map_at_5": 0.8662,
                    "map_at_10": 0.869,
                    "map_at_20": 0.87001,
                    "recall_at_1": 0.81431,
                    "recall_at_3": 0.91636,
                    "recall_at_5": 0.937,
                    "recall_at_10": 0.95724,
                    "recall_at_20": 0.97138,
                    "precision_at_1": 0.81484,
                    "precision_at_3": 0.30592,
                    "precision_at_5": 0.18777,
                    "precision_at_10": 0.09599,
                    "precision_at_20": 0.04873,
                    "mrr_at_1": 0.8148376489930127,
                    "mrr_at_3": 0.861634666196924,
                    "mrr_at_5": 0.8664259291879439,
                    "mrr_at_10": 0.8691943985430811,
                    "mrr_at_20": 0.870187378031579,
                    "main_score": 0.89089,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 51.64439940452576,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "6e346642246bfb4928c560ee08640dc84d074e8c",
        "task_name": "LEMBWikimQARetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.38,
                    "ndcg_at_3": 0.47853,
                    "ndcg_at_5": 0.51152,
                    "ndcg_at_10": 0.53739,
                    "ndcg_at_20": 0.56546,
                    "map_at_1": 0.38,
                    "map_at_3": 0.45389,
                    "map_at_5": 0.47222,
                    "map_at_10": 0.48291,
                    "map_at_20": 0.49075,
                    "recall_at_1": 0.38,
                    "recall_at_3": 0.55,
                    "recall_at_5": 0.63,
                    "recall_at_10": 0.71,
                    "recall_at_20": 0.82,
                    "precision_at_1": 0.38,
                    "precision_at_3": 0.18333,
                    "precision_at_5": 0.126,
                    "precision_at_10": 0.071,
                    "precision_at_20": 0.041,
                    "mrr_at_1": 0.38,
                    "mrr_at_3": 0.45388888888888884,
                    "mrr_at_5": 0.4722222222222224,
                    "mrr_at_10": 0.482910052910053,
                    "mrr_at_20": 0.49075257836132463,
                    "main_score": 0.53739,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 32.81579327583313,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.65183,
                    "ndcg_at_3": 0.74575,
                    "ndcg_at_5": 0.76703,
                    "ndcg_at_10": 0.78273,
                    "ndcg_at_20": 0.79191,
                    "map_at_1": 0.65154,
                    "map_at_3": 0.72304,
                    "map_at_5": 0.73489,
                    "map_at_10": 0.74147,
                    "map_at_20": 0.74403,
                    "recall_at_1": 0.65154,
                    "recall_at_3": 0.81093,
                    "recall_at_5": 0.86248,
                    "recall_at_10": 0.91058,
                    "recall_at_20": 0.94652,
                    "precision_at_1": 0.65183,
                    "precision_at_3": 0.27061,
                    "precision_at_5": 0.17271,
                    "precision_at_10": 0.0912,
                    "precision_at_20": 0.04742,
                    "mrr_at_1": 0.6518349801103555,
                    "mrr_at_3": 0.7232933401770728,
                    "mrr_at_5": 0.7351196586680342,
                    "mrr_at_10": 0.7416789003766099,
                    "mrr_at_20": 0.7442294457426043,
                    "main_score": 0.78273,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 35.79037809371948,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "6e346642246bfb4928c560ee08640dc84d074e8c",
        "task_name": "LEMBWikimQARetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.36,
                    "ndcg_at_3": 0.4225,
                    "ndcg_at_5": 0.45792,
                    "ndcg_at_10": 0.49285,
                    "ndcg_at_20": 0.5219,
                    "map_at_1": 0.36,
                    "map_at_3": 0.40722,
                    "map_at_5": 0.42672,
                    "map_at_10": 0.44076,
                    "map_at_20": 0.44894,
                    "recall_at_1": 0.36,
                    "recall_at_3": 0.46667,
                    "recall_at_5": 0.55333,
                    "recall_at_10": 0.66333,
                    "recall_at_20": 0.77667,
                    "precision_at_1": 0.36,
                    "precision_at_3": 0.15556,
                    "precision_at_5": 0.11067,
                    "precision_at_10": 0.06633,
                    "precision_at_20": 0.03883,
                    "mrr_at_1": 0.36,
                    "mrr_at_3": 0.40722222222222215,
                    "mrr_at_5": 0.42672222222222217,
                    "mrr_at_10": 0.440755291005291,
                    "mrr_at_20": 0.4489382508759444,
                    "main_score": 0.49285,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 47.45837926864624,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.18563,
                    "ndcg_at_3": 0.28763,
                    "ndcg_at_5": 0.32873,
                    "ndcg_at_10": 0.37099,
                    "map_at_1": 0.18563,
                    "map_at_3": 0.26221,
                    "map_at_5": 0.2849,
                    "map_at_10": 0.3027,
                    "recall_at_1": 0.18563,
                    "recall_at_3": 0.36131,
                    "recall_at_5": 0.46159,
                    "recall_at_10": 0.59033,
                    "precision_at_1": 0.18563,
                    "precision_at_3": 0.12044,
                    "precision_at_5": 0.09232,
                    "precision_at_10": 0.05903,
                    "mrr_at_1": 0.19487908961593173,
                    "mrr_at_3": 0.2656472261735416,
                    "mrr_at_5": 0.28773115220483564,
                    "mrr_at_10": 0.305891699970647,
                    "main_score": 0.37099,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 20.546359062194824,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.27399,
                    "ndcg_at_3": 0.26544,
                    "ndcg_at_5": 0.2579,
                    "ndcg_at_10": 0.23603,
                    "ndcg_at_20": 0.22336,
                    "map_at_1": 0.03233,
                    "map_at_3": 0.05392,
                    "map_at_5": 0.06465,
                    "map_at_10": 0.07466,
                    "map_at_20": 0.08412,
                    "recall_at_1": 0.03233,
                    "recall_at_3": 0.0695,
                    "recall_at_5": 0.09412,
                    "recall_at_10": 0.12069,
                    "recall_at_20": 0.1577,
                    "precision_at_1": 0.28793,
                    "precision_at_3": 0.25593,
                    "precision_at_5": 0.23096,
                    "precision_at_10": 0.17926,
                    "precision_at_20": 0.13421,
                    "mrr_at_1": 0.28792569659442724,
                    "mrr_at_3": 0.3704850361197109,
                    "mrr_at_5": 0.3884416924664602,
                    "mrr_at_10": 0.39804535849427497,
                    "mrr_at_20": 0.4021822655709208,
                    "main_score": 0.23603,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 24.35460090637207,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.62736,
                    "ndcg_at_3": 0.72116,
                    "ndcg_at_5": 0.74138,
                    "ndcg_at_10": 0.75832,
                    "ndcg_at_20": 0.76871,
                    "map_at_1": 0.6261,
                    "map_at_3": 0.69821,
                    "map_at_5": 0.7095,
                    "map_at_10": 0.71665,
                    "map_at_20": 0.71962,
                    "recall_at_1": 0.6261,
                    "recall_at_3": 0.78593,
                    "recall_at_5": 0.83475,
                    "recall_at_10": 0.88614,
                    "recall_at_20": 0.92616,
                    "precision_at_1": 0.62736,
                    "precision_at_3": 0.26296,
                    "precision_at_5": 0.16783,
                    "precision_at_10": 0.08939,
                    "precision_at_20": 0.04687,
                    "mrr_at_1": 0.6273215022699133,
                    "mrr_at_3": 0.6993896872147011,
                    "mrr_at_5": 0.7106867269475702,
                    "mrr_at_10": 0.7177661140620369,
                    "mrr_at_20": 0.7206171484838263,
                    "main_score": 0.75832,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 45.60551905632019,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.108,
                    "ndcg_at_3": 0.09752,
                    "ndcg_at_5": 0.0889,
                    "ndcg_at_10": 0.11143,
                    "ndcg_at_20": 0.13254,
                    "map_at_1": 0.02203,
                    "map_at_3": 0.04164,
                    "map_at_5": 0.05121,
                    "map_at_10": 0.06077,
                    "map_at_20": 0.06737,
                    "recall_at_1": 0.02203,
                    "recall_at_3": 0.05768,
                    "recall_at_5": 0.08323,
                    "recall_at_10": 0.12472,
                    "recall_at_20": 0.1745,
                    "precision_at_1": 0.108,
                    "precision_at_3": 0.09433,
                    "precision_at_5": 0.0816,
                    "precision_at_10": 0.0613,
                    "precision_at_20": 0.04285,
                    "mrr_at_1": 0.108,
                    "mrr_at_3": 0.1613333333333334,
                    "mrr_at_5": 0.17688333333333345,
                    "mrr_at_10": 0.19069166666666681,
                    "mrr_at_20": 0.19773639605148902,
                    "main_score": 0.11143,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 128.7991337776184,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.39,
                    "ndcg_at_3": 0.45351,
                    "ndcg_at_5": 0.46212,
                    "ndcg_at_10": 0.47514,
                    "ndcg_at_20": 0.48986,
                    "map_at_1": 0.39,
                    "map_at_3": 0.4375,
                    "map_at_5": 0.44225,
                    "map_at_10": 0.44767,
                    "map_at_20": 0.45175,
                    "recall_at_1": 0.39,
                    "recall_at_3": 0.5,
                    "recall_at_5": 0.521,
                    "recall_at_10": 0.561,
                    "recall_at_20": 0.619,
                    "precision_at_1": 0.39,
                    "precision_at_3": 0.16667,
                    "precision_at_5": 0.1042,
                    "precision_at_10": 0.0561,
                    "precision_at_20": 0.03095,
                    "mrr_at_1": 0.39,
                    "mrr_at_3": 0.43749999999999967,
                    "mrr_at_5": 0.44224999999999953,
                    "mrr_at_10": 0.447671825396825,
                    "mrr_at_20": 0.45174576894983187,
                    "main_score": 0.47514,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 107.70068192481995,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.4693,
                    "ndcg_at_3": 0.52982,
                    "ndcg_at_5": 0.54731,
                    "ndcg_at_10": 0.56513,
                    "ndcg_at_20": 0.57847,
                    "map_at_1": 0.46905,
                    "map_at_3": 0.51489,
                    "map_at_5": 0.52462,
                    "map_at_10": 0.53203,
                    "map_at_20": 0.53571,
                    "recall_at_1": 0.46905,
                    "recall_at_3": 0.57243,
                    "recall_at_5": 0.61489,
                    "recall_at_10": 0.66969,
                    "recall_at_20": 0.72215,
                    "precision_at_1": 0.4693,
                    "precision_at_3": 0.19105,
                    "precision_at_5": 0.12321,
                    "precision_at_10": 0.06714,
                    "precision_at_20": 0.03624,
                    "mrr_at_1": 0.4693045563549161,
                    "mrr_at_3": 0.5152744471089845,
                    "mrr_at_5": 0.5250366373567904,
                    "mrr_at_10": 0.5324554324794217,
                    "mrr_at_20": 0.536150368695222,
                    "main_score": 0.56513,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 42.163960218429565,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.74568,
                    "ndcg_at_3": 0.80826,
                    "ndcg_at_5": 0.8216,
                    "ndcg_at_10": 0.83305,
                    "ndcg_at_20": 0.83986,
                    "map_at_1": 0.74526,
                    "map_at_3": 0.79303,
                    "map_at_5": 0.80049,
                    "map_at_10": 0.80529,
                    "map_at_20": 0.80721,
                    "recall_at_1": 0.74526,
                    "recall_at_3": 0.85123,
                    "recall_at_5": 0.8836,
                    "recall_at_10": 0.91851,
                    "recall_at_20": 0.9449,
                    "precision_at_1": 0.74568,
                    "precision_at_3": 0.28421,
                    "precision_at_5": 0.17711,
                    "precision_at_10": 0.09218,
                    "precision_at_20": 0.04751,
                    "mrr_at_1": 0.74568345323741,
                    "mrr_at_3": 0.7936850519584344,
                    "mrr_at_5": 0.8011590727418125,
                    "mrr_at_10": 0.805986163450198,
                    "mrr_at_20": 0.8078544575210743,
                    "main_score": 0.83305,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 58.321401834487915,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.96121,
                    "ndcg_at_3": 0.97761,
                    "ndcg_at_5": 0.97918,
                    "ndcg_at_10": 0.98014,
                    "map_at_1": 0.96117,
                    "map_at_3": 0.97392,
                    "map_at_5": 0.9748,
                    "map_at_10": 0.97521,
                    "recall_at_1": 0.96117,
                    "recall_at_3": 0.98811,
                    "recall_at_5": 0.99187,
                    "recall_at_10": 0.99481,
                    "precision_at_1": 0.96121,
                    "precision_at_3": 0.32938,
                    "precision_at_5": 0.1984,
                    "precision_at_10": 0.09949,
                    "mrr_at_1": 0.9612130388314927,
                    "mrr_at_3": 0.9739638997743734,
                    "mrr_at_5": 0.9748278114238219,
                    "mrr_at_10": 0.9752368476484532,
                    "main_score": 0.98014,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 36.438541650772095,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.83647,
                    "ndcg_at_3": 0.89565,
                    "ndcg_at_5": 0.90307,
                    "ndcg_at_10": 0.90852,
                    "ndcg_at_20": 0.91127,
                    "map_at_1": 0.83585,
                    "map_at_3": 0.88185,
                    "map_at_5": 0.88599,
                    "map_at_10": 0.88828,
                    "map_at_20": 0.88908,
                    "recall_at_1": 0.83585,
                    "recall_at_3": 0.93487,
                    "recall_at_5": 0.95283,
                    "recall_at_10": 0.96949,
                    "recall_at_20": 0.98007,
                    "precision_at_1": 0.83647,
                    "precision_at_3": 0.31218,
                    "precision_at_5": 0.19097,
                    "precision_at_10": 0.0972,
                    "precision_at_20": 0.04917,
                    "mrr_at_1": 0.8364650616559014,
                    "mrr_at_3": 0.882119788608329,
                    "mrr_at_5": 0.8862654139753321,
                    "mrr_at_10": 0.8885167747858546,
                    "mrr_at_20": 0.8892793732956003,
                    "main_score": 0.90852,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 84.58889508247375,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.111,
                    "ndcg_at_3": 0.10047,
                    "ndcg_at_5": 0.09149,
                    "ndcg_at_10": 0.11392,
                    "map_at_1": 0.02268,
                    "map_at_3": 0.04298,
                    "map_at_5": 0.05297,
                    "map_at_10": 0.06262,
                    "recall_at_1": 0.02268,
                    "recall_at_3": 0.05933,
                    "recall_at_5": 0.08533,
                    "recall_at_10": 0.12672,
                    "precision_at_1": 0.111,
                    "precision_at_3": 0.097,
                    "precision_at_5": 0.0838,
                    "precision_at_10": 0.0623,
                    "mrr_at_1": 0.111,
                    "mrr_at_3": 0.1666666666666667,
                    "mrr_at_5": 0.18196666666666672,
                    "mrr_at_10": 0.1950920634920635,
                    "main_score": 0.11392,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 91.4058051109314,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.45667,
                    "ndcg_at_3": 0.50098,
                    "ndcg_at_5": 0.52226,
                    "ndcg_at_10": 0.54702,
                    "map_at_1": 0.43778,
                    "map_at_3": 0.48033,
                    "map_at_5": 0.49418,
                    "map_at_10": 0.50535,
                    "recall_at_1": 0.43778,
                    "recall_at_3": 0.53706,
                    "recall_at_5": 0.58844,
                    "recall_at_10": 0.6595,
                    "precision_at_1": 0.45667,
                    "precision_at_3": 0.19111,
                    "precision_at_5": 0.128,
                    "precision_at_10": 0.073,
                    "mrr_at_1": 0.45666666666666667,
                    "mrr_at_3": 0.5011111111111111,
                    "mrr_at_5": 0.5119444444444444,
                    "mrr_at_10": 0.5217314814814814,
                    "main_score": 0.54702,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 33.586854696273804,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.33127,
                    "ndcg_at_3": 0.28568,
                    "ndcg_at_5": 0.26556,
                    "ndcg_at_10": 0.24445,
                    "map_at_1": 0.03582,
                    "map_at_3": 0.0587,
                    "map_at_5": 0.067,
                    "map_at_10": 0.07835,
                    "recall_at_1": 0.03582,
                    "recall_at_3": 0.06668,
                    "recall_at_5": 0.0819,
                    "recall_at_10": 0.10939,
                    "precision_at_1": 0.34365,
                    "precision_at_3": 0.26935,
                    "precision_at_5": 0.23096,
                    "precision_at_10": 0.18607,
                    "mrr_at_1": 0.34674922600619196,
                    "mrr_at_3": 0.40247678018575844,
                    "mrr_at_5": 0.41439628482972124,
                    "mrr_at_10": 0.427516094156961,
                    "main_score": 0.24445,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 19.808983325958252,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.271,
                    "ndcg_at_3": 0.35859,
                    "ndcg_at_5": 0.39,
                    "ndcg_at_10": 0.4158,
                    "ndcg_at_20": 0.43681,
                    "map_at_1": 0.271,
                    "map_at_3": 0.33733,
                    "map_at_5": 0.35458,
                    "map_at_10": 0.36518,
                    "map_at_20": 0.37097,
                    "recall_at_1": 0.271,
                    "recall_at_3": 0.42,
                    "recall_at_5": 0.497,
                    "recall_at_10": 0.577,
                    "recall_at_20": 0.66,
                    "precision_at_1": 0.271,
                    "precision_at_3": 0.14,
                    "precision_at_5": 0.0994,
                    "precision_at_10": 0.0577,
                    "precision_at_20": 0.033,
                    "mrr_at_1": 0.271,
                    "mrr_at_3": 0.33733333333333326,
                    "mrr_at_5": 0.354583333333333,
                    "mrr_at_10": 0.36518253968253933,
                    "mrr_at_20": 0.3709673859164566,
                    "main_score": 0.4158,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 62.05339336395264,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.391,
                    "ndcg_at_3": 0.45251,
                    "ndcg_at_5": 0.46202,
                    "ndcg_at_10": 0.476,
                    "ndcg_at_20": 0.49066,
                    "map_at_1": 0.391,
                    "map_at_3": 0.43717,
                    "map_at_5": 0.44247,
                    "map_at_10": 0.44827,
                    "map_at_20": 0.4523,
                    "recall_at_1": 0.391,
                    "recall_at_3": 0.497,
                    "recall_at_5": 0.52,
                    "recall_at_10": 0.563,
                    "recall_at_20": 0.621,
                    "precision_at_1": 0.391,
                    "precision_at_3": 0.16567,
                    "precision_at_5": 0.104,
                    "precision_at_10": 0.0563,
                    "precision_at_20": 0.03105,
                    "mrr_at_1": 0.392,
                    "mrr_at_3": 0.4376666666666663,
                    "mrr_at_5": 0.4429666666666662,
                    "mrr_at_10": 0.44879801587301543,
                    "mrr_at_20": 0.452825527714459,
                    "main_score": 0.476,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 109.54587411880493,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.95523,
                    "ndcg_at_3": 0.97313,
                    "ndcg_at_5": 0.97447,
                    "ndcg_at_10": 0.97569,
                    "ndcg_at_20": 0.97637,
                    "map_at_1": 0.95523,
                    "map_at_3": 0.96912,
                    "map_at_5": 0.96987,
                    "map_at_10": 0.97037,
                    "map_at_20": 0.97056,
                    "recall_at_1": 0.95523,
                    "recall_at_3": 0.98459,
                    "recall_at_5": 0.98783,
                    "recall_at_10": 0.99156,
                    "recall_at_20": 0.99423,
                    "precision_at_1": 0.95523,
                    "precision_at_3": 0.3282,
                    "precision_at_5": 0.19757,
                    "precision_at_10": 0.09916,
                    "precision_at_20": 0.04971,
                    "mrr_at_1": 0.9552298467688208,
                    "mrr_at_3": 0.9691168850396028,
                    "mrr_at_5": 0.9698674957435784,
                    "mrr_at_10": 0.970370599494517,
                    "mrr_at_20": 0.9705609678029867,
                    "main_score": 0.97569,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 40.08926320075989,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.234,
                    "ndcg_at_3": 0.2897,
                    "ndcg_at_5": 0.30799,
                    "ndcg_at_10": 0.32824,
                    "ndcg_at_20": 0.34752,
                    "map_at_1": 0.234,
                    "map_at_3": 0.2755,
                    "map_at_5": 0.28575,
                    "map_at_10": 0.29403,
                    "map_at_20": 0.29922,
                    "recall_at_1": 0.234,
                    "recall_at_3": 0.331,
                    "recall_at_5": 0.375,
                    "recall_at_10": 0.438,
                    "recall_at_20": 0.515,
                    "precision_at_1": 0.234,
                    "precision_at_3": 0.11033,
                    "precision_at_5": 0.075,
                    "precision_at_10": 0.0438,
                    "precision_at_20": 0.02575,
                    "mrr_at_1": 0.233,
                    "mrr_at_3": 0.27500000000000013,
                    "mrr_at_5": 0.28525000000000006,
                    "mrr_at_10": 0.29353452380952383,
                    "mrr_at_20": 0.29872029065275973,
                    "main_score": 0.32824,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 64.58226943016052,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.24731,
                    "ndcg_at_3": 0.25426,
                    "ndcg_at_5": 0.26972,
                    "ndcg_at_10": 0.29676,
                    "ndcg_at_20": 0.32343,
                    "map_at_1": 0.15359,
                    "map_at_3": 0.20989,
                    "map_at_5": 0.22511,
                    "map_at_10": 0.23999,
                    "map_at_20": 0.24885,
                    "recall_at_1": 0.15359,
                    "recall_at_3": 0.2575,
                    "recall_at_5": 0.30675,
                    "recall_at_10": 0.3851,
                    "recall_at_20": 0.47734,
                    "precision_at_1": 0.24731,
                    "precision_at_3": 0.14804,
                    "precision_at_5": 0.10838,
                    "precision_at_10": 0.06989,
                    "precision_at_20": 0.04362,
                    "mrr_at_1": 0.24731182795698925,
                    "mrr_at_3": 0.2983662582312247,
                    "mrr_at_5": 0.31059431524547876,
                    "mrr_at_10": 0.32140029054882796,
                    "mrr_at_20": 0.3275376426208832,
                    "main_score": 0.29676,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 260.3940303325653,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.2963,
                    "ndcg_at_3": 0.2744,
                    "ndcg_at_5": 0.28243,
                    "ndcg_at_10": 0.31089,
                    "map_at_1": 0.14692,
                    "map_at_3": 0.20668,
                    "map_at_5": 0.22317,
                    "map_at_10": 0.24142,
                    "recall_at_1": 0.14692,
                    "recall_at_3": 0.24819,
                    "recall_at_5": 0.2938,
                    "recall_at_10": 0.37679,
                    "precision_at_1": 0.2963,
                    "precision_at_3": 0.1821,
                    "precision_at_5": 0.13611,
                    "precision_at_10": 0.09074,
                    "mrr_at_1": 0.2962962962962963,
                    "mrr_at_3": 0.35442386831275746,
                    "mrr_at_5": 0.3681584362139919,
                    "mrr_at_10": 0.3801152508328434,
                    "main_score": 0.31089,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 108.29274272918701,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.50874,
                    "ndcg_at_3": 0.58857,
                    "ndcg_at_5": 0.61434,
                    "ndcg_at_10": 0.63774,
                    "ndcg_at_20": 0.65143,
                    "map_at_1": 0.49005,
                    "map_at_3": 0.56466,
                    "map_at_5": 0.57977,
                    "map_at_10": 0.58995,
                    "map_at_20": 0.59386,
                    "recall_at_1": 0.49005,
                    "recall_at_3": 0.64705,
                    "recall_at_5": 0.70839,
                    "recall_at_10": 0.7787,
                    "recall_at_20": 0.83179,
                    "precision_at_1": 0.50874,
                    "precision_at_3": 0.22775,
                    "precision_at_5": 0.15026,
                    "precision_at_10": 0.08274,
                    "precision_at_20": 0.04424,
                    "mrr_at_1": 0.5087392550143266,
                    "mrr_at_3": 0.5752626552053522,
                    "mrr_at_5": 0.5887082139446055,
                    "mrr_at_10": 0.5980741460863256,
                    "mrr_at_20": 0.601694894391377,
                    "main_score": 0.63774,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 172.34446358680725,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "6e346642246bfb4928c560ee08640dc84d074e8c",
        "task_name": "LEMBWikimQARetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.28333,
                    "ndcg_at_3": 0.34873,
                    "ndcg_at_5": 0.38386,
                    "ndcg_at_10": 0.42469,
                    "ndcg_at_20": 0.45395,
                    "map_at_1": 0.28333,
                    "map_at_3": 0.33222,
                    "map_at_5": 0.35139,
                    "map_at_10": 0.36816,
                    "map_at_20": 0.37608,
                    "recall_at_1": 0.28333,
                    "recall_at_3": 0.39667,
                    "recall_at_5": 0.48333,
                    "recall_at_10": 0.61,
                    "recall_at_20": 0.72667,
                    "precision_at_1": 0.28333,
                    "precision_at_3": 0.13222,
                    "precision_at_5": 0.09667,
                    "precision_at_10": 0.061,
                    "precision_at_20": 0.03633,
                    "mrr_at_1": 0.2833333333333333,
                    "mrr_at_3": 0.3322222222222222,
                    "mrr_at_5": 0.3513888888888889,
                    "mrr_at_10": 0.3681587301587302,
                    "mrr_at_20": 0.3760798180291215,
                    "main_score": 0.42469,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 27.6428279876709,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.83127,
                    "ndcg_at_3": 0.89318,
                    "ndcg_at_5": 0.90141,
                    "ndcg_at_10": 0.90676,
                    "ndcg_at_20": 0.90968,
                    "map_at_1": 0.83062,
                    "map_at_3": 0.87867,
                    "map_at_5": 0.88331,
                    "map_at_10": 0.88558,
                    "map_at_20": 0.88642,
                    "recall_at_1": 0.83062,
                    "recall_at_3": 0.9344,
                    "recall_at_5": 0.95418,
                    "recall_at_10": 0.97042,
                    "recall_at_20": 0.9817,
                    "precision_at_1": 0.83127,
                    "precision_at_3": 0.31208,
                    "precision_at_5": 0.19129,
                    "precision_at_10": 0.09733,
                    "precision_at_20": 0.04927,
                    "mrr_at_1": 0.83126834997064,
                    "mrr_at_3": 0.8789880602857602,
                    "mrr_at_5": 0.8835814249363803,
                    "mrr_at_10": 0.8858204592269427,
                    "mrr_at_20": 0.8866139350048324,
                    "main_score": 0.90676,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 89.1467969417572,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.54373,
                    "ndcg_at_3": 0.63383,
                    "ndcg_at_5": 0.6573,
                    "ndcg_at_10": 0.67838,
                    "ndcg_at_20": 0.69324,
                    "map_at_1": 0.54268,
                    "map_at_3": 0.61178,
                    "map_at_5": 0.62477,
                    "map_at_10": 0.63354,
                    "map_at_20": 0.63776,
                    "recall_at_1": 0.54268,
                    "recall_at_3": 0.69758,
                    "recall_at_5": 0.75421,
                    "recall_at_10": 0.81902,
                    "recall_at_20": 0.87671,
                    "precision_at_1": 0.54373,
                    "precision_at_3": 0.23358,
                    "precision_at_5": 0.15174,
                    "precision_at_10": 0.08251,
                    "precision_at_20": 0.04426,
                    "mrr_at_1": 0.5437302423603794,
                    "mrr_at_3": 0.6120477695820162,
                    "mrr_at_5": 0.6250614682121534,
                    "mrr_at_10": 0.6336962884908093,
                    "mrr_at_20": 0.6378475775191643,
                    "main_score": 0.67838,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 191.4706106185913,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.65623,
                    "ndcg_at_3": 0.74937,
                    "ndcg_at_5": 0.76967,
                    "ndcg_at_10": 0.7854,
                    "ndcg_at_20": 0.79415,
                    "map_at_1": 0.65604,
                    "map_at_3": 0.72685,
                    "map_at_5": 0.73814,
                    "map_at_10": 0.74471,
                    "map_at_20": 0.74716,
                    "recall_at_1": 0.65604,
                    "recall_at_3": 0.81412,
                    "recall_at_5": 0.86323,
                    "recall_at_10": 0.9115,
                    "recall_at_20": 0.94576,
                    "precision_at_1": 0.65623,
                    "precision_at_3": 0.27164,
                    "precision_at_5": 0.17285,
                    "precision_at_10": 0.09128,
                    "precision_at_20": 0.04738,
                    "mrr_at_1": 0.6562299499550879,
                    "mrr_at_3": 0.7270574019419047,
                    "mrr_at_5": 0.7383431712220353,
                    "mrr_at_10": 0.7448970280614081,
                    "mrr_at_20": 0.7473253933966378,
                    "main_score": 0.7854,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 58.85495591163635,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.46,
                    "ndcg_at_3": 0.51718,
                    "ndcg_at_5": 0.53766,
                    "ndcg_at_10": 0.56833,
                    "ndcg_at_20": 0.58427,
                    "map_at_1": 0.43528,
                    "map_at_3": 0.49322,
                    "map_at_5": 0.50701,
                    "map_at_10": 0.52091,
                    "map_at_20": 0.52579,
                    "recall_at_1": 0.43528,
                    "recall_at_3": 0.55856,
                    "recall_at_5": 0.60822,
                    "recall_at_10": 0.69861,
                    "recall_at_20": 0.75889,
                    "precision_at_1": 0.46,
                    "precision_at_3": 0.20111,
                    "precision_at_5": 0.13467,
                    "precision_at_10": 0.07833,
                    "precision_at_20": 0.04283,
                    "mrr_at_1": 0.46,
                    "mrr_at_3": 0.5166666666666667,
                    "mrr_at_5": 0.5258333333333334,
                    "mrr_at_10": 0.5379603174603174,
                    "mrr_at_20": 0.5418454366267835,
                    "main_score": 0.56833,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 33.98633122444153,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.88665,
                    "ndcg_at_3": 0.92089,
                    "ndcg_at_5": 0.92619,
                    "ndcg_at_10": 0.93005,
                    "ndcg_at_20": 0.93262,
                    "map_at_1": 0.88665,
                    "map_at_3": 0.9129,
                    "map_at_5": 0.91584,
                    "map_at_10": 0.91744,
                    "map_at_20": 0.91816,
                    "recall_at_1": 0.88665,
                    "recall_at_3": 0.94382,
                    "recall_at_5": 0.9567,
                    "recall_at_10": 0.96864,
                    "recall_at_20": 0.97873,
                    "precision_at_1": 0.88665,
                    "precision_at_3": 0.31461,
                    "precision_at_5": 0.19134,
                    "precision_at_10": 0.09686,
                    "precision_at_20": 0.04894,
                    "mrr_at_1": 0.8866533422163002,
                    "mrr_at_3": 0.912902509438152,
                    "mrr_at_5": 0.9158405507439507,
                    "mrr_at_10": 0.9174396257873961,
                    "mrr_at_20": 0.9181559201847971,
                    "main_score": 0.93005,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 56.26391124725342,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.63726,
                    "ndcg_at_3": 0.73292,
                    "ndcg_at_5": 0.75394,
                    "ndcg_at_10": 0.77038,
                    "ndcg_at_20": 0.77949,
                    "map_at_1": 0.63587,
                    "map_at_3": 0.7093,
                    "map_at_5": 0.72109,
                    "map_at_10": 0.72806,
                    "map_at_20": 0.73063,
                    "recall_at_1": 0.63587,
                    "recall_at_3": 0.79911,
                    "recall_at_5": 0.84988,
                    "recall_at_10": 0.89977,
                    "recall_at_20": 0.93503,
                    "precision_at_1": 0.63726,
                    "precision_at_3": 0.26753,
                    "precision_at_5": 0.17099,
                    "precision_at_10": 0.09081,
                    "precision_at_20": 0.04736,
                    "mrr_at_1": 0.6372644696344119,
                    "mrr_at_3": 0.7109138453069106,
                    "mrr_at_5": 0.7226359382428835,
                    "mrr_at_10": 0.7294082889768365,
                    "mrr_at_20": 0.7318812833221927,
                    "main_score": 0.77038,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 57.52988052368164,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.6406,
                    "ndcg_at_3": 0.73205,
                    "ndcg_at_5": 0.75242,
                    "ndcg_at_10": 0.76884,
                    "ndcg_at_20": 0.77804,
                    "map_at_1": 0.63921,
                    "map_at_3": 0.70945,
                    "map_at_5": 0.72083,
                    "map_at_10": 0.72776,
                    "map_at_20": 0.73038,
                    "recall_at_1": 0.63921,
                    "recall_at_3": 0.79546,
                    "recall_at_5": 0.84467,
                    "recall_at_10": 0.89462,
                    "recall_at_20": 0.93018,
                    "precision_at_1": 0.6406,
                    "precision_at_3": 0.26639,
                    "precision_at_5": 0.17001,
                    "precision_at_10": 0.09032,
                    "precision_at_20": 0.04712,
                    "mrr_at_1": 0.640603309195963,
                    "mrr_at_3": 0.7109643692392368,
                    "mrr_at_5": 0.7223364474293162,
                    "mrr_at_10": 0.7291537061553652,
                    "mrr_at_20": 0.7316038476794045,
                    "main_score": 0.76884,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 37.923808336257935,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.782,
                    "ndcg_at_3": 0.73779,
                    "ndcg_at_5": 0.72998,
                    "ndcg_at_10": 0.7611,
                    "map_at_1": 0.2181,
                    "map_at_3": 0.44851,
                    "map_at_5": 0.56524,
                    "map_at_10": 0.65711,
                    "recall_at_1": 0.2181,
                    "recall_at_3": 0.48479,
                    "recall_at_5": 0.63879,
                    "recall_at_10": 0.7877,
                    "precision_at_1": 0.782,
                    "precision_at_3": 0.661,
                    "precision_at_5": 0.5624,
                    "precision_at_10": 0.37165,
                    "mrr_at_1": 0.782,
                    "mrr_at_3": 0.8447499999999993,
                    "mrr_at_5": 0.8502749999999997,
                    "mrr_at_10": 0.8527813492063487,
                    "main_score": 0.7611,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 415.3804063796997,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.95328,
                    "ndcg_at_3": 0.97218,
                    "ndcg_at_5": 0.97362,
                    "ndcg_at_10": 0.97473,
                    "ndcg_at_20": 0.97547,
                    "map_at_1": 0.95328,
                    "map_at_3": 0.96794,
                    "map_at_5": 0.96874,
                    "map_at_10": 0.96919,
                    "map_at_20": 0.9694,
                    "recall_at_1": 0.95328,
                    "recall_at_3": 0.98428,
                    "recall_at_5": 0.98779,
                    "recall_at_10": 0.99125,
                    "recall_at_20": 0.99414,
                    "precision_at_1": 0.95328,
                    "precision_at_3": 0.32809,
                    "precision_at_5": 0.19756,
                    "precision_at_10": 0.09913,
                    "precision_at_20": 0.04971,
                    "mrr_at_1": 0.9532755940484122,
                    "mrr_at_3": 0.9679398919239022,
                    "mrr_at_5": 0.9687393589458881,
                    "mrr_at_10": 0.9691928308817056,
                    "mrr_at_20": 0.9693972560405315,
                    "main_score": 0.97473,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 40.10172939300537,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.7645,
                    "ndcg_at_3": 0.72267,
                    "ndcg_at_5": 0.7107,
                    "ndcg_at_10": 0.74307,
                    "ndcg_at_20": 0.77054,
                    "map_at_1": 0.21289,
                    "map_at_3": 0.43466,
                    "map_at_5": 0.54482,
                    "map_at_10": 0.63492,
                    "map_at_20": 0.66191,
                    "recall_at_1": 0.21289,
                    "recall_at_3": 0.47173,
                    "recall_at_5": 0.61988,
                    "recall_at_10": 0.7706,
                    "recall_at_20": 0.8481,
                    "precision_at_1": 0.7645,
                    "precision_at_3": 0.6495,
                    "precision_at_5": 0.5468,
                    "precision_at_10": 0.36305,
                    "precision_at_20": 0.206,
                    "mrr_at_1": 0.7645,
                    "mrr_at_3": 0.8319999999999993,
                    "mrr_at_5": 0.8376249999999994,
                    "mrr_at_10": 0.840365079365079,
                    "mrr_at_20": 0.8412396819468796,
                    "main_score": 0.74307,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 339.8547751903534,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.75973,
                    "ndcg_at_3": 0.69748,
                    "ndcg_at_5": 0.67556,
                    "ndcg_at_10": 0.67603,
                    "ndcg_at_20": 0.70451,
                    "map_at_1": 0.20897,
                    "map_at_3": 0.40114,
                    "map_at_5": 0.49017,
                    "map_at_10": 0.57028,
                    "map_at_20": 0.59943,
                    "recall_at_1": 0.20897,
                    "recall_at_3": 0.42717,
                    "recall_at_5": 0.54137,
                    "recall_at_10": 0.67004,
                    "recall_at_20": 0.75575,
                    "precision_at_1": 0.75973,
                    "precision_at_3": 0.61438,
                    "precision_at_5": 0.51014,
                    "precision_at_10": 0.34383,
                    "precision_at_20": 0.19942,
                    "mrr_at_1": 0.7597317201472908,
                    "mrr_at_3": 0.8000175346308982,
                    "mrr_at_5": 0.8065272663510502,
                    "mrr_at_10": 0.8103177734358755,
                    "mrr_at_20": 0.8120775711445954,
                    "main_score": 0.67603,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 982.6113955974579,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.69787,
                    "ndcg_at_3": 0.77358,
                    "ndcg_at_5": 0.78766,
                    "ndcg_at_10": 0.79855,
                    "map_at_1": 0.69735,
                    "map_at_3": 0.75545,
                    "map_at_5": 0.76329,
                    "map_at_10": 0.76783,
                    "recall_at_1": 0.69735,
                    "recall_at_3": 0.82537,
                    "recall_at_5": 0.85942,
                    "recall_at_10": 0.8928,
                    "precision_at_1": 0.69787,
                    "precision_at_3": 0.27551,
                    "precision_at_5": 0.17217,
                    "precision_at_10": 0.08949,
                    "mrr_at_1": 0.6978744642123187,
                    "mrr_at_3": 0.7558520736695725,
                    "mrr_at_5": 0.7636965924882034,
                    "mrr_at_10": 0.7682069368369333,
                    "main_score": 0.79855,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 64.6567485332489,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.47,
                    "ndcg_at_3": 0.51943,
                    "ndcg_at_5": 0.53754,
                    "ndcg_at_10": 0.56615,
                    "ndcg_at_20": 0.58393,
                    "map_at_1": 0.4475,
                    "map_at_3": 0.49683,
                    "map_at_5": 0.50938,
                    "map_at_10": 0.5228,
                    "map_at_20": 0.52831,
                    "recall_at_1": 0.4475,
                    "recall_at_3": 0.55772,
                    "recall_at_5": 0.60072,
                    "recall_at_10": 0.68361,
                    "recall_at_20": 0.74956,
                    "precision_at_1": 0.47,
                    "precision_at_3": 0.2,
                    "precision_at_5": 0.13267,
                    "precision_at_10": 0.07667,
                    "precision_at_20": 0.0425,
                    "mrr_at_1": 0.47,
                    "mrr_at_3": 0.5199999999999999,
                    "mrr_at_5": 0.5279999999999999,
                    "mrr_at_10": 0.5391494708994707,
                    "mrr_at_20": 0.5436612905068787,
                    "main_score": 0.56615,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 27.079453945159912,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.8071,
                    "ndcg_at_3": 0.8485,
                    "ndcg_at_5": 0.85602,
                    "ndcg_at_10": 0.86189,
                    "map_at_1": 0.8071,
                    "map_at_3": 0.83875,
                    "map_at_5": 0.84292,
                    "map_at_10": 0.84534,
                    "recall_at_1": 0.8071,
                    "recall_at_3": 0.87655,
                    "recall_at_5": 0.8948,
                    "recall_at_10": 0.91295,
                    "precision_at_1": 0.8071,
                    "precision_at_3": 0.29218,
                    "precision_at_5": 0.17896,
                    "precision_at_10": 0.09129,
                    "mrr_at_1": 0.8071,
                    "mrr_at_3": 0.8387500000000043,
                    "mrr_at_5": 0.8429200000000062,
                    "mrr_at_10": 0.8453419047619103,
                    "main_score": 0.86189,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 267.274001121521,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.54268,
                    "ndcg_at_3": 0.64047,
                    "ndcg_at_5": 0.66735,
                    "ndcg_at_10": 0.69349,
                    "ndcg_at_20": 0.70667,
                    "map_at_1": 0.5411,
                    "map_at_3": 0.61582,
                    "map_at_5": 0.63094,
                    "map_at_10": 0.64211,
                    "map_at_20": 0.64584,
                    "recall_at_1": 0.5411,
                    "recall_at_3": 0.71048,
                    "recall_at_5": 0.77503,
                    "recall_at_10": 0.85458,
                    "recall_at_20": 0.90569,
                    "precision_at_1": 0.54268,
                    "precision_at_3": 0.2385,
                    "precision_at_5": 0.15638,
                    "precision_at_10": 0.08641,
                    "precision_at_20": 0.04579,
                    "mrr_at_1": 0.541622760800843,
                    "mrr_at_3": 0.6164383561643834,
                    "mrr_at_5": 0.63145416227608,
                    "mrr_at_10": 0.6421195243113053,
                    "mrr_at_20": 0.6458968475110609,
                    "main_score": 0.69349,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 286.38639998435974,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.65198,
                    "ndcg_at_3": 0.74488,
                    "ndcg_at_5": 0.76477,
                    "ndcg_at_10": 0.78083,
                    "ndcg_at_20": 0.78931,
                    "map_at_1": 0.65044,
                    "map_at_3": 0.7218,
                    "map_at_5": 0.73295,
                    "map_at_10": 0.73976,
                    "map_at_20": 0.74219,
                    "recall_at_1": 0.65044,
                    "recall_at_3": 0.80927,
                    "recall_at_5": 0.85736,
                    "recall_at_10": 0.90622,
                    "recall_at_20": 0.9389,
                    "precision_at_1": 0.65198,
                    "precision_at_3": 0.27109,
                    "precision_at_5": 0.17256,
                    "precision_at_10": 0.09149,
                    "precision_at_20": 0.04758,
                    "mrr_at_1": 0.6520156144433601,
                    "mrr_at_3": 0.723588068963793,
                    "mrr_at_5": 0.7346964692340493,
                    "mrr_at_10": 0.7412932557854186,
                    "mrr_at_20": 0.7435926165027478,
                    "main_score": 0.78083,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 37.964686155319214,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.51175,
                    "ndcg_at_3": 0.59182,
                    "ndcg_at_5": 0.61791,
                    "ndcg_at_10": 0.64065,
                    "map_at_1": 0.49314,
                    "map_at_3": 0.56795,
                    "map_at_5": 0.58314,
                    "map_at_10": 0.59303,
                    "recall_at_1": 0.49314,
                    "recall_at_3": 0.65018,
                    "recall_at_5": 0.71264,
                    "recall_at_10": 0.78109,
                    "precision_at_1": 0.51175,
                    "precision_at_3": 0.22894,
                    "precision_at_5": 0.15109,
                    "precision_at_10": 0.08298,
                    "mrr_at_1": 0.5117478510028654,
                    "mrr_at_3": 0.5784861509073577,
                    "mrr_at_5": 0.5920893027698196,
                    "mrr_at_10": 0.601111793332425,
                    "main_score": 0.64065,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 105.1909990310669,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.63294,
                    "ndcg_at_3": 0.73208,
                    "ndcg_at_5": 0.75277,
                    "ndcg_at_10": 0.76932,
                    "ndcg_at_20": 0.7791,
                    "map_at_1": 0.63275,
                    "map_at_3": 0.70807,
                    "map_at_5": 0.71961,
                    "map_at_10": 0.7265,
                    "map_at_20": 0.72923,
                    "recall_at_1": 0.63275,
                    "recall_at_3": 0.80112,
                    "recall_at_5": 0.85116,
                    "recall_at_10": 0.90197,
                    "recall_at_20": 0.94031,
                    "precision_at_1": 0.63294,
                    "precision_at_3": 0.26722,
                    "precision_at_5": 0.17038,
                    "precision_at_10": 0.09031,
                    "precision_at_20": 0.04709,
                    "mrr_at_1": 0.6329398177851918,
                    "mrr_at_3": 0.7082852132255363,
                    "mrr_at_5": 0.7198147910517977,
                    "mrr_at_10": 0.7266980160257777,
                    "mrr_at_20": 0.7294168642145508,
                    "main_score": 0.76932,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 38.35406970977783,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.66906,
                    "ndcg_at_3": 0.75889,
                    "ndcg_at_5": 0.77937,
                    "ndcg_at_10": 0.79493,
                    "ndcg_at_20": 0.80278,
                    "map_at_1": 0.66884,
                    "map_at_3": 0.73717,
                    "map_at_5": 0.74861,
                    "map_at_10": 0.75511,
                    "map_at_20": 0.75731,
                    "recall_at_1": 0.66884,
                    "recall_at_3": 0.82126,
                    "recall_at_5": 0.87071,
                    "recall_at_10": 0.91838,
                    "recall_at_20": 0.94906,
                    "precision_at_1": 0.66906,
                    "precision_at_3": 0.27393,
                    "precision_at_5": 0.1743,
                    "precision_at_10": 0.09194,
                    "precision_at_20": 0.04753,
                    "mrr_at_1": 0.6690619786988323,
                    "mrr_at_3": 0.7374192651524787,
                    "mrr_at_5": 0.7488349587236396,
                    "mrr_at_10": 0.7553466786432276,
                    "mrr_at_20": 0.7575246782301189,
                    "main_score": 0.79493,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 40.29250693321228,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.72861,
                    "ndcg_at_3": 0.6675,
                    "ndcg_at_5": 0.64565,
                    "ndcg_at_10": 0.64599,
                    "ndcg_at_20": 0.67521,
                    "map_at_1": 0.19668,
                    "map_at_3": 0.37758,
                    "map_at_5": 0.46143,
                    "map_at_10": 0.53712,
                    "map_at_20": 0.56576,
                    "recall_at_1": 0.19668,
                    "recall_at_3": 0.40466,
                    "recall_at_5": 0.51596,
                    "recall_at_10": 0.64187,
                    "recall_at_20": 0.72882,
                    "precision_at_1": 0.72861,
                    "precision_at_3": 0.58994,
                    "precision_at_5": 0.48936,
                    "precision_at_10": 0.33061,
                    "precision_at_20": 0.193,
                    "mrr_at_1": 0.7286077503068561,
                    "mrr_at_3": 0.7735402419779108,
                    "mrr_at_5": 0.7809420480448971,
                    "mrr_at_10": 0.7853395177698244,
                    "mrr_at_20": 0.7872204654885419,
                    "main_score": 0.64599,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2644.378758430481,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.29938,
                    "ndcg_at_3": 0.27589,
                    "ndcg_at_5": 0.28361,
                    "ndcg_at_10": 0.31144,
                    "ndcg_at_20": 0.33571,
                    "map_at_1": 0.14903,
                    "map_at_3": 0.20851,
                    "map_at_5": 0.22479,
                    "map_at_10": 0.24266,
                    "map_at_20": 0.2517,
                    "recall_at_1": 0.14903,
                    "recall_at_3": 0.24896,
                    "recall_at_5": 0.29412,
                    "recall_at_10": 0.37476,
                    "recall_at_20": 0.4506,
                    "precision_at_1": 0.29938,
                    "precision_at_3": 0.18261,
                    "precision_at_5": 0.13611,
                    "precision_at_10": 0.09043,
                    "precision_at_20": 0.05494,
                    "mrr_at_1": 0.2993827160493827,
                    "mrr_at_3": 0.35570987654321007,
                    "mrr_at_5": 0.369675925925926,
                    "mrr_at_10": 0.3817521555947481,
                    "mrr_at_20": 0.38723559702124377,
                    "main_score": 0.31144,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 101.17038035392761,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.5764,
                    "ndcg_at_3": 0.67613,
                    "ndcg_at_5": 0.69933,
                    "ndcg_at_10": 0.7187,
                    "ndcg_at_20": 0.7302,
                    "map_at_1": 0.57455,
                    "map_at_3": 0.65148,
                    "map_at_5": 0.66455,
                    "map_at_10": 0.67265,
                    "map_at_20": 0.67582,
                    "recall_at_1": 0.57455,
                    "recall_at_3": 0.74552,
                    "recall_at_5": 0.80216,
                    "recall_at_10": 0.86196,
                    "recall_at_20": 0.90727,
                    "precision_at_1": 0.5764,
                    "precision_at_3": 0.25009,
                    "precision_at_5": 0.16185,
                    "precision_at_10": 0.08704,
                    "precision_at_20": 0.04579,
                    "mrr_at_1": 0.5763962065331928,
                    "mrr_at_3": 0.6522655426765016,
                    "mrr_at_5": 0.6650158061116968,
                    "mrr_at_10": 0.6728624115610423,
                    "mrr_at_20": 0.6760315833702525,
                    "main_score": 0.7187,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 222.80323362350464,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.75592,
                    "ndcg_at_3": 0.69321,
                    "ndcg_at_5": 0.67148,
                    "ndcg_at_10": 0.67142,
                    "map_at_1": 0.20725,
                    "map_at_3": 0.39783,
                    "map_at_5": 0.4862,
                    "map_at_10": 0.56529,
                    "recall_at_1": 0.20725,
                    "recall_at_3": 0.42395,
                    "recall_at_5": 0.53813,
                    "recall_at_10": 0.66535,
                    "precision_at_1": 0.75592,
                    "precision_at_3": 0.61096,
                    "precision_at_5": 0.50743,
                    "precision_at_10": 0.34175,
                    "mrr_at_1": 0.7559179379274066,
                    "mrr_at_3": 0.7960941609679142,
                    "mrr_at_5": 0.8027266351043378,
                    "mrr_at_10": 0.806643885562882,
                    "main_score": 0.67142,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1354.0091488361359,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.74568,
                    "ndcg_at_3": 0.80826,
                    "ndcg_at_5": 0.8216,
                    "ndcg_at_10": 0.83305,
                    "ndcg_at_20": 0.83986,
                    "map_at_1": 0.74526,
                    "map_at_3": 0.79303,
                    "map_at_5": 0.80049,
                    "map_at_10": 0.80529,
                    "map_at_20": 0.80721,
                    "recall_at_1": 0.74526,
                    "recall_at_3": 0.85123,
                    "recall_at_5": 0.8836,
                    "recall_at_10": 0.91851,
                    "recall_at_20": 0.9449,
                    "precision_at_1": 0.74568,
                    "precision_at_3": 0.28421,
                    "precision_at_5": 0.17711,
                    "precision_at_10": 0.09218,
                    "precision_at_20": 0.04751,
                    "mrr_at_1": 0.74568345323741,
                    "mrr_at_3": 0.7936850519584344,
                    "mrr_at_5": 0.8011590727418125,
                    "mrr_at_10": 0.805986163450198,
                    "mrr_at_20": 0.8078544575210743,
                    "main_score": 0.83305,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 34.575448989868164,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.76462,
                    "ndcg_at_3": 0.82472,
                    "ndcg_at_5": 0.83715,
                    "ndcg_at_10": 0.8475,
                    "ndcg_at_20": 0.85347,
                    "map_at_1": 0.76419,
                    "map_at_3": 0.81026,
                    "map_at_5": 0.81722,
                    "map_at_10": 0.82156,
                    "map_at_20": 0.82325,
                    "recall_at_1": 0.76419,
                    "recall_at_3": 0.86552,
                    "recall_at_5": 0.89568,
                    "recall_at_10": 0.92718,
                    "recall_at_20": 0.95032,
                    "precision_at_1": 0.76462,
                    "precision_at_3": 0.28899,
                    "precision_at_5": 0.17952,
                    "precision_at_10": 0.09304,
                    "precision_at_20": 0.04777,
                    "mrr_at_1": 0.7646236773807147,
                    "mrr_at_3": 0.810813868370265,
                    "mrr_at_5": 0.8177813269448351,
                    "mrr_at_10": 0.8221539166009155,
                    "mrr_at_20": 0.8238085536911753,
                    "main_score": 0.8475,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 49.20669674873352,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.96308,
                    "ndcg_at_3": 0.97877,
                    "ndcg_at_5": 0.98023,
                    "ndcg_at_10": 0.98113,
                    "ndcg_at_20": 0.98158,
                    "map_at_1": 0.96304,
                    "map_at_3": 0.97525,
                    "map_at_5": 0.97607,
                    "map_at_10": 0.97645,
                    "map_at_20": 0.97658,
                    "recall_at_1": 0.96304,
                    "recall_at_3": 0.98878,
                    "recall_at_5": 0.99227,
                    "recall_at_10": 0.99499,
                    "recall_at_20": 0.99677,
                    "precision_at_1": 0.96308,
                    "precision_at_3": 0.32961,
                    "precision_at_5": 0.19848,
                    "precision_at_10": 0.09951,
                    "precision_at_20": 0.04985,
                    "mrr_at_1": 0.9630833630210189,
                    "mrr_at_3": 0.975292423702648,
                    "mrr_at_5": 0.9761006709416942,
                    "mrr_at_10": 0.976483094276781,
                    "mrr_at_20": 0.97661016147326,
                    "main_score": 0.98113,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 29.151923894882202,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.24706,
                    "ndcg_at_3": 0.25403,
                    "ndcg_at_5": 0.26955,
                    "ndcg_at_10": 0.29659,
                    "map_at_1": 0.15347,
                    "map_at_3": 0.20966,
                    "map_at_5": 0.22491,
                    "map_at_10": 0.23979,
                    "recall_at_1": 0.15347,
                    "recall_at_3": 0.25725,
                    "recall_at_5": 0.30666,
                    "recall_at_10": 0.38506,
                    "precision_at_1": 0.24706,
                    "precision_at_3": 0.14795,
                    "precision_at_5": 0.10833,
                    "precision_at_10": 0.06987,
                    "mrr_at_1": 0.24706176544136035,
                    "mrr_at_3": 0.29811619571559583,
                    "mrr_at_5": 0.3104067683587571,
                    "mrr_at_10": 0.3211631280836085,
                    "main_score": 0.29659,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 204.68431997299194,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.381,
                    "ndcg_at_3": 0.44351,
                    "ndcg_at_5": 0.45375,
                    "ndcg_at_10": 0.46747,
                    "ndcg_at_20": 0.48202,
                    "map_at_1": 0.381,
                    "map_at_3": 0.42783,
                    "map_at_5": 0.43348,
                    "map_at_10": 0.43922,
                    "map_at_20": 0.4433,
                    "recall_at_1": 0.381,
                    "recall_at_3": 0.489,
                    "recall_at_5": 0.514,
                    "recall_at_10": 0.556,
                    "recall_at_20": 0.613,
                    "precision_at_1": 0.381,
                    "precision_at_3": 0.163,
                    "precision_at_5": 0.1028,
                    "precision_at_10": 0.0556,
                    "precision_at_20": 0.03065,
                    "mrr_at_1": 0.381,
                    "mrr_at_3": 0.42783333333333307,
                    "mrr_at_5": 0.433483333333333,
                    "mrr_at_10": 0.43921825396825376,
                    "mrr_at_20": 0.4433026470004019,
                    "main_score": 0.46747,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 87.30091166496277,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.51175,
                    "ndcg_at_3": 0.59185,
                    "ndcg_at_5": 0.61794,
                    "ndcg_at_10": 0.64062,
                    "ndcg_at_20": 0.65433,
                    "map_at_1": 0.49314,
                    "map_at_3": 0.568,
                    "map_at_5": 0.58318,
                    "map_at_10": 0.59305,
                    "map_at_20": 0.59697,
                    "recall_at_1": 0.49314,
                    "recall_at_3": 0.65025,
                    "recall_at_5": 0.71271,
                    "recall_at_10": 0.78095,
                    "recall_at_20": 0.83413,
                    "precision_at_1": 0.51175,
                    "precision_at_3": 0.22899,
                    "precision_at_5": 0.15112,
                    "precision_at_10": 0.08297,
                    "precision_at_20": 0.04437,
                    "mrr_at_1": 0.5117478510028654,
                    "mrr_at_3": 0.578462273161417,
                    "mrr_at_5": 0.5920654250238788,
                    "mrr_at_10": 0.6010808091144779,
                    "mrr_at_20": 0.604664352103459,
                    "main_score": 0.64062,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2230.508868455887,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.783,
                    "ndcg_at_3": 0.73895,
                    "ndcg_at_5": 0.73097,
                    "ndcg_at_10": 0.76217,
                    "ndcg_at_20": 0.7885,
                    "map_at_1": 0.2184,
                    "map_at_3": 0.44935,
                    "map_at_5": 0.56625,
                    "map_at_10": 0.65801,
                    "map_at_20": 0.68516,
                    "recall_at_1": 0.2184,
                    "recall_at_3": 0.48585,
                    "recall_at_5": 0.63959,
                    "recall_at_10": 0.78919,
                    "recall_at_20": 0.86398,
                    "precision_at_1": 0.783,
                    "precision_at_3": 0.662,
                    "precision_at_5": 0.5632,
                    "precision_at_10": 0.37215,
                    "precision_at_20": 0.21015,
                    "mrr_at_1": 0.783,
                    "mrr_at_3": 0.8455833333333327,
                    "mrr_at_5": 0.850983333333333,
                    "mrr_at_10": 0.8535708333333327,
                    "mrr_at_20": 0.8542381655109592,
                    "main_score": 0.76217,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 195.6847038269043,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "2e643e7363944af1c33a652d1c87320d0871c4e4",
        "task_name": "NarrativeQAChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.35749,
                    "ndcg_at_3": 0.44776,
                    "ndcg_at_5": 0.47529,
                    "ndcg_at_10": 0.50263,
                    "map_at_1": 0.35749,
                    "map_at_3": 0.42559,
                    "map_at_5": 0.44086,
                    "map_at_10": 0.45221,
                    "recall_at_1": 0.35749,
                    "recall_at_3": 0.51189,
                    "recall_at_5": 0.57876,
                    "recall_at_10": 0.66297,
                    "precision_at_1": 0.35749,
                    "precision_at_3": 0.17063,
                    "precision_at_5": 0.11575,
                    "precision_at_10": 0.0663,
                    "mrr_at_1": 0.357487922705314,
                    "mrr_at_3": 0.42559439234631113,
                    "mrr_at_5": 0.44085914559060135,
                    "mrr_at_10": 0.45220623944693206,
                    "main_score": 0.50263,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 619.8774919509888,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "2e643e7363944af1c33a652d1c87320d0871c4e4",
        "task_name": "NarrativeQAChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.35986,
                    "ndcg_at_3": 0.45332,
                    "ndcg_at_5": 0.48196,
                    "ndcg_at_10": 0.50946,
                    "ndcg_at_20": 0.52961,
                    "map_at_1": 0.35986,
                    "map_at_3": 0.43039,
                    "map_at_5": 0.44622,
                    "map_at_10": 0.45755,
                    "map_at_20": 0.46308,
                    "recall_at_1": 0.35986,
                    "recall_at_3": 0.51966,
                    "recall_at_5": 0.58947,
                    "recall_at_10": 0.67462,
                    "recall_at_20": 0.75429,
                    "precision_at_1": 0.35986,
                    "precision_at_3": 0.17322,
                    "precision_at_5": 0.11789,
                    "precision_at_10": 0.06746,
                    "precision_at_20": 0.03771,
                    "mrr_at_1": 0.35985601970256703,
                    "mrr_at_3": 0.4303937355940781,
                    "mrr_at_5": 0.446217359729719,
                    "mrr_at_10": 0.4575466364753087,
                    "mrr_at_20": 0.46308160022618455,
                    "main_score": 0.50946,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 1434.7299938201904,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.55427,
                    "ndcg_at_3": 0.64858,
                    "ndcg_at_5": 0.67559,
                    "ndcg_at_10": 0.69865,
                    "map_at_1": 0.55321,
                    "map_at_3": 0.62592,
                    "map_at_5": 0.64102,
                    "map_at_10": 0.65084,
                    "recall_at_1": 0.55321,
                    "recall_at_3": 0.71312,
                    "recall_at_5": 0.77819,
                    "recall_at_10": 0.84826,
                    "precision_at_1": 0.55427,
                    "precision_at_3": 0.23885,
                    "precision_at_5": 0.1568,
                    "precision_at_10": 0.08556,
                    "mrr_at_1": 0.553213909378293,
                    "mrr_at_3": 0.6259220231822972,
                    "mrr_at_5": 0.6407797681770286,
                    "mrr_at_10": 0.6505067991369363,
                    "main_score": 0.69865,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 207.05328941345215,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.62998,
                    "ndcg_at_3": 0.72609,
                    "ndcg_at_5": 0.74673,
                    "ndcg_at_10": 0.76379,
                    "ndcg_at_20": 0.77354,
                    "map_at_1": 0.62855,
                    "map_at_3": 0.70238,
                    "map_at_5": 0.71394,
                    "map_at_10": 0.72115,
                    "map_at_20": 0.72391,
                    "recall_at_1": 0.62855,
                    "recall_at_3": 0.79271,
                    "recall_at_5": 0.8425,
                    "recall_at_10": 0.89441,
                    "recall_at_20": 0.93217,
                    "precision_at_1": 0.62998,
                    "precision_at_3": 0.26535,
                    "precision_at_5": 0.16948,
                    "precision_at_10": 0.0902,
                    "precision_at_20": 0.04718,
                    "mrr_at_1": 0.6299076645897456,
                    "mrr_at_3": 0.7039136200985947,
                    "mrr_at_5": 0.7153823536771616,
                    "mrr_at_10": 0.7224830438393711,
                    "mrr_at_20": 0.7251297259797617,
                    "main_score": 0.76379,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 40.30966901779175,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.35449,
                    "ndcg_at_3": 0.30655,
                    "ndcg_at_5": 0.28552,
                    "ndcg_at_10": 0.26156,
                    "ndcg_at_20": 0.24766,
                    "map_at_1": 0.03959,
                    "map_at_3": 0.06354,
                    "map_at_5": 0.07218,
                    "map_at_10": 0.08602,
                    "map_at_20": 0.09727,
                    "recall_at_1": 0.03959,
                    "recall_at_3": 0.07067,
                    "recall_at_5": 0.08674,
                    "recall_at_10": 0.1225,
                    "recall_at_20": 0.16629,
                    "precision_at_1": 0.36533,
                    "precision_at_3": 0.28896,
                    "precision_at_5": 0.2483,
                    "precision_at_10": 0.19721,
                    "precision_at_20": 0.14954,
                    "mrr_at_1": 0.3684210526315789,
                    "mrr_at_3": 0.42621259029927755,
                    "mrr_at_5": 0.4384416924664603,
                    "mrr_at_10": 0.44954420364637104,
                    "mrr_at_20": 0.4539529656789721,
                    "main_score": 0.26156,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 19.009437084197998,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.271,
                    "ndcg_at_3": 0.35859,
                    "ndcg_at_5": 0.39,
                    "ndcg_at_10": 0.4158,
                    "ndcg_at_20": 0.43681,
                    "map_at_1": 0.271,
                    "map_at_3": 0.33733,
                    "map_at_5": 0.35458,
                    "map_at_10": 0.36518,
                    "map_at_20": 0.37097,
                    "recall_at_1": 0.271,
                    "recall_at_3": 0.42,
                    "recall_at_5": 0.497,
                    "recall_at_10": 0.577,
                    "recall_at_20": 0.66,
                    "precision_at_1": 0.271,
                    "precision_at_3": 0.14,
                    "precision_at_5": 0.0994,
                    "precision_at_10": 0.0577,
                    "precision_at_20": 0.033,
                    "mrr_at_1": 0.271,
                    "mrr_at_3": 0.33733333333333326,
                    "mrr_at_5": 0.354583333333333,
                    "mrr_at_10": 0.36518253968253933,
                    "mrr_at_20": 0.3709673859164566,
                    "main_score": 0.4158,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 50.98732924461365,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.8347,
                    "ndcg_at_3": 0.8708,
                    "ndcg_at_5": 0.87689,
                    "ndcg_at_10": 0.88212,
                    "ndcg_at_20": 0.88561,
                    "map_at_1": 0.8347,
                    "map_at_3": 0.86232,
                    "map_at_5": 0.86568,
                    "map_at_10": 0.86786,
                    "map_at_20": 0.86883,
                    "recall_at_1": 0.8347,
                    "recall_at_3": 0.8952,
                    "recall_at_5": 0.91,
                    "recall_at_10": 0.9261,
                    "recall_at_20": 0.9398,
                    "precision_at_1": 0.8347,
                    "precision_at_3": 0.2984,
                    "precision_at_5": 0.182,
                    "precision_at_10": 0.09261,
                    "precision_at_20": 0.04699,
                    "mrr_at_1": 0.8347,
                    "mrr_at_3": 0.8623166666666692,
                    "mrr_at_5": 0.8656841666666713,
                    "mrr_at_10": 0.8678579563492107,
                    "mrr_at_20": 0.868828940663745,
                    "main_score": 0.88212,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 281.3493022918701,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.95523,
                    "ndcg_at_3": 0.97313,
                    "ndcg_at_5": 0.97447,
                    "ndcg_at_10": 0.97569,
                    "ndcg_at_20": 0.97638,
                    "map_at_1": 0.95523,
                    "map_at_3": 0.96912,
                    "map_at_5": 0.96987,
                    "map_at_10": 0.97037,
                    "map_at_20": 0.97056,
                    "recall_at_1": 0.95523,
                    "recall_at_3": 0.98459,
                    "recall_at_5": 0.98783,
                    "recall_at_10": 0.99156,
                    "recall_at_20": 0.99427,
                    "precision_at_1": 0.95523,
                    "precision_at_3": 0.3282,
                    "precision_at_5": 0.19757,
                    "precision_at_10": 0.09916,
                    "precision_at_20": 0.04971,
                    "mrr_at_1": 0.9552298467688208,
                    "mrr_at_3": 0.9691168850396028,
                    "mrr_at_5": 0.9698674957435784,
                    "mrr_at_10": 0.9703713926165627,
                    "mrr_at_20": 0.9705642663772382,
                    "main_score": 0.97569,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 53.90750312805176,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.96308,
                    "ndcg_at_3": 0.97876,
                    "ndcg_at_5": 0.98022,
                    "ndcg_at_10": 0.98112,
                    "ndcg_at_20": 0.98158,
                    "map_at_1": 0.96304,
                    "map_at_3": 0.97524,
                    "map_at_5": 0.97606,
                    "map_at_10": 0.97645,
                    "map_at_20": 0.97657,
                    "recall_at_1": 0.96304,
                    "recall_at_3": 0.98878,
                    "recall_at_5": 0.99227,
                    "recall_at_10": 0.99499,
                    "recall_at_20": 0.99677,
                    "precision_at_1": 0.96308,
                    "precision_at_3": 0.32961,
                    "precision_at_5": 0.19848,
                    "precision_at_10": 0.09951,
                    "precision_at_20": 0.04985,
                    "mrr_at_1": 0.9630833630210189,
                    "mrr_at_3": 0.975285001781261,
                    "mrr_at_5": 0.9760932490203071,
                    "mrr_at_10": 0.9764756723553939,
                    "mrr_at_20": 0.9766027395518729,
                    "main_score": 0.98112,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 53.100563287734985,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "6e346642246bfb4928c560ee08640dc84d074e8c",
        "task_name": "LEMBWikimQARetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.42667,
                    "ndcg_at_3": 0.50881,
                    "ndcg_at_5": 0.53348,
                    "ndcg_at_10": 0.57056,
                    "map_at_1": 0.42667,
                    "map_at_3": 0.48778,
                    "map_at_5": 0.50144,
                    "map_at_10": 0.51699,
                    "recall_at_1": 0.42667,
                    "recall_at_3": 0.57,
                    "recall_at_5": 0.63,
                    "recall_at_10": 0.74333,
                    "precision_at_1": 0.42667,
                    "precision_at_3": 0.19,
                    "precision_at_5": 0.126,
                    "precision_at_10": 0.07433,
                    "mrr_at_1": 0.4266666666666667,
                    "mrr_at_3": 0.4877777777777777,
                    "mrr_at_5": 0.5014444444444442,
                    "mrr_at_10": 0.5169947089947089,
                    "main_score": 0.57056,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 24.271262407302856,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.35032,
                    "ndcg_at_3": 0.43193,
                    "ndcg_at_5": 0.45581,
                    "ndcg_at_10": 0.48017,
                    "ndcg_at_20": 0.49752,
                    "map_at_1": 0.34948,
                    "map_at_3": 0.41154,
                    "map_at_5": 0.42481,
                    "map_at_10": 0.43492,
                    "map_at_20": 0.43973,
                    "recall_at_1": 0.34948,
                    "recall_at_3": 0.48975,
                    "recall_at_5": 0.54756,
                    "recall_at_10": 0.62232,
                    "recall_at_20": 0.69033,
                    "precision_at_1": 0.35032,
                    "precision_at_3": 0.16392,
                    "precision_at_5": 0.11015,
                    "precision_at_10": 0.06278,
                    "precision_at_20": 0.03493,
                    "mrr_at_1": 0.350354556710314,
                    "mrr_at_3": 0.41254267812254086,
                    "mrr_at_5": 0.42589201966008283,
                    "mrr_at_10": 0.436017581034097,
                    "mrr_at_20": 0.44079170825020303,
                    "main_score": 0.48017,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 37.30588173866272,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.64057,
                    "ndcg_at_3": 0.73205,
                    "ndcg_at_5": 0.75242,
                    "ndcg_at_10": 0.76884,
                    "ndcg_at_20": 0.77802,
                    "map_at_1": 0.63917,
                    "map_at_3": 0.70943,
                    "map_at_5": 0.72082,
                    "map_at_10": 0.72774,
                    "map_at_20": 0.73035,
                    "recall_at_1": 0.63917,
                    "recall_at_3": 0.7955,
                    "recall_at_5": 0.84474,
                    "recall_at_10": 0.89466,
                    "recall_at_20": 0.93018,
                    "precision_at_1": 0.64057,
                    "precision_at_3": 0.2664,
                    "precision_at_5": 0.17003,
                    "precision_at_10": 0.09033,
                    "precision_at_20": 0.04712,
                    "mrr_at_1": 0.6405657899673582,
                    "mrr_at_3": 0.7109456096249345,
                    "mrr_at_5": 0.7223214397378745,
                    "mrr_at_10": 0.7291320730445864,
                    "mrr_at_20": 0.7315791324911274,
                    "main_score": 0.76884,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 34.308488607406616,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.23302,
                    "ndcg_at_3": 0.22108,
                    "ndcg_at_5": 0.22819,
                    "ndcg_at_10": 0.25087,
                    "ndcg_at_20": 0.27103,
                    "map_at_1": 0.11828,
                    "map_at_3": 0.16302,
                    "map_at_5": 0.1775,
                    "map_at_10": 0.19051,
                    "map_at_20": 0.19701,
                    "recall_at_1": 0.11828,
                    "recall_at_3": 0.19819,
                    "recall_at_5": 0.24097,
                    "recall_at_10": 0.31066,
                    "recall_at_20": 0.3732,
                    "precision_at_1": 0.23302,
                    "precision_at_3": 0.14918,
                    "precision_at_5": 0.1108,
                    "precision_at_10": 0.07176,
                    "precision_at_20": 0.04429,
                    "mrr_at_1": 0.2330246913580247,
                    "mrr_at_3": 0.28780864197530875,
                    "mrr_at_5": 0.29976851851851855,
                    "mrr_at_10": 0.31166715657456395,
                    "mrr_at_20": 0.31680094388606894,
                    "main_score": 0.25087,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 104.19589519500732,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.74237,
                    "ndcg_at_3": 0.80439,
                    "ndcg_at_5": 0.81707,
                    "ndcg_at_10": 0.82822,
                    "ndcg_at_20": 0.83542,
                    "map_at_1": 0.74207,
                    "map_at_3": 0.78929,
                    "map_at_5": 0.79637,
                    "map_at_10": 0.80101,
                    "map_at_20": 0.80303,
                    "recall_at_1": 0.74207,
                    "recall_at_3": 0.84722,
                    "recall_at_5": 0.87796,
                    "recall_at_10": 0.91208,
                    "recall_at_20": 0.94013,
                    "precision_at_1": 0.74237,
                    "precision_at_3": 0.28276,
                    "precision_at_5": 0.17592,
                    "precision_at_10": 0.09151,
                    "precision_at_20": 0.04726,
                    "mrr_at_1": 0.7423661071143085,
                    "mrr_at_3": 0.7898148148148161,
                    "mrr_at_5": 0.7969171329603036,
                    "mrr_at_10": 0.8015795300267781,
                    "mrr_at_20": 0.8035622202200524,
                    "main_score": 0.82822,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 33.63505291938782,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.8346,
                    "ndcg_at_3": 0.87065,
                    "ndcg_at_5": 0.87681,
                    "ndcg_at_10": 0.88204,
                    "ndcg_at_20": 0.88552,
                    "map_at_1": 0.8346,
                    "map_at_3": 0.86218,
                    "map_at_5": 0.86559,
                    "map_at_10": 0.86776,
                    "map_at_20": 0.86872,
                    "recall_at_1": 0.8346,
                    "recall_at_3": 0.895,
                    "recall_at_5": 0.91,
                    "recall_at_10": 0.9261,
                    "recall_at_20": 0.9398,
                    "precision_at_1": 0.8346,
                    "precision_at_3": 0.29833,
                    "precision_at_5": 0.182,
                    "precision_at_10": 0.09261,
                    "precision_at_20": 0.04699,
                    "mrr_at_1": 0.8346,
                    "mrr_at_3": 0.8621750000000026,
                    "mrr_at_5": 0.8655875000000045,
                    "mrr_at_10": 0.8677555357142903,
                    "mrr_at_20": 0.8687236600875531,
                    "main_score": 0.88204,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 151.05747890472412,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.63294,
                    "ndcg_at_3": 0.73208,
                    "ndcg_at_5": 0.75277,
                    "ndcg_at_10": 0.76932,
                    "ndcg_at_20": 0.7791,
                    "map_at_1": 0.63275,
                    "map_at_3": 0.70807,
                    "map_at_5": 0.71961,
                    "map_at_10": 0.7265,
                    "map_at_20": 0.72923,
                    "recall_at_1": 0.63275,
                    "recall_at_3": 0.80112,
                    "recall_at_5": 0.85116,
                    "recall_at_10": 0.90197,
                    "recall_at_20": 0.94031,
                    "precision_at_1": 0.63294,
                    "precision_at_3": 0.26722,
                    "precision_at_5": 0.17038,
                    "precision_at_10": 0.09031,
                    "precision_at_20": 0.04709,
                    "mrr_at_1": 0.6329398177851918,
                    "mrr_at_3": 0.7082852132255363,
                    "mrr_at_5": 0.7198147910517977,
                    "mrr_at_10": 0.7266980160257777,
                    "mrr_at_20": 0.7294168642145508,
                    "main_score": 0.76932,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 30.40700125694275,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.8247,
                    "ndcg_at_3": 0.86343,
                    "ndcg_at_5": 0.86958,
                    "ndcg_at_10": 0.87551,
                    "ndcg_at_20": 0.87926,
                    "map_at_1": 0.8247,
                    "map_at_3": 0.85438,
                    "map_at_5": 0.85779,
                    "map_at_10": 0.86023,
                    "map_at_20": 0.86127,
                    "recall_at_1": 0.8247,
                    "recall_at_3": 0.8894,
                    "recall_at_5": 0.9044,
                    "recall_at_10": 0.9227,
                    "recall_at_20": 0.9375,
                    "precision_at_1": 0.8247,
                    "precision_at_3": 0.29647,
                    "precision_at_5": 0.18088,
                    "precision_at_10": 0.09227,
                    "precision_at_20": 0.04687,
                    "mrr_at_1": 0.8247,
                    "mrr_at_3": 0.8543833333333365,
                    "mrr_at_5": 0.8577858333333381,
                    "mrr_at_10": 0.8602336111111155,
                    "mrr_at_20": 0.8612692837195968,
                    "main_score": 0.87551,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 275.01702642440796,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.779,
                    "ndcg_at_3": 0.74,
                    "ndcg_at_5": 0.73124,
                    "ndcg_at_10": 0.76151,
                    "ndcg_at_20": 0.78848,
                    "map_at_1": 0.21739,
                    "map_at_3": 0.4493,
                    "map_at_5": 0.56634,
                    "map_at_10": 0.65784,
                    "map_at_20": 0.6854,
                    "recall_at_1": 0.21739,
                    "recall_at_3": 0.48634,
                    "recall_at_5": 0.6395,
                    "recall_at_10": 0.78816,
                    "recall_at_20": 0.86417,
                    "precision_at_1": 0.779,
                    "precision_at_3": 0.66383,
                    "precision_at_5": 0.5639,
                    "precision_at_10": 0.3717,
                    "precision_at_20": 0.21065,
                    "mrr_at_1": 0.779,
                    "mrr_at_3": 0.8450833333333331,
                    "mrr_at_5": 0.8502833333333333,
                    "mrr_at_10": 0.8526644841269838,
                    "mrr_at_20": 0.8533541094418993,
                    "main_score": 0.76151,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 262.1699526309967,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.80615,
                    "ndcg_at_3": 0.87165,
                    "ndcg_at_5": 0.88108,
                    "ndcg_at_10": 0.88744,
                    "ndcg_at_20": 0.89124,
                    "map_at_1": 0.80564,
                    "map_at_3": 0.85623,
                    "map_at_5": 0.86152,
                    "map_at_10": 0.86421,
                    "map_at_20": 0.86529,
                    "recall_at_1": 0.80564,
                    "recall_at_3": 0.91561,
                    "recall_at_5": 0.93826,
                    "recall_at_10": 0.95764,
                    "recall_at_20": 0.97235,
                    "precision_at_1": 0.80615,
                    "precision_at_3": 0.3057,
                    "precision_at_5": 0.18803,
                    "precision_at_10": 0.09604,
                    "precision_at_20": 0.04879,
                    "mrr_at_1": 0.8061476131759733,
                    "mrr_at_3": 0.8565116552169457,
                    "mrr_at_5": 0.8618049439257743,
                    "mrr_at_10": 0.8644236047618058,
                    "mrr_at_20": 0.8654831696392113,
                    "main_score": 0.88744,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 91.8982834815979,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.39,
                    "ndcg_at_3": 0.45214,
                    "ndcg_at_5": 0.46165,
                    "ndcg_at_10": 0.47563,
                    "ndcg_at_20": 0.49029,
                    "map_at_1": 0.39,
                    "map_at_3": 0.43667,
                    "map_at_5": 0.44197,
                    "map_at_10": 0.44777,
                    "map_at_20": 0.4518,
                    "recall_at_1": 0.39,
                    "recall_at_3": 0.497,
                    "recall_at_5": 0.52,
                    "recall_at_10": 0.563,
                    "recall_at_20": 0.621,
                    "precision_at_1": 0.39,
                    "precision_at_3": 0.16567,
                    "precision_at_5": 0.104,
                    "precision_at_10": 0.0563,
                    "precision_at_20": 0.03105,
                    "mrr_at_1": 0.392,
                    "mrr_at_3": 0.4376666666666663,
                    "mrr_at_5": 0.4429666666666662,
                    "mrr_at_10": 0.4488980158730154,
                    "mrr_at_20": 0.4528346186235499,
                    "main_score": 0.47563,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2588.094608068466,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "2e643e7363944af1c33a652d1c87320d0871c4e4",
        "task_name": "NarrativeQAChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.37691,
                    "ndcg_at_3": 0.46597,
                    "ndcg_at_5": 0.49454,
                    "ndcg_at_10": 0.5218,
                    "ndcg_at_20": 0.54111,
                    "map_at_1": 0.37691,
                    "map_at_3": 0.44408,
                    "map_at_5": 0.45996,
                    "map_at_10": 0.47131,
                    "map_at_20": 0.47662,
                    "recall_at_1": 0.37691,
                    "recall_at_3": 0.52932,
                    "recall_at_5": 0.59856,
                    "recall_at_10": 0.6823,
                    "recall_at_20": 0.75864,
                    "precision_at_1": 0.37691,
                    "precision_at_3": 0.17644,
                    "precision_at_5": 0.11971,
                    "precision_at_10": 0.06823,
                    "precision_at_20": 0.03793,
                    "mrr_at_1": 0.3769063180827887,
                    "mrr_at_3": 0.4440813362381989,
                    "mrr_at_5": 0.459961794701774,
                    "mrr_at_10": 0.4713115949546733,
                    "mrr_at_20": 0.4766182791988159,
                    "main_score": 0.5218,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 2781.471435070038,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "fixed_token",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.65202,
                    "ndcg_at_3": 0.7449,
                    "ndcg_at_5": 0.7648,
                    "ndcg_at_10": 0.78084,
                    "ndcg_at_20": 0.78934,
                    "map_at_1": 0.65048,
                    "map_at_3": 0.72182,
                    "map_at_5": 0.73298,
                    "map_at_10": 0.73978,
                    "map_at_20": 0.74221,
                    "recall_at_1": 0.65048,
                    "recall_at_3": 0.80927,
                    "recall_at_5": 0.8574,
                    "recall_at_10": 0.90618,
                    "recall_at_20": 0.93894,
                    "precision_at_1": 0.65202,
                    "precision_at_3": 0.27109,
                    "precision_at_5": 0.17257,
                    "precision_at_10": 0.09149,
                    "precision_at_20": 0.04758,
                    "mrr_at_1": 0.6520531491629757,
                    "mrr_at_3": 0.7236381152566138,
                    "mrr_at_5": 0.7347371318469662,
                    "mrr_at_10": 0.7413279754010631,
                    "mrr_at_20": 0.7436311119324489,
                    "main_score": 0.78084,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 75.88774991035461,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "semantic_llama_index",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.6352,
                    "ndcg_at_3": 0.7282,
                    "ndcg_at_5": 0.74762,
                    "ndcg_at_10": 0.76428,
                    "ndcg_at_20": 0.77371,
                    "map_at_1": 0.63405,
                    "map_at_3": 0.70538,
                    "map_at_5": 0.71622,
                    "map_at_10": 0.72328,
                    "map_at_20": 0.72595,
                    "recall_at_1": 0.63405,
                    "recall_at_3": 0.79263,
                    "recall_at_5": 0.83953,
                    "recall_at_10": 0.89001,
                    "recall_at_20": 0.92645,
                    "precision_at_1": 0.6352,
                    "precision_at_3": 0.26524,
                    "precision_at_5": 0.16879,
                    "precision_at_10": 0.08974,
                    "precision_at_20": 0.04688,
                    "mrr_at_1": 0.6351255018196826,
                    "mrr_at_3": 0.7064620618066777,
                    "mrr_at_5": 0.717350141947757,
                    "mrr_at_10": 0.724231585354168,
                    "mrr_at_20": 0.7268417228869438,
                    "main_score": 0.76428,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 370.0963523387909,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "semantic_llama_index",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.45754,
                    "ndcg_at_3": 0.52151,
                    "ndcg_at_5": 0.53799,
                    "ndcg_at_10": 0.5548,
                    "ndcg_at_20": 0.56716,
                    "map_at_1": 0.45735,
                    "map_at_3": 0.50604,
                    "map_at_5": 0.51522,
                    "map_at_10": 0.52221,
                    "map_at_20": 0.52562,
                    "recall_at_1": 0.45735,
                    "recall_at_3": 0.56583,
                    "recall_at_5": 0.60581,
                    "recall_at_10": 0.65746,
                    "recall_at_20": 0.70626,
                    "precision_at_1": 0.45754,
                    "precision_at_3": 0.18873,
                    "precision_at_5": 0.12125,
                    "precision_at_10": 0.06582,
                    "precision_at_20": 0.03536,
                    "mrr_at_1": 0.45753643441804753,
                    "mrr_at_3": 0.5062620616224175,
                    "mrr_at_5": 0.5154275637186476,
                    "mrr_at_10": 0.5224470556173563,
                    "mrr_at_20": 0.5258644894892882,
                    "main_score": 0.5548,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 257.0750195980072,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "semantic_llama_index",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.46208,
                    "ndcg_at_3": 0.55208,
                    "ndcg_at_5": 0.57518,
                    "ndcg_at_10": 0.59571,
                    "ndcg_at_20": 0.60949,
                    "map_at_1": 0.46199,
                    "map_at_3": 0.53011,
                    "map_at_5": 0.54295,
                    "map_at_10": 0.55149,
                    "map_at_20": 0.5553,
                    "recall_at_1": 0.46199,
                    "recall_at_3": 0.61551,
                    "recall_at_5": 0.67148,
                    "recall_at_10": 0.73456,
                    "recall_at_20": 0.78886,
                    "precision_at_1": 0.46208,
                    "precision_at_3": 0.20524,
                    "precision_at_5": 0.13435,
                    "precision_at_10": 0.07349,
                    "precision_at_20": 0.03946,
                    "mrr_at_1": 0.46208135506223535,
                    "mrr_at_3": 0.5301926942983135,
                    "mrr_at_5": 0.5430343470636219,
                    "mrr_at_10": 0.5515813565898717,
                    "mrr_at_20": 0.5553897108244928,
                    "main_score": 0.59571,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 298.8291435241699,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "semantic_llama_index",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.463,
                    "ndcg_at_3": 0.55825,
                    "ndcg_at_5": 0.58097,
                    "ndcg_at_10": 0.60613,
                    "ndcg_at_20": 0.62403,
                    "map_at_1": 0.463,
                    "map_at_3": 0.53483,
                    "map_at_5": 0.54748,
                    "map_at_10": 0.55782,
                    "map_at_20": 0.56284,
                    "recall_at_1": 0.463,
                    "recall_at_3": 0.626,
                    "recall_at_5": 0.681,
                    "recall_at_10": 0.759,
                    "recall_at_20": 0.829,
                    "precision_at_1": 0.463,
                    "precision_at_3": 0.20867,
                    "precision_at_5": 0.1362,
                    "precision_at_10": 0.0759,
                    "precision_at_20": 0.04145,
                    "mrr_at_1": 0.463,
                    "mrr_at_3": 0.5348333333333328,
                    "mrr_at_5": 0.5474833333333328,
                    "mrr_at_10": 0.557821428571428,
                    "mrr_at_20": 0.5628396226494518,
                    "main_score": 0.60613,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 4740.0544493198395,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "semantic_llama_index",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "2e643e7363944af1c33a652d1c87320d0871c4e4",
        "task_name": "NarrativeQAChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.33447,
                    "ndcg_at_3": 0.42765,
                    "ndcg_at_5": 0.45733,
                    "ndcg_at_10": 0.48585,
                    "ndcg_at_20": 0.50586,
                    "map_at_1": 0.33447,
                    "map_at_3": 0.40458,
                    "map_at_5": 0.42101,
                    "map_at_10": 0.43282,
                    "map_at_20": 0.43835,
                    "recall_at_1": 0.33447,
                    "recall_at_3": 0.49446,
                    "recall_at_5": 0.56673,
                    "recall_at_10": 0.65473,
                    "recall_at_20": 0.73354,
                    "precision_at_1": 0.33447,
                    "precision_at_3": 0.16482,
                    "precision_at_5": 0.11335,
                    "precision_at_10": 0.06547,
                    "precision_at_20": 0.03668,
                    "mrr_at_1": 0.3344700198920148,
                    "mrr_at_3": 0.4045814783240209,
                    "mrr_at_5": 0.4210065990969648,
                    "mrr_at_10": 0.43281144986174885,
                    "mrr_at_20": 0.4383405071271001,
                    "main_score": 0.48585,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 10359.55142736435,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "semantic_llama_index",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.31158,
                    "ndcg_at_3": 0.31351,
                    "ndcg_at_5": 0.32989,
                    "ndcg_at_10": 0.35887,
                    "ndcg_at_20": 0.38334,
                    "map_at_1": 0.20082,
                    "map_at_3": 0.2652,
                    "map_at_5": 0.2825,
                    "map_at_10": 0.29896,
                    "map_at_20": 0.30752,
                    "recall_at_1": 0.20082,
                    "recall_at_3": 0.31153,
                    "recall_at_5": 0.36497,
                    "recall_at_10": 0.44974,
                    "recall_at_20": 0.53282,
                    "precision_at_1": 0.31158,
                    "precision_at_3": 0.17871,
                    "precision_at_5": 0.12878,
                    "precision_at_10": 0.08137,
                    "precision_at_20": 0.04902,
                    "mrr_at_1": 0.3115778944736184,
                    "mrr_at_3": 0.36267400183379134,
                    "mrr_at_5": 0.3751646244894557,
                    "mrr_at_10": 0.38623683698702405,
                    "mrr_at_20": 0.39163136710374596,
                    "main_score": 0.35887,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 4305.741488695145,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "semantic_llama_index",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "bb9466bac8153a0349341eb1b22e06409e78ef4e",
        "task_name": "TRECCOVIDChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.91,
                    "ndcg_at_3": 0.83101,
                    "ndcg_at_5": 0.81233,
                    "ndcg_at_10": 0.77547,
                    "ndcg_at_20": 0.72513,
                    "map_at_1": 0.00251,
                    "map_at_3": 0.00676,
                    "map_at_5": 0.01081,
                    "map_at_10": 0.01948,
                    "map_at_20": 0.03343,
                    "recall_at_1": 0.00251,
                    "recall_at_3": 0.00695,
                    "recall_at_5": 0.01145,
                    "recall_at_10": 0.02124,
                    "recall_at_20": 0.03813,
                    "precision_at_1": 0.94,
                    "precision_at_3": 0.88,
                    "precision_at_5": 0.856,
                    "precision_at_10": 0.81,
                    "precision_at_20": 0.75,
                    "mrr_at_1": 0.94,
                    "mrr_at_3": 0.95,
                    "mrr_at_5": 0.955,
                    "mrr_at_10": 0.9583333333333335,
                    "mrr_at_20": 0.9583333333333335,
                    "main_score": 0.77547,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 993.2182512283325,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "bb9466bac8153a0349341eb1b22e06409e78ef4e",
        "task_name": "TRECCOVIDChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.71,
                    "ndcg_at_3": 0.68235,
                    "ndcg_at_5": 0.66449,
                    "ndcg_at_10": 0.64686,
                    "map_at_1": 0.00218,
                    "map_at_3": 0.00571,
                    "map_at_5": 0.00857,
                    "map_at_10": 0.0152,
                    "recall_at_1": 0.00218,
                    "recall_at_3": 0.00611,
                    "recall_at_5": 0.0095,
                    "recall_at_10": 0.01793,
                    "precision_at_1": 0.82,
                    "precision_at_3": 0.75333,
                    "precision_at_5": 0.72,
                    "precision_at_10": 0.698,
                    "mrr_at_1": 0.82,
                    "mrr_at_3": 0.8966666666666667,
                    "mrr_at_5": 0.9016666666666667,
                    "mrr_at_10": 0.9016666666666667,
                    "main_score": 0.64686,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 1144.5751042366028,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "Touche2020Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.37755,
                    "ndcg_at_3": 0.32457,
                    "ndcg_at_5": 0.28663,
                    "ndcg_at_10": 0.27108,
                    "ndcg_at_20": 0.27222,
                    "map_at_1": 0.03016,
                    "map_at_3": 0.05852,
                    "map_at_5": 0.07472,
                    "map_at_10": 0.10511,
                    "map_at_20": 0.12861,
                    "recall_at_1": 0.03016,
                    "recall_at_3": 0.07365,
                    "recall_at_5": 0.09972,
                    "recall_at_10": 0.17,
                    "recall_at_20": 0.23896,
                    "precision_at_1": 0.38776,
                    "precision_at_3": 0.32653,
                    "precision_at_5": 0.27347,
                    "precision_at_10": 0.23265,
                    "precision_at_20": 0.16939,
                    "mrr_at_1": 0.3877551020408163,
                    "mrr_at_3": 0.5204081632653061,
                    "mrr_at_5": 0.5357142857142857,
                    "mrr_at_10": 0.5477000323939099,
                    "mrr_at_20": 0.5506011928580955,
                    "main_score": 0.27108,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 11627.861077785492,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "e4e08e0b7dbe3c8700f0daef558ff32256715259",
        "task_name": "QuoraChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.8174,
                    "ndcg_at_3": 0.85708,
                    "ndcg_at_5": 0.87308,
                    "ndcg_at_10": 0.88569,
                    "ndcg_at_20": 0.89182,
                    "map_at_1": 0.70884,
                    "map_at_3": 0.81879,
                    "map_at_5": 0.83759,
                    "map_at_10": 0.84863,
                    "map_at_20": 0.85261,
                    "recall_at_1": 0.70884,
                    "recall_at_3": 0.8735,
                    "recall_at_5": 0.919,
                    "recall_at_10": 0.9561,
                    "recall_at_20": 0.97555,
                    "precision_at_1": 0.8174,
                    "precision_at_3": 0.37513,
                    "precision_at_5": 0.24696,
                    "precision_at_10": 0.13465,
                    "precision_at_20": 0.0713,
                    "mrr_at_1": 0.8171,
                    "mrr_at_3": 0.8680499999999974,
                    "mrr_at_5": 0.8748749999999967,
                    "mrr_at_10": 0.8777537698412667,
                    "mrr_at_20": 0.8784116709773682,
                    "main_score": 0.88569,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 434.0802285671234,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "fixed_token",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "e4e08e0b7dbe3c8700f0daef558ff32256715259",
        "task_name": "QuoraChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.4697,
                    "ndcg_at_3": 0.55024,
                    "ndcg_at_5": 0.58305,
                    "ndcg_at_10": 0.61615,
                    "ndcg_at_20": 0.63816,
                    "map_at_1": 0.41273,
                    "map_at_3": 0.50996,
                    "map_at_5": 0.53344,
                    "map_at_10": 0.55074,
                    "map_at_20": 0.55894,
                    "recall_at_1": 0.41273,
                    "recall_at_3": 0.60106,
                    "recall_at_5": 0.68049,
                    "recall_at_10": 0.77545,
                    "recall_at_20": 0.85254,
                    "precision_at_1": 0.4697,
                    "precision_at_3": 0.24673,
                    "precision_at_5": 0.17422,
                    "precision_at_10": 0.10396,
                    "precision_at_20": 0.05962,
                    "mrr_at_1": 0.4697,
                    "mrr_at_3": 0.5527166666666645,
                    "mrr_at_5": 0.5700016666666611,
                    "mrr_at_10": 0.5818841666666641,
                    "mrr_at_20": 0.5866163960948708,
                    "main_score": 0.61615,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 620.7927894592285,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "Touche2020Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.15306,
                    "ndcg_at_3": 0.17917,
                    "ndcg_at_5": 0.17363,
                    "ndcg_at_10": 0.16133,
                    "map_at_1": 0.01815,
                    "map_at_3": 0.04137,
                    "map_at_5": 0.05324,
                    "map_at_10": 0.06749,
                    "recall_at_1": 0.01815,
                    "recall_at_3": 0.05118,
                    "recall_at_5": 0.07497,
                    "recall_at_10": 0.11089,
                    "precision_at_1": 0.18367,
                    "precision_at_3": 0.20408,
                    "precision_at_5": 0.19184,
                    "precision_at_10": 0.14286,
                    "mrr_at_1": 0.1836734693877551,
                    "mrr_at_3": 0.28911564625850344,
                    "mrr_at_5": 0.31360544217687075,
                    "mrr_at_10": 0.3219873663751215,
                    "main_score": 0.16133,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 18937.93540406227,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "e4e08e0b7dbe3c8700f0daef558ff32256715259",
        "task_name": "QuoraChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.4696,
                    "ndcg_at_3": 0.5502,
                    "ndcg_at_5": 0.58301,
                    "ndcg_at_10": 0.61611,
                    "ndcg_at_20": 0.6381,
                    "map_at_1": 0.41263,
                    "map_at_3": 0.50991,
                    "map_at_5": 0.53339,
                    "map_at_10": 0.55069,
                    "map_at_20": 0.55888,
                    "recall_at_1": 0.41263,
                    "recall_at_3": 0.60106,
                    "recall_at_5": 0.68049,
                    "recall_at_10": 0.77545,
                    "recall_at_20": 0.85249,
                    "precision_at_1": 0.4696,
                    "precision_at_3": 0.24673,
                    "precision_at_5": 0.17422,
                    "precision_at_10": 0.10396,
                    "precision_at_20": 0.05961,
                    "mrr_at_1": 0.4696,
                    "mrr_at_3": 0.5526666666666645,
                    "mrr_at_5": 0.5699516666666611,
                    "mrr_at_10": 0.5818341666666641,
                    "mrr_at_20": 0.5865608466443214,
                    "main_score": 0.61611,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 605.6383373737335,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.59727,
                    "ndcg_at_3": 0.67172,
                    "ndcg_at_5": 0.68651,
                    "ndcg_at_10": 0.69975,
                    "ndcg_at_20": 0.709,
                    "map_at_1": 0.59697,
                    "map_at_3": 0.65406,
                    "map_at_5": 0.66232,
                    "map_at_10": 0.6678,
                    "map_at_20": 0.67036,
                    "recall_at_1": 0.59697,
                    "recall_at_3": 0.72238,
                    "recall_at_5": 0.75812,
                    "recall_at_10": 0.79895,
                    "recall_at_20": 0.83533,
                    "precision_at_1": 0.59727,
                    "precision_at_3": 0.24106,
                    "precision_at_5": 0.15182,
                    "precision_at_10": 0.08002,
                    "precision_at_20": 0.04184,
                    "mrr_at_1": 0.597269524368761,
                    "mrr_at_3": 0.6541935799569332,
                    "mrr_at_5": 0.6624173027989816,
                    "mrr_at_10": 0.6678936563860233,
                    "mrr_at_20": 0.670445900960623,
                    "main_score": 0.69975,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 87.74447417259216,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.59727,
                    "ndcg_at_3": 0.67172,
                    "ndcg_at_5": 0.68651,
                    "ndcg_at_10": 0.69975,
                    "ndcg_at_20": 0.709,
                    "map_at_1": 0.59697,
                    "map_at_3": 0.65406,
                    "map_at_5": 0.66232,
                    "map_at_10": 0.6678,
                    "map_at_20": 0.67036,
                    "recall_at_1": 0.59697,
                    "recall_at_3": 0.72238,
                    "recall_at_5": 0.75812,
                    "recall_at_10": 0.79895,
                    "recall_at_20": 0.83533,
                    "precision_at_1": 0.59727,
                    "precision_at_3": 0.24106,
                    "precision_at_5": 0.15182,
                    "precision_at_10": 0.08002,
                    "precision_at_20": 0.04184,
                    "mrr_at_1": 0.597269524368761,
                    "mrr_at_3": 0.6541935799569332,
                    "mrr_at_5": 0.6624173027989816,
                    "mrr_at_10": 0.6678936563860233,
                    "mrr_at_20": 0.670445900960623,
                    "main_score": 0.69975,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 88.07873892784119,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.61785,
                    "ndcg_at_3": 0.69051,
                    "ndcg_at_5": 0.70533,
                    "ndcg_at_10": 0.71771,
                    "ndcg_at_20": 0.72718,
                    "map_at_1": 0.61752,
                    "map_at_3": 0.67328,
                    "map_at_5": 0.68154,
                    "map_at_10": 0.6867,
                    "map_at_20": 0.68931,
                    "recall_at_1": 0.61752,
                    "recall_at_3": 0.73997,
                    "recall_at_5": 0.77582,
                    "recall_at_10": 0.81385,
                    "recall_at_20": 0.85116,
                    "precision_at_1": 0.61785,
                    "precision_at_3": 0.24695,
                    "precision_at_5": 0.15537,
                    "precision_at_10": 0.08151,
                    "precision_at_20": 0.04263,
                    "mrr_at_1": 0.6178508514386377,
                    "mrr_at_3": 0.6733949892346776,
                    "mrr_at_5": 0.6816260520649828,
                    "mrr_at_10": 0.686782487021036,
                    "mrr_at_20": 0.68938788072885,
                    "main_score": 0.71771,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 93.28897643089294,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 128,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.42035,
                    "ndcg_at_3": 0.49919,
                    "ndcg_at_5": 0.52173,
                    "ndcg_at_10": 0.54436,
                    "ndcg_at_20": 0.56001,
                    "map_at_1": 0.42024,
                    "map_at_3": 0.4797,
                    "map_at_5": 0.4922,
                    "map_at_10": 0.50159,
                    "map_at_20": 0.50591,
                    "recall_at_1": 0.42024,
                    "recall_at_3": 0.55544,
                    "recall_at_5": 0.61025,
                    "recall_at_10": 0.67996,
                    "recall_at_20": 0.74168,
                    "precision_at_1": 0.42035,
                    "precision_at_3": 0.18523,
                    "precision_at_5": 0.12212,
                    "precision_at_10": 0.06804,
                    "precision_at_20": 0.03711,
                    "mrr_at_1": 0.4203451815732067,
                    "mrr_at_3": 0.47980024808589883,
                    "mrr_at_5": 0.4923114761110572,
                    "mrr_at_10": 0.5017071690304239,
                    "mrr_at_20": 0.5060194879708976,
                    "main_score": 0.54436,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 353.39111614227295,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.62338,
                    "ndcg_at_3": 0.71853,
                    "ndcg_at_5": 0.7384,
                    "ndcg_at_10": 0.75519,
                    "ndcg_at_20": 0.76441,
                    "map_at_1": 0.62234,
                    "map_at_3": 0.69541,
                    "map_at_5": 0.70653,
                    "map_at_10": 0.71362,
                    "map_at_20": 0.71625,
                    "recall_at_1": 0.62234,
                    "recall_at_3": 0.78377,
                    "recall_at_5": 0.83171,
                    "recall_at_10": 0.88256,
                    "recall_at_20": 0.91813,
                    "precision_at_1": 0.62338,
                    "precision_at_3": 0.26233,
                    "precision_at_5": 0.16729,
                    "precision_at_10": 0.08904,
                    "precision_at_20": 0.04649,
                    "mrr_at_1": 0.6233444640378194,
                    "mrr_at_3": 0.696538225840746,
                    "mrr_at_5": 0.7075726309733819,
                    "mrr_at_10": 0.7145814759826382,
                    "mrr_at_20": 0.7170866145026912,
                    "main_score": 0.75519,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 357.3734550476074,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.482,
                    "ndcg_at_3": 0.58619,
                    "ndcg_at_5": 0.61187,
                    "ndcg_at_10": 0.63667,
                    "ndcg_at_20": 0.65188,
                    "map_at_1": 0.482,
                    "map_at_3": 0.56067,
                    "map_at_5": 0.57477,
                    "map_at_10": 0.58513,
                    "map_at_20": 0.58933,
                    "recall_at_1": 0.482,
                    "recall_at_3": 0.66,
                    "recall_at_5": 0.723,
                    "recall_at_10": 0.799,
                    "recall_at_20": 0.859,
                    "precision_at_1": 0.482,
                    "precision_at_3": 0.22,
                    "precision_at_5": 0.1446,
                    "precision_at_10": 0.0799,
                    "precision_at_20": 0.04295,
                    "mrr_at_1": 0.482,
                    "mrr_at_3": 0.5606666666666665,
                    "mrr_at_5": 0.5747666666666663,
                    "mrr_at_10": 0.5851269841269838,
                    "mrr_at_20": 0.5893293446878196,
                    "main_score": 0.63667,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 690.3423600196838,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.42522,
                    "ndcg_at_3": 0.49009,
                    "ndcg_at_5": 0.50639,
                    "ndcg_at_10": 0.52297,
                    "ndcg_at_20": 0.53531,
                    "map_at_1": 0.42512,
                    "map_at_3": 0.47429,
                    "map_at_5": 0.48333,
                    "map_at_10": 0.49015,
                    "map_at_20": 0.49354,
                    "recall_at_1": 0.42512,
                    "recall_at_3": 0.53538,
                    "recall_at_5": 0.57501,
                    "recall_at_10": 0.62641,
                    "recall_at_20": 0.67512,
                    "precision_at_1": 0.42522,
                    "precision_at_3": 0.17859,
                    "precision_at_5": 0.11511,
                    "precision_at_10": 0.06273,
                    "precision_at_20": 0.03383,
                    "mrr_at_1": 0.42521982414068743,
                    "mrr_at_3": 0.47450706101785645,
                    "mrr_at_5": 0.4835718092192977,
                    "mrr_at_10": 0.49040562787865627,
                    "mrr_at_20": 0.49381746493227896,
                    "main_score": 0.52297,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 375.4003040790558,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.59771,
                    "ndcg_at_3": 0.68082,
                    "ndcg_at_5": 0.70217,
                    "ndcg_at_10": 0.7234,
                    "ndcg_at_20": 0.73531,
                    "map_at_1": 0.5777,
                    "map_at_3": 0.65684,
                    "map_at_5": 0.66942,
                    "map_at_10": 0.6788,
                    "map_at_20": 0.68229,
                    "recall_at_1": 0.5777,
                    "recall_at_3": 0.74065,
                    "recall_at_5": 0.79146,
                    "recall_at_10": 0.85489,
                    "recall_at_20": 0.90049,
                    "precision_at_1": 0.59771,
                    "precision_at_3": 0.26051,
                    "precision_at_5": 0.16765,
                    "precision_at_10": 0.09079,
                    "precision_at_20": 0.04787,
                    "mrr_at_1": 0.5977077363896848,
                    "mrr_at_3": 0.6662607449856747,
                    "mrr_at_5": 0.6772206303724916,
                    "mrr_at_10": 0.6855800018192575,
                    "mrr_at_20": 0.6887682911293432,
                    "main_score": 0.7234,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2328.04034280777,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.3627,
                    "ndcg_at_3": 0.44828,
                    "ndcg_at_5": 0.47092,
                    "ndcg_at_10": 0.49228,
                    "ndcg_at_20": 0.50709,
                    "map_at_1": 0.36203,
                    "map_at_3": 0.42719,
                    "map_at_5": 0.4398,
                    "map_at_10": 0.44868,
                    "map_at_20": 0.45277,
                    "recall_at_1": 0.36203,
                    "recall_at_3": 0.50832,
                    "recall_at_5": 0.56311,
                    "recall_at_10": 0.62885,
                    "recall_at_20": 0.68702,
                    "precision_at_1": 0.3627,
                    "precision_at_3": 0.16998,
                    "precision_at_5": 0.11311,
                    "precision_at_10": 0.06326,
                    "precision_at_20": 0.03464,
                    "mrr_at_1": 0.36273553036558814,
                    "mrr_at_3": 0.4279771288441855,
                    "mrr_at_5": 0.44063008282662336,
                    "mrr_at_10": 0.44939126727938583,
                    "mrr_at_20": 0.4534635955031597,
                    "main_score": 0.49228,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1945.11505651474,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.14723,
                    "ndcg_at_3": 0.23659,
                    "ndcg_at_5": 0.27158,
                    "ndcg_at_10": 0.31276,
                    "ndcg_at_20": 0.34024,
                    "map_at_1": 0.14723,
                    "map_at_3": 0.2142,
                    "map_at_5": 0.23351,
                    "map_at_10": 0.25064,
                    "map_at_20": 0.25827,
                    "recall_at_1": 0.14723,
                    "recall_at_3": 0.30156,
                    "recall_at_5": 0.38691,
                    "recall_at_10": 0.51351,
                    "recall_at_20": 0.62162,
                    "precision_at_1": 0.14723,
                    "precision_at_3": 0.10052,
                    "precision_at_5": 0.07738,
                    "precision_at_10": 0.05135,
                    "precision_at_20": 0.03108,
                    "mrr_at_1": 0.1514935988620199,
                    "mrr_at_3": 0.2160976766239923,
                    "mrr_at_5": 0.23501659554291088,
                    "mrr_at_10": 0.25246251890988713,
                    "mrr_at_20": 0.2600177860331434,
                    "main_score": 0.31276,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 241.0997350215912,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.2023,
                    "ndcg_at_3": 0.21064,
                    "ndcg_at_5": 0.22673,
                    "ndcg_at_10": 0.25041,
                    "ndcg_at_20": 0.27664,
                    "map_at_1": 0.12229,
                    "map_at_3": 0.17031,
                    "map_at_5": 0.18478,
                    "map_at_10": 0.19749,
                    "map_at_20": 0.20606,
                    "recall_at_1": 0.12229,
                    "recall_at_3": 0.21453,
                    "recall_at_5": 0.26418,
                    "recall_at_10": 0.3334,
                    "recall_at_20": 0.42319,
                    "precision_at_1": 0.2023,
                    "precision_at_3": 0.12528,
                    "precision_at_5": 0.09392,
                    "precision_at_10": 0.06087,
                    "precision_at_20": 0.03903,
                    "mrr_at_1": 0.20255063765941486,
                    "mrr_at_3": 0.25047928648828927,
                    "mrr_at_5": 0.26338251229474136,
                    "mrr_at_10": 0.27315995665583076,
                    "mrr_at_20": 0.27955458244016296,
                    "main_score": 0.25041,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2658.5976099967957,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.53,
                    "ndcg_at_3": 0.60674,
                    "ndcg_at_5": 0.6241,
                    "ndcg_at_10": 0.65414,
                    "ndcg_at_20": 0.66622,
                    "map_at_1": 0.50789,
                    "map_at_3": 0.57832,
                    "map_at_5": 0.58984,
                    "map_at_10": 0.60479,
                    "map_at_20": 0.60885,
                    "recall_at_1": 0.50789,
                    "recall_at_3": 0.65933,
                    "recall_at_5": 0.70528,
                    "recall_at_10": 0.79039,
                    "recall_at_20": 0.83422,
                    "precision_at_1": 0.53,
                    "precision_at_3": 0.23889,
                    "precision_at_5": 0.154,
                    "precision_at_10": 0.08867,
                    "precision_at_20": 0.04733,
                    "mrr_at_1": 0.53,
                    "mrr_at_3": 0.5983333333333333,
                    "mrr_at_5": 0.6084999999999999,
                    "mrr_at_10": 0.618977513227513,
                    "mrr_at_20": 0.6218483351443875,
                    "main_score": 0.65414,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 441.8407652378082,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.95088,
                    "ndcg_at_3": 0.9709,
                    "ndcg_at_5": 0.97247,
                    "ndcg_at_10": 0.97375,
                    "ndcg_at_20": 0.97446,
                    "map_at_1": 0.95088,
                    "map_at_3": 0.96636,
                    "map_at_5": 0.96723,
                    "map_at_10": 0.96777,
                    "map_at_20": 0.96796,
                    "recall_at_1": 0.95088,
                    "recall_at_3": 0.98388,
                    "recall_at_5": 0.9877,
                    "recall_at_10": 0.99161,
                    "recall_at_20": 0.9944,
                    "precision_at_1": 0.95088,
                    "precision_at_3": 0.32796,
                    "precision_at_5": 0.19754,
                    "precision_at_10": 0.09916,
                    "precision_at_20": 0.04972,
                    "mrr_at_1": 0.9508771929824561,
                    "mrr_at_3": 0.9663557628247835,
                    "mrr_at_5": 0.9672285143237846,
                    "mrr_at_10": 0.9677693001843575,
                    "mrr_at_20": 0.9679636621011314,
                    "main_score": 0.97375,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 255.47663617134094,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.436,
                    "ndcg_at_3": 0.49445,
                    "ndcg_at_5": 0.51209,
                    "ndcg_at_10": 0.52503,
                    "map_at_1": 0.436,
                    "map_at_3": 0.481,
                    "map_at_5": 0.49075,
                    "map_at_10": 0.49609,
                    "recall_at_1": 0.436,
                    "recall_at_3": 0.533,
                    "recall_at_5": 0.576,
                    "recall_at_10": 0.616,
                    "precision_at_1": 0.436,
                    "precision_at_3": 0.17767,
                    "precision_at_5": 0.1152,
                    "precision_at_10": 0.0616,
                    "mrr_at_1": 0.437,
                    "mrr_at_3": 0.48149999999999993,
                    "mrr_at_5": 0.49124999999999974,
                    "mrr_at_10": 0.49659166666666676,
                    "main_score": 0.52503,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2403.0615072250366,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.49319,
                    "ndcg_at_3": 0.56069,
                    "ndcg_at_5": 0.57763,
                    "ndcg_at_10": 0.59288,
                    "map_at_1": 0.49305,
                    "map_at_3": 0.54428,
                    "map_at_5": 0.5537,
                    "map_at_10": 0.55998,
                    "recall_at_1": 0.49305,
                    "recall_at_3": 0.60784,
                    "recall_at_5": 0.64892,
                    "recall_at_10": 0.69609,
                    "precision_at_1": 0.49319,
                    "precision_at_3": 0.2027,
                    "precision_at_5": 0.12987,
                    "precision_at_10": 0.06967,
                    "mrr_at_1": 0.4931123976841685,
                    "mrr_at_3": 0.5444533173620886,
                    "mrr_at_5": 0.5538963199574208,
                    "mrr_at_10": 0.5602007972950379,
                    "main_score": 0.59288,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1858.7468059062958,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.353,
                    "ndcg_at_3": 0.40825,
                    "ndcg_at_5": 0.42434,
                    "ndcg_at_10": 0.43773,
                    "map_at_1": 0.353,
                    "map_at_3": 0.39483,
                    "map_at_5": 0.40378,
                    "map_at_10": 0.40939,
                    "recall_at_1": 0.353,
                    "recall_at_3": 0.447,
                    "recall_at_5": 0.486,
                    "recall_at_10": 0.527,
                    "precision_at_1": 0.353,
                    "precision_at_3": 0.149,
                    "precision_at_5": 0.0972,
                    "precision_at_10": 0.0527,
                    "mrr_at_1": 0.354,
                    "mrr_at_3": 0.3953333333333333,
                    "mrr_at_5": 0.4042833333333333,
                    "mrr_at_10": 0.4098873015873015,
                    "main_score": 0.43773,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2189.1287038326263,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.56275,
                    "ndcg_at_3": 0.62009,
                    "ndcg_at_5": 0.63495,
                    "ndcg_at_10": 0.65013,
                    "ndcg_at_20": 0.66092,
                    "map_at_1": 0.5627,
                    "map_at_3": 0.60618,
                    "map_at_5": 0.61441,
                    "map_at_10": 0.62072,
                    "map_at_20": 0.62368,
                    "recall_at_1": 0.5627,
                    "recall_at_3": 0.66011,
                    "recall_at_5": 0.69623,
                    "recall_at_10": 0.74295,
                    "recall_at_20": 0.78554,
                    "precision_at_1": 0.56275,
                    "precision_at_3": 0.2201,
                    "precision_at_5": 0.13931,
                    "precision_at_10": 0.07434,
                    "precision_at_20": 0.03931,
                    "mrr_at_1": 0.5627498001598721,
                    "mrr_at_3": 0.6062883026911872,
                    "mrr_at_5": 0.6145397015720873,
                    "mrr_at_10": 0.6208667034626365,
                    "mrr_at_20": 0.6238397585564778,
                    "main_score": 0.65013,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 579.6992633342743,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.185,
                    "ndcg_at_3": 0.15078,
                    "ndcg_at_5": 0.12874,
                    "ndcg_at_10": 0.15691,
                    "ndcg_at_20": 0.17903,
                    "map_at_1": 0.03758,
                    "map_at_3": 0.06628,
                    "map_at_5": 0.07732,
                    "map_at_10": 0.09013,
                    "map_at_20": 0.09783,
                    "recall_at_1": 0.03758,
                    "recall_at_3": 0.08538,
                    "recall_at_5": 0.11288,
                    "recall_at_10": 0.16462,
                    "recall_at_20": 0.21698,
                    "precision_at_1": 0.185,
                    "precision_at_3": 0.14067,
                    "precision_at_5": 0.1116,
                    "precision_at_10": 0.0813,
                    "precision_at_20": 0.0534,
                    "mrr_at_1": 0.185,
                    "mrr_at_3": 0.25066666666666687,
                    "mrr_at_5": 0.26481666666666676,
                    "mrr_at_10": 0.27913809523809513,
                    "mrr_at_20": 0.2854142251066785,
                    "main_score": 0.15691,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 2282.8095948696136,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.424,
                    "ndcg_at_3": 0.51835,
                    "ndcg_at_5": 0.54327,
                    "ndcg_at_10": 0.57281,
                    "ndcg_at_20": 0.5883,
                    "map_at_1": 0.424,
                    "map_at_3": 0.495,
                    "map_at_5": 0.5087,
                    "map_at_10": 0.52076,
                    "map_at_20": 0.52506,
                    "recall_at_1": 0.424,
                    "recall_at_3": 0.586,
                    "recall_at_5": 0.647,
                    "recall_at_10": 0.739,
                    "recall_at_20": 0.8,
                    "precision_at_1": 0.424,
                    "precision_at_3": 0.19533,
                    "precision_at_5": 0.1294,
                    "precision_at_10": 0.0739,
                    "precision_at_20": 0.04,
                    "mrr_at_1": 0.424,
                    "mrr_at_3": 0.49499999999999955,
                    "mrr_at_5": 0.5086999999999993,
                    "mrr_at_10": 0.5207642857142852,
                    "mrr_at_20": 0.525057982656318,
                    "main_score": 0.57281,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1200.7842106819153,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.57005,
                    "ndcg_at_3": 0.62588,
                    "ndcg_at_5": 0.64,
                    "ndcg_at_10": 0.6541,
                    "map_at_1": 0.56995,
                    "map_at_3": 0.61231,
                    "map_at_5": 0.62015,
                    "map_at_10": 0.62596,
                    "recall_at_1": 0.56995,
                    "recall_at_3": 0.66496,
                    "recall_at_5": 0.69925,
                    "recall_at_10": 0.74283,
                    "precision_at_1": 0.57005,
                    "precision_at_3": 0.22169,
                    "precision_at_5": 0.13988,
                    "precision_at_10": 0.07432,
                    "mrr_at_1": 0.5700938311040128,
                    "mrr_at_3": 0.6124309576096422,
                    "mrr_at_5": 0.6202828242496946,
                    "mrr_at_10": 0.626115167302041,
                    "main_score": 0.6541,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 731.5666851997375,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.57221,
                    "ndcg_at_3": 0.65861,
                    "ndcg_at_5": 0.68244,
                    "ndcg_at_10": 0.70095,
                    "ndcg_at_20": 0.71167,
                    "map_at_1": 0.55398,
                    "map_at_3": 0.63425,
                    "map_at_5": 0.64828,
                    "map_at_10": 0.6564,
                    "map_at_20": 0.65956,
                    "recall_at_1": 0.55398,
                    "recall_at_3": 0.71979,
                    "recall_at_5": 0.77605,
                    "recall_at_10": 0.83151,
                    "recall_at_20": 0.87262,
                    "precision_at_1": 0.57221,
                    "precision_at_3": 0.2532,
                    "precision_at_5": 0.16438,
                    "precision_at_10": 0.08834,
                    "precision_at_20": 0.04644,
                    "mrr_at_1": 0.5720630372492836,
                    "mrr_at_3": 0.6430754536771746,
                    "mrr_at_5": 0.6556255969436482,
                    "mrr_at_10": 0.6628627143311963,
                    "mrr_at_20": 0.6656448023872583,
                    "main_score": 0.70095,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 4299.138077735901,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.462,
                    "ndcg_at_3": 0.55851,
                    "ndcg_at_5": 0.57998,
                    "ndcg_at_10": 0.60584,
                    "ndcg_at_20": 0.62392,
                    "map_at_1": 0.462,
                    "map_at_3": 0.53483,
                    "map_at_5": 0.54678,
                    "map_at_10": 0.55743,
                    "map_at_20": 0.56247,
                    "recall_at_1": 0.462,
                    "recall_at_3": 0.627,
                    "recall_at_5": 0.679,
                    "recall_at_10": 0.759,
                    "recall_at_20": 0.83,
                    "precision_at_1": 0.462,
                    "precision_at_3": 0.209,
                    "precision_at_5": 0.1358,
                    "precision_at_10": 0.0759,
                    "precision_at_20": 0.0415,
                    "mrr_at_1": 0.462,
                    "mrr_at_3": 0.5348333333333328,
                    "mrr_at_5": 0.5467833333333327,
                    "mrr_at_10": 0.5574329365079359,
                    "mrr_at_20": 0.5624650130485265,
                    "main_score": 0.60584,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 4556.870505571365,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.27671,
                    "ndcg_at_3": 0.34156,
                    "ndcg_at_5": 0.36144,
                    "ndcg_at_10": 0.38238,
                    "ndcg_at_20": 0.39911,
                    "map_at_1": 0.2762,
                    "map_at_3": 0.32542,
                    "map_at_5": 0.33644,
                    "map_at_10": 0.34513,
                    "map_at_20": 0.34975,
                    "recall_at_1": 0.2762,
                    "recall_at_3": 0.38745,
                    "recall_at_5": 0.43584,
                    "recall_at_10": 0.50025,
                    "recall_at_20": 0.56601,
                    "precision_at_1": 0.27671,
                    "precision_at_3": 0.12959,
                    "precision_at_5": 0.08755,
                    "precision_at_10": 0.05035,
                    "precision_at_20": 0.02855,
                    "mrr_at_1": 0.2766684182869154,
                    "mrr_at_3": 0.32592022620924016,
                    "mrr_at_5": 0.3370229962715475,
                    "mrr_at_10": 0.34569439529183554,
                    "mrr_at_20": 0.3502917770145533,
                    "main_score": 0.38238,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 336.29896306991577,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.71132,
                    "ndcg_at_3": 0.77098,
                    "ndcg_at_5": 0.78104,
                    "ndcg_at_10": 0.79001,
                    "ndcg_at_20": 0.79527,
                    "map_at_1": 0.7109,
                    "map_at_3": 0.75684,
                    "map_at_5": 0.76246,
                    "map_at_10": 0.7662,
                    "map_at_20": 0.76767,
                    "recall_at_1": 0.7109,
                    "recall_at_3": 0.8114,
                    "recall_at_5": 0.83572,
                    "recall_at_10": 0.86318,
                    "recall_at_20": 0.8838,
                    "precision_at_1": 0.71132,
                    "precision_at_3": 0.27078,
                    "precision_at_5": 0.16737,
                    "precision_at_10": 0.08645,
                    "precision_at_20": 0.04427,
                    "mrr_at_1": 0.7112911749163291,
                    "mrr_at_3": 0.7570704401777081,
                    "mrr_at_5": 0.7627189634587881,
                    "mrr_at_10": 0.7664739159124374,
                    "mrr_at_20": 0.767949583335646,
                    "main_score": 0.79001,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 821.2175033092499,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.63908,
                    "ndcg_at_3": 0.71209,
                    "ndcg_at_5": 0.72571,
                    "ndcg_at_10": 0.73833,
                    "ndcg_at_20": 0.74701,
                    "map_at_1": 0.63867,
                    "map_at_3": 0.69468,
                    "map_at_5": 0.70227,
                    "map_at_10": 0.70755,
                    "map_at_20": 0.70995,
                    "recall_at_1": 0.63867,
                    "recall_at_3": 0.76196,
                    "recall_at_5": 0.79493,
                    "recall_at_10": 0.83367,
                    "recall_at_20": 0.86782,
                    "precision_at_1": 0.63908,
                    "precision_at_3": 0.25426,
                    "precision_at_5": 0.15919,
                    "precision_at_10": 0.0835,
                    "precision_at_20": 0.04346,
                    "mrr_at_1": 0.6390780974750441,
                    "mrr_at_3": 0.6949109414758196,
                    "mrr_at_5": 0.7024593853983148,
                    "mrr_at_10": 0.7077030963099673,
                    "mrr_at_20": 0.7101056764183888,
                    "main_score": 0.73833,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 557.4743728637695,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "6e346642246bfb4928c560ee08640dc84d074e8c",
        "task_name": "LEMBWikimQARetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.31667,
                    "ndcg_at_3": 0.42063,
                    "ndcg_at_5": 0.44976,
                    "ndcg_at_10": 0.48026,
                    "ndcg_at_20": 0.5121,
                    "map_at_1": 0.31667,
                    "map_at_3": 0.39444,
                    "map_at_5": 0.41078,
                    "map_at_10": 0.42356,
                    "map_at_20": 0.43263,
                    "recall_at_1": 0.31667,
                    "recall_at_3": 0.49667,
                    "recall_at_5": 0.56667,
                    "recall_at_10": 0.66,
                    "recall_at_20": 0.78333,
                    "precision_at_1": 0.31667,
                    "precision_at_3": 0.16556,
                    "precision_at_5": 0.11333,
                    "precision_at_10": 0.066,
                    "precision_at_20": 0.03917,
                    "mrr_at_1": 0.31666666666666665,
                    "mrr_at_3": 0.39444444444444426,
                    "mrr_at_5": 0.41077777777777763,
                    "mrr_at_10": 0.4235555555555554,
                    "mrr_at_20": 0.43262964724187614,
                    "main_score": 0.48026,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 221.00010752677917,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.66289,
                    "ndcg_at_3": 0.7384,
                    "ndcg_at_5": 0.75906,
                    "ndcg_at_10": 0.77536,
                    "ndcg_at_20": 0.78397,
                    "map_at_1": 0.64099,
                    "map_at_3": 0.7167,
                    "map_at_5": 0.72897,
                    "map_at_10": 0.73603,
                    "map_at_20": 0.73856,
                    "recall_at_1": 0.64099,
                    "recall_at_3": 0.79226,
                    "recall_at_5": 0.84126,
                    "recall_at_10": 0.89052,
                    "recall_at_20": 0.92367,
                    "precision_at_1": 0.66289,
                    "precision_at_3": 0.27908,
                    "precision_at_5": 0.1784,
                    "precision_at_10": 0.09463,
                    "precision_at_20": 0.04914,
                    "mrr_at_1": 0.6628939828080229,
                    "mrr_at_3": 0.7253581661891115,
                    "mrr_at_5": 0.7359527220630345,
                    "mrr_at_10": 0.7422771978896606,
                    "mrr_at_20": 0.7445103164799177,
                    "main_score": 0.77536,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 12177.697429656982,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.42396,
                    "ndcg_at_3": 0.48269,
                    "ndcg_at_5": 0.49962,
                    "ndcg_at_10": 0.51545,
                    "map_at_1": 0.42388,
                    "map_at_3": 0.4684,
                    "map_at_5": 0.47782,
                    "map_at_10": 0.48437,
                    "recall_at_1": 0.42388,
                    "recall_at_3": 0.52386,
                    "recall_at_5": 0.56484,
                    "recall_at_10": 0.61373,
                    "precision_at_1": 0.42396,
                    "precision_at_3": 0.17467,
                    "precision_at_5": 0.11302,
                    "precision_at_10": 0.0614,
                    "mrr_at_1": 0.42399680574965065,
                    "mrr_at_3": 0.4685100153057856,
                    "mrr_at_5": 0.47795301790111683,
                    "mrr_at_10": 0.4845136215130283,
                    "main_score": 0.51545,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 329.8571789264679,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "6e346642246bfb4928c560ee08640dc84d074e8c",
        "task_name": "LEMBWikimQARetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.92,
                    "ndcg_at_3": 0.94016,
                    "ndcg_at_5": 0.94288,
                    "ndcg_at_10": 0.95033,
                    "ndcg_at_20": 0.95289,
                    "map_at_1": 0.92,
                    "map_at_3": 0.93556,
                    "map_at_5": 0.93706,
                    "map_at_10": 0.94006,
                    "map_at_20": 0.94078,
                    "recall_at_1": 0.92,
                    "recall_at_3": 0.95333,
                    "recall_at_5": 0.96,
                    "recall_at_10": 0.98333,
                    "recall_at_20": 0.99333,
                    "precision_at_1": 0.92,
                    "precision_at_3": 0.31778,
                    "precision_at_5": 0.192,
                    "precision_at_10": 0.09833,
                    "precision_at_20": 0.04967,
                    "mrr_at_1": 0.92,
                    "mrr_at_3": 0.9355555555555556,
                    "mrr_at_5": 0.9370555555555555,
                    "mrr_at_10": 0.9400582010582011,
                    "mrr_at_20": 0.9407804232804233,
                    "main_score": 0.95033,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 405.4228322505951,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.4211,
                    "ndcg_at_3": 0.4981,
                    "ndcg_at_5": 0.51796,
                    "ndcg_at_10": 0.53652,
                    "ndcg_at_20": 0.55006,
                    "map_at_1": 0.42045,
                    "map_at_3": 0.47924,
                    "map_at_5": 0.4903,
                    "map_at_10": 0.49801,
                    "map_at_20": 0.50176,
                    "recall_at_1": 0.42045,
                    "recall_at_3": 0.55166,
                    "recall_at_5": 0.59976,
                    "recall_at_10": 0.65689,
                    "recall_at_20": 0.71003,
                    "precision_at_1": 0.4211,
                    "precision_at_3": 0.1845,
                    "precision_at_5": 0.12047,
                    "precision_at_10": 0.06608,
                    "precision_at_20": 0.03579,
                    "mrr_at_1": 0.4211770888071466,
                    "mrr_at_3": 0.47990641343243085,
                    "mrr_at_5": 0.49093223731953034,
                    "mrr_at_10": 0.4986260207358561,
                    "mrr_at_20": 0.5023314615650919,
                    "main_score": 0.53652,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 617.1043305397034,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.52307,
                    "ndcg_at_3": 0.61084,
                    "ndcg_at_5": 0.63297,
                    "ndcg_at_10": 0.65257,
                    "map_at_1": 0.5229,
                    "map_at_3": 0.58949,
                    "map_at_5": 0.60178,
                    "map_at_10": 0.60993,
                    "recall_at_1": 0.5229,
                    "recall_at_3": 0.67235,
                    "recall_at_5": 0.72603,
                    "recall_at_10": 0.78636,
                    "precision_at_1": 0.52307,
                    "precision_at_3": 0.22422,
                    "precision_at_5": 0.14528,
                    "precision_at_10": 0.07868,
                    "mrr_at_1": 0.5230655716668805,
                    "mrr_at_3": 0.5896424141323455,
                    "mrr_at_5": 0.6019242696437089,
                    "mrr_at_10": 0.610070787479209,
                    "main_score": 0.65257,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2108.9915993213654,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "2e643e7363944af1c33a652d1c87320d0871c4e4",
        "task_name": "NarrativeQAChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.31969,
                    "ndcg_at_3": 0.40826,
                    "ndcg_at_5": 0.43668,
                    "ndcg_at_10": 0.46472,
                    "ndcg_at_20": 0.48447,
                    "map_at_1": 0.31969,
                    "map_at_3": 0.38646,
                    "map_at_5": 0.40222,
                    "map_at_10": 0.4138,
                    "map_at_20": 0.41923,
                    "recall_at_1": 0.31969,
                    "recall_at_3": 0.47135,
                    "recall_at_5": 0.5404,
                    "recall_at_10": 0.62707,
                    "recall_at_20": 0.70503,
                    "precision_at_1": 0.31969,
                    "precision_at_3": 0.15712,
                    "precision_at_5": 0.10808,
                    "precision_at_10": 0.06271,
                    "precision_at_20": 0.03525,
                    "mrr_at_1": 0.319693094629156,
                    "mrr_at_3": 0.3864576426383796,
                    "mrr_at_5": 0.40221969625209225,
                    "mrr_at_10": 0.4137986380811057,
                    "mrr_at_20": 0.41923446383202423,
                    "main_score": 0.46472,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 2317.7848398685455,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.7326,
                    "ndcg_at_3": 0.66848,
                    "ndcg_at_5": 0.6454,
                    "ndcg_at_10": 0.64545,
                    "ndcg_at_20": 0.67449,
                    "map_at_1": 0.19744,
                    "map_at_3": 0.37785,
                    "map_at_5": 0.46115,
                    "map_at_10": 0.53641,
                    "map_at_20": 0.56511,
                    "recall_at_1": 0.19744,
                    "recall_at_3": 0.40478,
                    "recall_at_5": 0.51481,
                    "recall_at_10": 0.64014,
                    "recall_at_20": 0.72637,
                    "precision_at_1": 0.7326,
                    "precision_at_3": 0.58991,
                    "precision_at_5": 0.4882,
                    "precision_at_10": 0.32955,
                    "precision_at_20": 0.19244,
                    "mrr_at_1": 0.7325968788357005,
                    "mrr_at_3": 0.776835291367122,
                    "mrr_at_5": 0.7837066748495033,
                    "mrr_at_10": 0.7879399139689867,
                    "mrr_at_20": 0.7897451687192218,
                    "main_score": 0.64545,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 7175.4255521297455,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.43981,
                    "ndcg_at_3": 0.41147,
                    "ndcg_at_5": 0.41488,
                    "ndcg_at_10": 0.44863,
                    "ndcg_at_20": 0.47246,
                    "map_at_1": 0.2187,
                    "map_at_3": 0.32032,
                    "map_at_5": 0.34107,
                    "map_at_10": 0.3651,
                    "map_at_20": 0.37503,
                    "recall_at_1": 0.2187,
                    "recall_at_3": 0.37473,
                    "recall_at_5": 0.42184,
                    "recall_at_10": 0.52308,
                    "recall_at_20": 0.59542,
                    "precision_at_1": 0.43981,
                    "precision_at_3": 0.27623,
                    "precision_at_5": 0.1966,
                    "precision_at_10": 0.12654,
                    "precision_at_20": 0.07353,
                    "mrr_at_1": 0.4398148148148148,
                    "mrr_at_3": 0.5072016460905348,
                    "mrr_at_5": 0.5163065843621394,
                    "mrr_at_10": 0.5306082206545166,
                    "mrr_at_20": 0.5344999843197435,
                    "main_score": 0.44863,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 6740.4384133815765,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.79505,
                    "ndcg_at_3": 0.83852,
                    "ndcg_at_5": 0.84562,
                    "ndcg_at_10": 0.85206,
                    "map_at_1": 0.79505,
                    "map_at_3": 0.82837,
                    "map_at_5": 0.83233,
                    "map_at_10": 0.83501,
                    "recall_at_1": 0.79505,
                    "recall_at_3": 0.8677,
                    "recall_at_5": 0.88485,
                    "recall_at_10": 0.9046,
                    "precision_at_1": 0.79505,
                    "precision_at_3": 0.28923,
                    "precision_at_5": 0.17697,
                    "precision_at_10": 0.09046,
                    "mrr_at_1": 0.7951,
                    "mrr_at_3": 0.8284166666666706,
                    "mrr_at_5": 0.8323666666666725,
                    "mrr_at_10": 0.8350485317460367,
                    "main_score": 0.85206,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2215.2271473407745,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MMarcoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.48883,
                    "ndcg_at_3": 0.56836,
                    "ndcg_at_5": 0.59463,
                    "ndcg_at_10": 0.61981,
                    "ndcg_at_20": 0.63484,
                    "map_at_1": 0.47234,
                    "map_at_3": 0.54524,
                    "map_at_5": 0.56055,
                    "map_at_10": 0.5713,
                    "map_at_20": 0.57561,
                    "recall_at_1": 0.47234,
                    "recall_at_3": 0.62588,
                    "recall_at_5": 0.68823,
                    "recall_at_10": 0.76454,
                    "recall_at_20": 0.82278,
                    "precision_at_1": 0.48883,
                    "precision_at_3": 0.2202,
                    "precision_at_5": 0.14576,
                    "precision_at_10": 0.08109,
                    "precision_at_20": 0.04371,
                    "mrr_at_1": 0.48868194842406876,
                    "mrr_at_3": 0.5543935052531072,
                    "mrr_at_5": 0.5683118433619884,
                    "mrr_at_10": 0.578446297812346,
                    "mrr_at_20": 0.5823752300581131,
                    "main_score": 0.61981,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2293.7334983348846,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.36223,
                    "ndcg_at_3": 0.32159,
                    "ndcg_at_5": 0.29878,
                    "ndcg_at_10": 0.26466,
                    "map_at_1": 0.04468,
                    "map_at_3": 0.0755,
                    "map_at_5": 0.08658,
                    "map_at_10": 0.09903,
                    "recall_at_1": 0.04468,
                    "recall_at_3": 0.08603,
                    "recall_at_5": 0.10397,
                    "recall_at_10": 0.12732,
                    "precision_at_1": 0.37771,
                    "precision_at_3": 0.30341,
                    "precision_at_5": 0.25635,
                    "precision_at_10": 0.18916,
                    "mrr_at_1": 0.38080495356037153,
                    "mrr_at_3": 0.4437564499484005,
                    "mrr_at_5": 0.45304437564499495,
                    "mrr_at_10": 0.4578750798565041,
                    "main_score": 0.26466,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 353.0077693462372,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.59667,
                    "ndcg_at_3": 0.67839,
                    "ndcg_at_5": 0.69646,
                    "ndcg_at_10": 0.71299,
                    "ndcg_at_20": 0.73029,
                    "map_at_1": 0.57189,
                    "map_at_3": 0.64931,
                    "map_at_5": 0.66214,
                    "map_at_10": 0.67043,
                    "map_at_20": 0.6758,
                    "recall_at_1": 0.57189,
                    "recall_at_3": 0.73506,
                    "recall_at_5": 0.78028,
                    "recall_at_10": 0.82789,
                    "recall_at_20": 0.89367,
                    "precision_at_1": 0.59667,
                    "precision_at_3": 0.26556,
                    "precision_at_5": 0.17267,
                    "precision_at_10": 0.093,
                    "precision_at_20": 0.05067,
                    "mrr_at_1": 0.5966666666666667,
                    "mrr_at_3": 0.6677777777777777,
                    "mrr_at_5": 0.677611111111111,
                    "mrr_at_10": 0.6823783068783068,
                    "mrr_at_20": 0.6862049432049431,
                    "main_score": 0.71299,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 668.598521232605,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.8541,
                    "ndcg_at_3": 0.89755,
                    "ndcg_at_5": 0.90456,
                    "ndcg_at_10": 0.90967,
                    "ndcg_at_20": 0.91244,
                    "map_at_1": 0.8541,
                    "map_at_3": 0.88731,
                    "map_at_5": 0.89121,
                    "map_at_10": 0.89334,
                    "map_at_20": 0.89412,
                    "recall_at_1": 0.8541,
                    "recall_at_3": 0.92698,
                    "recall_at_5": 0.94399,
                    "recall_at_10": 0.95967,
                    "recall_at_20": 0.97046,
                    "precision_at_1": 0.8541,
                    "precision_at_3": 0.30899,
                    "precision_at_5": 0.1888,
                    "precision_at_10": 0.09597,
                    "precision_at_20": 0.04852,
                    "mrr_at_1": 0.8540972684876749,
                    "mrr_at_3": 0.8873121622621952,
                    "mrr_at_5": 0.891209563994376,
                    "mrr_at_10": 0.8933381978152153,
                    "mrr_at_20": 0.8941232625510678,
                    "main_score": 0.90967,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 262.89690041542053,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.40622,
                    "ndcg_at_3": 0.48587,
                    "ndcg_at_5": 0.50735,
                    "ndcg_at_10": 0.5283,
                    "ndcg_at_20": 0.54297,
                    "map_at_1": 0.40556,
                    "map_at_3": 0.46628,
                    "map_at_5": 0.47824,
                    "map_at_10": 0.48695,
                    "map_at_20": 0.49104,
                    "recall_at_1": 0.40556,
                    "recall_at_3": 0.54153,
                    "recall_at_5": 0.59359,
                    "recall_at_10": 0.65795,
                    "recall_at_20": 0.71547,
                    "precision_at_1": 0.40622,
                    "precision_at_3": 0.18112,
                    "precision_at_5": 0.11927,
                    "precision_at_10": 0.0662,
                    "precision_at_20": 0.03606,
                    "mrr_at_1": 0.4062582073312573,
                    "mrr_at_3": 0.46708313010418395,
                    "mrr_at_5": 0.47902925249191236,
                    "mrr_at_10": 0.48768285412941825,
                    "mrr_at_20": 0.49171006560434305,
                    "main_score": 0.5283,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 601.4356331825256,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.29212,
                    "ndcg_at_3": 0.36733,
                    "ndcg_at_5": 0.39041,
                    "ndcg_at_10": 0.41378,
                    "ndcg_at_20": 0.43102,
                    "map_at_1": 0.29155,
                    "map_at_3": 0.3484,
                    "map_at_5": 0.36122,
                    "map_at_10": 0.37089,
                    "map_at_20": 0.37568,
                    "recall_at_1": 0.29155,
                    "recall_at_3": 0.4214,
                    "recall_at_5": 0.47732,
                    "recall_at_10": 0.54934,
                    "recall_at_20": 0.61698,
                    "precision_at_1": 0.29212,
                    "precision_at_3": 0.14107,
                    "precision_at_5": 0.09605,
                    "precision_at_10": 0.05535,
                    "precision_at_20": 0.03115,
                    "mrr_at_1": 0.2922747908303005,
                    "mrr_at_3": 0.34916019459973063,
                    "mrr_at_5": 0.3619842669368046,
                    "mrr_at_10": 0.3716247731724442,
                    "mrr_at_20": 0.37636973195131407,
                    "main_score": 0.41378,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 1772.187906742096,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.51405,
                    "ndcg_at_3": 0.6014,
                    "ndcg_at_5": 0.6222,
                    "ndcg_at_10": 0.64251,
                    "ndcg_at_20": 0.65542,
                    "map_at_1": 0.51392,
                    "map_at_3": 0.58001,
                    "map_at_5": 0.59155,
                    "map_at_10": 0.59999,
                    "map_at_20": 0.60355,
                    "recall_at_1": 0.51392,
                    "recall_at_3": 0.6631,
                    "recall_at_5": 0.71354,
                    "recall_at_10": 0.77611,
                    "recall_at_20": 0.82699,
                    "precision_at_1": 0.51405,
                    "precision_at_3": 0.2211,
                    "precision_at_5": 0.14278,
                    "precision_at_10": 0.07767,
                    "precision_at_20": 0.04139,
                    "mrr_at_1": 0.5140510714744001,
                    "mrr_at_3": 0.5801467128619747,
                    "mrr_at_5": 0.5917099747636873,
                    "mrr_at_10": 0.6001381734523731,
                    "mrr_at_20": 0.6036944343495247,
                    "main_score": 0.64251,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 1897.477679014206,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.28083,
                    "ndcg_at_3": 0.34742,
                    "ndcg_at_5": 0.36803,
                    "ndcg_at_10": 0.39112,
                    "ndcg_at_20": 0.40933,
                    "map_at_1": 0.28039,
                    "map_at_3": 0.33069,
                    "map_at_5": 0.34212,
                    "map_at_10": 0.35168,
                    "map_at_20": 0.35674,
                    "recall_at_1": 0.28039,
                    "recall_at_3": 0.39505,
                    "recall_at_5": 0.44507,
                    "recall_at_10": 0.51615,
                    "recall_at_20": 0.58765,
                    "precision_at_1": 0.28083,
                    "precision_at_3": 0.13216,
                    "precision_at_5": 0.08942,
                    "precision_at_10": 0.05199,
                    "precision_at_20": 0.02967,
                    "mrr_at_1": 0.2808689453344839,
                    "mrr_at_3": 0.3313760802411208,
                    "mrr_at_5": 0.3429207468827745,
                    "mrr_at_10": 0.3524552166318582,
                    "mrr_at_20": 0.3574498125642697,
                    "main_score": 0.39112,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 318.46554136276245,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.37191,
                    "ndcg_at_3": 0.33933,
                    "ndcg_at_5": 0.34907,
                    "ndcg_at_10": 0.37557,
                    "ndcg_at_20": 0.40138,
                    "map_at_1": 0.18239,
                    "map_at_3": 0.25775,
                    "map_at_5": 0.2785,
                    "map_at_10": 0.29627,
                    "map_at_20": 0.30608,
                    "recall_at_1": 0.18239,
                    "recall_at_3": 0.31107,
                    "recall_at_5": 0.36899,
                    "recall_at_10": 0.44938,
                    "recall_at_20": 0.52673,
                    "precision_at_1": 0.37191,
                    "precision_at_3": 0.22428,
                    "precision_at_5": 0.16235,
                    "precision_at_10": 0.1034,
                    "precision_at_20": 0.06289,
                    "mrr_at_1": 0.37191358024691357,
                    "mrr_at_3": 0.43698559670781895,
                    "mrr_at_5": 0.4494855967078186,
                    "mrr_at_10": 0.4603107240838717,
                    "mrr_at_20": 0.4656032212252464,
                    "main_score": 0.37557,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 4121.023020982742,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.377,
                    "ndcg_at_3": 0.44411,
                    "ndcg_at_5": 0.45779,
                    "ndcg_at_10": 0.47052,
                    "map_at_1": 0.377,
                    "map_at_3": 0.42817,
                    "map_at_5": 0.43582,
                    "map_at_10": 0.44113,
                    "recall_at_1": 0.377,
                    "recall_at_3": 0.49,
                    "recall_at_5": 0.523,
                    "recall_at_10": 0.562,
                    "precision_at_1": 0.377,
                    "precision_at_3": 0.16333,
                    "precision_at_5": 0.1046,
                    "precision_at_10": 0.0562,
                    "mrr_at_1": 0.377,
                    "mrr_at_3": 0.4284999999999999,
                    "mrr_at_5": 0.43589999999999984,
                    "mrr_at_10": 0.44121825396825387,
                    "main_score": 0.47052,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 4234.64985537529,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.49209,
                    "ndcg_at_3": 0.56139,
                    "ndcg_at_5": 0.57883,
                    "ndcg_at_10": 0.59549,
                    "ndcg_at_20": 0.60764,
                    "map_at_1": 0.49203,
                    "map_at_3": 0.54461,
                    "map_at_5": 0.55429,
                    "map_at_10": 0.56118,
                    "map_at_20": 0.56453,
                    "recall_at_1": 0.49203,
                    "recall_at_3": 0.60971,
                    "recall_at_5": 0.65202,
                    "recall_at_10": 0.70335,
                    "recall_at_20": 0.75127,
                    "precision_at_1": 0.49209,
                    "precision_at_3": 0.2033,
                    "precision_at_5": 0.13048,
                    "precision_at_10": 0.0704,
                    "precision_at_20": 0.03762,
                    "mrr_at_1": 0.49204636290967224,
                    "mrr_at_3": 0.5446975752731215,
                    "mrr_at_5": 0.5544018118838369,
                    "mrr_at_10": 0.5613230050880027,
                    "mrr_at_20": 0.5646821967785572,
                    "main_score": 0.59549,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 1718.426460981369,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.25462,
                    "ndcg_at_3": 0.40326,
                    "ndcg_at_5": 0.45939,
                    "ndcg_at_10": 0.5082,
                    "ndcg_at_20": 0.5357,
                    "map_at_1": 0.25462,
                    "map_at_3": 0.36664,
                    "map_at_5": 0.39772,
                    "map_at_10": 0.4179,
                    "map_at_20": 0.42562,
                    "recall_at_1": 0.25462,
                    "recall_at_3": 0.50925,
                    "recall_at_5": 0.6458,
                    "recall_at_10": 0.79659,
                    "recall_at_20": 0.90398,
                    "precision_at_1": 0.25462,
                    "precision_at_3": 0.16975,
                    "precision_at_5": 0.12916,
                    "precision_at_10": 0.07966,
                    "precision_at_20": 0.0452,
                    "mrr_at_1": 0.26458036984352773,
                    "mrr_at_3": 0.3696064485538165,
                    "mrr_at_5": 0.4012920815552394,
                    "mrr_at_10": 0.42162416175574097,
                    "mrr_at_20": 0.42941218584651886,
                    "main_score": 0.5082,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 722.4302167892456,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.57208,
                    "ndcg_at_3": 0.64453,
                    "ndcg_at_5": 0.66162,
                    "ndcg_at_10": 0.67683,
                    "map_at_1": 0.57196,
                    "map_at_3": 0.62695,
                    "map_at_5": 0.63643,
                    "map_at_10": 0.64275,
                    "recall_at_1": 0.57196,
                    "recall_at_3": 0.69516,
                    "recall_at_5": 0.73668,
                    "recall_at_10": 0.78354,
                    "precision_at_1": 0.57208,
                    "precision_at_3": 0.23182,
                    "precision_at_5": 0.14741,
                    "precision_at_10": 0.07839,
                    "mrr_at_1": 0.572083921467984,
                    "mrr_at_3": 0.6270531245989994,
                    "mrr_at_5": 0.6365279738226685,
                    "mrr_at_10": 0.6428333755975618,
                    "main_score": 0.67683,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 829.8175957202911,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.89158,
                    "ndcg_at_3": 0.92724,
                    "ndcg_at_5": 0.93218,
                    "ndcg_at_10": 0.93547,
                    "ndcg_at_20": 0.93711,
                    "map_at_1": 0.89158,
                    "map_at_3": 0.91894,
                    "map_at_5": 0.9217,
                    "map_at_10": 0.92309,
                    "map_at_20": 0.92354,
                    "recall_at_1": 0.89158,
                    "recall_at_3": 0.95105,
                    "recall_at_5": 0.96296,
                    "recall_at_10": 0.973,
                    "recall_at_20": 0.97948,
                    "precision_at_1": 0.89158,
                    "precision_at_3": 0.31702,
                    "precision_at_5": 0.19259,
                    "precision_at_10": 0.0973,
                    "precision_at_20": 0.04897,
                    "mrr_at_1": 0.8915833888518765,
                    "mrr_at_3": 0.9189429269375964,
                    "mrr_at_5": 0.921703308905175,
                    "mrr_at_10": 0.9230905498627033,
                    "mrr_at_20": 0.9235421051327956,
                    "main_score": 0.93547,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 1532.0376160144806,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.90216,
                    "ndcg_at_3": 0.93409,
                    "ndcg_at_5": 0.93865,
                    "ndcg_at_10": 0.94223,
                    "ndcg_at_20": 0.94378,
                    "map_at_1": 0.90216,
                    "map_at_3": 0.92664,
                    "map_at_5": 0.92916,
                    "map_at_10": 0.93066,
                    "map_at_20": 0.9311,
                    "recall_at_1": 0.90216,
                    "recall_at_3": 0.95549,
                    "recall_at_5": 0.96656,
                    "recall_at_10": 0.97751,
                    "recall_at_20": 0.98361,
                    "precision_at_1": 0.90216,
                    "precision_at_3": 0.3185,
                    "precision_at_5": 0.19332,
                    "precision_at_10": 0.09776,
                    "precision_at_20": 0.04918,
                    "mrr_at_1": 0.9021642322764517,
                    "mrr_at_3": 0.9266491509321932,
                    "mrr_at_5": 0.9291763151644715,
                    "mrr_at_10": 0.9306770276689253,
                    "mrr_at_20": 0.9311099680791406,
                    "main_score": 0.94223,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1593.9588632583618,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.69941,
                    "ndcg_at_3": 0.76981,
                    "ndcg_at_5": 0.7818,
                    "ndcg_at_10": 0.79238,
                    "ndcg_at_20": 0.79971,
                    "map_at_1": 0.69896,
                    "map_at_3": 0.75316,
                    "map_at_5": 0.75983,
                    "map_at_10": 0.76425,
                    "map_at_20": 0.76629,
                    "recall_at_1": 0.69896,
                    "recall_at_3": 0.81752,
                    "recall_at_5": 0.84659,
                    "recall_at_10": 0.87898,
                    "recall_at_20": 0.90781,
                    "precision_at_1": 0.69941,
                    "precision_at_3": 0.27282,
                    "precision_at_5": 0.16954,
                    "precision_at_10": 0.08804,
                    "precision_at_20": 0.04548,
                    "mrr_at_1": 0.6994421608925425,
                    "mrr_at_3": 0.7533470346447348,
                    "mrr_at_5": 0.7600029359952988,
                    "mrr_at_10": 0.76441573693482,
                    "mrr_at_20": 0.7664305209275559,
                    "main_score": 0.79238,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2422.062469482422,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.67612,
                    "ndcg_at_3": 0.76516,
                    "ndcg_at_5": 0.78422,
                    "ndcg_at_10": 0.79869,
                    "map_at_1": 0.67591,
                    "map_at_3": 0.74367,
                    "map_at_5": 0.75429,
                    "map_at_10": 0.76034,
                    "recall_at_1": 0.67591,
                    "recall_at_3": 0.82686,
                    "recall_at_5": 0.873,
                    "recall_at_10": 0.91725,
                    "precision_at_1": 0.67612,
                    "precision_at_3": 0.27579,
                    "precision_at_5": 0.17473,
                    "precision_at_10": 0.09183,
                    "mrr_at_1": 0.6761195945078917,
                    "mrr_at_3": 0.7439154797039984,
                    "mrr_at_5": 0.7545323794858608,
                    "mrr_at_10": 0.7605872766361349,
                    "main_score": 0.79869,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 368.1516366004944,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.17141,
                    "ndcg_at_3": 0.29092,
                    "ndcg_at_5": 0.34457,
                    "ndcg_at_10": 0.40789,
                    "ndcg_at_20": 0.44896,
                    "map_at_1": 0.17141,
                    "map_at_3": 0.25972,
                    "map_at_5": 0.28934,
                    "map_at_10": 0.31525,
                    "map_at_20": 0.32683,
                    "recall_at_1": 0.17141,
                    "recall_at_3": 0.38193,
                    "recall_at_5": 0.5128,
                    "recall_at_10": 0.70982,
                    "recall_at_20": 0.86984,
                    "precision_at_1": 0.17141,
                    "precision_at_3": 0.12731,
                    "precision_at_5": 0.10256,
                    "precision_at_10": 0.07098,
                    "precision_at_20": 0.04349,
                    "mrr_at_1": 0.17994310099573257,
                    "mrr_at_3": 0.26303935514461796,
                    "mrr_at_5": 0.29223565670933993,
                    "mrr_at_10": 0.3183154959470743,
                    "mrr_at_20": 0.33005918438438275,
                    "main_score": 0.40789,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 1074.1365582942963,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.229,
                    "ndcg_at_3": 0.18535,
                    "ndcg_at_5": 0.15977,
                    "ndcg_at_10": 0.19049,
                    "ndcg_at_20": 0.22076,
                    "map_at_1": 0.04648,
                    "map_at_3": 0.08264,
                    "map_at_5": 0.09705,
                    "map_at_10": 0.11247,
                    "map_at_20": 0.12325,
                    "recall_at_1": 0.04648,
                    "recall_at_3": 0.10502,
                    "recall_at_5": 0.14052,
                    "recall_at_10": 0.1975,
                    "recall_at_20": 0.26855,
                    "precision_at_1": 0.229,
                    "precision_at_3": 0.17267,
                    "precision_at_5": 0.1386,
                    "precision_at_10": 0.0972,
                    "precision_at_20": 0.06625,
                    "mrr_at_1": 0.229,
                    "mrr_at_3": 0.30399999999999994,
                    "mrr_at_5": 0.32259999999999955,
                    "mrr_at_10": 0.33440476190476154,
                    "mrr_at_20": 0.34188051741000614,
                    "main_score": 0.19049,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 3217.1167542934418,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.556,
                    "ndcg_at_3": 0.66487,
                    "ndcg_at_5": 0.68918,
                    "ndcg_at_10": 0.70601,
                    "ndcg_at_20": 0.71854,
                    "map_at_1": 0.556,
                    "map_at_3": 0.6385,
                    "map_at_5": 0.652,
                    "map_at_10": 0.65895,
                    "map_at_20": 0.66233,
                    "recall_at_1": 0.556,
                    "recall_at_3": 0.741,
                    "recall_at_5": 0.8,
                    "recall_at_10": 0.852,
                    "recall_at_20": 0.902,
                    "precision_at_1": 0.556,
                    "precision_at_3": 0.247,
                    "precision_at_5": 0.16,
                    "precision_at_10": 0.0852,
                    "precision_at_20": 0.0451,
                    "mrr_at_1": 0.555,
                    "mrr_at_3": 0.638,
                    "mrr_at_5": 0.6515000000000001,
                    "mrr_at_10": 0.6584519841269842,
                    "mrr_at_20": 0.6618322837035686,
                    "main_score": 0.70601,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 627.7353746891022,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.89686,
                    "ndcg_at_3": 0.92625,
                    "ndcg_at_5": 0.93019,
                    "ndcg_at_10": 0.93278,
                    "ndcg_at_20": 0.93411,
                    "map_at_1": 0.89684,
                    "map_at_3": 0.9194,
                    "map_at_5": 0.92159,
                    "map_at_10": 0.92268,
                    "map_at_20": 0.92304,
                    "recall_at_1": 0.89684,
                    "recall_at_3": 0.94592,
                    "recall_at_5": 0.95545,
                    "recall_at_10": 0.96337,
                    "recall_at_20": 0.96863,
                    "precision_at_1": 0.89686,
                    "precision_at_3": 0.31531,
                    "precision_at_5": 0.19109,
                    "precision_at_10": 0.09634,
                    "precision_at_20": 0.04843,
                    "mrr_at_1": 0.8968649804061275,
                    "mrr_at_3": 0.9194201995012462,
                    "mrr_at_5": 0.9216111506946922,
                    "mrr_at_10": 0.9226997875209936,
                    "mrr_at_20": 0.9230674629506358,
                    "main_score": 0.93278,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 494.6521258354187,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.233,
                    "ndcg_at_3": 0.29072,
                    "ndcg_at_5": 0.3082,
                    "ndcg_at_10": 0.32813,
                    "ndcg_at_20": 0.34771,
                    "map_at_1": 0.233,
                    "map_at_3": 0.27617,
                    "map_at_5": 0.28597,
                    "map_at_10": 0.29413,
                    "map_at_20": 0.29942,
                    "recall_at_1": 0.233,
                    "recall_at_3": 0.333,
                    "recall_at_5": 0.375,
                    "recall_at_10": 0.437,
                    "recall_at_20": 0.515,
                    "precision_at_1": 0.233,
                    "precision_at_3": 0.111,
                    "precision_at_5": 0.075,
                    "precision_at_10": 0.0437,
                    "precision_at_20": 0.02575,
                    "mrr_at_1": 0.233,
                    "mrr_at_3": 0.2761666666666667,
                    "mrr_at_5": 0.28596666666666676,
                    "mrr_at_10": 0.2941261904761905,
                    "mrr_at_20": 0.2994163872032681,
                    "main_score": 0.32813,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 613.3135714530945,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.51333,
                    "ndcg_at_3": 0.57081,
                    "ndcg_at_5": 0.58796,
                    "ndcg_at_10": 0.61031,
                    "ndcg_at_20": 0.62627,
                    "map_at_1": 0.48883,
                    "map_at_3": 0.54801,
                    "map_at_5": 0.5599,
                    "map_at_10": 0.57083,
                    "map_at_20": 0.57598,
                    "recall_at_1": 0.48883,
                    "recall_at_3": 0.60889,
                    "recall_at_5": 0.65344,
                    "recall_at_10": 0.71633,
                    "recall_at_20": 0.77633,
                    "precision_at_1": 0.51333,
                    "precision_at_3": 0.22333,
                    "precision_at_5": 0.146,
                    "precision_at_10": 0.082,
                    "precision_at_20": 0.0445,
                    "mrr_at_1": 0.5133333333333333,
                    "mrr_at_3": 0.566111111111111,
                    "mrr_at_5": 0.5759444444444445,
                    "mrr_at_10": 0.583760582010582,
                    "mrr_at_20": 0.587586150977792,
                    "main_score": 0.61031,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 247.8372724056244,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.57144,
                    "ndcg_at_3": 0.64591,
                    "ndcg_at_5": 0.66415,
                    "ndcg_at_10": 0.68036,
                    "ndcg_at_20": 0.69031,
                    "map_at_1": 0.57129,
                    "map_at_3": 0.62781,
                    "map_at_5": 0.63796,
                    "map_at_10": 0.64472,
                    "map_at_20": 0.64747,
                    "recall_at_1": 0.57129,
                    "recall_at_3": 0.69793,
                    "recall_at_5": 0.74213,
                    "recall_at_10": 0.79201,
                    "recall_at_20": 0.83111,
                    "precision_at_1": 0.57144,
                    "precision_at_3": 0.23274,
                    "precision_at_5": 0.14851,
                    "precision_at_10": 0.07925,
                    "precision_at_20": 0.04159,
                    "mrr_at_1": 0.5714423200307969,
                    "mrr_at_3": 0.6279674066469921,
                    "mrr_at_5": 0.6381159373797064,
                    "mrr_at_10": 0.6448588120393016,
                    "mrr_at_20": 0.6476148362581926,
                    "main_score": 0.68036,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 639.3799922466278,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.89554,
                    "ndcg_at_3": 0.92815,
                    "ndcg_at_5": 0.93203,
                    "ndcg_at_10": 0.93477,
                    "ndcg_at_20": 0.93598,
                    "map_at_1": 0.89554,
                    "map_at_3": 0.92065,
                    "map_at_5": 0.92279,
                    "map_at_10": 0.92395,
                    "map_at_20": 0.92428,
                    "recall_at_1": 0.89554,
                    "recall_at_3": 0.94968,
                    "recall_at_5": 0.95909,
                    "recall_at_10": 0.96744,
                    "recall_at_20": 0.97224,
                    "precision_at_1": 0.89554,
                    "precision_at_3": 0.31656,
                    "precision_at_5": 0.19182,
                    "precision_at_10": 0.09674,
                    "precision_at_20": 0.04861,
                    "mrr_at_1": 0.8955363091272485,
                    "mrr_at_3": 0.9206232881782506,
                    "mrr_at_5": 0.9227707454289739,
                    "mrr_at_10": 0.9239317174793534,
                    "mrr_at_20": 0.9242717315759704,
                    "main_score": 0.93477,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 485.09934854507446,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.26389,
                    "ndcg_at_3": 0.2413,
                    "ndcg_at_5": 0.24914,
                    "ndcg_at_10": 0.27134,
                    "ndcg_at_20": 0.29727,
                    "map_at_1": 0.13246,
                    "map_at_3": 0.17929,
                    "map_at_5": 0.19443,
                    "map_at_10": 0.2085,
                    "map_at_20": 0.21709,
                    "recall_at_1": 0.13246,
                    "recall_at_3": 0.21445,
                    "recall_at_5": 0.25923,
                    "recall_at_10": 0.32922,
                    "recall_at_20": 0.40764,
                    "precision_at_1": 0.26389,
                    "precision_at_3": 0.15998,
                    "precision_at_5": 0.11914,
                    "precision_at_10": 0.07716,
                    "precision_at_20": 0.04954,
                    "mrr_at_1": 0.2638888888888889,
                    "mrr_at_3": 0.3173868312757203,
                    "mrr_at_5": 0.3288837448559672,
                    "mrr_at_10": 0.33980869096609834,
                    "mrr_at_20": 0.34697244595317495,
                    "main_score": 0.27134,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 1677.6232414245605,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.415,
                    "ndcg_at_3": 0.52234,
                    "ndcg_at_5": 0.54756,
                    "ndcg_at_10": 0.56822,
                    "ndcg_at_20": 0.5892,
                    "map_at_1": 0.415,
                    "map_at_3": 0.49617,
                    "map_at_5": 0.51022,
                    "map_at_10": 0.51872,
                    "map_at_20": 0.52447,
                    "recall_at_1": 0.415,
                    "recall_at_3": 0.598,
                    "recall_at_5": 0.659,
                    "recall_at_10": 0.723,
                    "recall_at_20": 0.806,
                    "precision_at_1": 0.415,
                    "precision_at_3": 0.19933,
                    "precision_at_5": 0.1318,
                    "precision_at_10": 0.0723,
                    "precision_at_20": 0.0403,
                    "mrr_at_1": 0.415,
                    "mrr_at_3": 0.49616666666666603,
                    "mrr_at_5": 0.510216666666666,
                    "mrr_at_10": 0.5187246031746029,
                    "mrr_at_20": 0.5244736785230587,
                    "main_score": 0.56822,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 1115.6646745204926,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.69098,
                    "ndcg_at_3": 0.76502,
                    "ndcg_at_5": 0.77814,
                    "ndcg_at_10": 0.78952,
                    "ndcg_at_20": 0.79719,
                    "map_at_1": 0.69059,
                    "map_at_3": 0.74753,
                    "map_at_5": 0.75487,
                    "map_at_10": 0.75962,
                    "map_at_20": 0.76173,
                    "recall_at_1": 0.69059,
                    "recall_at_3": 0.81504,
                    "recall_at_5": 0.84665,
                    "recall_at_10": 0.88161,
                    "recall_at_20": 0.91182,
                    "precision_at_1": 0.69098,
                    "precision_at_3": 0.27195,
                    "precision_at_5": 0.16956,
                    "precision_at_10": 0.08831,
                    "precision_at_20": 0.04568,
                    "mrr_at_1": 0.6910046386001997,
                    "mrr_at_3": 0.7477834537020634,
                    "mrr_at_5": 0.7550995243966844,
                    "mrr_at_10": 0.7598224130041091,
                    "mrr_at_20": 0.7619301993979071,
                    "main_score": 0.78952,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 2248.945936203003,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.73855,
                    "ndcg_at_3": 0.77629,
                    "ndcg_at_5": 0.78198,
                    "ndcg_at_10": 0.7878,
                    "map_at_1": 0.73855,
                    "map_at_3": 0.76751,
                    "map_at_5": 0.77069,
                    "map_at_10": 0.7731,
                    "recall_at_1": 0.73855,
                    "recall_at_3": 0.8015,
                    "recall_at_5": 0.8152,
                    "recall_at_10": 0.83315,
                    "precision_at_1": 0.73855,
                    "precision_at_3": 0.26717,
                    "precision_at_5": 0.16304,
                    "precision_at_10": 0.08331,
                    "mrr_at_1": 0.7386,
                    "mrr_at_3": 0.7675666666666698,
                    "mrr_at_5": 0.7707341666666714,
                    "mrr_at_10": 0.7731515873015916,
                    "main_score": 0.7878,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 4601.03973865509,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.21,
                    "ndcg_at_3": 0.16769,
                    "ndcg_at_5": 0.14351,
                    "ndcg_at_10": 0.17239,
                    "ndcg_at_20": 0.19599,
                    "map_at_1": 0.04258,
                    "map_at_3": 0.07427,
                    "map_at_5": 0.08705,
                    "map_at_10": 0.1009,
                    "map_at_20": 0.109,
                    "recall_at_1": 0.04258,
                    "recall_at_3": 0.09493,
                    "recall_at_5": 0.12553,
                    "recall_at_10": 0.17838,
                    "recall_at_20": 0.23372,
                    "precision_at_1": 0.21,
                    "precision_at_3": 0.156,
                    "precision_at_5": 0.1238,
                    "precision_at_10": 0.088,
                    "precision_at_20": 0.05765,
                    "mrr_at_1": 0.209,
                    "mrr_at_3": 0.2771666666666667,
                    "mrr_at_5": 0.2930166666666666,
                    "mrr_at_10": 0.3070623015873014,
                    "mrr_at_20": 0.3132782720289685,
                    "main_score": 0.17239,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 713.1863989830017,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "SCIDOCSChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.119,
                    "ndcg_at_3": 0.09915,
                    "ndcg_at_5": 0.08874,
                    "ndcg_at_10": 0.11135,
                    "ndcg_at_20": 0.1316,
                    "map_at_1": 0.02423,
                    "map_at_3": 0.04261,
                    "map_at_5": 0.05123,
                    "map_at_10": 0.06102,
                    "map_at_20": 0.06706,
                    "recall_at_1": 0.02423,
                    "recall_at_3": 0.05703,
                    "recall_at_5": 0.08053,
                    "recall_at_10": 0.12252,
                    "recall_at_20": 0.17053,
                    "precision_at_1": 0.119,
                    "precision_at_3": 0.09333,
                    "precision_at_5": 0.0792,
                    "precision_at_10": 0.0603,
                    "precision_at_20": 0.0419,
                    "mrr_at_1": 0.119,
                    "mrr_at_3": 0.1673333333333334,
                    "mrr_at_5": 0.18383333333333335,
                    "mrr_at_10": 0.1959047619047619,
                    "mrr_at_20": 0.20299193668388726,
                    "main_score": 0.11135,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 736.3269963264465,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "EcomRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.267,
                    "ndcg_at_3": 0.35583,
                    "ndcg_at_5": 0.38509,
                    "ndcg_at_10": 0.41009,
                    "ndcg_at_20": 0.43258,
                    "map_at_1": 0.267,
                    "map_at_3": 0.334,
                    "map_at_5": 0.35,
                    "map_at_10": 0.36018,
                    "map_at_20": 0.36635,
                    "recall_at_1": 0.267,
                    "recall_at_3": 0.419,
                    "recall_at_5": 0.491,
                    "recall_at_10": 0.569,
                    "recall_at_20": 0.658,
                    "precision_at_1": 0.267,
                    "precision_at_3": 0.13967,
                    "precision_at_5": 0.0982,
                    "precision_at_10": 0.0569,
                    "precision_at_20": 0.0329,
                    "mrr_at_1": 0.267,
                    "mrr_at_3": 0.3339999999999999,
                    "mrr_at_5": 0.34999999999999964,
                    "mrr_at_10": 0.3601845238095233,
                    "mrr_at_20": 0.36635441292024046,
                    "main_score": 0.41009,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 673.7314546108246,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.43963,
                    "ndcg_at_3": 0.40188,
                    "ndcg_at_5": 0.38719,
                    "ndcg_at_10": 0.35679,
                    "map_at_1": 0.05275,
                    "map_at_3": 0.0917,
                    "map_at_5": 0.11073,
                    "map_at_10": 0.13123,
                    "recall_at_1": 0.05275,
                    "recall_at_3": 0.10402,
                    "recall_at_5": 0.13589,
                    "recall_at_10": 0.17175,
                    "precision_at_1": 0.45511,
                    "precision_at_3": 0.38184,
                    "precision_at_5": 0.34118,
                    "precision_at_10": 0.2709,
                    "mrr_at_1": 0.4582043343653251,
                    "mrr_at_3": 0.5330237358101135,
                    "mrr_at_5": 0.5472652218782251,
                    "mrr_at_10": 0.5521426114305372,
                    "main_score": 0.35679,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 498.7772605419159,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.44104,
                    "ndcg_at_3": 0.5219,
                    "ndcg_at_5": 0.54339,
                    "ndcg_at_10": 0.56341,
                    "map_at_1": 0.44092,
                    "map_at_3": 0.50213,
                    "map_at_5": 0.51405,
                    "map_at_10": 0.52235,
                    "recall_at_1": 0.44092,
                    "recall_at_3": 0.57893,
                    "recall_at_5": 0.63113,
                    "recall_at_10": 0.69284,
                    "precision_at_1": 0.44104,
                    "precision_at_3": 0.19306,
                    "precision_at_5": 0.12629,
                    "precision_at_10": 0.06933,
                    "mrr_at_1": 0.44103682792249455,
                    "mrr_at_3": 0.5022242183155928,
                    "mrr_at_5": 0.5141531930365031,
                    "mrr_at_10": 0.522461613393395,
                    "main_score": 0.56341,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 386.5593626499176,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "ArguAnaChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.16501,
                    "ndcg_at_3": 0.26797,
                    "ndcg_at_5": 0.31713,
                    "ndcg_at_10": 0.3798,
                    "ndcg_at_20": 0.41593,
                    "map_at_1": 0.16501,
                    "map_at_3": 0.24218,
                    "map_at_5": 0.26942,
                    "map_at_10": 0.29496,
                    "map_at_20": 0.30514,
                    "recall_at_1": 0.16501,
                    "recall_at_3": 0.34282,
                    "recall_at_5": 0.4623,
                    "recall_at_10": 0.65789,
                    "recall_at_20": 0.79872,
                    "precision_at_1": 0.16501,
                    "precision_at_3": 0.11427,
                    "precision_at_5": 0.09246,
                    "precision_at_10": 0.06579,
                    "precision_at_20": 0.03994,
                    "mrr_at_1": 0.1721194879089616,
                    "mrr_at_3": 0.24561403508771928,
                    "mrr_at_5": 0.27182313892840143,
                    "mrr_at_10": 0.29743700467384654,
                    "mrr_at_20": 0.30772569431115876,
                    "main_score": 0.3798,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 236.13608503341675,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.86877,
                    "ndcg_at_3": 0.90834,
                    "ndcg_at_5": 0.91481,
                    "ndcg_at_10": 0.91947,
                    "ndcg_at_20": 0.92144,
                    "map_at_1": 0.86877,
                    "map_at_3": 0.89897,
                    "map_at_5": 0.90255,
                    "map_at_10": 0.90446,
                    "map_at_20": 0.90501,
                    "recall_at_1": 0.86877,
                    "recall_at_3": 0.93532,
                    "recall_at_5": 0.95104,
                    "recall_at_10": 0.96549,
                    "recall_at_20": 0.97324,
                    "precision_at_1": 0.86877,
                    "precision_at_3": 0.31178,
                    "precision_at_5": 0.19021,
                    "precision_at_10": 0.09655,
                    "precision_at_20": 0.04866,
                    "mrr_at_1": 0.8687655860349127,
                    "mrr_at_3": 0.8989728060800383,
                    "mrr_at_5": 0.902557594109966,
                    "mrr_at_10": 0.9044728385951251,
                    "mrr_at_20": 0.9050209905277452,
                    "main_score": 0.91947,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 260.23519802093506,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "0228b52cf27578f30900b9e5271d331663a030d7",
        "task_name": "SciFactChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.45,
                    "ndcg_at_3": 0.51355,
                    "ndcg_at_5": 0.53382,
                    "ndcg_at_10": 0.55811,
                    "ndcg_at_20": 0.57531,
                    "map_at_1": 0.43833,
                    "map_at_3": 0.49338,
                    "map_at_5": 0.50599,
                    "map_at_10": 0.5172,
                    "map_at_20": 0.52238,
                    "recall_at_1": 0.43833,
                    "recall_at_3": 0.55389,
                    "recall_at_5": 0.60089,
                    "recall_at_10": 0.67422,
                    "recall_at_20": 0.73933,
                    "precision_at_1": 0.45,
                    "precision_at_3": 0.19778,
                    "precision_at_5": 0.132,
                    "precision_at_10": 0.07533,
                    "precision_at_20": 0.04167,
                    "mrr_at_1": 0.45,
                    "mrr_at_3": 0.5072222222222222,
                    "mrr_at_5": 0.5175555555555555,
                    "mrr_at_10": 0.5256560846560846,
                    "mrr_at_20": 0.5298710003876412,
                    "main_score": 0.55811,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 169.3966565132141,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "VideoRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.558,
                    "ndcg_at_3": 0.66868,
                    "ndcg_at_5": 0.69118,
                    "ndcg_at_10": 0.70469,
                    "ndcg_at_20": 0.71635,
                    "map_at_1": 0.558,
                    "map_at_3": 0.6425,
                    "map_at_5": 0.6549,
                    "map_at_10": 0.66062,
                    "map_at_20": 0.66384,
                    "recall_at_1": 0.558,
                    "recall_at_3": 0.744,
                    "recall_at_5": 0.799,
                    "recall_at_10": 0.84,
                    "recall_at_20": 0.886,
                    "precision_at_1": 0.558,
                    "precision_at_3": 0.248,
                    "precision_at_5": 0.1598,
                    "precision_at_10": 0.084,
                    "precision_at_20": 0.0443,
                    "mrr_at_1": 0.557,
                    "mrr_at_3": 0.6420000000000001,
                    "mrr_at_5": 0.6544000000000003,
                    "mrr_at_10": 0.6601206349206351,
                    "mrr_at_20": 0.6633361955382079,
                    "main_score": 0.70469,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 4342.064614057541,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "MedicalRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.439,
                    "ndcg_at_3": 0.49112,
                    "ndcg_at_5": 0.49999,
                    "ndcg_at_10": 0.51715,
                    "map_at_1": 0.439,
                    "map_at_3": 0.47867,
                    "map_at_5": 0.48372,
                    "map_at_10": 0.49081,
                    "recall_at_1": 0.439,
                    "recall_at_3": 0.527,
                    "recall_at_5": 0.548,
                    "recall_at_10": 0.601,
                    "precision_at_1": 0.439,
                    "precision_at_3": 0.17567,
                    "precision_at_5": 0.1096,
                    "precision_at_10": 0.0601,
                    "mrr_at_1": 0.439,
                    "mrr_at_3": 0.4789999999999998,
                    "mrr_at_5": 0.4840499999999998,
                    "mrr_at_10": 0.49114563492063507,
                    "main_score": 0.51715,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 11658.130139112473,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalBooksZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.65424,
                    "ndcg_at_3": 0.74025,
                    "ndcg_at_5": 0.7594,
                    "ndcg_at_10": 0.77452,
                    "ndcg_at_20": 0.78312,
                    "map_at_1": 0.65392,
                    "map_at_3": 0.7193,
                    "map_at_5": 0.72994,
                    "map_at_10": 0.73629,
                    "map_at_20": 0.73868,
                    "recall_at_1": 0.65392,
                    "recall_at_3": 0.80039,
                    "recall_at_5": 0.84685,
                    "recall_at_10": 0.89312,
                    "recall_at_20": 0.92696,
                    "precision_at_1": 0.65424,
                    "precision_at_3": 0.26708,
                    "precision_at_5": 0.16958,
                    "precision_at_10": 0.08945,
                    "precision_at_20": 0.04644,
                    "mrr_at_1": 0.6542409854998075,
                    "mrr_at_3": 0.7195667051627455,
                    "mrr_at_5": 0.7302028529877244,
                    "mrr_at_10": 0.7365259751832661,
                    "mrr_at_20": 0.7388934475157752,
                    "main_score": 0.77452,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 341.0774564743042,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.31424,
                    "ndcg_at_3": 0.27598,
                    "ndcg_at_5": 0.2589,
                    "ndcg_at_10": 0.23978,
                    "map_at_1": 0.03654,
                    "map_at_3": 0.05744,
                    "map_at_5": 0.06753,
                    "map_at_10": 0.07818,
                    "recall_at_1": 0.03654,
                    "recall_at_3": 0.06714,
                    "recall_at_5": 0.0859,
                    "recall_at_10": 0.11469,
                    "precision_at_1": 0.32817,
                    "precision_at_3": 0.26006,
                    "precision_at_5": 0.22415,
                    "precision_at_10": 0.17864,
                    "mrr_at_1": 0.3281733746130031,
                    "mrr_at_3": 0.39525283797729605,
                    "mrr_at_5": 0.40670794633642926,
                    "mrr_at_10": 0.41848370927318285,
                    "main_score": 0.23978,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 147.39749240875244,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.73915,
                    "ndcg_at_3": 0.80057,
                    "ndcg_at_5": 0.81463,
                    "ndcg_at_10": 0.827,
                    "map_at_1": 0.7387,
                    "map_at_3": 0.78562,
                    "map_at_5": 0.79347,
                    "map_at_10": 0.79864,
                    "recall_at_1": 0.7387,
                    "recall_at_3": 0.84283,
                    "recall_at_5": 0.87692,
                    "recall_at_10": 0.91484,
                    "precision_at_1": 0.73915,
                    "precision_at_3": 0.28132,
                    "precision_at_5": 0.17575,
                    "precision_at_10": 0.09177,
                    "mrr_at_1": 0.73914953084448,
                    "mrr_at_3": 0.786204831303654,
                    "mrr_at_5": 0.7940626871631119,
                    "mrr_at_10": 0.7992549442749118,
                    "main_score": 0.827,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 324.8196220397949,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalLawEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.62754,
                    "ndcg_at_3": 0.72674,
                    "ndcg_at_5": 0.74688,
                    "ndcg_at_10": 0.76387,
                    "ndcg_at_20": 0.77333,
                    "map_at_1": 0.62626,
                    "map_at_3": 0.70227,
                    "map_at_5": 0.71355,
                    "map_at_10": 0.72074,
                    "map_at_20": 0.72342,
                    "recall_at_1": 0.62626,
                    "recall_at_3": 0.79543,
                    "recall_at_5": 0.844,
                    "recall_at_10": 0.89571,
                    "recall_at_20": 0.93235,
                    "precision_at_1": 0.62754,
                    "precision_at_3": 0.26632,
                    "precision_at_5": 0.1698,
                    "precision_at_10": 0.09039,
                    "precision_at_20": 0.04721,
                    "mrr_at_1": 0.6273928383754973,
                    "mrr_at_3": 0.7036633886344904,
                    "mrr_at_5": 0.7150063809023437,
                    "mrr_at_10": 0.7220302440471814,
                    "mrr_at_20": 0.7246057470119638,
                    "main_score": 0.76387,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 325.31023955345154,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.82795,
                    "ndcg_at_3": 0.88857,
                    "ndcg_at_5": 0.89715,
                    "ndcg_at_10": 0.90319,
                    "ndcg_at_20": 0.90608,
                    "map_at_1": 0.82739,
                    "map_at_3": 0.87436,
                    "map_at_5": 0.87917,
                    "map_at_10": 0.88172,
                    "map_at_20": 0.88254,
                    "recall_at_1": 0.82739,
                    "recall_at_3": 0.92909,
                    "recall_at_5": 0.94974,
                    "recall_at_10": 0.96809,
                    "recall_at_20": 0.97932,
                    "precision_at_1": 0.82795,
                    "precision_at_3": 0.31022,
                    "precision_at_5": 0.19035,
                    "precision_at_10": 0.09708,
                    "precision_at_20": 0.04914,
                    "mrr_at_1": 0.8279213153258955,
                    "mrr_at_3": 0.8745449207281152,
                    "mrr_at_5": 0.8793408690546017,
                    "mrr_at_10": 0.8818716271006295,
                    "mrr_at_20": 0.8826597096687059,
                    "main_score": 0.90319,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 480.382297039032,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalFinanceZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.69173,
                    "ndcg_at_3": 0.7531,
                    "ndcg_at_5": 0.76657,
                    "ndcg_at_10": 0.77899,
                    "ndcg_at_20": 0.78675,
                    "map_at_1": 0.69141,
                    "map_at_3": 0.7382,
                    "map_at_5": 0.74571,
                    "map_at_10": 0.75086,
                    "map_at_20": 0.75304,
                    "recall_at_1": 0.69141,
                    "recall_at_3": 0.79544,
                    "recall_at_5": 0.82808,
                    "recall_at_10": 0.86623,
                    "recall_at_20": 0.8965,
                    "precision_at_1": 0.69173,
                    "precision_at_3": 0.26547,
                    "precision_at_5": 0.1659,
                    "precision_at_10": 0.08686,
                    "precision_at_20": 0.045,
                    "mrr_at_1": 0.6916866506794564,
                    "mrr_at_3": 0.7386224353850271,
                    "mrr_at_5": 0.7461783906208426,
                    "mrr_at_10": 0.7513646543083048,
                    "mrr_at_20": 0.7535230713366652,
                    "main_score": 0.77899,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 309.26029753685,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.69654,
                    "ndcg_at_3": 0.754,
                    "ndcg_at_5": 0.76366,
                    "ndcg_at_10": 0.77272,
                    "ndcg_at_20": 0.77808,
                    "map_at_1": 0.69613,
                    "map_at_3": 0.74046,
                    "map_at_5": 0.74585,
                    "map_at_10": 0.74963,
                    "map_at_20": 0.75112,
                    "recall_at_1": 0.69613,
                    "recall_at_3": 0.79272,
                    "recall_at_5": 0.81601,
                    "recall_at_10": 0.84387,
                    "recall_at_20": 0.86489,
                    "precision_at_1": 0.69654,
                    "precision_at_3": 0.26454,
                    "precision_at_5": 0.16344,
                    "precision_at_10": 0.08454,
                    "precision_at_20": 0.04332,
                    "mrr_at_1": 0.6965942454492072,
                    "mrr_at_3": 0.7407369348208984,
                    "mrr_at_5": 0.7461274221961228,
                    "mrr_at_10": 0.7499213223163602,
                    "mrr_at_20": 0.7514586265874665,
                    "main_score": 0.77272,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 856.9974598884583,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.7675,
                    "ndcg_at_3": 0.7151,
                    "ndcg_at_5": 0.70392,
                    "ndcg_at_10": 0.73565,
                    "ndcg_at_20": 0.76319,
                    "map_at_1": 0.21271,
                    "map_at_3": 0.42846,
                    "map_at_5": 0.53781,
                    "map_at_10": 0.6269,
                    "map_at_20": 0.65362,
                    "recall_at_1": 0.21271,
                    "recall_at_3": 0.46491,
                    "recall_at_5": 0.61015,
                    "recall_at_10": 0.76079,
                    "recall_at_20": 0.83847,
                    "precision_at_1": 0.7675,
                    "precision_at_3": 0.63967,
                    "precision_at_5": 0.5427,
                    "precision_at_10": 0.35995,
                    "precision_at_20": 0.2044,
                    "mrr_at_1": 0.7675,
                    "mrr_at_3": 0.8315833333333328,
                    "mrr_at_5": 0.8370583333333331,
                    "mrr_at_10": 0.8396527777777774,
                    "mrr_at_20": 0.8406113970674143,
                    "main_score": 0.73565,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 3258.5621254444122,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.80665,
                    "ndcg_at_3": 0.86933,
                    "ndcg_at_5": 0.87838,
                    "ndcg_at_10": 0.88477,
                    "ndcg_at_20": 0.8886,
                    "map_at_1": 0.80609,
                    "map_at_3": 0.85463,
                    "map_at_5": 0.8597,
                    "map_at_10": 0.86238,
                    "map_at_20": 0.86347,
                    "recall_at_1": 0.80609,
                    "recall_at_3": 0.91113,
                    "recall_at_5": 0.93295,
                    "recall_at_10": 0.95246,
                    "recall_at_20": 0.96737,
                    "precision_at_1": 0.80665,
                    "precision_at_3": 0.30421,
                    "precision_at_5": 0.18699,
                    "precision_at_10": 0.0955,
                    "precision_at_20": 0.04853,
                    "mrr_at_1": 0.806705419529094,
                    "mrr_at_3": 0.8549654551504025,
                    "mrr_at_5": 0.860037089229439,
                    "mrr_at_10": 0.8626707087822082,
                    "mrr_at_20": 0.8637243759316771,
                    "main_score": 0.88477,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 440.83808064460754,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.71075,
                    "ndcg_at_3": 0.75134,
                    "ndcg_at_5": 0.7583,
                    "ndcg_at_10": 0.76488,
                    "map_at_1": 0.71075,
                    "map_at_3": 0.7418,
                    "map_at_5": 0.74568,
                    "map_at_10": 0.74843,
                    "recall_at_1": 0.71075,
                    "recall_at_3": 0.77875,
                    "recall_at_5": 0.7956,
                    "recall_at_10": 0.81575,
                    "precision_at_1": 0.71075,
                    "precision_at_3": 0.25958,
                    "precision_at_5": 0.15912,
                    "precision_at_10": 0.08157,
                    "mrr_at_1": 0.71065,
                    "mrr_at_3": 0.7417500000000037,
                    "mrr_at_5": 0.7456225000000051,
                    "mrr_at_10": 0.7483806547619086,
                    "main_score": 0.76488,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2654.7549788951874,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.53214,
                    "ndcg_at_3": 0.64155,
                    "ndcg_at_5": 0.66853,
                    "ndcg_at_10": 0.68896,
                    "ndcg_at_20": 0.70247,
                    "map_at_1": 0.53082,
                    "map_at_3": 0.61495,
                    "map_at_5": 0.63015,
                    "map_at_10": 0.63871,
                    "map_at_20": 0.64251,
                    "recall_at_1": 0.53082,
                    "recall_at_3": 0.71681,
                    "recall_at_5": 0.78214,
                    "recall_at_10": 0.8451,
                    "recall_at_20": 0.89779,
                    "precision_at_1": 0.53214,
                    "precision_at_3": 0.24025,
                    "precision_at_5": 0.15764,
                    "precision_at_10": 0.08525,
                    "precision_at_20": 0.04531,
                    "mrr_at_1": 0.5331928345626976,
                    "mrr_at_3": 0.6167896030909731,
                    "mrr_at_5": 0.6317527221636812,
                    "mrr_at_10": 0.6398690350745148,
                    "mrr_at_20": 0.6435306647161152,
                    "main_score": 0.68896,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2720.8388710021973,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "2e643e7363944af1c33a652d1c87320d0871c4e4",
        "task_name": "NarrativeQAChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.58899,
                    "ndcg_at_3": 0.6601,
                    "ndcg_at_5": 0.67727,
                    "ndcg_at_10": 0.69189,
                    "ndcg_at_20": 0.70286,
                    "map_at_1": 0.58899,
                    "map_at_3": 0.64299,
                    "map_at_5": 0.65254,
                    "map_at_10": 0.65858,
                    "map_at_20": 0.66161,
                    "recall_at_1": 0.58899,
                    "recall_at_3": 0.70948,
                    "recall_at_5": 0.75107,
                    "recall_at_10": 0.79625,
                    "recall_at_20": 0.83944,
                    "precision_at_1": 0.58899,
                    "precision_at_3": 0.23649,
                    "precision_at_5": 0.15021,
                    "precision_at_10": 0.07962,
                    "precision_at_20": 0.04197,
                    "mrr_at_1": 0.5889930851567681,
                    "mrr_at_3": 0.6429856966941335,
                    "mrr_at_5": 0.6525385999810498,
                    "mrr_at_10": 0.658580630319758,
                    "mrr_at_20": 0.6616095176698585,
                    "main_score": 0.69189,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 6626.834450960159,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalPaperEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.95983,
                    "ndcg_at_3": 0.9768,
                    "ndcg_at_5": 0.97858,
                    "ndcg_at_10": 0.97949,
                    "ndcg_at_20": 0.97992,
                    "map_at_1": 0.95979,
                    "map_at_3": 0.97298,
                    "map_at_5": 0.97398,
                    "map_at_10": 0.97437,
                    "map_at_20": 0.97449,
                    "recall_at_1": 0.95979,
                    "recall_at_3": 0.98766,
                    "recall_at_5": 0.99194,
                    "recall_at_10": 0.9947,
                    "recall_at_20": 0.99637,
                    "precision_at_1": 0.95983,
                    "precision_at_3": 0.32924,
                    "precision_at_5": 0.19841,
                    "precision_at_10": 0.09948,
                    "precision_at_20": 0.04983,
                    "mrr_at_1": 0.959832561453509,
                    "mrr_at_3": 0.97302873767961,
                    "mrr_at_5": 0.974003978149864,
                    "mrr_at_10": 0.9743878681979865,
                    "mrr_at_20": 0.9745109970737339,
                    "main_score": 0.97949,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 255.22276854515076,
        "kg_co2_emissions": null,
        "model_name": "maidalun1020/bce-embedding-base_v1",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "ec0fa4fe99da2ff19ca1214b7966684033a58814",
        "task_name": "NFCorpusChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.32508,
                    "ndcg_at_3": 0.2917,
                    "ndcg_at_5": 0.27165,
                    "ndcg_at_10": 0.24044,
                    "map_at_1": 0.03918,
                    "map_at_3": 0.06441,
                    "map_at_5": 0.07545,
                    "map_at_10": 0.08763,
                    "recall_at_1": 0.03918,
                    "recall_at_3": 0.07146,
                    "recall_at_5": 0.09094,
                    "recall_at_10": 0.11776,
                    "precision_at_1": 0.33437,
                    "precision_at_3": 0.27245,
                    "precision_at_5": 0.23282,
                    "precision_at_10": 0.17183,
                    "mrr_at_1": 0.33436532507739936,
                    "mrr_at_3": 0.39422084623323006,
                    "mrr_at_5": 0.40459236326109393,
                    "mrr_at_10": 0.4105214015430733,
                    "main_score": 0.24044,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 126.31220054626465,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalWikiZh2EnChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.63223,
                    "ndcg_at_3": 0.70605,
                    "ndcg_at_5": 0.72017,
                    "ndcg_at_10": 0.73395,
                    "ndcg_at_20": 0.74336,
                    "map_at_1": 0.63185,
                    "map_at_3": 0.68842,
                    "map_at_5": 0.6963,
                    "map_at_10": 0.70205,
                    "map_at_20": 0.70464,
                    "recall_at_1": 0.63185,
                    "recall_at_3": 0.75661,
                    "recall_at_5": 0.79074,
                    "recall_at_10": 0.83294,
                    "recall_at_20": 0.87013,
                    "precision_at_1": 0.63223,
                    "precision_at_3": 0.25252,
                    "precision_at_5": 0.15836,
                    "precision_at_10": 0.08342,
                    "precision_at_20": 0.04358,
                    "mrr_at_1": 0.6322294639187365,
                    "mrr_at_3": 0.6885972638130394,
                    "mrr_at_5": 0.6964946274440705,
                    "mrr_at_10": 0.7022259246211155,
                    "mrr_at_20": 0.7048147942880088,
                    "main_score": 0.73395,
                    "hf_subset": "default",
                    "languages": [
                        "zh-en"
                    ]
                }
            ]
        },
        "evaluation_time": 264.52944684028625,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.67439,
                    "ndcg_at_3": 0.76907,
                    "ndcg_at_5": 0.78787,
                    "ndcg_at_10": 0.80381,
                    "ndcg_at_20": 0.81175,
                    "map_at_1": 0.67176,
                    "map_at_3": 0.74579,
                    "map_at_5": 0.75622,
                    "map_at_10": 0.76322,
                    "map_at_20": 0.76537,
                    "recall_at_1": 0.67176,
                    "recall_at_3": 0.83377,
                    "recall_at_5": 0.87987,
                    "recall_at_10": 0.92782,
                    "recall_at_20": 0.95943,
                    "precision_at_1": 0.67439,
                    "precision_at_3": 0.27994,
                    "precision_at_5": 0.17745,
                    "precision_at_10": 0.09378,
                    "precision_at_20": 0.04847,
                    "mrr_at_1": 0.6765015806111696,
                    "mrr_at_3": 0.7493853178784686,
                    "mrr_at_5": 0.7597119775201968,
                    "mrr_at_10": 0.7660164417013734,
                    "mrr_at_20": 0.7681639285633798,
                    "main_score": 0.80381,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2170.3441667556763,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CrosslingualRetrievalQasEn2ZhChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.764,
                    "ndcg_at_3": 0.80084,
                    "ndcg_at_5": 0.80669,
                    "ndcg_at_10": 0.81197,
                    "map_at_1": 0.764,
                    "map_at_3": 0.79222,
                    "map_at_5": 0.79546,
                    "map_at_10": 0.79765,
                    "recall_at_1": 0.764,
                    "recall_at_3": 0.8256,
                    "recall_at_5": 0.8398,
                    "recall_at_10": 0.8561,
                    "precision_at_1": 0.764,
                    "precision_at_3": 0.2752,
                    "precision_at_5": 0.16796,
                    "precision_at_10": 0.08561,
                    "mrr_at_1": 0.76405,
                    "mrr_at_3": 0.7922416666666702,
                    "mrr_at_5": 0.7954891666666719,
                    "mrr_at_10": 0.7976735119047669,
                    "main_score": 0.81197,
                    "hf_subset": "default",
                    "languages": [
                        "en-zh"
                    ]
                }
            ]
        },
        "evaluation_time": 3181.57812166214,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "6e346642246bfb4928c560ee08640dc84d074e8c",
        "task_name": "LEMBWikimQARetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.91333,
                    "ndcg_at_3": 0.93813,
                    "ndcg_at_5": 0.93813,
                    "ndcg_at_10": 0.94456,
                    "ndcg_at_20": 0.94724,
                    "map_at_1": 0.91333,
                    "map_at_3": 0.93278,
                    "map_at_5": 0.93278,
                    "map_at_10": 0.93541,
                    "map_at_20": 0.93622,
                    "recall_at_1": 0.91333,
                    "recall_at_3": 0.95333,
                    "recall_at_5": 0.95333,
                    "recall_at_10": 0.97333,
                    "recall_at_20": 0.98333,
                    "precision_at_1": 0.91333,
                    "precision_at_3": 0.31778,
                    "precision_at_5": 0.19067,
                    "precision_at_10": 0.09733,
                    "precision_at_20": 0.04917,
                    "mrr_at_1": 0.9133333333333333,
                    "mrr_at_3": 0.9327777777777779,
                    "mrr_at_5": 0.9327777777777779,
                    "mrr_at_10": 0.9354060846560844,
                    "mrr_at_20": 0.9362204785954785,
                    "main_score": 0.94456,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 214.7522189617157,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.30783,
                    "ndcg_at_3": 0.30892,
                    "ndcg_at_5": 0.32709,
                    "ndcg_at_10": 0.35489,
                    "ndcg_at_20": 0.38141,
                    "map_at_1": 0.19549,
                    "map_at_3": 0.26002,
                    "map_at_5": 0.27893,
                    "map_at_10": 0.29481,
                    "map_at_20": 0.30411,
                    "recall_at_1": 0.19549,
                    "recall_at_3": 0.30777,
                    "recall_at_5": 0.3635,
                    "recall_at_10": 0.44545,
                    "recall_at_20": 0.53659,
                    "precision_at_1": 0.30783,
                    "precision_at_3": 0.17663,
                    "precision_at_5": 0.13008,
                    "precision_at_10": 0.0815,
                    "precision_at_20": 0.0494,
                    "mrr_at_1": 0.3078269567391848,
                    "mrr_at_3": 0.3591731266149869,
                    "mrr_at_5": 0.3718012836542473,
                    "mrr_at_10": 0.38234677717048315,
                    "mrr_at_20": 0.38818938791189916,
                    "main_score": 0.35489,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 2202.941522836685,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.28282,
                    "ndcg_at_3": 0.28632,
                    "ndcg_at_5": 0.30217,
                    "ndcg_at_10": 0.32705,
                    "ndcg_at_20": 0.35186,
                    "map_at_1": 0.17921,
                    "map_at_3": 0.23998,
                    "map_at_5": 0.25614,
                    "map_at_10": 0.27031,
                    "map_at_20": 0.27884,
                    "recall_at_1": 0.17921,
                    "recall_at_3": 0.28667,
                    "recall_at_5": 0.33718,
                    "recall_at_10": 0.4106,
                    "recall_at_20": 0.49538,
                    "precision_at_1": 0.28282,
                    "precision_at_3": 0.16437,
                    "precision_at_5": 0.11973,
                    "precision_at_10": 0.07464,
                    "precision_at_20": 0.04559,
                    "mrr_at_1": 0.2828207051762941,
                    "mrr_at_3": 0.33312494790364255,
                    "mrr_at_5": 0.3452654830374266,
                    "mrr_at_10": 0.355185125646491,
                    "mrr_at_20": 0.36078788732327444,
                    "main_score": 0.32705,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 4205.888690233231,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "27a168819829fe9bcd655c2df245fb19452e8e06",
        "task_name": "FiQA2018Chunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.33025,
                    "ndcg_at_3": 0.29246,
                    "ndcg_at_5": 0.30846,
                    "ndcg_at_10": 0.33187,
                    "ndcg_at_20": 0.35127,
                    "map_at_1": 0.15878,
                    "map_at_3": 0.22057,
                    "map_at_5": 0.24359,
                    "map_at_10": 0.25979,
                    "map_at_20": 0.26676,
                    "recall_at_1": 0.15878,
                    "recall_at_3": 0.26272,
                    "recall_at_5": 0.32651,
                    "recall_at_10": 0.39789,
                    "recall_at_20": 0.45794,
                    "precision_at_1": 0.33025,
                    "precision_at_3": 0.19393,
                    "precision_at_5": 0.14877,
                    "precision_at_10": 0.09398,
                    "precision_at_20": 0.05502,
                    "mrr_at_1": 0.33024691358024694,
                    "mrr_at_3": 0.38065843621399204,
                    "mrr_at_5": 0.39493312757201654,
                    "mrr_at_10": 0.4071134626690182,
                    "mrr_at_20": 0.41150277150843306,
                    "main_score": 0.33187,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 1138.9889607429504,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.87375,
                    "ndcg_at_3": 0.82951,
                    "ndcg_at_5": 0.81419,
                    "ndcg_at_10": 0.81315,
                    "ndcg_at_20": 0.83233,
                    "map_at_1": 0.26208,
                    "map_at_3": 0.51518,
                    "map_at_5": 0.63252,
                    "map_at_10": 0.73109,
                    "map_at_20": 0.75855,
                    "recall_at_1": 0.26208,
                    "recall_at_3": 0.53361,
                    "recall_at_5": 0.67026,
                    "recall_at_10": 0.80269,
                    "recall_at_20": 0.86589,
                    "precision_at_1": 0.87375,
                    "precision_at_3": 0.72665,
                    "precision_at_5": 0.60798,
                    "precision_at_10": 0.40501,
                    "precision_at_20": 0.22614,
                    "mrr_at_1": 0.8737506575486585,
                    "mrr_at_3": 0.8978242445496512,
                    "mrr_at_5": 0.9014736396048878,
                    "mrr_at_10": 0.9034261416297201,
                    "mrr_at_20": 0.9042007373211596,
                    "main_score": 0.81315,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 8888.843197345734,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "6e346642246bfb4928c560ee08640dc84d074e8c",
        "task_name": "LEMBWikimQARetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.94,
                    "ndcg_at_3": 0.95929,
                    "ndcg_at_5": 0.96072,
                    "ndcg_at_10": 0.96072,
                    "ndcg_at_20": 0.96072,
                    "map_at_1": 0.94,
                    "map_at_3": 0.95444,
                    "map_at_5": 0.95528,
                    "map_at_10": 0.95528,
                    "map_at_20": 0.95528,
                    "recall_at_1": 0.94,
                    "recall_at_3": 0.97333,
                    "recall_at_5": 0.97667,
                    "recall_at_10": 0.97667,
                    "recall_at_20": 0.97667,
                    "precision_at_1": 0.94,
                    "precision_at_3": 0.32444,
                    "precision_at_5": 0.19533,
                    "precision_at_10": 0.09767,
                    "precision_at_20": 0.04883,
                    "mrr_at_1": 0.94,
                    "mrr_at_3": 0.9522222222222221,
                    "mrr_at_5": 0.9530555555555554,
                    "mrr_at_10": 0.9536111111111111,
                    "mrr_at_20": 0.9536111111111111,
                    "main_score": 0.96072,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 515.128420829773,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CmedqaRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.26182,
                    "ndcg_at_3": 0.26223,
                    "ndcg_at_5": 0.27846,
                    "ndcg_at_10": 0.30097,
                    "ndcg_at_20": 0.32403,
                    "map_at_1": 0.16393,
                    "map_at_3": 0.21825,
                    "map_at_5": 0.23404,
                    "map_at_10": 0.24676,
                    "map_at_20": 0.25454,
                    "recall_at_1": 0.16393,
                    "recall_at_3": 0.26273,
                    "recall_at_5": 0.31318,
                    "recall_at_10": 0.37888,
                    "recall_at_20": 0.45732,
                    "precision_at_1": 0.26182,
                    "precision_at_3": 0.15112,
                    "precision_at_5": 0.11108,
                    "precision_at_10": 0.06942,
                    "precision_at_20": 0.0423,
                    "mrr_at_1": 0.26206551637909475,
                    "mrr_at_3": 0.30878552971576223,
                    "mrr_at_5": 0.3209260648495463,
                    "mrr_at_10": 0.33020913958648396,
                    "mrr_at_20": 0.33568327841612655,
                    "main_score": 0.30097,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 5109.14417386055,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.797,
                    "ndcg_at_3": 0.75498,
                    "ndcg_at_5": 0.745,
                    "ndcg_at_10": 0.78158,
                    "ndcg_at_20": 0.8041,
                    "map_at_1": 0.21922,
                    "map_at_3": 0.46171,
                    "map_at_5": 0.58377,
                    "map_at_10": 0.68414,
                    "map_at_20": 0.70876,
                    "recall_at_1": 0.21922,
                    "recall_at_3": 0.49595,
                    "recall_at_5": 0.65354,
                    "recall_at_10": 0.81121,
                    "recall_at_20": 0.87691,
                    "precision_at_1": 0.797,
                    "precision_at_3": 0.68117,
                    "precision_at_5": 0.5762,
                    "precision_at_10": 0.3853,
                    "precision_at_20": 0.21415,
                    "mrr_at_1": 0.797,
                    "mrr_at_3": 0.8540833333333331,
                    "mrr_at_5": 0.8588833333333332,
                    "mrr_at_10": 0.8610134920634919,
                    "mrr_at_20": 0.8617141145404298,
                    "main_score": 0.78158,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 5409.061585187912,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.65859,
                    "ndcg_at_3": 0.75016,
                    "ndcg_at_5": 0.77145,
                    "ndcg_at_10": 0.78277,
                    "ndcg_at_20": 0.79374,
                    "map_at_1": 0.65701,
                    "map_at_3": 0.72761,
                    "map_at_5": 0.73952,
                    "map_at_10": 0.74444,
                    "map_at_20": 0.74738,
                    "recall_at_1": 0.65701,
                    "recall_at_3": 0.81401,
                    "recall_at_5": 0.86538,
                    "recall_at_10": 0.89989,
                    "recall_at_20": 0.94362,
                    "precision_at_1": 0.65859,
                    "precision_at_3": 0.27257,
                    "precision_at_5": 0.17429,
                    "precision_at_10": 0.09094,
                    "precision_at_20": 0.04768,
                    "mrr_at_1": 0.6554267650158061,
                    "mrr_at_3": 0.727256761503337,
                    "mrr_at_5": 0.7390059711977524,
                    "mrr_at_10": 0.7432652583337519,
                    "mrr_at_20": 0.7461308658587368,
                    "main_score": 0.78277,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 5260.818122148514,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.81457,
                    "ndcg_at_3": 0.77675,
                    "ndcg_at_5": 0.76329,
                    "ndcg_at_10": 0.76588,
                    "ndcg_at_20": 0.78811,
                    "map_at_1": 0.23555,
                    "map_at_3": 0.46889,
                    "map_at_5": 0.57872,
                    "map_at_10": 0.67426,
                    "map_at_20": 0.7027,
                    "recall_at_1": 0.23555,
                    "recall_at_3": 0.49496,
                    "recall_at_5": 0.62904,
                    "recall_at_10": 0.76534,
                    "recall_at_20": 0.83541,
                    "precision_at_1": 0.81457,
                    "precision_at_3": 0.6859,
                    "precision_at_5": 0.57678,
                    "precision_at_10": 0.38855,
                    "precision_at_20": 0.21931,
                    "mrr_at_1": 0.8145712782745923,
                    "mrr_at_3": 0.853381261324449,
                    "mrr_at_5": 0.8586021976737419,
                    "mrr_at_10": 0.8612286000963035,
                    "mrr_at_20": 0.8622393979579575,
                    "main_score": 0.76588,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 15852.533648252487,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.8355,
                    "ndcg_at_3": 0.79404,
                    "ndcg_at_5": 0.78417,
                    "ndcg_at_10": 0.81263,
                    "ndcg_at_20": 0.83373,
                    "map_at_1": 0.2337,
                    "map_at_3": 0.49518,
                    "map_at_5": 0.62588,
                    "map_at_10": 0.72391,
                    "map_at_20": 0.74806,
                    "recall_at_1": 0.2337,
                    "recall_at_3": 0.52508,
                    "recall_at_5": 0.68848,
                    "recall_at_10": 0.83275,
                    "recall_at_20": 0.89647,
                    "precision_at_1": 0.8355,
                    "precision_at_3": 0.71567,
                    "precision_at_5": 0.6049,
                    "precision_at_10": 0.3957,
                    "precision_at_20": 0.21895,
                    "mrr_at_1": 0.8355,
                    "mrr_at_3": 0.880916666666666,
                    "mrr_at_5": 0.8846166666666664,
                    "mrr_at_10": 0.8860767857142853,
                    "mrr_at_20": 0.8866404449201465,
                    "main_score": 0.81263,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 4270.10711979866,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "CovidRetrievallChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.6765,
                    "ndcg_at_3": 0.75219,
                    "ndcg_at_5": 0.77586,
                    "ndcg_at_10": 0.79413,
                    "ndcg_at_20": 0.80161,
                    "map_at_1": 0.6736,
                    "map_at_3": 0.73323,
                    "map_at_5": 0.74674,
                    "map_at_10": 0.75453,
                    "map_at_20": 0.75654,
                    "recall_at_1": 0.6736,
                    "recall_at_3": 0.80479,
                    "recall_at_5": 0.8617,
                    "recall_at_10": 0.91728,
                    "recall_at_20": 0.94731,
                    "precision_at_1": 0.6765,
                    "precision_at_3": 0.27011,
                    "precision_at_5": 0.17387,
                    "precision_at_10": 0.09273,
                    "precision_at_20": 0.04789,
                    "mrr_at_1": 0.6775553213909379,
                    "mrr_at_3": 0.7363891815946614,
                    "mrr_at_5": 0.748823322795926,
                    "mrr_at_10": 0.7563604964289902,
                    "mrr_at_20": 0.7582880647126213,
                    "main_score": 0.79413,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 5613.721234321594,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "T2RetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.84583,
                    "ndcg_at_3": 0.80089,
                    "ndcg_at_5": 0.78571,
                    "ndcg_at_10": 0.78677,
                    "ndcg_at_20": 0.80811,
                    "map_at_1": 0.24953,
                    "map_at_3": 0.48975,
                    "map_at_5": 0.60199,
                    "map_at_10": 0.69887,
                    "map_at_20": 0.72754,
                    "recall_at_1": 0.24953,
                    "recall_at_3": 0.5111,
                    "recall_at_5": 0.64487,
                    "recall_at_10": 0.78019,
                    "recall_at_20": 0.84773,
                    "precision_at_1": 0.84583,
                    "precision_at_3": 0.70317,
                    "precision_at_5": 0.58946,
                    "precision_at_10": 0.39527,
                    "precision_at_20": 0.22253,
                    "mrr_at_1": 0.8458267578467473,
                    "mrr_at_3": 0.8763370156058223,
                    "mrr_at_5": 0.8804379274066317,
                    "mrr_at_10": 0.8828997165234704,
                    "mrr_at_20": 0.88369793865054,
                    "main_score": 0.78677,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 11133.221404075623,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "",
        "task_name": "DuRetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "dev": [
                {
                    "ndcg_at_1": 0.8575,
                    "ndcg_at_3": 0.80474,
                    "ndcg_at_5": 0.79137,
                    "ndcg_at_10": 0.81858,
                    "ndcg_at_20": 0.83956,
                    "map_at_1": 0.24377,
                    "map_at_3": 0.50462,
                    "map_at_5": 0.63413,
                    "map_at_10": 0.72939,
                    "map_at_20": 0.7541,
                    "recall_at_1": 0.24377,
                    "recall_at_3": 0.53201,
                    "recall_at_5": 0.68912,
                    "recall_at_10": 0.83388,
                    "recall_at_20": 0.89579,
                    "precision_at_1": 0.8575,
                    "precision_at_3": 0.71983,
                    "precision_at_5": 0.6057,
                    "precision_at_10": 0.3941,
                    "precision_at_20": 0.21848,
                    "mrr_at_1": 0.8575,
                    "mrr_at_3": 0.897666666666666,
                    "mrr_at_5": 0.9001166666666661,
                    "mrr_at_10": 0.90179742063492,
                    "mrr_at_20": 0.902324267785877,
                    "main_score": 0.81858,
                    "hf_subset": "default",
                    "languages": [
                        "zh"
                    ]
                }
            ]
        },
        "evaluation_time": 4552.490962505341,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "semantic_langchain",
        "chunk_size": -1,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "6e346642246bfb4928c560ee08640dc84d074e8c",
        "task_name": "LEMBWikimQARetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.93667,
                    "ndcg_at_3": 0.95385,
                    "ndcg_at_5": 0.95385,
                    "ndcg_at_10": 0.96054,
                    "ndcg_at_20": 0.96054,
                    "map_at_1": 0.93667,
                    "map_at_3": 0.94944,
                    "map_at_5": 0.94944,
                    "map_at_10": 0.95234,
                    "map_at_20": 0.95234,
                    "recall_at_1": 0.93667,
                    "recall_at_3": 0.96667,
                    "recall_at_5": 0.96667,
                    "recall_at_10": 0.98667,
                    "recall_at_20": 0.98667,
                    "precision_at_1": 0.93667,
                    "precision_at_3": 0.32222,
                    "precision_at_5": 0.19333,
                    "precision_at_10": 0.09867,
                    "precision_at_20": 0.04933,
                    "mrr_at_1": 0.9366666666666666,
                    "mrr_at_3": 0.9494444444444445,
                    "mrr_at_5": 0.9494444444444445,
                    "mrr_at_10": 0.9523373015873017,
                    "mrr_at_20": 0.9523373015873017,
                    "main_score": 0.96054,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 154.65594291687012,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "6e346642246bfb4928c560ee08640dc84d074e8c",
        "task_name": "LEMBWikimQARetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.32,
                    "ndcg_at_3": 0.44825,
                    "ndcg_at_5": 0.47752,
                    "ndcg_at_10": 0.50969,
                    "ndcg_at_20": 0.53398,
                    "map_at_1": 0.32,
                    "map_at_3": 0.41556,
                    "map_at_5": 0.43206,
                    "map_at_10": 0.44523,
                    "map_at_20": 0.45181,
                    "recall_at_1": 0.32,
                    "recall_at_3": 0.54333,
                    "recall_at_5": 0.61333,
                    "recall_at_10": 0.71333,
                    "recall_at_20": 0.81,
                    "precision_at_1": 0.32,
                    "precision_at_3": 0.18111,
                    "precision_at_5": 0.12267,
                    "precision_at_10": 0.07133,
                    "precision_at_20": 0.0405,
                    "mrr_at_1": 0.32,
                    "mrr_at_3": 0.41555555555555546,
                    "mrr_at_5": 0.4320555555555554,
                    "mrr_at_10": 0.4452261904761905,
                    "mrr_at_20": 0.45181111256304746,
                    "main_score": 0.50969,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 494.2591145038605,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "6e346642246bfb4928c560ee08640dc84d074e8c",
        "task_name": "LEMBWikimQARetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.28,
                    "ndcg_at_3": 0.40833,
                    "ndcg_at_5": 0.43573,
                    "ndcg_at_10": 0.46977,
                    "ndcg_at_20": 0.50197,
                    "map_at_1": 0.28,
                    "map_at_3": 0.37667,
                    "map_at_5": 0.39183,
                    "map_at_10": 0.40561,
                    "map_at_20": 0.41455,
                    "recall_at_1": 0.28,
                    "recall_at_3": 0.5,
                    "recall_at_5": 0.56667,
                    "recall_at_10": 0.67333,
                    "recall_at_20": 0.8,
                    "precision_at_1": 0.28,
                    "precision_at_3": 0.16667,
                    "precision_at_5": 0.11333,
                    "precision_at_10": 0.06733,
                    "precision_at_20": 0.04,
                    "mrr_at_1": 0.28,
                    "mrr_at_3": 0.3766666666666666,
                    "mrr_at_5": 0.39183333333333326,
                    "mrr_at_10": 0.4056137566137566,
                    "mrr_at_20": 0.4145521551461954,
                    "main_score": 0.46977,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 340.08345675468445,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "6e346642246bfb4928c560ee08640dc84d074e8c",
        "task_name": "LEMBWikimQARetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.95667,
                    "ndcg_at_3": 0.96675,
                    "ndcg_at_5": 0.96947,
                    "ndcg_at_10": 0.97043,
                    "map_at_1": 0.95667,
                    "map_at_3": 0.96444,
                    "map_at_5": 0.96594,
                    "map_at_10": 0.96628,
                    "recall_at_1": 0.95667,
                    "recall_at_3": 0.97333,
                    "recall_at_5": 0.98,
                    "recall_at_10": 0.98333,
                    "precision_at_1": 0.95667,
                    "precision_at_3": 0.32444,
                    "precision_at_5": 0.196,
                    "precision_at_10": 0.09833,
                    "mrr_at_1": 0.9566666666666667,
                    "mrr_at_3": 0.9644444444444443,
                    "mrr_at_5": 0.9659444444444444,
                    "mrr_at_10": 0.9662777777777778,
                    "main_score": 0.97043,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 155.03747749328613,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v2-base-zh",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "6e346642246bfb4928c560ee08640dc84d074e8c",
        "task_name": "LEMBWikimQARetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.62333,
                    "ndcg_at_3": 0.70686,
                    "ndcg_at_5": 0.72638,
                    "ndcg_at_10": 0.75105,
                    "ndcg_at_20": 0.75971,
                    "map_at_1": 0.62333,
                    "map_at_3": 0.68722,
                    "map_at_5": 0.69822,
                    "map_at_10": 0.70834,
                    "map_at_20": 0.71083,
                    "recall_at_1": 0.62333,
                    "recall_at_3": 0.76333,
                    "recall_at_5": 0.81,
                    "recall_at_10": 0.88667,
                    "recall_at_20": 0.92,
                    "precision_at_1": 0.62333,
                    "precision_at_3": 0.25444,
                    "precision_at_5": 0.162,
                    "precision_at_10": 0.08867,
                    "precision_at_20": 0.046,
                    "mrr_at_1": 0.6233333333333333,
                    "mrr_at_3": 0.6872222222222224,
                    "mrr_at_5": 0.6982222222222222,
                    "mrr_at_10": 0.7083386243386244,
                    "mrr_at_20": 0.7108337987548514,
                    "main_score": 0.75105,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 157.42635297775269,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 512,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "2e643e7363944af1c33a652d1c87320d0871c4e4",
        "task_name": "NarrativeQAChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.48205,
                    "ndcg_at_3": 0.56567,
                    "ndcg_at_5": 0.58401,
                    "ndcg_at_10": 0.60419,
                    "ndcg_at_20": 0.619,
                    "map_at_1": 0.48205,
                    "map_at_3": 0.54531,
                    "map_at_5": 0.55549,
                    "map_at_10": 0.56385,
                    "map_at_20": 0.5679,
                    "recall_at_1": 0.48205,
                    "recall_at_3": 0.62451,
                    "recall_at_5": 0.66903,
                    "recall_at_10": 0.73127,
                    "recall_at_20": 0.7899,
                    "precision_at_1": 0.48205,
                    "precision_at_3": 0.20817,
                    "precision_at_5": 0.13381,
                    "precision_at_10": 0.07313,
                    "precision_at_20": 0.0395,
                    "mrr_at_1": 0.4820498247608222,
                    "mrr_at_3": 0.5453095892141042,
                    "mrr_at_5": 0.5554876701082954,
                    "mrr_at_10": 0.5638493454279154,
                    "mrr_at_20": 0.5679037183452459,
                    "main_score": 0.60419,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 1948.4703681468964,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 1024,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "6e346642246bfb4928c560ee08640dc84d074e8c",
        "task_name": "LEMBWikimQARetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.65667,
                    "ndcg_at_3": 0.73143,
                    "ndcg_at_5": 0.75739,
                    "ndcg_at_10": 0.77156,
                    "map_at_1": 0.65667,
                    "map_at_3": 0.71444,
                    "map_at_5": 0.72878,
                    "map_at_10": 0.73471,
                    "recall_at_1": 0.65667,
                    "recall_at_3": 0.78,
                    "recall_at_5": 0.84333,
                    "recall_at_10": 0.88667,
                    "precision_at_1": 0.65667,
                    "precision_at_3": 0.26,
                    "precision_at_5": 0.16867,
                    "precision_at_10": 0.08867,
                    "mrr_at_1": 0.6566666666666666,
                    "mrr_at_3": 0.7144444444444444,
                    "mrr_at_5": 0.7287777777777777,
                    "mrr_at_10": 0.7347103174603173,
                    "main_score": 0.77156,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 76.23399949073792,
        "kg_co2_emissions": null,
        "model_name": "jinaai/jina-embeddings-v3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    },
    {
        "dataset_revision": "6e346642246bfb4928c560ee08640dc84d074e8c",
        "task_name": "LEMBWikimQARetrievalChunked",
        "mteb_version": "1.14.20",
        "scores": {
            "test": [
                {
                    "ndcg_at_1": 0.41,
                    "ndcg_at_3": 0.51274,
                    "ndcg_at_5": 0.54459,
                    "ndcg_at_10": 0.57631,
                    "map_at_1": 0.41,
                    "map_at_3": 0.48722,
                    "map_at_5": 0.50506,
                    "map_at_10": 0.5184,
                    "recall_at_1": 0.41,
                    "recall_at_3": 0.58667,
                    "recall_at_5": 0.66333,
                    "recall_at_10": 0.76,
                    "precision_at_1": 0.41,
                    "precision_at_3": 0.19556,
                    "precision_at_5": 0.13267,
                    "precision_at_10": 0.076,
                    "mrr_at_1": 0.41,
                    "mrr_at_3": 0.4872222222222221,
                    "mrr_at_5": 0.5050555555555555,
                    "mrr_at_10": 0.518404761904762,
                    "main_score": 0.57631,
                    "hf_subset": "default",
                    "languages": [
                        "eng-Latn"
                    ]
                }
            ]
        },
        "evaluation_time": 278.27001953125,
        "kg_co2_emissions": null,
        "model_name": "BAAI/bge-m3",
        "chunking_strategy": "late_chunking",
        "chunk_size": 256,
        "n_sentences": 5,
        "chunking_model": null
    }
]